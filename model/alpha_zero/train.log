已加载上次最终模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003338759997859597 time
recovery_state_mcts_prob spend 0.36635304099763744 time
state_batch spend 0.005230387003393844 time
mcts_probs_batch spend 0.014615424006478861 time
winner_batch spend 0.0002206009958172217 time
policy_value spend 1.0380554750008741 time
train_step spend 1.275707835011417 time
policy_value spend 0.2556674699881114 time
kl:19.01875,lr_multiplier:0.667,loss:2.983590841293335,entropy:3.6007375717163086,explained_var_old:0.988478184,explained_var_new:0.000000000
output spend 0.0013655210059368983 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006692298004054464 time
recovery_state_mcts_prob spend 0.39471018000040203 time
state_batch spend 0.006329169002128765 time
mcts_probs_batch spend 0.01693566500034649 time
winner_batch spend 0.0002897359954658896 time
policy_value spend 0.25051985899335705 time
train_step spend 0.7127514960011467 time
policy_value spend 0.2677899980044458 time
kl:22.97167,lr_multiplier:0.444,loss:8.637295722961426,entropy:5.527621746063232,explained_var_old:0.000000000,explained_var_new:0.000000000
output spend 0.0007729770004516467 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0033997310092672706 time
recovery_state_mcts_prob spend 0.2880589139967924 time
state_batch spend 0.002021727996179834 time
mcts_probs_batch spend 0.007175719001679681 time
winner_batch spend 0.00027277899789623916 time
policy_value spend 0.24075420000008307 time
train_step spend 0.7338964800001122 time
policy_value spend 0.255923824995989 time
kl:14.27112,lr_multiplier:0.296,loss:8.07992172241211,entropy:5.648537635803223,explained_var_old:0.000000000,explained_var_new:0.000000000
output spend 0.00018326799909118563 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007316168994293548 time
recovery_state_mcts_prob spend 0.40242884600593243 time
state_batch spend 0.00449859700165689 time
mcts_probs_batch spend 0.006884449991048314 time
winner_batch spend 0.0003097570006502792 time
policy_value spend 0.2440158030076418 time
train_step spend 0.7104017940000631 time
policy_value spend 0.24463609499798622 time
kl:0.28496,lr_multiplier:0.198,loss:7.5801496505737305,entropy:6.771634578704834,explained_var_old:0.000000000,explained_var_new:0.000000000
output spend 0.0002216949942521751 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007947292004246265 time
recovery_state_mcts_prob spend 0.6048652659956133 time
state_batch spend 0.0018563699995866045 time
mcts_probs_batch spend 0.005636973000946455 time
winner_batch spend 0.00031890199170447886 time
policy_value spend 0.2593053989985492 time
train_step spend 0.7294009800098138 time
policy_value spend 0.2484062349976739 time
kl:6.95788,lr_multiplier:0.132,loss:7.425226211547852,entropy:6.5075483322143555,explained_var_old:0.000000000,explained_var_new:0.000000000
output spend 0.0002946780005004257 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006627370996284299 time
recovery_state_mcts_prob spend 0.30568221300200094 time
state_batch spend 0.0036503169976640493 time
mcts_probs_batch spend 0.005848924003657885 time
winner_batch spend 0.0005589899956248701 time
policy_value spend 0.27678970400302205 time
train_step spend 0.7362895230035065 time
policy_value spend 0.28853505199367646 time
kl:1.36367,lr_multiplier:0.088,loss:7.275470733642578,entropy:6.418747901916504,explained_var_old:0.000000000,explained_var_new:0.000000000
output spend 0.0002998340060003102 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004785027005709708 time
recovery_state_mcts_prob spend 0.610536232998129 time
state_batch spend 0.004004436996183358 time
mcts_probs_batch spend 0.007807957008481026 time
winner_batch spend 0.0005495219957083464 time
policy_value spend 0.2612100200058194 time
train_step spend 0.8152362999971956 time
policy_value spend 0.2692746140091913 time
kl:0.13648,lr_multiplier:0.088,loss:7.199594974517822,entropy:6.443198204040527,explained_var_old:0.000000000,explained_var_new:0.000000000
output spend 0.0005731970013584942 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007835680997231975 time
recovery_state_mcts_prob spend 0.4036323239997728 time
state_batch spend 0.009345587008283474 time
mcts_probs_batch spend 0.025025442999321967 time
winner_batch spend 0.00032364200160373 time
policy_value spend 0.25203958799829707 time
train_step spend 0.708040539000649 time
policy_value spend 0.24128454399760813 time
train_step spend 0.7184531999955652 time
policy_value spend 0.24386207999486942 time
kl:0.22717,lr_multiplier:0.088,loss:7.067749500274658,entropy:6.497890472412109,explained_var_old:0.000000000,explained_var_new:0.000000000
output spend 0.0004488989943638444 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0035694359976332635 time
recovery_state_mcts_prob spend 0.4004971160029527 time
state_batch spend 0.001991070996155031 time
mcts_probs_batch spend 0.007214637007564306 time
winner_batch spend 0.000334679993102327 time
policy_value spend 0.24413418500625994 time
train_step spend 0.7087140509975143 time
policy_value spend 0.24709857600100804 time
kl:0.11077,lr_multiplier:0.088,loss:6.973015308380127,entropy:6.510040283203125,explained_var_old:0.000000060,explained_var_new:0.000024199
output spend 0.0001625459990464151 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006756019007298164 time
recovery_state_mcts_prob spend 0.4106234829960158 time
state_batch spend 0.003607071004807949 time
mcts_probs_batch spend 0.014594712993130088 time
winner_batch spend 0.0002981930010719225 time
policy_value spend 0.25531690499337856 time
train_step spend 0.7261397410038626 time
policy_value spend 0.24023429899534676 time
kl:0.12194,lr_multiplier:0.088,loss:6.933622360229492,entropy:6.476303577423096,explained_var_old:0.000007808,explained_var_new:0.000127256
output spend 0.0001711169898044318 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.017234771003131755 time
recovery_state_mcts_prob spend 0.41936337399238255 time
state_batch spend 0.003510113005177118 time
mcts_probs_batch spend 0.013053964998107404 time
winner_batch spend 0.0002957579999929294 time
policy_value spend 0.24659003999840934 time
train_step spend 0.72058877699601 time
policy_value spend 0.24546517299313564 time
kl:0.11841,lr_multiplier:0.088,loss:6.874228477478027,entropy:6.437322616577148,explained_var_old:0.000080824,explained_var_new:0.006993771
output spend 0.00018414101214148104 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005604168996796943 time
recovery_state_mcts_prob spend 0.3001178550039185 time
state_batch spend 0.004669910995289683 time
mcts_probs_batch spend 0.007146492003812455 time
winner_batch spend 0.00043673899199347943 time
policy_value spend 0.25796691099822056 time
train_step spend 0.7402072020049673 time
policy_value spend 0.25894403900019825 time
kl:0.14025,lr_multiplier:0.088,loss:6.811617374420166,entropy:6.397950172424316,explained_var_old:0.010660529,explained_var_new:0.013257563
output spend 0.00037757800600957125 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005106550990603864 time
recovery_state_mcts_prob spend 0.3760085190006066 time
state_batch spend 0.0172400209994521 time
mcts_probs_batch spend 0.03355775600357447 time
winner_batch spend 0.0008373169985134155 time
policy_value spend 0.2662433270015754 time
train_step spend 0.7175999999890337 time
policy_value spend 0.24754382700484712 time
kl:0.14808,lr_multiplier:0.088,loss:6.751485824584961,entropy:6.379910469055176,explained_var_old:0.010701120,explained_var_new:0.013625681
output spend 0.00017725200450513512 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004937649006024003 time
recovery_state_mcts_prob spend 0.379075056000147 time
state_batch spend 0.004370312992250547 time
mcts_probs_batch spend 0.008697605997440405 time
winner_batch spend 0.0004567440046230331 time
policy_value spend 0.2557632780080894 time
train_step spend 0.7741875069914386 time
policy_value spend 0.25808075700479094 time
kl:0.11318,lr_multiplier:0.088,loss:6.765353679656982,entropy:6.3596720695495605,explained_var_old:0.011693597,explained_var_new:0.021127939
output spend 0.0005772410077042878 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004203538992442191 time
recovery_state_mcts_prob spend 0.3106082000012975 time
state_batch spend 0.0021665560052497312 time
mcts_probs_batch spend 0.008809127990389243 time
winner_batch spend 0.00030248200346250087 time
policy_value spend 0.2671164229977876 time
train_step spend 0.7156059389963048 time
policy_value spend 0.24216297800012399 time
kl:0.08147,lr_multiplier:0.088,loss:6.570799827575684,entropy:6.36673641204834,explained_var_old:0.023830712,explained_var_new:0.067723572
output spend 0.00017096300143748522 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005231699993601069 time
recovery_state_mcts_prob spend 0.28409298999758903 time
state_batch spend 0.0019425390055403113 time
mcts_probs_batch spend 0.0069824069942114875 time
winner_batch spend 0.0003066890058107674 time
policy_value spend 0.259795905003557 time
train_step spend 0.7260525640012929 time
policy_value spend 0.25602036000054795 time
train_step spend 0.7240041439945344 time
policy_value spend 0.25879161700140685 time
kl:0.18991,lr_multiplier:0.088,loss:6.459829330444336,entropy:6.338066577911377,explained_var_old:0.068091750,explained_var_new:0.015599310
output spend 0.0003592849971028045 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.01932112898794003 time
recovery_state_mcts_prob spend 0.3869079230062198 time
state_batch spend 0.003525792999425903 time
mcts_probs_batch spend 0.00693335899268277 time
winner_batch spend 0.00031878000299911946 time
policy_value spend 0.26754451800661627 time
train_step spend 0.7891263299970888 time
policy_value spend 0.3036034690012457 time
train_step spend 0.8102189380006166 time
policy_value spend 0.2586730449984316 time
kl:0.08740,lr_multiplier:0.088,loss:6.2943806648254395,entropy:6.2733683586120605,explained_var_old:0.012948394,explained_var_new:0.132968724
output spend 0.00026503700064495206 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.008841244998620823 time
recovery_state_mcts_prob spend 0.4062659490009537 time
state_batch spend 0.0041808499954640865 time
mcts_probs_batch spend 0.010528619997785427 time
winner_batch spend 0.00032597300014458597 time
policy_value spend 0.24328980200516526 time
train_step spend 0.7112491660082014 time
policy_value spend 0.24060545899556018 time
train_step spend 0.707889052995597 time
policy_value spend 0.24507297300442588 time
train_step spend 0.7229311629926087 time
policy_value spend 0.2523960920079844 time
train_step spend 0.7219940340000903 time
policy_value spend 0.24818647200299893 time
train_step spend 0.721546512999339 time
policy_value spend 0.2461968599964166 time
kl:0.09026,lr_multiplier:0.088,loss:6.00699520111084,entropy:6.162449359893799,explained_var_old:0.119982719,explained_var_new:0.045352638
output spend 0.00035867400583811104 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0045936949900351465 time
recovery_state_mcts_prob spend 0.28730250299850013 time
state_batch spend 0.001934051004354842 time
mcts_probs_batch spend 0.008225302997743711 time
winner_batch spend 0.0003034570108866319 time
policy_value spend 0.2451388889894588 time
train_step spend 0.7076270370016573 time
policy_value spend 0.2418253369978629 time
train_step spend 0.7077343290002318 time
policy_value spend 0.24270735200843774 time
train_step spend 0.7061432860064087 time
policy_value spend 0.24257119999674615 time
train_step spend 0.7079828999994788 time
policy_value spend 0.25105202599661425 time
train_step spend 0.7132930779916933 time
policy_value spend 0.24195451600826345 time
kl:0.05080,lr_multiplier:0.088,loss:5.634354114532471,entropy:5.950112342834473,explained_var_old:0.036994338,explained_var_new:0.467304468
output spend 0.00017321699124295264 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0044506470003398135 time
recovery_state_mcts_prob spend 0.3088941070018336 time
state_batch spend 0.002320753992535174 time
mcts_probs_batch spend 0.0064732360042398795 time
winner_batch spend 0.0002808440040098503 time
policy_value spend 0.2417950200033374 time
train_step spend 0.7108828019991051 time
policy_value spend 0.24392766899836715 time
train_step spend 0.7084480320045259 time
policy_value spend 0.24015983499702998 time
train_step spend 0.7097343339992221 time
policy_value spend 0.2438145159976557 time
train_step spend 0.7627573109930381 time
policy_value spend 0.241409462003503 time
train_step spend 0.7099627260031411 time
policy_value spend 0.24040690199763048 time
kl:0.04509,lr_multiplier:0.088,loss:5.35993766784668,entropy:5.724818229675293,explained_var_old:0.433966875,explained_var_new:0.216264963
output spend 0.00018086099589709193 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004143060010392219 time
recovery_state_mcts_prob spend 0.31206222299078945 time
state_batch spend 0.00392682000529021 time
mcts_probs_batch spend 0.014876105997245759 time
winner_batch spend 0.0002912339987233281 time
policy_value spend 0.24694689000898506 time
train_step spend 0.733406876999652 time
policy_value spend 0.26040980000107083 time
train_step spend 0.7277293969964376 time
policy_value spend 0.24227323099330533 time
train_step spend 0.7613060919975396 time
policy_value spend 0.2768702659959672 time
train_step spend 0.7677802379912464 time
policy_value spend 0.3078604490001453 time
train_step spend 0.7624251309898682 time
policy_value spend 0.25626289000501856 time
kl:0.04044,lr_multiplier:0.088,loss:5.054744720458984,entropy:5.589705467224121,explained_var_old:0.220077276,explained_var_new:0.242465615
output spend 0.00018458400154486299 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00512666700524278 time
recovery_state_mcts_prob spend 0.28764230699744076 time
state_batch spend 0.0032154770015040413 time
mcts_probs_batch spend 0.006639434999669902 time
winner_batch spend 0.0002927169989561662 time
policy_value spend 0.2446579509996809 time
train_step spend 0.7109223770094104 time
policy_value spend 0.24554541699762922 time
train_step spend 0.7131936919904547 time
policy_value spend 0.24183796800207347 time
train_step spend 0.7131524220021674 time
policy_value spend 0.24075118500331882 time
train_step spend 0.7096382770105265 time
policy_value spend 0.2689505640009884 time
kl:0.08793,lr_multiplier:0.088,loss:4.843875408172607,entropy:5.435422897338867,explained_var_old:0.287713051,explained_var_new:0.498745561
output spend 0.0005499399994732812 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005875267990631983 time
recovery_state_mcts_prob spend 0.6306761190062389 time
state_batch spend 0.00664019699615892 time
mcts_probs_batch spend 0.022593265006435104 time
winner_batch spend 0.00038234199746511877 time
policy_value spend 0.2963469520036597 time
train_step spend 0.7994877269957215 time
policy_value spend 0.24315452000882942 time
train_step spend 0.7378936759923818 time
policy_value spend 0.2769673820002936 time
train_step spend 0.7954565580002964 time
policy_value spend 0.2863629149942426 time
train_step spend 0.7232096750085475 time
policy_value spend 0.2551406009879429 time
train_step spend 0.7848894030030351 time
policy_value spend 0.26342738699167967 time
kl:0.06059,lr_multiplier:0.088,loss:4.593817234039307,entropy:5.245562553405762,explained_var_old:0.441628098,explained_var_new:0.253951788
output spend 0.0010171799949603155 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.015981987002305686 time
recovery_state_mcts_prob spend 0.8854217859916389 time
state_batch spend 0.008387376001337543 time
mcts_probs_batch spend 0.028258885999093764 time
winner_batch spend 0.0005290830013109371 time
policy_value spend 0.30637439400015865 time
train_step spend 0.7595038720028242 time
policy_value spend 0.25981807700009085 time
train_step spend 0.7337412719934946 time
policy_value spend 0.2471324610087322 time
train_step spend 0.711155413009692 time
policy_value spend 0.2468624710018048 time
train_step spend 0.7826969739980996 time
policy_value spend 0.2903078630042728 time
train_step spend 0.8294718679971993 time
policy_value spend 0.2933497729973169 time
kl:0.04434,lr_multiplier:0.088,loss:4.418327331542969,entropy:5.231973648071289,explained_var_old:0.227865756,explained_var_new:0.131435096
output spend 0.0006413619994418696 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006787244987208396 time
recovery_state_mcts_prob spend 0.46693507200689055 time
state_batch spend 0.007930583000415936 time
mcts_probs_batch spend 0.01864146499428898 time
winner_batch spend 0.0007211080082925037 time
policy_value spend 0.25046307299635373 time
train_step spend 0.7294732890004525 time
policy_value spend 0.25333205600327346 time
train_step spend 0.7241741759935394 time
policy_value spend 0.24558583200268913 time
train_step spend 0.7154566440003691 time
policy_value spend 0.2421284449956147 time
train_step spend 0.7143072790058795 time
policy_value spend 0.2738060410047183 time
train_step spend 0.7358707529929234 time
policy_value spend 0.25404509500367567 time
kl:0.06888,lr_multiplier:0.088,loss:4.283369064331055,entropy:5.175264358520508,explained_var_old:0.068529248,explained_var_new:0.617193580
output spend 0.00041055900510400534 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006205137993674725 time
recovery_state_mcts_prob spend 0.35958793900499586 time
state_batch spend 0.0021876660030102357 time
mcts_probs_batch spend 0.004824492993066087 time
winner_batch spend 0.00028878101147711277 time
policy_value spend 0.2426614209980471 time
train_step spend 0.728601955997874 time
policy_value spend 0.2437496180064045 time
train_step spend 0.7121262879954884 time
policy_value spend 0.25418354899738915 time
train_step spend 0.729741068003932 time
policy_value spend 0.24276547999761533 time
train_step spend 0.7104565139889019 time
policy_value spend 0.24289992000558414 time
train_step spend 0.7091833839949686 time
policy_value spend 0.24107630700746085 time
kl:0.05757,lr_multiplier:0.088,loss:4.130481243133545,entropy:5.044987678527832,explained_var_old:0.572934985,explained_var_new:0.272847831
output spend 0.00028237899823579937 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004859110995312221 time
recovery_state_mcts_prob spend 0.28264427100657485 time
state_batch spend 0.0020806889951927587 time
mcts_probs_batch spend 0.005043682991527021 time
winner_batch spend 0.00029584400181192905 time
policy_value spend 0.24166713999875356 time
train_step spend 0.7311335760023212 time
policy_value spend 0.2443455989996437 time
train_step spend 0.7113352489977842 time
policy_value spend 0.24297078700328711 time
train_step spend 0.733558430991252 time
policy_value spend 0.24235369300004095 time
train_step spend 0.7116545009921538 time
policy_value spend 0.24243375399964862 time
train_step spend 0.7098759030050132 time
policy_value spend 0.24231973399582785 time
kl:0.07310,lr_multiplier:0.088,loss:4.032297611236572,entropy:4.9692912101745605,explained_var_old:0.310645759,explained_var_new:0.628981292
output spend 0.000190938008017838 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.010800371994264424 time
recovery_state_mcts_prob spend 0.4251434000034351 time
state_batch spend 0.002014077006606385 time
mcts_probs_batch spend 0.010436139986268245 time
winner_batch spend 0.00035524400300346315 time
policy_value spend 0.25375282899767626 time
train_step spend 0.7417707889981102 time
policy_value spend 0.24629392400674988 time
train_step spend 0.7587703140015947 time
policy_value spend 0.25001720000000205 time
train_step spend 0.8458940540003823 time
policy_value spend 0.27018857600342017 time
train_step spend 0.7797261320083635 time
policy_value spend 0.3169768569932785 time
train_step spend 0.7807901479973225 time
policy_value spend 0.24838461499894038 time
kl:0.06713,lr_multiplier:0.088,loss:3.9700849056243896,entropy:4.877583026885986,explained_var_old:0.608343601,explained_var_new:0.626201391
output spend 0.0003334459906909615 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.008156431998941116 time
recovery_state_mcts_prob spend 0.7195248350035399 time
state_batch spend 0.0021689319983124733 time
mcts_probs_batch spend 0.0052903189935022965 time
winner_batch spend 0.0003017670096596703 time
policy_value spend 0.24674698599847034 time
train_step spend 0.7246750399935991 time
policy_value spend 0.2482528490072582 time
train_step spend 0.717229932997725 time
policy_value spend 0.24227639799937606 time
train_step spend 0.710514016012894 time
policy_value spend 0.2410696890001418 time
train_step spend 0.7455118709913222 time
policy_value spend 0.25662083200586494 time
kl:0.08698,lr_multiplier:0.088,loss:3.973729372024536,entropy:4.9026665687561035,explained_var_old:0.610533416,explained_var_new:0.947309375
output spend 0.00017988499894272536 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004344818997196853 time
recovery_state_mcts_prob spend 0.2788779310067184 time
state_batch spend 0.003452706994721666 time
mcts_probs_batch spend 0.007415091007715091 time
winner_batch spend 0.00031164799293037504 time
policy_value spend 0.24495403999753762 time
train_step spend 0.7099373559904052 time
policy_value spend 0.24500176499714144 time
train_step spend 0.7071316499932436 time
policy_value spend 0.240562217994011 time
train_step spend 0.7143619030102855 time
policy_value spend 0.26045143300143536 time
train_step spend 0.770738456005347 time
policy_value spend 0.27332185399427544 time
train_step spend 0.7468575030070497 time
policy_value spend 0.243988714995794 time
kl:0.06296,lr_multiplier:0.088,loss:3.8967626094818115,entropy:4.883401393890381,explained_var_old:0.943918884,explained_var_new:0.920777440
output spend 0.00024267799744848162 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005431855999631807 time
recovery_state_mcts_prob spend 0.40722590999212116 time
state_batch spend 0.003565268008969724 time
mcts_probs_batch spend 0.01153971599705983 time
winner_batch spend 0.0002918779937317595 time
policy_value spend 0.24811727501219139 time
train_step spend 0.7123954140115529 time
policy_value spend 0.24518023600103334 time
train_step spend 0.7201457629998913 time
policy_value spend 0.24833582500286866 time
train_step spend 0.7120223850070033 time
policy_value spend 0.24457825100398622 time
train_step spend 0.7065390369971283 time
policy_value spend 0.247382079003728 time
train_step spend 0.715667009993922 time
policy_value spend 0.24264975100231823 time
kl:0.06030,lr_multiplier:0.088,loss:3.88462233543396,entropy:4.779512882232666,explained_var_old:0.903050184,explained_var_new:0.929121137
output spend 0.0001730899966787547 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0038987989973975345 time
recovery_state_mcts_prob spend 0.28742678499838803 time
state_batch spend 0.005843780003488064 time
mcts_probs_batch spend 0.010534082000958733 time
winner_batch spend 0.000399918993934989 time
policy_value spend 0.24680168500344735 time
train_step spend 0.7155495309998514 time
policy_value spend 0.24622125799942296 time
train_step spend 0.7085176179971313 time
policy_value spend 0.2424467880045995 time
train_step spend 0.7074139460019069 time
policy_value spend 0.2410545979946619 time
train_step spend 0.7083148379897466 time
policy_value spend 0.26912352500949055 time
train_step spend 0.7162193849944742 time
policy_value spend 0.2559369950031396 time
kl:0.06183,lr_multiplier:0.088,loss:3.781507968902588,entropy:4.749922752380371,explained_var_old:0.914357245,explained_var_new:0.942789972
output spend 0.000497592001920566 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004727485007606447 time
recovery_state_mcts_prob spend 0.3228428619913757 time
state_batch spend 0.005662703013513237 time
mcts_probs_batch spend 0.00897472898941487 time
winner_batch spend 0.0003705460112541914 time
policy_value spend 0.2469904079916887 time
train_step spend 0.7119009599991841 time
policy_value spend 0.24246034200768918 time
train_step spend 0.7106564799905755 time
policy_value spend 0.24322641000617296 time
train_step spend 0.7083885869942605 time
policy_value spend 0.2632824660104234 time
train_step spend 0.7124765440094052 time
policy_value spend 0.24245229199004825 time
train_step spend 0.708001131992205 time
policy_value spend 0.24238201399566606 time
kl:0.06889,lr_multiplier:0.088,loss:3.80965518951416,entropy:4.698191165924072,explained_var_old:0.919934630,explained_var_new:0.935569525
output spend 0.00018187800014857203 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005062101990915835 time
recovery_state_mcts_prob spend 0.2966752140055178 time
state_batch spend 0.001994574995478615 time
mcts_probs_batch spend 0.009904042002744973 time
winner_batch spend 0.00029138200625311583 time
policy_value spend 0.2480152199859731 time
train_step spend 0.7093437750008889 time
policy_value spend 0.2423006819881266 time
train_step spend 0.7095936019904912 time
policy_value spend 0.2412704529997427 time
train_step spend 0.7088823090016376 time
policy_value spend 0.2405960090109147 time
train_step spend 0.7134350279957289 time
policy_value spend 0.24194705599802546 time
train_step spend 0.7130730929929996 time
policy_value spend 0.2430651710019447 time
kl:0.07360,lr_multiplier:0.088,loss:3.6867969036102295,entropy:4.646876811981201,explained_var_old:0.959415913,explained_var_new:0.912740111
output spend 0.00019282799621578306 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0040705779974814504 time
recovery_state_mcts_prob spend 0.3629177440016065 time
state_batch spend 0.004205267992801964 time
mcts_probs_batch spend 0.007339531002799049 time
winner_batch spend 0.00028357600967865437 time
policy_value spend 0.24321819499891717 time
train_step spend 0.7083839740080293 time
policy_value spend 0.24599622099776752 time
train_step spend 0.7214896380028222 time
policy_value spend 0.24347686099645216 time
train_step spend 0.7110782800009474 time
policy_value spend 0.2420821080013411 time
train_step spend 0.7173481899953913 time
policy_value spend 0.24554518800869118 time
train_step spend 0.7193486959877191 time
policy_value spend 0.24691126801189966 time
kl:0.07096,lr_multiplier:0.088,loss:3.6065196990966797,entropy:4.607863426208496,explained_var_old:0.899535000,explained_var_new:0.944309056
output spend 0.0002833239996107295 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005879018004634418 time
recovery_state_mcts_prob spend 0.317968828996527 time
state_batch spend 0.002134206995833665 time
mcts_probs_batch spend 0.007443195005180314 time
winner_batch spend 0.00030212900310289115 time
policy_value spend 0.26976438298879657 time
train_step spend 0.7161053660092875 time
policy_value spend 0.24454446499294136 time
train_step spend 0.717605255995295 time
policy_value spend 0.2526990559999831 time
train_step spend 0.7123166390083497 time
policy_value spend 0.2467595249909209 time
train_step spend 0.7210252270015189 time
policy_value spend 0.2693756749940803 time
train_step spend 0.7165226790093584 time
policy_value spend 0.24073269599466585 time
kl:0.06757,lr_multiplier:0.088,loss:3.6069226264953613,entropy:4.497331619262695,explained_var_old:0.908172965,explained_var_new:0.599056721
output spend 0.00016592899919487536 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005526655993890017 time
recovery_state_mcts_prob spend 0.3042844320007134 time
state_batch spend 0.0032042940001701936 time
mcts_probs_batch spend 0.008617618004791439 time
winner_batch spend 0.00028861699684057385 time
policy_value spend 0.24659395900380332 time
train_step spend 0.7101480530109257 time
policy_value spend 0.24192064099770505 time
train_step spend 0.7138727310084505 time
policy_value spend 0.24280274000193458 time
train_step spend 0.7192114839999704 time
policy_value spend 0.24149429899989627 time
train_step spend 0.7085899800003972 time
policy_value spend 0.2419446129933931 time
train_step spend 0.7096778160048416 time
policy_value spend 0.2411777939996682 time
kl:0.08887,lr_multiplier:0.088,loss:3.6151981353759766,entropy:4.505618095397949,explained_var_old:0.621889353,explained_var_new:0.771585584
output spend 0.0001745750050758943 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004774753004312515 time
recovery_state_mcts_prob spend 0.28590618999442086 time
state_batch spend 0.003547334999893792 time
mcts_probs_batch spend 0.007778123996104114 time
winner_batch spend 0.0002903560089180246 time
policy_value spend 0.24298609398829285 time
train_step spend 0.7081858250021469 time
policy_value spend 0.24421468299988192 time
train_step spend 0.7140070400055265 time
policy_value spend 0.24312993900093716 time
train_step spend 0.7078794920089422 time
policy_value spend 0.2428196359978756 time
train_step spend 0.7076658650039462 time
policy_value spend 0.242390326995519 time
train_step spend 0.7148317760002101 time
policy_value spend 0.25518905599892605 time
kl:0.07895,lr_multiplier:0.088,loss:3.532952070236206,entropy:4.480165481567383,explained_var_old:0.759138703,explained_var_new:0.958838165
output spend 0.00022832599643152207 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00469483899360057 time
recovery_state_mcts_prob spend 0.302949154007365 time
state_batch spend 0.0043539979960769415 time
mcts_probs_batch spend 0.007295535004232079 time
winner_batch spend 0.0003018080024048686 time
policy_value spend 0.24202692200196907 time
train_step spend 0.7075573570036795 time
policy_value spend 0.2634299600031227 time
train_step spend 0.7098486609902466 time
policy_value spend 0.2415899059997173 time
train_step spend 0.7076464359997772 time
policy_value spend 0.26147725200280547 time
train_step spend 0.7148088990070391 time
policy_value spend 0.2416255319985794 time
train_step spend 0.7079660119925393 time
policy_value spend 0.2450541889993474 time
kl:0.09473,lr_multiplier:0.088,loss:3.4924981594085693,entropy:4.417078495025635,explained_var_old:0.955847323,explained_var_new:0.938202143
output spend 0.00046503799967467785 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005123376991832629 time
recovery_state_mcts_prob spend 0.3691966620099265 time
state_batch spend 0.0026548919995548204 time
mcts_probs_batch spend 0.005204969987971708 time
winner_batch spend 0.00033900700509548187 time
policy_value spend 0.24464648899447639 time
train_step spend 0.7128945660078898 time
policy_value spend 0.2441676359885605 time
train_step spend 0.7107224389910698 time
policy_value spend 0.24252002099819947 time
train_step spend 0.7077686090051429 time
policy_value spend 0.24566287400375586 time
kl:0.09913,lr_multiplier:0.088,loss:3.5798912048339844,entropy:4.446161270141602,explained_var_old:0.921270788,explained_var_new:0.978296459
output spend 0.00024136599677149206 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0068980360083514825 time
recovery_state_mcts_prob spend 0.343824894996942 time
state_batch spend 0.0020058090012753382 time
mcts_probs_batch spend 0.007983200994203798 time
winner_batch spend 0.0003449770010774955 time
policy_value spend 0.24323757899401244 time
train_step spend 0.7227174190047663 time
policy_value spend 0.24184698400495108 time
train_step spend 0.7186162909929408 time
policy_value spend 0.24696272899745964 time
train_step spend 0.7144490630016662 time
policy_value spend 0.2412134309997782 time
kl:0.09801,lr_multiplier:0.088,loss:3.634800910949707,entropy:4.436548709869385,explained_var_old:0.959618568,explained_var_new:0.955539465
output spend 0.00020709499949589372 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007444200993631966 time
recovery_state_mcts_prob spend 0.3319751270028064 time
state_batch spend 0.0022128819982754067 time
mcts_probs_batch spend 0.007358660994214006 time
winner_batch spend 0.000289807008812204 time
policy_value spend 0.2649592259986093 time
train_step spend 0.7606506979936967 time
policy_value spend 0.2947630870039575 time
train_step spend 0.7466001360007795 time
policy_value spend 0.2824646499939263 time
train_step spend 0.7760203670040937 time
policy_value spend 0.3005650849954691 time
kl:0.08505,lr_multiplier:0.088,loss:3.5241544246673584,entropy:4.341945648193359,explained_var_old:0.948014438,explained_var_new:0.929722726
output spend 0.0004783460026374087 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.018109989003278315 time
recovery_state_mcts_prob spend 1.1749324720003642 time
state_batch spend 0.0026580499979900196 time
mcts_probs_batch spend 0.014396872007637285 time
winner_batch spend 0.00033026799792423844 time
policy_value spend 0.4708194589911727 time
train_step spend 0.7190663630026393 time
policy_value spend 0.2568382199970074 time
train_step spend 0.7194706139998743 time
policy_value spend 0.2422024639963638 time
train_step spend 0.7174915619980311 time
policy_value spend 0.2423370350006735 time
kl:0.09515,lr_multiplier:0.088,loss:3.5696451663970947,entropy:4.450455188751221,explained_var_old:0.937874019,explained_var_new:0.528110981
output spend 0.00017894500342663378 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004392253002151847 time
recovery_state_mcts_prob spend 0.49525563399947714 time
state_batch spend 0.024416144005954266 time
mcts_probs_batch spend 0.023522707997472025 time
winner_batch spend 0.0008982849976746365 time
policy_value spend 0.3000093150039902 time
train_step spend 0.7901772650075145 time
policy_value spend 0.3212775949941715 time
train_step spend 0.7776619310025126 time
policy_value spend 0.2551477600063663 time
kl:0.12690,lr_multiplier:0.088,loss:3.454305648803711,entropy:4.367248058319092,explained_var_old:0.463190854,explained_var_new:0.903611064
output spend 0.0001688030024524778 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.01916595500370022 time
recovery_state_mcts_prob spend 1.2911586109985365 time
state_batch spend 0.005560420002439059 time
mcts_probs_batch spend 0.009479088999796659 time
winner_batch spend 0.00043327099410817027 time
policy_value spend 0.4034487099997932 time
train_step spend 0.770553131995257 time
policy_value spend 0.260669149007299 time
train_step spend 0.7231753629894229 time
policy_value spend 0.2824498390109511 time
train_step spend 0.7672793539968552 time
policy_value spend 0.2531287279998651 time
kl:0.08190,lr_multiplier:0.088,loss:3.526639223098755,entropy:4.32985782623291,explained_var_old:0.897293448,explained_var_new:0.973007262
output spend 0.00018153600103687495 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.01231028100301046 time
recovery_state_mcts_prob spend 0.44232970698794816 time
state_batch spend 0.0021012050128774717 time
mcts_probs_batch spend 0.008234514985815622 time
winner_batch spend 0.00030618700839113444 time
policy_value spend 0.24626749800518155 time
train_step spend 0.7145688489981694 time
policy_value spend 0.24370850900595542 time
train_step spend 0.7463388440082781 time
policy_value spend 0.2702880129945697 time
kl:0.09565,lr_multiplier:0.088,loss:3.5117926597595215,entropy:4.432363510131836,explained_var_old:0.961140633,explained_var_new:0.815259457
output spend 0.00036232199636287987 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.014923392998753116 time
recovery_state_mcts_prob spend 0.6954638340102974 time
state_batch spend 0.003967800992541015 time
mcts_probs_batch spend 0.016481861006468534 time
winner_batch spend 0.000347031993442215 time
policy_value spend 0.266113810997922 time
train_step spend 0.7326069449918577 time
policy_value spend 0.24752733900095336 time
train_step spend 0.7194554500019876 time
policy_value spend 0.24273648799862713 time
kl:0.10290,lr_multiplier:0.088,loss:3.513277053833008,entropy:4.335596561431885,explained_var_old:0.811660886,explained_var_new:0.345746279
output spend 0.00017040599777828902 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004507563004153781 time
recovery_state_mcts_prob spend 0.32990957600122783 time
state_batch spend 0.004165612001088448 time
mcts_probs_batch spend 0.0069685339985881 time
winner_batch spend 0.000287282993667759 time
policy_value spend 0.2486397230095463 time
train_step spend 0.7185201020038221 time
policy_value spend 0.245114803998149 time
kl:0.11481,lr_multiplier:0.088,loss:3.5677952766418457,entropy:4.327023506164551,explained_var_old:0.304839909,explained_var_new:0.885387957
output spend 0.000170667000929825 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00520976800180506 time
recovery_state_mcts_prob spend 0.30107527200016193 time
state_batch spend 0.003540199002600275 time
mcts_probs_batch spend 0.008118212994304486 time
winner_batch spend 0.00031559499620925635 time
policy_value spend 0.2514582620060537 time
train_step spend 0.7230660250061192 time
policy_value spend 0.25759675599692855 time
kl:0.15232,lr_multiplier:0.088,loss:3.5159294605255127,entropy:4.350159645080566,explained_var_old:0.867406130,explained_var_new:0.670256257
output spend 0.0006466990016633645 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007613626992679201 time
recovery_state_mcts_prob spend 0.3231123430014122 time
state_batch spend 0.003292466004495509 time
mcts_probs_batch spend 0.009520573003101163 time
winner_batch spend 0.000481506998767145 time
policy_value spend 0.24744449199351948 time
train_step spend 0.7205603220063495 time
policy_value spend 0.24773600698972587 time
kl:0.20233,lr_multiplier:0.088,loss:3.6276588439941406,entropy:4.284807205200195,explained_var_old:0.553817511,explained_var_new:0.939228535
output spend 0.00022205400455277413 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004935556004056707 time
recovery_state_mcts_prob spend 0.3423623369890265 time
state_batch spend 0.0032621280115563422 time
mcts_probs_batch spend 0.019284699999843724 time
winner_batch spend 0.000490663995151408 time
policy_value spend 0.24700707499869168 time
train_step spend 0.7123288659931859 time
policy_value spend 0.26269178099755663 time
kl:0.10364,lr_multiplier:0.088,loss:3.558777093887329,entropy:4.305552959442139,explained_var_old:0.958461881,explained_var_new:0.372774363
output spend 0.00042047300667036325 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006035343001713045 time
recovery_state_mcts_prob spend 0.5186501310090534 time
state_batch spend 0.0031833690009079874 time
mcts_probs_batch spend 0.013240227999631315 time
winner_batch spend 0.0011371479922672734 time
policy_value spend 0.2560689870006172 time
train_step spend 0.7201253989915131 time
policy_value spend 0.24217008199775591 time
train_step spend 0.7080338160012616 time
policy_value spend 0.24325914699875284 time
kl:0.19834,lr_multiplier:0.088,loss:3.557718276977539,entropy:4.3962812423706055,explained_var_old:0.280664682,explained_var_new:0.749491811
output spend 0.00017815199680626392 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005627698003081605 time
recovery_state_mcts_prob spend 0.2916606679937104 time
state_batch spend 0.001988547999644652 time
mcts_probs_batch spend 0.006543005001731217 time
winner_batch spend 0.0002954880037577823 time
policy_value spend 0.24671933299396187 time
train_step spend 0.7095556109998142 time
policy_value spend 0.2469587829982629 time
train_step spend 0.7211239799944451 time
policy_value spend 0.265044037005282 time
kl:0.15733,lr_multiplier:0.088,loss:3.4350991249084473,entropy:4.2833967208862305,explained_var_old:0.748475790,explained_var_new:0.663350403
output spend 0.0018612239946378395 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.020794500000192784 time
recovery_state_mcts_prob spend 1.0526187969953753 time
state_batch spend 0.004099212004803121 time
mcts_probs_batch spend 0.014572763990145177 time
winner_batch spend 0.0002988550113514066 time
policy_value spend 0.44265657699725125 time
train_step spend 0.7184649420087226 time
policy_value spend 0.24647526499757078 time
kl:0.10052,lr_multiplier:0.088,loss:3.50423526763916,entropy:4.268442153930664,explained_var_old:0.645588517,explained_var_new:0.501615822
output spend 0.00017040599777828902 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005343008000636473 time
recovery_state_mcts_prob spend 0.29877428300096653 time
state_batch spend 0.0020816640026168898 time
mcts_probs_batch spend 0.010301711998181418 time
winner_batch spend 0.0003001470031449571 time
policy_value spend 0.2457748799934052 time
train_step spend 0.7203311630000826 time
policy_value spend 0.26845637800579425 time
train_step spend 0.7719860709912609 time
policy_value spend 0.2845603580062743 time
kl:0.17030,lr_multiplier:0.088,loss:3.403441905975342,entropy:4.340513229370117,explained_var_old:0.417024136,explained_var_new:0.636390448
output spend 0.0006377730023814365 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.011907373991562054 time
recovery_state_mcts_prob spend 1.6026824120053789 time
state_batch spend 0.01318377499410417 time
mcts_probs_batch spend 0.08575394400395453 time
winner_batch spend 0.001185533998068422 time
policy_value spend 0.3489365590066882 time
train_step spend 0.8028086249978514 time
policy_value spend 0.28527514199959114 time
train_step spend 0.7878382610069821 time
policy_value spend 0.2720859139953973 time
kl:0.10883,lr_multiplier:0.088,loss:3.4793202877044678,entropy:4.325428009033203,explained_var_old:0.653776884,explained_var_new:0.980157435
output spend 0.0012387010065140203 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.008998639998026192 time
recovery_state_mcts_prob spend 0.43774260899226647 time
state_batch spend 0.00774416999774985 time
mcts_probs_batch spend 0.019001134001882747 time
winner_batch spend 0.00029510800959542394 time
policy_value spend 0.26253764299326576 time
train_step spend 0.7381040929903975 time
policy_value spend 0.2443832600110909 time
train_step spend 0.7109450939897215 time
policy_value spend 0.24945296499936376 time
kl:0.11377,lr_multiplier:0.088,loss:3.40917706489563,entropy:4.282732009887695,explained_var_old:0.969862163,explained_var_new:0.964811981
output spend 0.00030366299324668944 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.012060766006470658 time
recovery_state_mcts_prob spend 0.6190806679951493 time
state_batch spend 0.007563002000097185 time
mcts_probs_batch spend 0.009889747001579963 time
winner_batch spend 0.0003941629984183237 time
policy_value spend 0.28525608200288843 time
train_step spend 0.7968670820118859 time
policy_value spend 0.2884822599880863 time
train_step spend 0.7714922949962784 time
policy_value spend 0.2773716860101558 time
train_step spend 0.7885988539928803 time
policy_value spend 0.2932682230020873 time
train_step spend 0.7922115990077145 time
policy_value spend 0.27314000399201177 time
train_step spend 0.7759011089947307 time
policy_value spend 0.27197684699785896 time
kl:0.10366,lr_multiplier:0.088,loss:3.2055459022521973,entropy:4.165334701538086,explained_var_old:0.966755807,explained_var_new:0.874487758
output spend 0.0009641720098443329 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.008456441006273963 time
recovery_state_mcts_prob spend 0.6505071449937532 time
state_batch spend 0.0026826079993043095 time
mcts_probs_batch spend 0.007377839996479452 time
winner_batch spend 0.00029283900221344084 time
policy_value spend 0.2449074570031371 time
train_step spend 0.7125847159913974 time
policy_value spend 0.2440079360094387 time
train_step spend 0.7073770190036157 time
policy_value spend 0.2421304199961014 time
train_step spend 0.7212134830042487 time
policy_value spend 0.24738236199482344 time
train_step spend 0.7244419869966805 time
policy_value spend 0.2513928870030213 time
kl:0.09315,lr_multiplier:0.088,loss:3.287263870239258,entropy:4.174639701843262,explained_var_old:0.869223833,explained_var_new:0.982708156
output spend 0.00023473599867429584 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.01920124699245207 time
recovery_state_mcts_prob spend 0.6941641040029936 time
state_batch spend 0.017509445999166928 time
mcts_probs_batch spend 0.008612965000793338 time
winner_batch spend 0.00033802799589466304 time
policy_value spend 0.25126751299831085 time
train_step spend 0.7332767070038244 time
policy_value spend 0.26234707099501975 time
train_step spend 0.762267942991457 time
policy_value spend 0.2737509190046694 time
train_step spend 0.780914342001779 time
policy_value spend 0.2880912059918046 time
kl:0.08692,lr_multiplier:0.088,loss:3.3354997634887695,entropy:4.209355354309082,explained_var_old:0.979504585,explained_var_new:0.964000165
output spend 0.001977603998966515 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005809989001136273 time
recovery_state_mcts_prob spend 0.8382189629919594 time
state_batch spend 0.0030529110081261024 time
mcts_probs_batch spend 0.00632171900360845 time
winner_batch spend 0.0005564949969993904 time
policy_value spend 0.2430358589917887 time
train_step spend 0.7151980549970176 time
policy_value spend 0.24320818101114128 time
train_step spend 0.7185234350035898 time
policy_value spend 0.2682918529899325 time
train_step spend 0.7392196509899804 time
policy_value spend 0.26501924500917085 time
kl:0.09832,lr_multiplier:0.088,loss:3.3199000358581543,entropy:4.201244354248047,explained_var_old:0.962131500,explained_var_new:0.716847539
output spend 0.00029646200709976256 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006245274998946115 time
recovery_state_mcts_prob spend 0.5288692480098689 time
state_batch spend 0.006150706991320476 time
mcts_probs_batch spend 0.008952748001320288 time
winner_batch spend 0.00036726299731526524 time
policy_value spend 0.2539809680019971 time
train_step spend 0.7582367430004524 time
policy_value spend 0.2944425760069862 time
train_step spend 0.7484382189868484 time
policy_value spend 0.24587541101209354 time
kl:0.08906,lr_multiplier:0.088,loss:3.3060226440429688,entropy:4.118137836456299,explained_var_old:0.698905349,explained_var_new:0.963871479
output spend 0.000179055001353845 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004693369992310181 time
recovery_state_mcts_prob spend 0.3224656750098802 time
state_batch spend 0.0035163860011380166 time
mcts_probs_batch spend 0.013075198992737569 time
winner_batch spend 0.0002991700021084398 time
policy_value spend 0.2448388379998505 time
train_step spend 0.715860016993247 time
policy_value spend 0.24987297000188846 time
train_step spend 0.7148233670013724 time
policy_value spend 0.24100662699493114 time
kl:0.09428,lr_multiplier:0.088,loss:3.3373336791992188,entropy:4.091946601867676,explained_var_old:0.975813031,explained_var_new:0.978095829
output spend 0.00017428399587515742 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0045813830074621364 time
recovery_state_mcts_prob spend 0.5131909519986948 time
state_batch spend 0.00414400699082762 time
mcts_probs_batch spend 0.010116996010765433 time
winner_batch spend 0.0004392569971969351 time
policy_value spend 0.2437753209960647 time
train_step spend 0.7177802090009209 time
policy_value spend 0.2404517229879275 time
train_step spend 0.7101450679911068 time
policy_value spend 0.24151541100582108 time
train_step spend 0.708498341991799 time
policy_value spend 0.24202428800344933 time
train_step spend 0.7284160779963713 time
policy_value spend 0.2672956390015315 time
kl:0.09239,lr_multiplier:0.088,loss:3.234819173812866,entropy:4.048373222351074,explained_var_old:0.966428876,explained_var_new:0.816553116
output spend 0.0007329149957513437 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.01402575901011005 time
recovery_state_mcts_prob spend 0.7741106299945386 time
state_batch spend 0.0021561229950748384 time
mcts_probs_batch spend 0.014612120998208411 time
winner_batch spend 0.0003427230112720281 time
policy_value spend 0.2572951420006575 time
train_step spend 0.7286621220118832 time
policy_value spend 0.2571787059860071 time
train_step spend 0.7654693310032599 time
policy_value spend 0.29064630799985025 time
train_step spend 0.7478184070059797 time
policy_value spend 0.25189992699597497 time
kl:0.08779,lr_multiplier:0.088,loss:3.2707297801971436,entropy:4.096043109893799,explained_var_old:0.843381047,explained_var_new:0.974915087
output spend 0.00028149300487712026 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004938664991641417 time
recovery_state_mcts_prob spend 0.5723384739976609 time
state_batch spend 0.008036405008169822 time
mcts_probs_batch spend 0.01817691199539695 time
winner_batch spend 0.0005831739981658757 time
policy_value spend 0.25811239700124133 time
train_step spend 0.7514406580012292 time
policy_value spend 0.24987932000658475 time
train_step spend 0.7534295079967706 time
policy_value spend 0.2715567590057617 time
train_step spend 0.755758857994806 time
policy_value spend 0.25276888100779615 time
train_step spend 0.713710859999992 time
policy_value spend 0.2402493949921336 time
kl:0.09531,lr_multiplier:0.088,loss:3.142991304397583,entropy:3.998734712600708,explained_var_old:0.982170463,explained_var_new:0.984005213
output spend 0.00017913299961946905 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005089401005534455 time
recovery_state_mcts_prob spend 0.2949353649892146 time
state_batch spend 0.007792281001457013 time
mcts_probs_batch spend 0.021035646001109853 time
winner_batch spend 0.00032434400054626167 time
policy_value spend 0.24689323600614443 time
train_step spend 0.7091021770029329 time
policy_value spend 0.24605140699713957 time
train_step spend 0.7075725269969553 time
policy_value spend 0.24266436300240457 time
train_step spend 0.7075624260032782 time
policy_value spend 0.2418334380054148 time
kl:0.09742,lr_multiplier:0.088,loss:3.2457125186920166,entropy:4.040740013122559,explained_var_old:0.977588713,explained_var_new:0.978506625
output spend 0.00017268200463149697 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004966227992554195 time
recovery_state_mcts_prob spend 0.5498580670100637 time
state_batch spend 0.002023527995334007 time
mcts_probs_batch spend 0.00681711699871812 time
winner_batch spend 0.00028869799280073494 time
policy_value spend 0.241931693002698 time
train_step spend 0.7077704440016532 time
policy_value spend 0.24062024999875575 time
train_step spend 0.7084811649983749 time
policy_value spend 0.24053455999819562 time
train_step spend 0.7075002250057878 time
policy_value spend 0.2404118349950295 time
train_step spend 0.7067452640039846 time
policy_value spend 0.24092664899944793 time
kl:0.11083,lr_multiplier:0.088,loss:3.237208127975464,entropy:4.071255207061768,explained_var_old:0.963756919,explained_var_new:0.971165121
output spend 0.00018830300541594625 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0066680140007520095 time
recovery_state_mcts_prob spend 0.32867236000311095 time
state_batch spend 0.003981526999268681 time
mcts_probs_batch spend 0.011876278003910556 time
winner_batch spend 0.00037284300196915865 time
policy_value spend 0.24559436299023218 time
train_step spend 0.7095561129972339 time
policy_value spend 0.2410584440076491 time
train_step spend 0.7100215030077379 time
policy_value spend 0.2462387009873055 time
train_step spend 0.709064477996435 time
policy_value spend 0.2458235189988045 time
train_step spend 0.7197640869999304 time
policy_value spend 0.24882123399584088 time
kl:0.09369,lr_multiplier:0.088,loss:3.1159164905548096,entropy:3.9593687057495117,explained_var_old:0.973576546,explained_var_new:0.971043110
output spend 0.0002333309967070818 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.009710807004012167 time
recovery_state_mcts_prob spend 0.44787482799438294 time
state_batch spend 0.00466976199822966 time
mcts_probs_batch spend 0.015159979011514224 time
winner_batch spend 0.0003141839988529682 time
policy_value spend 0.25094244499632623 time
train_step spend 0.7281131630006712 time
policy_value spend 0.31536678300471976 time
train_step spend 0.7269975909875939 time
policy_value spend 0.24292566000076476 time
train_step spend 0.7182778759888606 time
policy_value spend 0.24908541000331752 time
train_step spend 0.7185562520025996 time
policy_value spend 0.24628173200471792 time
kl:0.08707,lr_multiplier:0.088,loss:3.164984941482544,entropy:4.009020805358887,explained_var_old:0.956653118,explained_var_new:0.759600759
output spend 0.00022510898998007178 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005078201997093856 time
recovery_state_mcts_prob spend 0.5225888040004065 time
state_batch spend 0.00398769200546667 time
mcts_probs_batch spend 0.011568461995921098 time
winner_batch spend 0.0006334190111374483 time
policy_value spend 0.26862037999671884 time
train_step spend 0.7274990000005346 time
policy_value spend 0.2432397980010137 time
train_step spend 0.70678374999261 time
policy_value spend 0.24141242100449745 time
train_step spend 0.7353758639947046 time
policy_value spend 0.25616463100595865 time
train_step spend 0.7231396879942622 time
policy_value spend 0.24348936299793422 time
kl:0.09607,lr_multiplier:0.088,loss:3.1923511028289795,entropy:4.001667022705078,explained_var_old:0.711571217,explained_var_new:0.979545295
output spend 0.00019357199198566377 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007787448004819453 time
recovery_state_mcts_prob spend 0.6816270900017116 time
state_batch spend 0.0067154889984522015 time
mcts_probs_batch spend 0.018424590001814067 time
winner_batch spend 0.0003035950066987425 time
policy_value spend 0.24429633899126202 time
train_step spend 0.7096982010116335 time
policy_value spend 0.24419420499179978 time
train_step spend 0.7063951740128687 time
policy_value spend 0.2411200979986461 time
train_step spend 0.7081931760039879 time
policy_value spend 0.25119170699326787 time
train_step spend 0.7176575440098532 time
policy_value spend 0.27832642498833593 time
kl:0.08396,lr_multiplier:0.088,loss:3.1539528369903564,entropy:3.9658541679382324,explained_var_old:0.983533025,explained_var_new:0.982192934
output spend 0.0006554299907293171 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004634503013221547 time
recovery_state_mcts_prob spend 0.4291680269961944 time
state_batch spend 0.004456868991837837 time
mcts_probs_batch spend 0.014969807001762092 time
winner_batch spend 0.0003250500012654811 time
policy_value spend 0.24665818200446665 time
train_step spend 0.7171204400074203 time
policy_value spend 0.24295578298915643 time
train_step spend 0.7279314009938389 time
policy_value spend 0.24880490500072483 time
train_step spend 0.7347541890048888 time
policy_value spend 0.25945702800527215 time
kl:0.08114,lr_multiplier:0.088,loss:3.1673099994659424,entropy:3.946120500564575,explained_var_old:0.979768872,explained_var_new:0.982791960
output spend 0.0004319440049584955 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005095947999507189 time
recovery_state_mcts_prob spend 0.3132010890112724 time
state_batch spend 0.002027341994107701 time
mcts_probs_batch spend 0.008345901995198801 time
winner_batch spend 0.00032509501033928245 time
policy_value spend 0.24882377398898825 time
train_step spend 0.7322542540059658 time
policy_value spend 0.2550592119951034 time
train_step spend 0.7307804960000794 time
policy_value spend 0.2591373100003693 time
train_step spend 0.7345651240029838 time
policy_value spend 0.2501403089991072 time
train_step spend 0.7118259990093065 time
policy_value spend 0.2420588789973408 time
kl:0.10712,lr_multiplier:0.088,loss:3.1808416843414307,entropy:3.9750044345855713,explained_var_old:0.983377099,explained_var_new:0.964783669
output spend 0.000172385000041686 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005080043003545143 time
recovery_state_mcts_prob spend 0.2962378089869162 time
state_batch spend 0.004487017009523697 time
mcts_probs_batch spend 0.0063037200015969574 time
winner_batch spend 0.00027993098774459213 time
policy_value spend 0.2420621100027347 time
train_step spend 0.7085492789919954 time
policy_value spend 0.24484803000814281 time
train_step spend 0.707934154997929 time
policy_value spend 0.24131101201055571 time
train_step spend 0.7073506869928678 time
policy_value spend 0.24124497899902053 time
kl:0.09453,lr_multiplier:0.088,loss:3.1084558963775635,entropy:3.895486831665039,explained_var_old:0.964633048,explained_var_new:0.979046404
output spend 0.0002545040042605251 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004612037999322638 time
recovery_state_mcts_prob spend 0.3050607229961315 time
state_batch spend 0.003752988006453961 time
mcts_probs_batch spend 0.01425343299342785 time
winner_batch spend 0.0002892479969887063 time
policy_value spend 0.24664283500169404 time
train_step spend 0.7065259069931926 time
policy_value spend 0.24503040799754672 time
train_step spend 0.7065413399977842 time
policy_value spend 0.242567292007152 time
train_step spend 0.7073877179936972 time
policy_value spend 0.24743735599622596 time
train_step spend 0.7078897780011175 time
policy_value spend 0.24138146100449376 time
kl:0.10377,lr_multiplier:0.088,loss:3.0564448833465576,entropy:3.862485885620117,explained_var_old:0.977708101,explained_var_new:0.983146191
output spend 0.00022255499789025635 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005167859999346547 time
recovery_state_mcts_prob spend 0.28698319201066624 time
state_batch spend 0.002050187991699204 time
mcts_probs_batch spend 0.006897932005813345 time
winner_batch spend 0.0003746189904632047 time
policy_value spend 0.2414387530006934 time
train_step spend 0.7077060599985998 time
policy_value spend 0.24058229799265973 time
train_step spend 0.7073982459987747 time
policy_value spend 0.2466663170052925 time
train_step spend 0.7208643269987078 time
policy_value spend 0.24039356500725262 time
train_step spend 0.7067242259945488 time
policy_value spend 0.24089228799857665 time
kl:0.10023,lr_multiplier:0.088,loss:3.0997300148010254,entropy:3.8755013942718506,explained_var_old:0.981205702,explained_var_new:0.767338037
output spend 0.0001689750060904771 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004978679993655533 time
recovery_state_mcts_prob spend 0.4273911250056699 time
state_batch spend 0.004253169987350702 time
mcts_probs_batch spend 0.007809487011400051 time
winner_batch spend 0.00038228099583648145 time
policy_value spend 0.24302586600242648 time
train_step spend 0.7085107709863223 time
policy_value spend 0.24101925200375263 time
train_step spend 0.7066059360076906 time
policy_value spend 0.24068821399123408 time
train_step spend 0.7141041209979448 time
policy_value spend 0.24034078400291037 time
kl:0.10276,lr_multiplier:0.088,loss:3.0497379302978516,entropy:3.8260927200317383,explained_var_old:0.763892353,explained_var_new:0.955669999
output spend 0.00019712898938450962 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005476997001096606 time
recovery_state_mcts_prob spend 0.37890089199936483 time
state_batch spend 0.002130736000253819 time
mcts_probs_batch spend 0.00705262299743481 time
winner_batch spend 0.00029276800341904163 time
policy_value spend 0.24624157899233978 time
train_step spend 0.7072481479990529 time
policy_value spend 0.24186139799712691 time
train_step spend 0.7078195520007284 time
policy_value spend 0.2436593900056323 time
train_step spend 0.7063367910013767 time
policy_value spend 0.24169025399896782 time
train_step spend 0.7080868300108705 time
policy_value spend 0.24422321699967142 time
kl:0.13425,lr_multiplier:0.088,loss:3.053863048553467,entropy:3.8080766201019287,explained_var_old:0.954206765,explained_var_new:0.985866010
output spend 0.0001907359983306378 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0040877930005081 time
recovery_state_mcts_prob spend 0.3076707099971827 time
state_batch spend 0.0035952650068793446 time
mcts_probs_batch spend 0.007802663996699266 time
winner_batch spend 0.00029205299506429583 time
policy_value spend 0.24245009099831805 time
train_step spend 0.7086158039892325 time
policy_value spend 0.2406020560010802 time
train_step spend 0.7103068100113887 time
policy_value spend 0.24091508299170528 time
train_step spend 0.7075551809975877 time
policy_value spend 0.24040298401087057 time
train_step spend 0.7070138260023668 time
policy_value spend 0.25101171899586916 time
kl:0.09237,lr_multiplier:0.088,loss:3.045147657394409,entropy:3.864095449447632,explained_var_old:0.988139391,explained_var_new:0.989189625
output spend 0.0015706100093666464 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005821416998514906 time
recovery_state_mcts_prob spend 0.31890809499600437 time
state_batch spend 0.004245257005095482 time
mcts_probs_batch spend 0.006827767996583134 time
winner_batch spend 0.0002891390031436458 time
policy_value spend 0.257533986994531 time
train_step spend 0.7109049699938623 time
policy_value spend 0.24705064301087987 time
train_step spend 0.7714141860051313 time
policy_value spend 0.32665790600003675 time
train_step spend 0.731096493997029 time
policy_value spend 0.250158217997523 time
train_step spend 0.7226319210021757 time
policy_value spend 0.24749940099718515 time
kl:0.08803,lr_multiplier:0.088,loss:3.1035315990448,entropy:3.8823440074920654,explained_var_old:0.992065489,explained_var_new:0.995402038
output spend 0.00017127000319305807 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005168853997020051 time
recovery_state_mcts_prob spend 0.33291098500194494 time
state_batch spend 0.004471191001357511 time
mcts_probs_batch spend 0.016222810998442583 time
winner_batch spend 0.0003255780029576272 time
policy_value spend 0.24843387999862898 time
train_step spend 0.7169585639931029 time
policy_value spend 0.26302980599575676 time
train_step spend 0.7135599300090689 time
policy_value spend 0.24506892600038555 time
train_step spend 0.7136204220005311 time
policy_value spend 0.2617420009919442 time
train_step spend 0.71460854599718 time
policy_value spend 0.2427404199988814 time
kl:0.09578,lr_multiplier:0.088,loss:3.152439594268799,entropy:3.8866517543792725,explained_var_old:0.977291286,explained_var_new:0.983409226
output spend 0.00017747101082932204 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003915339999366552 time
recovery_state_mcts_prob spend 0.31605086600757204 time
state_batch spend 0.004366189998108894 time
mcts_probs_batch spend 0.01443603700317908 time
winner_batch spend 0.0002974340022774413 time
policy_value spend 0.24954021199664567 time
train_step spend 0.7149954320047982 time
policy_value spend 0.24254343500069808 time
train_step spend 0.712653861992294 time
policy_value spend 0.243577360000927 time
kl:0.08343,lr_multiplier:0.088,loss:3.0960187911987305,entropy:3.8410677909851074,explained_var_old:0.992210865,explained_var_new:0.982641160
output spend 0.00032231799559667706 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004060225997818634 time
recovery_state_mcts_prob spend 0.32317754901305307 time
state_batch spend 0.0037912389962002635 time
mcts_probs_batch spend 0.009499181003775448 time
winner_batch spend 0.0003657689958345145 time
policy_value spend 0.24710917299671564 time
train_step spend 0.7577304470032686 time
policy_value spend 0.2413103129947558 time
train_step spend 0.7080488139908994 time
policy_value spend 0.24175365699920803 time
train_step spend 0.7074483720061835 time
policy_value spend 0.24128343000484165 time
train_step spend 0.7083856670069508 time
policy_value spend 0.24137540899391752 time
kl:0.09713,lr_multiplier:0.088,loss:3.0159196853637695,entropy:3.809420585632324,explained_var_old:0.982195556,explained_var_new:0.995473802
output spend 0.0002148100029444322 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006425209998269565 time
recovery_state_mcts_prob spend 0.29279018100351095 time
state_batch spend 0.004135212991968729 time
mcts_probs_batch spend 0.006470663007348776 time
winner_batch spend 0.00031698099337518215 time
policy_value spend 0.2420431750069838 time
train_step spend 0.7071062769973651 time
policy_value spend 0.24143443899811246 time
train_step spend 0.70753212699492 time
policy_value spend 0.24102485399635043 time
train_step spend 0.7107874450011877 time
policy_value spend 0.24042191899206955 time
train_step spend 0.7073312400025316 time
policy_value spend 0.2409032129944535 time
kl:0.10190,lr_multiplier:0.088,loss:3.035881996154785,entropy:3.7854695320129395,explained_var_old:0.978782892,explained_var_new:0.980870068
output spend 0.00016840500757098198 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004556182990199886 time
recovery_state_mcts_prob spend 0.2966315950034186 time
state_batch spend 0.003484938992187381 time
mcts_probs_batch spend 0.007717446002061479 time
winner_batch spend 0.0002867959992727265 time
policy_value spend 0.24578486100654118 time
train_step spend 0.707020920002833 time
policy_value spend 0.24281384100322612 time
train_step spend 0.7069035710010212 time
policy_value spend 0.25156624100054614 time
train_step spend 0.708329925997532 time
policy_value spend 0.2425469269946916 time
train_step spend 0.7073801110091154 time
policy_value spend 0.2522596389899263 time
kl:0.09655,lr_multiplier:0.088,loss:3.022139310836792,entropy:3.792931318283081,explained_var_old:0.983160973,explained_var_new:0.971101999
output spend 0.00044660200364887714 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003923550000763498 time
recovery_state_mcts_prob spend 0.3040327139897272 time
state_batch spend 0.002721039010793902 time
mcts_probs_batch spend 0.012612055987119675 time
winner_batch spend 0.0003198360063834116 time
policy_value spend 0.2449746630009031 time
train_step spend 0.7086762139952043 time
policy_value spend 0.2407921480044024 time
train_step spend 0.7069693399971584 time
policy_value spend 0.2407286310044583 time
train_step spend 0.7062967450037831 time
policy_value spend 0.24199874998885207 time
kl:0.08497,lr_multiplier:0.088,loss:3.1531848907470703,entropy:3.8787121772766113,explained_var_old:0.959852815,explained_var_new:0.971907258
output spend 0.00017350399866700172 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006587537005543709 time
recovery_state_mcts_prob spend 0.3946469590009656 time
state_batch spend 0.0037164539971854538 time
mcts_probs_batch spend 0.007516095007304102 time
winner_batch spend 0.00027963299362454563 time
policy_value spend 0.2424245139991399 time
train_step spend 0.715371984988451 time
policy_value spend 0.24047862501174677 time
train_step spend 0.7069947029958712 time
policy_value spend 0.24084606100223027 time
train_step spend 0.707181354999193 time
policy_value spend 0.24045947699050885 time
train_step spend 0.7083675790054258 time
policy_value spend 0.24088889600534458 time
kl:0.09350,lr_multiplier:0.088,loss:3.0444717407226562,entropy:3.781497001647949,explained_var_old:0.954046428,explained_var_new:0.986262023
output spend 0.00018161500338464975 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0060661320021608844 time
recovery_state_mcts_prob spend 0.3315075499995146 time
state_batch spend 0.005421060006483458 time
mcts_probs_batch spend 0.018124087000614963 time
winner_batch spend 0.0003261439997004345 time
policy_value spend 0.24523036000027787 time
train_step spend 0.7073291499982588 time
policy_value spend 0.24277479101147037 time
train_step spend 0.7079364079982042 time
policy_value spend 0.2423731110029621 time
train_step spend 0.7092823410057463 time
policy_value spend 0.24156516799121164 time
train_step spend 0.7080808540049475 time
policy_value spend 0.24490657600108534 time
kl:0.12538,lr_multiplier:0.088,loss:3.0445709228515625,entropy:3.8298323154449463,explained_var_old:0.979818106,explained_var_new:0.924498856
output spend 0.00031110898999031633 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006616440005018376 time
recovery_state_mcts_prob spend 0.3169567779987119 time
state_batch spend 0.0038081780076026917 time
mcts_probs_batch spend 0.013810585995088331 time
winner_batch spend 0.00028143399686086923 time
policy_value spend 0.2462133509980049 time
train_step spend 0.7237077669997234 time
policy_value spend 0.24108205000811722 time
train_step spend 0.7075712199875852 time
policy_value spend 0.24188812301144935 time
train_step spend 0.708132989006117 time
policy_value spend 0.24333444399235304 time
kl:0.09219,lr_multiplier:0.088,loss:3.0073227882385254,entropy:3.765918493270874,explained_var_old:0.936830461,explained_var_new:0.960160732
output spend 0.00041219600825570524 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0073083640018012375 time
recovery_state_mcts_prob spend 0.6167598140018526 time
state_batch spend 0.003143131994875148 time
mcts_probs_batch spend 0.008085672991001047 time
winner_batch spend 0.00035267500788904727 time
policy_value spend 0.24667021300410852 time
train_step spend 0.7104477459943155 time
policy_value spend 0.24236693400598597 time
train_step spend 0.7069872360007139 time
policy_value spend 0.2509503610053798 time
train_step spend 0.7072878740000306 time
policy_value spend 0.24096492199169006 time
train_step spend 0.7071572490094695 time
policy_value spend 0.24773553799604997 time
kl:0.10223,lr_multiplier:0.088,loss:3.037463665008545,entropy:3.7631163597106934,explained_var_old:0.945440829,explained_var_new:0.970466256
output spend 0.0007727420015726238 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005157769992365502 time
recovery_state_mcts_prob spend 0.3358025570050813 time
state_batch spend 0.0031011810060590506 time
mcts_probs_batch spend 0.0076550239900825545 time
winner_batch spend 0.00029630700009875 time
policy_value spend 0.24590123300731648 time
train_step spend 0.7082059410022339 time
policy_value spend 0.24246179100009613 time
train_step spend 0.7092036649992224 time
policy_value spend 0.24049533499055542 time
train_step spend 0.7064630429958925 time
policy_value spend 0.24003775899473112 time
train_step spend 0.7067273650027346 time
policy_value spend 0.24025205899670254 time
train_step spend 0.7068092760018772 time
policy_value spend 0.24023984299856238 time
kl:0.10721,lr_multiplier:0.088,loss:3.003519296646118,entropy:3.7384350299835205,explained_var_old:0.980238974,explained_var_new:0.990406215
output spend 0.00017367200052831322 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0063731150003150105 time
recovery_state_mcts_prob spend 0.3751771569950506 time
state_batch spend 0.004660739999962971 time
mcts_probs_batch spend 0.016541404998861253 time
winner_batch spend 0.000301595006021671 time
policy_value spend 0.24257239898724947 time
train_step spend 0.7088049149897415 time
policy_value spend 0.2419982530118432 time
train_step spend 0.711386440001661 time
policy_value spend 0.24047321399848443 time
train_step spend 0.7073106030002236 time
policy_value spend 0.24089385200932156 time
train_step spend 0.7074759380047908 time
policy_value spend 0.2407925869920291 time
kl:0.08706,lr_multiplier:0.088,loss:2.9822888374328613,entropy:3.711013078689575,explained_var_old:0.985982955,explained_var_new:0.987940729
output spend 0.00016987501294352114 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005495339006301947 time
recovery_state_mcts_prob spend 0.32650901199667715 time
state_batch spend 0.0030817410006420687 time
mcts_probs_batch spend 0.01362320699263364 time
winner_batch spend 0.00029399601044133306 time
policy_value spend 0.24512251900159754 time
train_step spend 0.7057631030038465 time
policy_value spend 0.24337361600191798 time
train_step spend 0.7126500059966929 time
policy_value spend 0.24468136799987406 time
train_step spend 0.7075524370011408 time
policy_value spend 0.24666384600277524 time
kl:0.08525,lr_multiplier:0.088,loss:2.9598946571350098,entropy:3.68501615524292,explained_var_old:0.977387488,explained_var_new:0.914136410
output spend 0.00030225700174923986 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004776129004312679 time
recovery_state_mcts_prob spend 0.2937039509997703 time
state_batch spend 0.0021512730018002912 time
mcts_probs_batch spend 0.0080824169999687 time
winner_batch spend 0.00032032599847298115 time
policy_value spend 0.24600546799774747 time
train_step spend 0.7087949709966779 time
policy_value spend 0.24078922299668193 time
train_step spend 0.7090779550053412 time
policy_value spend 0.24116182600846514 time
train_step spend 0.7080478739953833 time
policy_value spend 0.24191944900667295 time
kl:0.08464,lr_multiplier:0.088,loss:3.0027825832366943,entropy:3.7257561683654785,explained_var_old:0.891482234,explained_var_new:0.966156542
output spend 0.00017652599490247667 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004503225005464628 time
recovery_state_mcts_prob spend 0.3888391270011198 time
state_batch spend 0.00353300099959597 time
mcts_probs_batch spend 0.007423771996400319 time
winner_batch spend 0.00028162699891254306 time
policy_value spend 0.24387559200113174 time
train_step spend 0.7082474150083726 time
policy_value spend 0.24034026399021968 time
train_step spend 0.7058469909970881 time
policy_value spend 0.24025916399841662 time
train_step spend 0.7054242440062808 time
policy_value spend 0.24033619099645875 time
train_step spend 0.7065275120112346 time
policy_value spend 0.24311665899585932 time
kl:0.08808,lr_multiplier:0.088,loss:3.019390821456909,entropy:3.7370855808258057,explained_var_old:0.961315215,explained_var_new:0.987897515
output spend 0.00017507800657767802 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0059244169970043 time
recovery_state_mcts_prob spend 0.3030326559965033 time
state_batch spend 0.004158583004027605 time
mcts_probs_batch spend 0.0067735359916696325 time
winner_batch spend 0.000337484001647681 time
policy_value spend 0.2423217100003967 time
train_step spend 0.708201169007225 time
policy_value spend 0.24034906399901956 time
train_step spend 0.7084099459898425 time
policy_value spend 0.2407155450055143 time
train_step spend 0.7071492120012408 time
policy_value spend 0.24277892999816686 time
train_step spend 0.7080162100028247 time
policy_value spend 0.2413600789877819 time
kl:0.08983,lr_multiplier:0.088,loss:3.004012107849121,entropy:3.73140811920166,explained_var_old:0.978120863,explained_var_new:0.989563525
output spend 0.00023110699839890003 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004417370000737719 time
recovery_state_mcts_prob spend 0.29976471699774265 time
state_batch spend 0.0046162290091160685 time
mcts_probs_batch spend 0.007755010999972001 time
winner_batch spend 0.00031436998688150197 time
policy_value spend 0.24308088600810152 time
train_step spend 0.7051904649997596 time
policy_value spend 0.24227833798795473 time
train_step spend 0.7071975259896135 time
policy_value spend 0.24166052900545765 time
train_step spend 0.7080946549976943 time
policy_value spend 0.24056796201330144 time
train_step spend 0.7085416810004972 time
policy_value spend 0.24029929999960586 time
kl:0.09440,lr_multiplier:0.088,loss:2.989124059677124,entropy:3.7220187187194824,explained_var_old:0.982736707,explained_var_new:0.985392869
output spend 0.00021763100812677294 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004392670001834631 time
recovery_state_mcts_prob spend 0.4304535400005989 time
state_batch spend 0.004347577996668406 time
mcts_probs_batch spend 0.010614219005219638 time
winner_batch spend 0.0002949310000985861 time
policy_value spend 0.2483715469861636 time
train_step spend 0.7103035399923101 time
policy_value spend 0.2402630720025627 time
train_step spend 0.7079084830038482 time
policy_value spend 0.24102626300009433 time
train_step spend 0.7061922650027554 time
policy_value spend 0.23985313999583013 time
kl:0.08174,lr_multiplier:0.088,loss:2.9910759925842285,entropy:3.7377803325653076,explained_var_old:0.984547138,explained_var_new:0.986510396
output spend 0.0001739309955155477 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004675684001995251 time
recovery_state_mcts_prob spend 0.3818429940001806 time
state_batch spend 0.003844715000013821 time
mcts_probs_batch spend 0.007778732993756421 time
winner_batch spend 0.0002742120123002678 time
policy_value spend 0.24222887599898968 time
train_step spend 0.707248063001316 time
policy_value spend 0.2405213809979614 time
train_step spend 0.7130417340085842 time
policy_value spend 0.24400579299253877 time
train_step spend 0.7064708129910287 time
policy_value spend 0.24045016699528787 time
kl:0.09373,lr_multiplier:0.088,loss:3.074061632156372,entropy:3.799557685852051,explained_var_old:0.985306203,explained_var_new:0.990341783
output spend 0.0001654250081628561 time
已保存最新模型
current self-play batch: 100
load data begin
已加载数据
step i 46: 
random.sample spend 0.004034995989059098 time
recovery_state_mcts_prob spend 0.3214732769993134 time
state_batch spend 0.005467501003295183 time
mcts_probs_batch spend 0.007389393009361811 time
winner_batch spend 0.00027629199030343443 time
policy_value spend 0.24848682699666824 time
train_step spend 0.7305098060023738 time
policy_value spend 0.25619823300803546 time
train_step spend 0.7330540929979179 time
policy_value spend 0.24479214299935848 time
train_step spend 0.7135240770003293 time
policy_value spend 0.24188440099533182 time
train_step spend 0.7074636970064603 time
policy_value spend 0.26338287300313823 time
kl:0.10125,lr_multiplier:0.088,loss:3.018833637237549,entropy:3.7392802238464355,explained_var_old:0.986780286,explained_var_new:0.989024341
output spend 0.000334304990246892 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004629982999176718 time
recovery_state_mcts_prob spend 0.2842854909977177 time
state_batch spend 0.004350051996880211 time
mcts_probs_batch spend 0.008281417001853697 time
winner_batch spend 0.00039843900594860315 time
policy_value spend 0.2423729820002336 time
train_step spend 0.7064664920035284 time
policy_value spend 0.2421266469900729 time
train_step spend 0.7067442160041537 time
policy_value spend 0.2407279149920214 time
train_step spend 0.7064985080069164 time
policy_value spend 0.24295951500243973 time
train_step spend 0.707977653000853 time
policy_value spend 0.24051085399696603 time
kl:0.09131,lr_multiplier:0.088,loss:3.0505478382110596,entropy:3.774479389190674,explained_var_old:0.986035228,explained_var_new:0.993801713
output spend 0.00021486799232661724 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004433276000781916 time
recovery_state_mcts_prob spend 0.2864834799984237 time
state_batch spend 0.0035714209952857345 time
mcts_probs_batch spend 0.007196896011009812 time
winner_batch spend 0.00041860700002871454 time
policy_value spend 0.24410126698785461 time
train_step spend 0.7094134649960324 time
policy_value spend 0.2417476050031837 time
train_step spend 0.7082963050052058 time
policy_value spend 0.24049607600318268 time
train_step spend 0.7074150109983748 time
policy_value spend 0.2409430680127116 time
train_step spend 0.7107793100003619 time
policy_value spend 0.24056195199955255 time
kl:0.09012,lr_multiplier:0.088,loss:3.03124737739563,entropy:3.711182117462158,explained_var_old:0.961197913,explained_var_new:0.902473986
output spend 0.00022939199698157609 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005107600998599082 time
recovery_state_mcts_prob spend 0.3193224880087655 time
state_batch spend 0.0019882070046151057 time
mcts_probs_batch spend 0.010316046988009475 time
winner_batch spend 0.00028055100119672716 time
policy_value spend 0.2540926650108304 time
train_step spend 0.7111651269951835 time
policy_value spend 0.24046861300303135 time
train_step spend 0.7121015760058071 time
policy_value spend 0.25422181499016006 time
train_step spend 0.708695177003392 time
policy_value spend 0.24035925399221014 time
train_step spend 0.7091035500052385 time
policy_value spend 0.2503168459952576 time
kl:0.09201,lr_multiplier:0.088,loss:3.0536816120147705,entropy:3.787053108215332,explained_var_old:0.904481828,explained_var_new:0.988141000
output spend 0.0006335400103125721 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004767376012750901 time
recovery_state_mcts_prob spend 0.2901100789895281 time
state_batch spend 0.0047108169965213165 time
mcts_probs_batch spend 0.007123948002117686 time
winner_batch spend 0.0002766450052149594 time
policy_value spend 0.24215141200693324 time
train_step spend 0.7066184980067192 time
policy_value spend 0.24220185799640603 time
train_step spend 0.7106918180070352 time
policy_value spend 0.2445195289910771 time
train_step spend 0.7098724489915185 time
policy_value spend 0.24093544199422467 time
train_step spend 0.7070328080008039 time
policy_value spend 0.24491300999943633 time
train_step spend 0.7085158160043648 time
policy_value spend 0.24019638200115878 time
kl:0.10445,lr_multiplier:0.088,loss:2.9902522563934326,entropy:3.7049877643585205,explained_var_old:0.980013549,explained_var_new:0.978952527
output spend 0.00022036099107936025 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0051358740020077676 time
recovery_state_mcts_prob spend 0.3817159710015403 time
state_batch spend 0.006251561004319228 time
mcts_probs_batch spend 0.01705176499672234 time
winner_batch spend 0.000281417989754118 time
policy_value spend 0.2422932790068444 time
train_step spend 0.7069320070004323 time
policy_value spend 0.2419205710029928 time
train_step spend 0.7070669919921784 time
policy_value spend 0.2406212060013786 time
train_step spend 0.7064361499942606 time
policy_value spend 0.2432900350104319 time
train_step spend 0.7093300660053501 time
policy_value spend 0.2428053670009831 time
train_step spend 0.7082984809967456 time
policy_value spend 0.24926254399179015 time
kl:0.11338,lr_multiplier:0.088,loss:3.0251293182373047,entropy:3.7239208221435547,explained_var_old:0.971907794,explained_var_new:0.986539304
output spend 0.00021197099704295397 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007168529002228752 time
recovery_state_mcts_prob spend 0.3096172560035484 time
state_batch spend 0.002063025996903889 time
mcts_probs_batch spend 0.00927712200791575 time
winner_batch spend 0.00037571199936792254 time
policy_value spend 0.24254380600177683 time
train_step spend 0.7068893789983122 time
policy_value spend 0.24043793699820526 time
train_step spend 0.7073578160052421 time
policy_value spend 0.2411183429940138 time
train_step spend 0.7130200840038015 time
policy_value spend 0.2431982540001627 time
train_step spend 0.706933105000644 time
policy_value spend 0.25585512300312985 time
kl:0.08898,lr_multiplier:0.088,loss:3.0013976097106934,entropy:3.719006061553955,explained_var_old:0.983671486,explained_var_new:0.993695915
output spend 0.00034250800672452897 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003547599000739865 time
recovery_state_mcts_prob spend 0.3085274220065912 time
state_batch spend 0.004558521002763882 time
mcts_probs_batch spend 0.008846561991958879 time
winner_batch spend 0.0003133959980914369 time
policy_value spend 0.24269693900714628 time
train_step spend 0.7065099200117402 time
policy_value spend 0.24241624199203216 time
train_step spend 0.7063374379940797 time
policy_value spend 0.24060263500723522 time
train_step spend 0.7060888679989148 time
policy_value spend 0.24180121399695054 time
train_step spend 0.7071154820005177 time
policy_value spend 0.24079717899439856 time
kl:0.08490,lr_multiplier:0.088,loss:3.048415184020996,entropy:3.7583394050598145,explained_var_old:0.989545584,explained_var_new:0.989122570
output spend 0.0001674759987508878 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004447147992323153 time
recovery_state_mcts_prob spend 0.2892910170048708 time
state_batch spend 0.003937569999834523 time
mcts_probs_batch spend 0.006666279994533397 time
winner_batch spend 0.0002710430126171559 time
policy_value spend 0.2421336529951077 time
train_step spend 0.7065533189888811 time
policy_value spend 0.24147435100167058 time
train_step spend 0.7069866429956164 time
policy_value spend 0.24024716700660065 time
train_step spend 0.7062645879923366 time
policy_value spend 0.24073125699942466 time
kl:0.10026,lr_multiplier:0.088,loss:2.9481024742126465,entropy:3.6583101749420166,explained_var_old:0.994270086,explained_var_new:0.994452059
output spend 0.0002244380011688918 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0058222739899065346 time
recovery_state_mcts_prob spend 0.32759385601093527 time
state_batch spend 0.0038394639996113256 time
mcts_probs_batch spend 0.006554962994414382 time
winner_batch spend 0.0003030280058737844 time
policy_value spend 0.24290559299697634 time
train_step spend 0.7067622519971337 time
policy_value spend 0.24182156300230417 time
train_step spend 0.7077120719914092 time
policy_value spend 0.24066998099442571 time
train_step spend 0.7070326920074876 time
policy_value spend 0.250353975003236 time
train_step spend 0.7087252759956755 time
policy_value spend 0.2408486839995021 time
kl:0.10045,lr_multiplier:0.088,loss:2.902920961380005,entropy:3.6069204807281494,explained_var_old:0.997337937,explained_var_new:0.979646564
output spend 0.00017167699115816504 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0053025959932710975 time
recovery_state_mcts_prob spend 0.3193551130098058 time
state_batch spend 0.005268394001177512 time
mcts_probs_batch spend 0.007572410991997458 time
winner_batch spend 0.00029002700466662645 time
policy_value spend 0.24669649999123067 time
train_step spend 0.7097196739923675 time
policy_value spend 0.2406239120027749 time
train_step spend 0.7059740140102804 time
policy_value spend 0.24159133499779273 time
train_step spend 0.7062053239933448 time
policy_value spend 0.2411422170116566 time
train_step spend 0.7069112749886699 time
policy_value spend 0.24145926799974404 time
kl:0.09392,lr_multiplier:0.088,loss:2.9076318740844727,entropy:3.607863187789917,explained_var_old:0.960968971,explained_var_new:0.991568148
output spend 0.0001886789978016168 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004848996992222965 time
recovery_state_mcts_prob spend 0.3644203370058676 time
state_batch spend 0.006307175994152203 time
mcts_probs_batch spend 0.01872642000671476 time
winner_batch spend 0.0003077269939240068 time
policy_value spend 0.24315996500081383 time
train_step spend 0.709821826996631 time
policy_value spend 0.24211230300716124 time
train_step spend 0.707080403008149 time
policy_value spend 0.24084433399548288 time
train_step spend 0.7073713029967621 time
policy_value spend 0.24368843399861362 time
train_step spend 0.7095769470033702 time
policy_value spend 0.24042679098783992 time
kl:0.08156,lr_multiplier:0.088,loss:2.872652769088745,entropy:3.5664939880371094,explained_var_old:0.986794353,explained_var_new:0.966842294
output spend 0.0001880670024547726 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0073678519984241575 time
recovery_state_mcts_prob spend 0.39830009499564767 time
state_batch spend 0.004811734004761092 time
mcts_probs_batch spend 0.014414871999179013 time
winner_batch spend 0.0003121879999525845 time
policy_value spend 0.24491348800074775 time
train_step spend 0.7101605729985749 time
policy_value spend 0.25016041701019276 time
train_step spend 0.7087056029995438 time
policy_value spend 0.24041088699596003 time
train_step spend 0.7078872410056647 time
policy_value spend 0.24979049299145117 time
train_step spend 0.7067440680111758 time
policy_value spend 0.2405032209935598 time
kl:0.09106,lr_multiplier:0.088,loss:2.968780279159546,entropy:3.654679536819458,explained_var_old:0.964167714,explained_var_new:0.980001152
output spend 0.0001962240057764575 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004809525999007747 time
recovery_state_mcts_prob spend 0.29438145300082397 time
state_batch spend 0.004115656993235461 time
mcts_probs_batch spend 0.007520814004237764 time
winner_batch spend 0.00028130400460213423 time
policy_value spend 0.24238417099695653 time
train_step spend 0.7183203699969454 time
policy_value spend 0.24192766699707136 time
train_step spend 0.7080893999955151 time
policy_value spend 0.2408778910030378 time
train_step spend 0.7067523060104577 time
policy_value spend 0.24096865199680906 time
kl:0.09316,lr_multiplier:0.088,loss:2.9586288928985596,entropy:3.6473147869110107,explained_var_old:0.958959401,explained_var_new:0.980196476
output spend 0.0001758350117597729 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004130248009460047 time
recovery_state_mcts_prob spend 0.30477231499389745 time
state_batch spend 0.0036363429971970618 time
mcts_probs_batch spend 0.014406567002879456 time
winner_batch spend 0.0002859619999071583 time
policy_value spend 0.24532298400299624 time
train_step spend 0.7083237219922012 time
policy_value spend 0.24227707600221038 time
train_step spend 0.7064796329941601 time
policy_value spend 0.24324061900551897 time
train_step spend 0.712576955993427 time
policy_value spend 0.24145913300162647 time
train_step spend 0.707052369005396 time
policy_value spend 0.24099194099835586 time
kl:0.10472,lr_multiplier:0.088,loss:2.99444842338562,entropy:3.6917901039123535,explained_var_old:0.978245020,explained_var_new:0.991974711
output spend 0.00016792799578979611 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004539379995549098 time
recovery_state_mcts_prob spend 0.369061794001027 time
state_batch spend 0.0036108310014242306 time
mcts_probs_batch spend 0.012867376994108781 time
winner_batch spend 0.00028677700902335346 time
policy_value spend 0.2448885329940822 time
train_step spend 0.7097036630002549 time
policy_value spend 0.2406325259944424 time
train_step spend 0.7068871959927492 time
policy_value spend 0.24173996200261172 time
train_step spend 0.7092702719965018 time
policy_value spend 0.24144473200431094 time
train_step spend 0.706916633003857 time
policy_value spend 0.24048107099952176 time
kl:0.09633,lr_multiplier:0.088,loss:2.9760420322418213,entropy:3.678192615509033,explained_var_old:0.979923427,explained_var_new:0.989781439
output spend 0.00016864300414454192 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004007722993264906 time
recovery_state_mcts_prob spend 0.30298114800825715 time
state_batch spend 0.004282436988432892 time
mcts_probs_batch spend 0.006801743002142757 time
winner_batch spend 0.0002667079970706254 time
policy_value spend 0.2508151960064424 time
train_step spend 0.7118225509912008 time
policy_value spend 0.2401399450027384 time
train_step spend 0.7068921190075343 time
policy_value spend 0.24131228399346583 time
train_step spend 0.7075320279982407 time
policy_value spend 0.2405809959891485 time
kl:0.08516,lr_multiplier:0.088,loss:3.012439250946045,entropy:3.706411838531494,explained_var_old:0.989162564,explained_var_new:0.970097542
output spend 0.00024038499395828694 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006828429002780467 time
recovery_state_mcts_prob spend 0.3172493039892288 time
state_batch spend 0.00352608400862664 time
mcts_probs_batch spend 0.012443254003301263 time
winner_batch spend 0.0002857159997802228 time
policy_value spend 0.24550443499174435 time
train_step spend 0.7079569659981644 time
policy_value spend 0.240696722001303 time
train_step spend 0.7136131089937408 time
policy_value spend 0.241432775001158 time
train_step spend 0.7062637820054078 time
policy_value spend 0.24114014599763323 time
train_step spend 0.7069573740009218 time
policy_value spend 0.2428124790021684 time
kl:0.11493,lr_multiplier:0.088,loss:2.965482711791992,entropy:3.6611828804016113,explained_var_old:0.960484862,explained_var_new:0.990521669
output spend 0.00022514499141834676 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004435120994457975 time
recovery_state_mcts_prob spend 0.28876504801155534 time
state_batch spend 0.004193139000562951 time
mcts_probs_batch spend 0.00685613599489443 time
winner_batch spend 0.00026624699239619076 time
policy_value spend 0.2437863030063454 time
train_step spend 0.7073043380078161 time
policy_value spend 0.24043469999742229 time
train_step spend 0.707988052003202 time
policy_value spend 0.240934721994563 time
train_step spend 0.7075688610057114 time
policy_value spend 0.2420476499974029 time
train_step spend 0.7071338389941957 time
policy_value spend 0.24064902499958407 time
kl:0.09401,lr_multiplier:0.088,loss:2.9078736305236816,entropy:3.5868916511535645,explained_var_old:0.980862796,explained_var_new:0.986758590
output spend 0.00016710199997760355 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005155077000381425 time
recovery_state_mcts_prob spend 0.3103824409918161 time
state_batch spend 0.004537271001026966 time
mcts_probs_batch spend 0.008038567000767216 time
winner_batch spend 0.0002929799957200885 time
policy_value spend 0.2585617690056097 time
train_step spend 0.7325386089942185 time
policy_value spend 0.24066324600426015 time
train_step spend 0.7070246869989205 time
policy_value spend 0.2423781339894049 time
train_step spend 0.7089947580097942 time
policy_value spend 0.24048224299622234 time
train_step spend 0.7071328479942167 time
policy_value spend 0.24108213200815953 time
kl:0.08109,lr_multiplier:0.088,loss:3.0155327320098877,entropy:3.6850223541259766,explained_var_old:0.978629470,explained_var_new:0.974927187
output spend 0.0001830020046327263 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004590030002873391 time
recovery_state_mcts_prob spend 0.31769104998966213 time
state_batch spend 0.0037926759978290647 time
mcts_probs_batch spend 0.006672718009212986 time
winner_batch spend 0.00026780899497680366 time
policy_value spend 0.24222502400516532 time
train_step spend 0.7094266509957379 time
policy_value spend 0.24188650101132225 time
train_step spend 0.7074765400029719 time
policy_value spend 0.24001393299840856 time
train_step spend 0.7065354240039596 time
policy_value spend 0.24109735499951057 time
train_step spend 0.7070093030051794 time
policy_value spend 0.24177032000443432 time
kl:0.08006,lr_multiplier:0.088,loss:2.9106874465942383,entropy:3.6023645401000977,explained_var_old:0.980502784,explained_var_new:0.993873358
output spend 0.00025032299163285643 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005641620999085717 time
recovery_state_mcts_prob spend 0.28446093799720984 time
state_batch spend 0.0035228269989602268 time
mcts_probs_batch spend 0.007577476993901655 time
winner_batch spend 0.0005289079999784008 time
policy_value spend 0.24794882000423968 time
train_step spend 0.7150706880056532 time
policy_value spend 0.24459661699074786 time
train_step spend 0.7067176030104747 time
policy_value spend 0.24136221798835322 time
train_step spend 0.7069127279974055 time
policy_value spend 0.2414189230039483 time
train_step spend 0.7070079719997011 time
policy_value spend 0.24068895199161489 time
kl:0.11138,lr_multiplier:0.088,loss:2.8633813858032227,entropy:3.5449328422546387,explained_var_old:0.991211295,explained_var_new:0.987979472
output spend 0.0001673439983278513 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005219372003921308 time
recovery_state_mcts_prob spend 0.30341792000399437 time
state_batch spend 0.0047851739946054295 time
mcts_probs_batch spend 0.014410886011319235 time
winner_batch spend 0.00029341899789869785 time
policy_value spend 0.25065786999766715 time
train_step spend 0.7385885499970755 time
policy_value spend 0.2409304150060052 time
train_step spend 0.7091083599952981 time
policy_value spend 0.24099702900275588 time
train_step spend 0.7074203030060744 time
policy_value spend 0.24087960500037298 time
train_step spend 0.7082357720064465 time
policy_value spend 0.24076455399335828 time
kl:0.10327,lr_multiplier:0.088,loss:2.9790124893188477,entropy:3.654362678527832,explained_var_old:0.980418682,explained_var_new:0.989301026
output spend 0.00016601101378910244 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004865342998527922 time
recovery_state_mcts_prob spend 0.2928103839949472 time
state_batch spend 0.003580735996365547 time
mcts_probs_batch spend 0.013454533007461578 time
winner_batch spend 0.00030927899933885783 time
policy_value spend 0.24494392199267168 time
train_step spend 0.7066929299908224 time
policy_value spend 0.24307506400509737 time
train_step spend 0.7098600290046306 time
policy_value spend 0.2401925470039714 time
train_step spend 0.706505530004506 time
policy_value spend 0.24034877600206528 time
train_step spend 0.706893091002712 time
policy_value spend 0.2419338890031213 time
kl:0.08576,lr_multiplier:0.088,loss:2.9368786811828613,entropy:3.6513566970825195,explained_var_old:0.990161896,explained_var_new:0.988527358
output spend 0.0001845700026024133 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004676425000070594 time
recovery_state_mcts_prob spend 0.2864573810074944 time
state_batch spend 0.0031166010012384504 time
mcts_probs_batch spend 0.007080655996105634 time
winner_batch spend 0.00031717999081593007 time
policy_value spend 0.24326800100971013 time
train_step spend 0.7081731240032241 time
policy_value spend 0.2503524439962348 time
train_step spend 0.7072200430120574 time
policy_value spend 0.24285475099168252 time
train_step spend 0.707955530990148 time
policy_value spend 0.24147384701063856 time
train_step spend 0.7069540670054266 time
policy_value spend 0.24095326400129125 time
kl:0.09889,lr_multiplier:0.088,loss:2.92020845413208,entropy:3.5788064002990723,explained_var_old:0.980147421,explained_var_new:0.993755519
output spend 0.0001905530079966411 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004261341004166752 time
recovery_state_mcts_prob spend 0.3073109239921905 time
state_batch spend 0.0035728630027733743 time
mcts_probs_batch spend 0.007585090002976358 time
winner_batch spend 0.0002798570058075711 time
policy_value spend 0.24572429798718076 time
train_step spend 0.7107271640124964 time
policy_value spend 0.2414914409891935 time
train_step spend 0.7069193779898342 time
policy_value spend 0.24090044399781618 time
train_step spend 0.7091481590032345 time
policy_value spend 0.2408712329925038 time
train_step spend 0.7074065660126507 time
policy_value spend 0.24084781399869826 time
kl:0.09076,lr_multiplier:0.088,loss:3.001955032348633,entropy:3.6931047439575195,explained_var_old:0.988183677,explained_var_new:0.992796302
output spend 0.00020935000793542713 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005297733994666487 time
recovery_state_mcts_prob spend 0.2908943240036024 time
state_batch spend 0.0019563810055842623 time
mcts_probs_batch spend 0.007311143999686465 time
winner_batch spend 0.00027403699641581625 time
policy_value spend 0.2428764240030432 time
train_step spend 0.7087803199974587 time
policy_value spend 0.24050707698916085 time
train_step spend 0.7067001340037677 time
policy_value spend 0.24108704399259295 time
train_step spend 0.7074379519908689 time
policy_value spend 0.2428826149989618 time
train_step spend 0.7073696659936104 time
policy_value spend 0.2411050740047358 time
kl:0.09019,lr_multiplier:0.088,loss:2.9881277084350586,entropy:3.6675448417663574,explained_var_old:0.969026566,explained_var_new:0.907016516
output spend 0.00024281600781250745 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004497765999985859 time
recovery_state_mcts_prob spend 0.2858992340043187 time
state_batch spend 0.0035052299936069176 time
mcts_probs_batch spend 0.007305760009330697 time
winner_batch spend 0.00027496900293044746 time
policy_value spend 0.2426518329884857 time
train_step spend 0.7073315699963132 time
policy_value spend 0.24318035000760574 time
train_step spend 0.7072287149931071 time
policy_value spend 0.23996858799364418 time
train_step spend 0.7071339760004776 time
policy_value spend 0.24070916599885095 time
train_step spend 0.708876244010753 time
policy_value spend 0.23993664699082728 time
kl:0.08238,lr_multiplier:0.088,loss:2.9526312351226807,entropy:3.6444783210754395,explained_var_old:0.926621437,explained_var_new:0.983377218
output spend 0.00017307499365415424 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004761664007673971 time
recovery_state_mcts_prob spend 0.2942892099963501 time
state_batch spend 0.003774109994992614 time
mcts_probs_batch spend 0.013987896003527567 time
winner_batch spend 0.000260622997302562 time
policy_value spend 0.2449831389967585 time
train_step spend 0.7074630389979575 time
policy_value spend 0.24219718799577095 time
train_step spend 0.7060318129952066 time
policy_value spend 0.24128939099318814 time
train_step spend 0.7072024250082904 time
policy_value spend 0.24144571799843106 time
kl:0.08798,lr_multiplier:0.088,loss:3.004923105239868,entropy:3.684182643890381,explained_var_old:0.967448950,explained_var_new:0.835925937
output spend 0.00018574899877421558 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005097408997244202 time
recovery_state_mcts_prob spend 0.3031507790001342 time
state_batch spend 0.0019600509986048564 time
mcts_probs_batch spend 0.0073714799946174026 time
winner_batch spend 0.0002656319993548095 time
policy_value spend 0.24314583900559228 time
train_step spend 0.7061659219907597 time
policy_value spend 0.24175864300923422 time
train_step spend 0.7073838850046741 time
policy_value spend 0.24104709399398416 time
train_step spend 0.7065310190082528 time
policy_value spend 0.24144495200016536 time
train_step spend 0.706066215003375 time
policy_value spend 0.24124284599383827 time
kl:0.09519,lr_multiplier:0.088,loss:2.8966565132141113,entropy:3.5677809715270996,explained_var_old:0.835969925,explained_var_new:0.988429368
output spend 0.00016522999794688076 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004188626000541262 time
recovery_state_mcts_prob spend 0.2878241650032578 time
state_batch spend 0.00456301799567882 time
mcts_probs_batch spend 0.0071007609949447215 time
winner_batch spend 0.0003266139974584803 time
policy_value spend 0.24721631700231228 time
train_step spend 0.7109223989973543 time
policy_value spend 0.2412936710024951 time
train_step spend 0.7095551709935535 time
policy_value spend 0.24681023199809715 time
train_step spend 0.709088798990706 time
policy_value spend 0.2399473190016579 time
train_step spend 0.7069052250008099 time
policy_value spend 0.2458530809963122 time
kl:0.08345,lr_multiplier:0.088,loss:2.9407405853271484,entropy:3.6174535751342773,explained_var_old:0.989057183,explained_var_new:0.988528609
output spend 0.0008621169981779531 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004278491993318312 time
recovery_state_mcts_prob spend 0.31562199800100643 time
state_batch spend 0.003608828003052622 time
mcts_probs_batch spend 0.0124867910053581 time
winner_batch spend 0.00028920899785589427 time
policy_value spend 0.24499390998971649 time
train_step spend 0.7090757300029509 time
policy_value spend 0.24299094898742624 time
train_step spend 0.706885899999179 time
policy_value spend 0.24096543599443976 time
train_step spend 0.7070324809901649 time
policy_value spend 0.24030564400891308 time
train_step spend 0.7072642010025447 time
policy_value spend 0.24105131399119273 time
kl:0.10632,lr_multiplier:0.088,loss:2.910916566848755,entropy:3.5966358184814453,explained_var_old:0.969583571,explained_var_new:0.986492753
output spend 0.00017642200691625476 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004640464001568034 time
recovery_state_mcts_prob spend 0.2873277720063925 time
state_batch spend 0.0019947559922002256 time
mcts_probs_batch spend 0.0074054040014743805 time
winner_batch spend 0.00034295799559913576 time
policy_value spend 0.24490951000188943 time
train_step spend 0.7092217500030529 time
policy_value spend 0.24811482000222895 time
train_step spend 0.7088956179941306 time
policy_value spend 0.24177384701033588 time
train_step spend 0.7069426170055522 time
policy_value spend 0.241844404998119 time
train_step spend 0.7067050920013571 time
policy_value spend 0.24187245599750895 time
train_step spend 0.7061883399874205 time
policy_value spend 0.2487159150041407 time
kl:0.09365,lr_multiplier:0.088,loss:2.922873020172119,entropy:3.6048927307128906,explained_var_old:0.978564382,explained_var_new:0.981083751
output spend 0.00030418799724429846 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004254187995684333 time
recovery_state_mcts_prob spend 0.29875444900244474 time
state_batch spend 0.003776352998102084 time
mcts_probs_batch spend 0.007377644011285156 time
winner_batch spend 0.00029546099540311843 time
policy_value spend 0.24402221900527366 time
train_step spend 0.7066922189987963 time
policy_value spend 0.25815714499913156 time
train_step spend 0.7088896259956528 time
policy_value spend 0.24027947199647315 time
train_step spend 0.7061429210007191 time
policy_value spend 0.25320266500057187 time
train_step spend 0.711189880996244 time
policy_value spend 0.24140287800400984 time
kl:0.08651,lr_multiplier:0.088,loss:2.8842594623565674,entropy:3.5329456329345703,explained_var_old:0.974424005,explained_var_new:0.992662132
output spend 0.00016825100465212017 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004492236999794841 time
recovery_state_mcts_prob spend 0.31738935101020616 time
state_batch spend 0.004645294990041293 time
mcts_probs_batch spend 0.013922458005254157 time
winner_batch spend 0.00030725699616596103 time
policy_value spend 0.2450887960003456 time
train_step spend 0.7091238610009896 time
policy_value spend 0.2408080109889852 time
train_step spend 0.7094587190076709 time
policy_value spend 0.24018818099284545 time
train_step spend 0.7072707129991613 time
policy_value spend 0.2411218409979483 time
train_step spend 0.7084179369994672 time
policy_value spend 0.2412152570032049 time
kl:0.09110,lr_multiplier:0.088,loss:2.887362480163574,entropy:3.5606887340545654,explained_var_old:0.991556704,explained_var_new:0.986719429
output spend 0.00017428099818062037 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003994732993305661 time
recovery_state_mcts_prob spend 0.3843479520000983 time
state_batch spend 0.0053368980006780475 time
mcts_probs_batch spend 0.007912757006124593 time
winner_batch spend 0.000304229004541412 time
policy_value spend 0.24300623199087568 time
train_step spend 0.7096831250091782 time
policy_value spend 0.24181188699731138 time
train_step spend 0.7086991449905327 time
policy_value spend 0.24267684599908534 time
train_step spend 0.7065263519907603 time
policy_value spend 0.24099110800307244 time
train_step spend 0.7063460019999184 time
policy_value spend 0.24256600798980799 time
train_step spend 0.7065811339998618 time
policy_value spend 0.24117676199239213 time
kl:0.09585,lr_multiplier:0.088,loss:2.9550085067749023,entropy:3.642888307571411,explained_var_old:0.983893692,explained_var_new:0.987565756
output spend 0.00016990200674626976 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004764315992360935 time
recovery_state_mcts_prob spend 0.29105044101015665 time
state_batch spend 0.0043271649919915944 time
mcts_probs_batch spend 0.00689720299851615 time
winner_batch spend 0.00027171699912287295 time
policy_value spend 0.2593167870072648 time
train_step spend 0.7085030429880135 time
policy_value spend 0.2443029749993002 time
train_step spend 0.7094689789955737 time
policy_value spend 0.24514476700278465 time
train_step spend 0.7190879410045454 time
policy_value spend 0.24117945598845836 time
train_step spend 0.7082382570079062 time
policy_value spend 0.24039446499955375 time
kl:0.09406,lr_multiplier:0.088,loss:2.859168291091919,entropy:3.5204927921295166,explained_var_old:0.978386283,explained_var_new:0.994484007
output spend 0.00020600100106094033 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004388175992062315 time
recovery_state_mcts_prob spend 0.31403184800001327 time
state_batch spend 0.0036378050135681406 time
mcts_probs_batch spend 0.012199368997244164 time
winner_batch spend 0.00027844199212267995 time
policy_value spend 0.24564206000650302 time
train_step spend 0.7089035170065472 time
policy_value spend 0.24266928499855567 time
train_step spend 0.7112905480025802 time
policy_value spend 0.24063816999841947 time
train_step spend 0.7067578860005597 time
policy_value spend 0.2402542369964067 time
train_step spend 0.7090834889968392 time
policy_value spend 0.24157372700574342 time
kl:0.09377,lr_multiplier:0.088,loss:2.857395887374878,entropy:3.526007652282715,explained_var_old:0.980111718,explained_var_new:0.975602984
output spend 0.0002449989988235757 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0048247800004901364 time
recovery_state_mcts_prob spend 0.29707789000531193 time
state_batch spend 0.004253898005117662 time
mcts_probs_batch spend 0.007217712001875043 time
winner_batch spend 0.0002764870005194098 time
policy_value spend 0.24170240199600812 time
train_step spend 0.7078622690023622 time
policy_value spend 0.24083131899533328 time
train_step spend 0.7084679289982887 time
policy_value spend 0.24208931799512357 time
train_step spend 0.7068161259958288 time
policy_value spend 0.24070081500394735 time
train_step spend 0.7068294380005682 time
policy_value spend 0.24059950601076707 time
kl:0.09627,lr_multiplier:0.088,loss:2.852092981338501,entropy:3.5059895515441895,explained_var_old:0.966233790,explained_var_new:0.986751318
output spend 0.00017104600556194782 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003938396999728866 time
recovery_state_mcts_prob spend 0.28859141799330246 time
state_batch spend 0.0035697130078915507 time
mcts_probs_batch spend 0.0073857489915098995 time
winner_batch spend 0.0002770890132524073 time
policy_value spend 0.2470370329974685 time
train_step spend 0.7082273949927185 time
policy_value spend 0.24500290100695565 time
train_step spend 0.7076878999941982 time
policy_value spend 0.25297924599726684 time
train_step spend 0.7125294490106171 time
policy_value spend 0.24081538600148633 time
train_step spend 0.7070540499989875 time
policy_value spend 0.2406500969955232 time
train_step spend 0.7196757559868274 time
policy_value spend 0.24137571500614285 time
kl:0.09752,lr_multiplier:0.088,loss:2.8923277854919434,entropy:3.5647246837615967,explained_var_old:0.990271330,explained_var_new:0.987035155
output spend 0.00017939099052455276 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004136317002121359 time
recovery_state_mcts_prob spend 0.3217978679895168 time
state_batch spend 0.002091836999170482 time
mcts_probs_batch spend 0.011554390002856962 time
winner_batch spend 0.00027353000768925995 time
policy_value spend 0.24687466099567246 time
train_step spend 0.7121663840080146 time
policy_value spend 0.24058904498815536 time
train_step spend 0.7091588909970596 time
policy_value spend 0.24104344700754154 time
train_step spend 0.706819130005897 time
policy_value spend 0.24118843699397985 time
train_step spend 0.7070217999862507 time
policy_value spend 0.24061526900914032 time
kl:0.09474,lr_multiplier:0.088,loss:2.8774936199188232,entropy:3.5247156620025635,explained_var_old:0.977066457,explained_var_new:0.989585817
output spend 0.00016654600040055811 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004706762993009761 time
recovery_state_mcts_prob spend 0.37974652099364903 time
state_batch spend 0.003973463011789136 time
mcts_probs_batch spend 0.015913541996269487 time
winner_batch spend 0.00031203299295157194 time
policy_value spend 0.24967646900040563 time
train_step spend 0.7074745720019564 time
policy_value spend 0.2418331049993867 time
train_step spend 0.7076364149979781 time
policy_value spend 0.23999099699722137 time
train_step spend 0.7132422719878377 time
policy_value spend 0.24057571800949518 time
train_step spend 0.7068515879946062 time
policy_value spend 0.24221241399936844 time
kl:0.08641,lr_multiplier:0.088,loss:2.8762574195861816,entropy:3.5426783561706543,explained_var_old:0.985588968,explained_var_new:0.960772395
output spend 0.00017183700401801616 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00517001400294248 time
recovery_state_mcts_prob spend 0.3000050919945352 time
state_batch spend 0.004181349999271333 time
mcts_probs_batch spend 0.006409100999007933 time
winner_batch spend 0.00027873500948771834 time
policy_value spend 0.24263506798888557 time
train_step spend 0.7102531169948634 time
policy_value spend 0.2583037250005873 time
train_step spend 0.7096239509992301 time
policy_value spend 0.24181412599864416 time
train_step spend 0.7129695369949332 time
policy_value spend 0.2523281030007638 time
train_step spend 0.7101489860069705 time
policy_value spend 0.24076951498864219 time
kl:0.08581,lr_multiplier:0.088,loss:2.940553665161133,entropy:3.5862534046173096,explained_var_old:0.962010682,explained_var_new:0.988379717
output spend 0.000178027999936603 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00456706499971915 time
recovery_state_mcts_prob spend 0.2992453800106887 time
state_batch spend 0.0037063979980302975 time
mcts_probs_batch spend 0.007626107995747589 time
winner_batch spend 0.00028160899819340557 time
policy_value spend 0.24199351499555632 time
train_step spend 0.7081211839977186 time
policy_value spend 0.24154216999886557 time
train_step spend 0.7071020610019332 time
policy_value spend 0.241592053003842 time
train_step spend 0.7091447770071682 time
policy_value spend 0.24170632699679118 time
train_step spend 0.706747581003583 time
policy_value spend 0.24080812399915885 time
train_step spend 0.7074251969897887 time
policy_value spend 0.24185199200292118 time
kl:0.09215,lr_multiplier:0.088,loss:2.9205658435821533,entropy:3.5749926567077637,explained_var_old:0.980090618,explained_var_new:0.989780962
output spend 0.00016909599071368575 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005918063005083241 time
recovery_state_mcts_prob spend 0.29575267199834343 time
state_batch spend 0.0038677910051774234 time
mcts_probs_batch spend 0.006754795991582796 time
winner_batch spend 0.0003073249972658232 time
policy_value spend 0.24224099700222723 time
train_step spend 0.7064921529963613 time
policy_value spend 0.24198728600458708 time
train_step spend 0.7068057370051974 time
policy_value spend 0.24290040400228463 time
train_step spend 0.7081368729996029 time
policy_value spend 0.24292406100721564 time
train_step spend 0.7062608570122393 time
policy_value spend 0.24107686699426267 time
train_step spend 0.7061637050064746 time
policy_value spend 0.24997679798980244 time
kl:0.09846,lr_multiplier:0.088,loss:2.8226099014282227,entropy:3.5078773498535156,explained_var_old:0.990937352,explained_var_new:0.994708002
output spend 0.0002995109971379861 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005363881995435804 time
recovery_state_mcts_prob spend 0.2912694249971537 time
state_batch spend 0.0038999350072117522 time
mcts_probs_batch spend 0.007558340992545709 time
winner_batch spend 0.0002809850120684132 time
policy_value spend 0.2428888019931037 time
train_step spend 0.7146833349979715 time
policy_value spend 0.24105712199525442 time
train_step spend 0.7099700380058493 time
policy_value spend 0.24145715999475215 time
train_step spend 0.7068831759970635 time
policy_value spend 0.24068135100242216 time
kl:0.08145,lr_multiplier:0.088,loss:2.9164719581604004,entropy:3.586270809173584,explained_var_old:0.990283966,explained_var_new:0.984052539
output spend 0.00020857500203419477 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0037442210013978183 time
recovery_state_mcts_prob spend 0.35680184900411405 time
state_batch spend 0.0048210629902314395 time
mcts_probs_batch spend 0.0076183530036360025 time
winner_batch spend 0.00030621400219388306 time
policy_value spend 0.24237183399964124 time
train_step spend 0.708019024998066 time
policy_value spend 0.2404847569996491 time
train_step spend 0.7070168109930819 time
policy_value spend 0.241453510010615 time
train_step spend 0.7081375810084864 time
policy_value spend 0.2425378269981593 time
train_step spend 0.7077215600002091 time
policy_value spend 0.24211117401137017 time
kl:0.09314,lr_multiplier:0.088,loss:2.8692708015441895,entropy:3.555227041244507,explained_var_old:0.983306885,explained_var_new:0.993744135
output spend 0.00020971700723748654 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004176631002337672 time
recovery_state_mcts_prob spend 0.29355087799194735 time
state_batch spend 0.0038183300057426095 time
mcts_probs_batch spend 0.007657887996174395 time
winner_batch spend 0.0002679780009202659 time
policy_value spend 0.24213284500001464 time
train_step spend 0.7072235910018208 time
policy_value spend 0.2410172939999029 time
train_step spend 0.7069394909922266 time
policy_value spend 0.24024720300803892 time
train_step spend 0.7071221160003915 time
policy_value spend 0.2449943810061086 time
train_step spend 0.7097117069934029 time
policy_value spend 0.2413992479996523 time
kl:0.08355,lr_multiplier:0.088,loss:2.880495309829712,entropy:3.4972434043884277,explained_var_old:0.972374439,explained_var_new:0.979680955
output spend 0.00017460199887864292 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004622182008461095 time
recovery_state_mcts_prob spend 0.2813621239911299 time
state_batch spend 0.004148988999077119 time
mcts_probs_batch spend 0.006574842002009973 time
winner_batch spend 0.0002721920027397573 time
policy_value spend 0.2448342879943084 time
train_step spend 0.713943021997693 time
policy_value spend 0.240327146006166 time
train_step spend 0.7071359359979397 time
policy_value spend 0.24056873899826314 time
train_step spend 0.7063179279939504 time
policy_value spend 0.2407818089995999 time
train_step spend 0.7081423289928352 time
policy_value spend 0.24205686700588558 time
kl:0.08562,lr_multiplier:0.088,loss:2.9112844467163086,entropy:3.5845232009887695,explained_var_old:0.991185427,explained_var_new:0.997061610
output spend 0.00019707299361471087 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006264395997277461 time
recovery_state_mcts_prob spend 0.41506783600198105 time
state_batch spend 0.004777712005306967 time
mcts_probs_batch spend 0.017649790999712422 time
winner_batch spend 0.0003480320010567084 time
policy_value spend 0.2468585149908904 time
train_step spend 0.7140234999969834 time
policy_value spend 0.24306730499665719 time
train_step spend 0.7096246309956769 time
policy_value spend 0.24173672300821636 time
train_step spend 0.707026798001607 time
policy_value spend 0.24103187100263312 time
train_step spend 0.7098141750029754 time
policy_value spend 0.2453516719979234 time
kl:0.08437,lr_multiplier:0.088,loss:2.8557231426239014,entropy:3.519801139831543,explained_var_old:0.991750836,explained_var_new:0.991302192
output spend 0.00021312499302439392 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005593966008746065 time
recovery_state_mcts_prob spend 0.38890389999141917 time
state_batch spend 0.006330336007522419 time
mcts_probs_batch spend 0.00827542100159917 time
winner_batch spend 0.00031691198819316924 time
policy_value spend 0.24389381900255103 time
train_step spend 0.707298379013082 time
policy_value spend 0.24555093598610256 time
train_step spend 0.7101352449972183 time
policy_value spend 0.24131827199016698 time
train_step spend 0.7080420280108228 time
policy_value spend 0.24215229898982216 time
train_step spend 0.707331350989989 time
policy_value spend 0.2421200530079659 time
kl:0.09979,lr_multiplier:0.088,loss:2.868607521057129,entropy:3.478271722793579,explained_var_old:0.979804397,explained_var_new:0.982701719
output spend 0.00016776000848039985 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004244527008268051 time
recovery_state_mcts_prob spend 0.39917800699186046 time
state_batch spend 0.00257977400906384 time
mcts_probs_batch spend 0.006032678997144103 time
winner_batch spend 0.0003051130042877048 time
policy_value spend 0.2415534689935157 time
train_step spend 0.7074011359945871 time
policy_value spend 0.24115824399632402 time
train_step spend 0.7073455629870296 time
policy_value spend 0.24079254601383582 time
train_step spend 0.7067196970019722 time
policy_value spend 0.24075862299650908 time
train_step spend 0.7070566699985648 time
policy_value spend 0.24027160900004674 time
kl:0.09835,lr_multiplier:0.088,loss:2.858219623565674,entropy:3.492990016937256,explained_var_old:0.966830373,explained_var_new:0.986220956
output spend 0.00018300599185749888 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007994466010131873 time
recovery_state_mcts_prob spend 0.4357159279898042 time
state_batch spend 0.0022004760103300214 time
mcts_probs_batch spend 0.004809734993614256 time
winner_batch spend 0.0002818119974108413 time
policy_value spend 0.24200185500376392 time
train_step spend 0.7080026970070321 time
policy_value spend 0.2474681129970122 time
train_step spend 0.7100761339970632 time
policy_value spend 0.24069042499468196 time
train_step spend 0.7068705030105775 time
policy_value spend 0.24112197899376042 time
train_step spend 0.7065724119893275 time
policy_value spend 0.24161926700617187 time
kl:0.08515,lr_multiplier:0.088,loss:2.9118356704711914,entropy:3.5539331436157227,explained_var_old:0.977980316,explained_var_new:0.984230816
output spend 0.00016693900397513062 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005129142999066971 time
recovery_state_mcts_prob spend 0.29071937799744774 time
state_batch spend 0.0035387560055823997 time
mcts_probs_batch spend 0.008085623994702473 time
winner_batch spend 0.0002686360094230622 time
policy_value spend 0.2440038700005971 time
train_step spend 0.7069142849941272 time
policy_value spend 0.24657046599895693 time
train_step spend 0.7072850669937907 time
policy_value spend 0.24048215700895526 time
train_step spend 0.7069537820061669 time
policy_value spend 0.24030922699603252 time
train_step spend 0.70646015300008 time
policy_value spend 0.24022666199016385 time
kl:0.10633,lr_multiplier:0.088,loss:2.92730975151062,entropy:3.5626325607299805,explained_var_old:0.976767361,explained_var_new:0.981084287
output spend 0.00016858900198712945 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.009648813007515855 time
recovery_state_mcts_prob spend 0.43918243699590676 time
state_batch spend 0.0028855970012955368 time
mcts_probs_batch spend 0.011634387003141455 time
winner_batch spend 0.0002757699985522777 time
policy_value spend 0.246462437993614 time
train_step spend 0.7099816739937523 time
policy_value spend 0.24161607499991078 time
train_step spend 0.7060916329937754 time
policy_value spend 0.24060310301138088 time
train_step spend 0.7067401629901724 time
policy_value spend 0.24059594600112177 time
train_step spend 0.7071297289949143 time
policy_value spend 0.24054877000162378 time
kl:0.08266,lr_multiplier:0.088,loss:2.92498779296875,entropy:3.5482218265533447,explained_var_old:0.970665932,explained_var_new:0.981865168
output spend 0.00016665800649207085 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003876295988447964 time
recovery_state_mcts_prob spend 0.2952515570068499 time
state_batch spend 0.0031536110036540776 time
mcts_probs_batch spend 0.00649563099432271 time
winner_batch spend 0.00031157099874690175 time
policy_value spend 0.24163761800446082 time
train_step spend 0.7192633209924679 time
policy_value spend 0.24388662799901795 time
train_step spend 0.7071480939921457 time
policy_value spend 0.24057919101323932 time
train_step spend 0.7068861719890265 time
policy_value spend 0.24061928800074384 time
train_step spend 0.7065672270109644 time
policy_value spend 0.2411484299955191 time
kl:0.09266,lr_multiplier:0.088,loss:2.9432919025421143,entropy:3.5839078426361084,explained_var_old:0.989744186,explained_var_new:0.988468409
output spend 0.00016689900076016784 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0033171679970109835 time
recovery_state_mcts_prob spend 0.2846352839987958 time
state_batch spend 0.002135551010724157 time
mcts_probs_batch spend 0.006186977989273146 time
winner_batch spend 0.00028622000536415726 time
policy_value spend 0.24264747799315955 time
train_step spend 0.7089133330009645 time
policy_value spend 0.24224609701195732 time
train_step spend 0.7087962340010563 time
policy_value spend 0.2412770460068714 time
train_step spend 0.7069570430030581 time
policy_value spend 0.24073443398810923 time
train_step spend 0.7066014239971992 time
policy_value spend 0.2401599110016832 time
kl:0.08847,lr_multiplier:0.088,loss:2.964271306991577,entropy:3.6149091720581055,explained_var_old:0.987106442,explained_var_new:0.986401677
output spend 0.00016467299428768456 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004391159993247129 time
recovery_state_mcts_prob spend 0.38036133800051175 time
state_batch spend 0.001975466002477333 time
mcts_probs_batch spend 0.006820178998168558 time
winner_batch spend 0.00028064400248695165 time
policy_value spend 0.2428840280044824 time
train_step spend 0.7078469949919963 time
policy_value spend 0.24137098400387913 time
train_step spend 0.7108243929978926 time
policy_value spend 0.24055534700164571 time
train_step spend 0.7066528690047562 time
policy_value spend 0.24210916500305757 time
kl:0.08471,lr_multiplier:0.088,loss:2.8613831996917725,entropy:3.499554395675659,explained_var_old:0.965989053,explained_var_new:0.986670673
output spend 0.0002348849957343191 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005534390002139844 time
recovery_state_mcts_prob spend 0.5681283769954462 time
state_batch spend 0.004787636004039086 time
mcts_probs_batch spend 0.008832074992824346 time
winner_batch spend 0.0003800940030487254 time
policy_value spend 0.2461646970041329 time
train_step spend 0.7084646610019263 time
policy_value spend 0.24535904701042455 time
train_step spend 0.7078192890039645 time
policy_value spend 0.24354377700365148 time
train_step spend 0.7101233249995857 time
policy_value spend 0.2425565209996421 time
train_step spend 0.7083504019974498 time
policy_value spend 0.24229561499669217 time
kl:0.10550,lr_multiplier:0.088,loss:2.9365692138671875,entropy:3.5933713912963867,explained_var_old:0.989927471,explained_var_new:0.991228044
output spend 0.0003977590095018968 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.010695636010495946 time
recovery_state_mcts_prob spend 0.48366378899663687 time
state_batch spend 0.00247841099917423 time
mcts_probs_batch spend 0.011110945997643284 time
winner_batch spend 0.00033666299714241177 time
policy_value spend 0.24617578300239984 time
train_step spend 0.7101797619980061 time
policy_value spend 0.24259399699803907 time
train_step spend 0.7082022420072462 time
policy_value spend 0.2408333589992253 time
train_step spend 0.7098503650049679 time
policy_value spend 0.24025053800141905 time
train_step spend 0.7065472179965582 time
policy_value spend 0.24013230700802524 time
kl:0.08261,lr_multiplier:0.088,loss:2.859086513519287,entropy:3.517350673675537,explained_var_old:0.985106587,explained_var_new:0.945321143
output spend 0.0001743729953886941 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005319222997059114 time
recovery_state_mcts_prob spend 0.35932918000617065 time
state_batch spend 0.0032069680019048974 time
mcts_probs_batch spend 0.006426758001907729 time
winner_batch spend 0.00027891599165741354 time
policy_value spend 0.24190556100802496 time
train_step spend 0.7069541969976854 time
policy_value spend 0.2416600480064517 time
train_step spend 0.70705648198782 time
policy_value spend 0.24075240700040013 time
train_step spend 0.707813389992225 time
policy_value spend 0.24173149499983992 time
train_step spend 0.7069112449971726 time
policy_value spend 0.2413792870065663 time
train_step spend 0.7068838739942294 time
policy_value spend 0.2403410640108632 time
kl:0.10002,lr_multiplier:0.088,loss:2.8483726978302,entropy:3.463320732116699,explained_var_old:0.931677222,explained_var_new:0.989391625
output spend 0.00016642900300212204 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003947678997064941 time
recovery_state_mcts_prob spend 0.28770809700654354 time
state_batch spend 0.003993876001914032 time
mcts_probs_batch spend 0.007955010994919576 time
winner_batch spend 0.0002765829995041713 time
policy_value spend 0.24290175600617658 time
train_step spend 0.7069900450005662 time
policy_value spend 0.24086474199430086 time
train_step spend 0.7061748989945045 time
policy_value spend 0.24437085099634714 time
train_step spend 0.7089757859939709 time
policy_value spend 0.24079299600271042 time
train_step spend 0.706470288001583 time
policy_value spend 0.2407617969874991 time
train_step spend 0.7071261510136537 time
policy_value spend 0.2404457079974236 time
kl:0.09441,lr_multiplier:0.088,loss:2.8620216846466064,entropy:3.4860458374023438,explained_var_old:0.987863421,explained_var_new:0.989875436
output spend 0.00017615899560041726 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004108284992980771 time
recovery_state_mcts_prob spend 0.29712330900656525 time
state_batch spend 0.0037685619900003076 time
mcts_probs_batch spend 0.013605005005956627 time
winner_batch spend 0.00026974300271831453 time
policy_value spend 0.24491459799173754 time
train_step spend 0.706881999009056 time
policy_value spend 0.24313610499666538 time
train_step spend 0.7090426859940635 time
policy_value spend 0.2405037819989957 time
train_step spend 0.7065940760076046 time
policy_value spend 0.2408964819915127 time
train_step spend 0.7075081649963977 time
policy_value spend 0.24070210799982306 time
kl:0.08191,lr_multiplier:0.088,loss:2.85488224029541,entropy:3.462555408477783,explained_var_old:0.988480985,explained_var_new:0.991575122
output spend 0.00025777700648177415 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005473976998473518 time
recovery_state_mcts_prob spend 0.2941722249961458 time
state_batch spend 0.004219027003273368 time
mcts_probs_batch spend 0.007454709004377946 time
winner_batch spend 0.00027406700246501714 time
policy_value spend 0.24239705099898856 time
train_step spend 0.7082548330072314 time
policy_value spend 0.2410021109972149 time
train_step spend 0.706648370003677 time
policy_value spend 0.25190353200014215 time
train_step spend 0.7079904670099495 time
policy_value spend 0.24039058599737473 time
train_step spend 0.7072192810010165 time
policy_value spend 0.25059627200243995 time
kl:0.08736,lr_multiplier:0.088,loss:2.8534460067749023,entropy:3.5031824111938477,explained_var_old:0.993377745,explained_var_new:0.993812680
output spend 0.0005931839987169951 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004036691985675134 time
recovery_state_mcts_prob spend 0.28898982900136616 time
state_batch spend 0.005133081009262241 time
mcts_probs_batch spend 0.006840736998128705 time
winner_batch spend 0.0002902859996538609 time
policy_value spend 0.24335219799831975 time
train_step spend 0.7075352200045018 time
policy_value spend 0.24086834699846804 time
train_step spend 0.708492240999476 time
policy_value spend 0.24149445100920275 time
train_step spend 0.709538959999918 time
policy_value spend 0.24042702300357632 time
train_step spend 0.7075622699921951 time
policy_value spend 0.24074344600376207 time
train_step spend 0.7072433249995811 time
policy_value spend 0.24072231000172906 time
kl:0.10759,lr_multiplier:0.088,loss:2.8244192600250244,entropy:3.46248459815979,explained_var_old:0.985245347,explained_var_new:0.993727684
output spend 0.00016502199287060648 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004791828992892988 time
recovery_state_mcts_prob spend 0.39149531901057344 time
state_batch spend 0.0035582049895310774 time
mcts_probs_batch spend 0.013434958003927022 time
winner_batch spend 0.0002832729951478541 time
policy_value spend 0.24507725500734523 time
train_step spend 0.706891412002733 time
policy_value spend 0.24134147400036454 time
train_step spend 0.7082351399876643 time
policy_value spend 0.24278901801153552 time
train_step spend 0.7064241240004776 time
policy_value spend 0.24070192100771237 time
train_step spend 0.7069155799981672 time
policy_value spend 0.24198762900778092 time
kl:0.08441,lr_multiplier:0.088,loss:2.8710548877716064,entropy:3.5186097621917725,explained_var_old:0.991951108,explained_var_new:0.992151439
output spend 0.00043020700104534626 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004374598007416353 time
recovery_state_mcts_prob spend 0.29279414399934467 time
state_batch spend 0.001989436990697868 time
mcts_probs_batch spend 0.00863075400411617 time
winner_batch spend 0.00030093800160102546 time
policy_value spend 0.242385628996999 time
train_step spend 0.7075899570045294 time
policy_value spend 0.24334430899762083 time
train_step spend 0.713573456989252 time
policy_value spend 0.24273348299902864 time
train_step spend 0.7074273969919886 time
policy_value spend 0.24896581600478385 time
train_step spend 0.7079577929980587 time
policy_value spend 0.2408728570007952 time
train_step spend 0.7074774489883566 time
policy_value spend 0.24900932000309695 time
kl:0.08356,lr_multiplier:0.088,loss:2.842068672180176,entropy:3.4612574577331543,explained_var_old:0.982801497,explained_var_new:0.988122642
output spend 0.0007888730033300817 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004251348989782855 time
recovery_state_mcts_prob spend 0.2973756819992559 time
state_batch spend 0.004210762010188773 time
mcts_probs_batch spend 0.00798050599405542 time
winner_batch spend 0.00028629100415855646 time
policy_value spend 0.24392720199830364 time
train_step spend 0.71058021299541 time
policy_value spend 0.24362291900615674 time
train_step spend 0.7102900350000709 time
policy_value spend 0.24114831199403852 time
train_step spend 0.7063418280013138 time
policy_value spend 0.24039591000473592 time
train_step spend 0.7067502720019547 time
policy_value spend 0.24038278199441265 time
train_step spend 0.7069791970134247 time
policy_value spend 0.24076077599602286 time
kl:0.10097,lr_multiplier:0.088,loss:2.782714605331421,entropy:3.4357662200927734,explained_var_old:0.990809441,explained_var_new:0.996565700
output spend 0.0005475459911394864 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004620995998266153 time
recovery_state_mcts_prob spend 0.3720884620124707 time
state_batch spend 0.0036826519935857505 time
mcts_probs_batch spend 0.00728626899945084 time
winner_batch spend 0.0003034639958059415 time
policy_value spend 0.24301140299940016 time
train_step spend 0.7109825399966212 time
policy_value spend 0.2424373959947843 time
train_step spend 0.7089634669973748 time
policy_value spend 0.24053623600048013 time
train_step spend 0.7071255500050029 time
policy_value spend 0.24056149400712457 time
train_step spend 0.7066440749913454 time
policy_value spend 0.24046602001180872 time
kl:0.08751,lr_multiplier:0.088,loss:2.885056734085083,entropy:3.5042386054992676,explained_var_old:0.980932534,explained_var_new:0.989673018
output spend 0.00016897400200832635 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007034125010250136 time
recovery_state_mcts_prob spend 0.32756196398986503 time
state_batch spend 0.006077054000343196 time
mcts_probs_batch spend 0.010671463998733088 time
winner_batch spend 0.0004169140011072159 time
policy_value spend 0.24299882299965248 time
train_step spend 0.7073487869929522 time
policy_value spend 0.24406216699571814 time
train_step spend 0.7100800229964079 time
policy_value spend 0.2404660049942322 time
train_step spend 0.7105025379860308 time
policy_value spend 0.24801100700278766 time
train_step spend 0.7074836190004135 time
policy_value spend 0.2401836280041607 time
kl:0.08824,lr_multiplier:0.088,loss:2.9105753898620605,entropy:3.5850675106048584,explained_var_old:0.989287913,explained_var_new:0.991154850
output spend 0.00017006699636112899 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004290445998776704 time
recovery_state_mcts_prob spend 0.28327003300364595 time
state_batch spend 0.002513865998480469 time
mcts_probs_batch spend 0.005991112004267052 time
winner_batch spend 0.00027081399457529187 time
policy_value spend 0.2421295850072056 time
train_step spend 0.7075718620035332 time
policy_value spend 0.24080066199530847 time
train_step spend 0.707395680990885 time
policy_value spend 0.24253925900848117 time
train_step spend 0.7065894779952941 time
policy_value spend 0.24102447500627022 time
train_step spend 0.7070695290021831 time
policy_value spend 0.24046632200770546 time
train_step spend 0.707242557007703 time
policy_value spend 0.24079867100226693 time
kl:0.09877,lr_multiplier:0.088,loss:2.8377301692962646,entropy:3.478917360305786,explained_var_old:0.993857563,explained_var_new:0.986491919
output spend 0.0002189980004914105 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005433887999970466 time
recovery_state_mcts_prob spend 0.28284804499708116 time
state_batch spend 0.002114782007993199 time
mcts_probs_batch spend 0.004733722991659306 time
winner_batch spend 0.0006307180010480806 time
policy_value spend 0.2408644240058493 time
train_step spend 0.7070338009943953 time
policy_value spend 0.24253846000647172 time
train_step spend 0.70994672300003 time
policy_value spend 0.2409957559866598 time
train_step spend 0.7071746900037397 time
policy_value spend 0.2403888580010971 time
train_step spend 0.7068110359978164 time
policy_value spend 0.24074380200181622 time
train_step spend 0.706583559003775 time
policy_value spend 0.24085916100011673 time
kl:0.09894,lr_multiplier:0.088,loss:2.868807315826416,entropy:3.488046169281006,explained_var_old:0.957840800,explained_var_new:0.982868314
output spend 0.00017446500714868307 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0043695290078176185 time
recovery_state_mcts_prob spend 0.3154547129961429 time
state_batch spend 0.004240137001033872 time
mcts_probs_batch spend 0.015368955006124452 time
winner_batch spend 0.0003269989974796772 time
policy_value spend 0.2456248069938738 time
train_step spend 0.7063503579993267 time
policy_value spend 0.24353920100838877 time
train_step spend 0.708553412987385 time
policy_value spend 0.24316025800362695 time
train_step spend 0.7076675559947034 time
policy_value spend 0.2424846790090669 time
train_step spend 0.707101274994784 time
policy_value spend 0.2418090220016893 time
kl:0.08133,lr_multiplier:0.088,loss:2.817197799682617,entropy:3.457740306854248,explained_var_old:0.985208929,explained_var_new:0.987264812
output spend 0.00016269300249405205 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0048643689951859415 time
recovery_state_mcts_prob spend 0.283268395010964 time
state_batch spend 0.00204640299489256 time
mcts_probs_batch spend 0.007313159003388137 time
winner_batch spend 0.00027885899180546403 time
policy_value spend 0.24462399201001972 time
train_step spend 0.7091502700059209 time
policy_value spend 0.2724787879997166 time
train_step spend 0.7249979869957315 time
policy_value spend 0.24202937200607266 time
train_step spend 0.7071485459891846 time
policy_value spend 0.2407386539998697 time
train_step spend 0.7074894640099956 time
policy_value spend 0.25203515800239984 time
train_step spend 0.7119199049921008 time
policy_value spend 0.24059957500139717 time
kl:0.10204,lr_multiplier:0.088,loss:2.8710124492645264,entropy:3.483086109161377,explained_var_old:0.974167585,explained_var_new:0.955342889
output spend 0.0001656989916227758 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006428906010114588 time
recovery_state_mcts_prob spend 0.4147056980000343 time
state_batch spend 0.006304397989879362 time
mcts_probs_batch spend 0.01885824100463651 time
winner_batch spend 0.00029609100602101535 time
policy_value spend 0.24216021900065243 time
train_step spend 0.7100459109933581 time
policy_value spend 0.241445626001223 time
train_step spend 0.708610628003953 time
policy_value spend 0.24124967100215144 time
train_step spend 0.7074779450049391 time
policy_value spend 0.24085471499711275 time
train_step spend 0.707101659005275 time
policy_value spend 0.24068134000117425 time
kl:0.08705,lr_multiplier:0.088,loss:2.869123935699463,entropy:3.478867769241333,explained_var_old:0.937022209,explained_var_new:0.916186452
output spend 0.00016717099060770124 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006462354998802766 time
recovery_state_mcts_prob spend 0.3417681949940743 time
state_batch spend 0.0037919120077276602 time
mcts_probs_batch spend 0.012333999999100342 time
winner_batch spend 0.00028793599631171674 time
policy_value spend 0.24487811799917836 time
train_step spend 0.7066993530024774 time
policy_value spend 0.2418654869979946 time
train_step spend 0.708296719007194 time
policy_value spend 0.2658820179931354 time
train_step spend 0.7111213919997681 time
policy_value spend 0.2739176980103366 time
train_step spend 0.7097445089893881 time
policy_value spend 0.2580231830070261 time
kl:0.09433,lr_multiplier:0.088,loss:2.8843986988067627,entropy:3.493283748626709,explained_var_old:0.923618734,explained_var_new:0.978374839
output spend 0.000246702998992987 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004625560992280953 time
recovery_state_mcts_prob spend 0.3014451170020038 time
state_batch spend 0.003648577010608278 time
mcts_probs_batch spend 0.007227822992717847 time
winner_batch spend 0.0002690450055524707 time
policy_value spend 0.24188802899152506 time
train_step spend 0.7063205770100467 time
policy_value spend 0.24184185299964156 time
train_step spend 0.709583678006311 time
policy_value spend 0.24188216098991688 time
train_step spend 0.7063421129860217 time
policy_value spend 0.24109876400325447 time
train_step spend 0.7063751259993296 time
policy_value spend 0.24177109000447672 time
train_step spend 0.7064664490026189 time
policy_value spend 0.24051815300481394 time
kl:0.08579,lr_multiplier:0.088,loss:2.9237618446350098,entropy:3.557586193084717,explained_var_old:0.974107802,explained_var_new:0.992093861
output spend 0.00016478600446134806 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005224713997449726 time
recovery_state_mcts_prob spend 0.3618802359997062 time
state_batch spend 0.002209603990195319 time
mcts_probs_batch spend 0.020436569000594318 time
winner_batch spend 0.00029520600219257176 time
policy_value spend 0.24458626100386027 time
train_step spend 0.7165234480053186 time
policy_value spend 0.2406781210011104 time
train_step spend 0.7085796269966522 time
policy_value spend 0.24137191199406516 time
train_step spend 0.7070601759915007 time
policy_value spend 0.24017278000246733 time
train_step spend 0.7120262199896388 time
policy_value spend 0.24093511200044304 time
kl:0.08086,lr_multiplier:0.088,loss:2.8509762287139893,entropy:3.4596712589263916,explained_var_old:0.980758250,explained_var_new:0.991276324
output spend 0.00016736199904698879 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0038535310013685375 time
recovery_state_mcts_prob spend 0.3021922949992586 time
state_batch spend 0.003066478995606303 time
mcts_probs_batch spend 0.012710670998785645 time
winner_batch spend 0.0002919830003520474 time
policy_value spend 0.24526628499734215 time
train_step spend 0.7088504650018876 time
policy_value spend 0.24162646899640094 time
train_step spend 0.7093232449988136 time
policy_value spend 0.24059164700156543 time
train_step spend 0.7079372060106834 time
policy_value spend 0.2437784319918137 time
train_step spend 0.7076690149988281 time
policy_value spend 0.24303421498916578 time
train_step spend 0.7131050250027329 time
policy_value spend 0.25499388099706266 time
kl:0.09826,lr_multiplier:0.088,loss:2.9067635536193848,entropy:3.511700391769409,explained_var_old:0.968389988,explained_var_new:0.984840453
output spend 0.0002975209936266765 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0037646710115950555 time
recovery_state_mcts_prob spend 0.30135899598826654 time
state_batch spend 0.004128157001105137 time
mcts_probs_batch spend 0.007478635001461953 time
winner_batch spend 0.0002707009989535436 time
policy_value spend 0.24190410600567702 time
train_step spend 0.7070633830007864 time
policy_value spend 0.24350405199220404 time
train_step spend 0.7092420639964985 time
policy_value spend 0.2406289330101572 time
train_step spend 0.7070233190024737 time
policy_value spend 0.24150579700653907 time
train_step spend 0.7069480439968174 time
policy_value spend 0.24069706400041468 time
train_step spend 0.7062703760020668 time
policy_value spend 0.24069138900085818 time
kl:0.10244,lr_multiplier:0.088,loss:2.8376526832580566,entropy:3.451751947402954,explained_var_old:0.984060466,explained_var_new:0.988094449
output spend 0.0001884099910967052 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004548754994175397 time
recovery_state_mcts_prob spend 0.3576770950021455 time
state_batch spend 0.004209626000374556 time
mcts_probs_batch spend 0.00792940499377437 time
winner_batch spend 0.0002798140048980713 time
policy_value spend 0.2423731150047388 time
train_step spend 0.7073687499942025 time
policy_value spend 0.24733984500926454 time
train_step spend 0.7083654529997148 time
policy_value spend 0.24105832100030966 time
train_step spend 0.7066932669986272 time
policy_value spend 0.24108210499980487 time
train_step spend 0.7070592530071735 time
policy_value spend 0.24036095300107263 time
kl:0.08039,lr_multiplier:0.088,loss:2.827291965484619,entropy:3.4752917289733887,explained_var_old:0.993704557,explained_var_new:0.996536195
output spend 0.00016949500422924757 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004869166994467378 time
recovery_state_mcts_prob spend 0.290034839999862 time
state_batch spend 0.0020637780107790604 time
mcts_probs_batch spend 0.007290369991096668 time
winner_batch spend 0.00027101399609819055 time
policy_value spend 0.24232497900084127 time
train_step spend 0.7124523050006246 time
policy_value spend 0.25671576701279264 time
train_step spend 0.7114362470019842 time
policy_value spend 0.24088430100528058 time
train_step spend 0.7064918399992166 time
policy_value spend 0.2541982660040958 time
train_step spend 0.7078523309901357 time
policy_value spend 0.24857826200604904 time
kl:0.10334,lr_multiplier:0.088,loss:2.7399799823760986,entropy:3.3684539794921875,explained_var_old:0.989510536,explained_var_new:0.996390700
output spend 0.0005783619999419898 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.009279331003199331 time
recovery_state_mcts_prob spend 0.6413848649972351 time
state_batch spend 0.005532997005502693 time
mcts_probs_batch spend 0.020067568999365903 time
winner_batch spend 0.0003614529996411875 time
policy_value spend 0.25154943999950774 time
train_step spend 0.709141974002705 time
policy_value spend 0.2497019599977648 time
train_step spend 0.7193423010030529 time
policy_value spend 0.24067359299806412 time
train_step spend 0.7065283859992633 time
policy_value spend 0.24018500999954995 time
train_step spend 0.7070470429898705 time
policy_value spend 0.24082987000292633 time
train_step spend 0.7070261100016069 time
policy_value spend 0.24048608700104523 time
kl:0.08902,lr_multiplier:0.088,loss:2.7940080165863037,entropy:3.4067423343658447,explained_var_old:0.994943619,explained_var_new:0.995923460
output spend 0.0001706769980955869 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004864529997576028 time
recovery_state_mcts_prob spend 0.3049164789990755 time
state_batch spend 0.003943365009035915 time
mcts_probs_batch spend 0.007290672991075553 time
winner_batch spend 0.0002987660118378699 time
policy_value spend 0.25082513300003484 time
train_step spend 0.7109497799974633 time
policy_value spend 0.2421165810083039 time
train_step spend 0.7088912449980853 time
policy_value spend 0.2422457569919061 time
train_step spend 0.7128055379871512 time
policy_value spend 0.2407949080079561 time
train_step spend 0.7072568330040667 time
policy_value spend 0.2403209030017024 time
train_step spend 0.7077684609976131 time
policy_value spend 0.24071993101097178 time
kl:0.09839,lr_multiplier:0.088,loss:2.8030622005462646,entropy:3.447618007659912,explained_var_old:0.989920974,explained_var_new:0.994207680
output spend 0.00021740399824921042 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0045268159883562475 time
recovery_state_mcts_prob spend 0.2868070070107933 time
state_batch spend 0.004313177996664308 time
mcts_probs_batch spend 0.007851984992157668 time
winner_batch spend 0.00028875700081698596 time
policy_value spend 0.24238057600450702 time
train_step spend 0.7060862609941978 time
policy_value spend 0.24338345900468994 time
train_step spend 0.707656764992862 time
policy_value spend 0.24136788300529588 time
train_step spend 0.7065251080057351 time
policy_value spend 0.2412633539934177 time
train_step spend 0.7064641530014342 time
policy_value spend 0.24120931200741325 time
train_step spend 0.706598335003946 time
policy_value spend 0.24090213600720745 time
kl:0.10338,lr_multiplier:0.088,loss:2.9678893089294434,entropy:3.5818843841552734,explained_var_old:0.980321407,explained_var_new:0.991261005
output spend 0.00017946699517779052 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003921938012354076 time
recovery_state_mcts_prob spend 0.2928972099907696 time
state_batch spend 0.0025517419999232516 time
mcts_probs_batch spend 0.006321332009974867 time
winner_batch spend 0.0002694719878491014 time
policy_value spend 0.24310343099932652 time
train_step spend 0.7064519910054514 time
policy_value spend 0.24603609599580523 time
train_step spend 0.7077888769999845 time
policy_value spend 0.24074506699980702 time
train_step spend 0.7067892670020228 time
policy_value spend 0.24361576499359217 time
train_step spend 0.7066966790007427 time
policy_value spend 0.24104043999977876 time
train_step spend 0.7072503340023104 time
policy_value spend 0.2530917060066713 time
kl:0.08659,lr_multiplier:0.088,loss:2.8553638458251953,entropy:3.4653143882751465,explained_var_old:0.983063459,explained_var_new:0.989790022
output spend 0.0007595330098411068 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0046417560079135 time
recovery_state_mcts_prob spend 0.31423720699967816 time
state_batch spend 0.002550357996369712 time
mcts_probs_batch spend 0.008418530997005291 time
winner_batch spend 0.000327303001540713 time
policy_value spend 0.24439190600242 time
train_step spend 0.7086120099993423 time
policy_value spend 0.24208137100504246 time
train_step spend 0.708189801996923 time
policy_value spend 0.24066800699802116 time
train_step spend 0.7072467349935323 time
policy_value spend 0.24038539199682418 time
train_step spend 0.7065354990045307 time
policy_value spend 0.24097043799702078 time
kl:0.08762,lr_multiplier:0.088,loss:2.875147819519043,entropy:3.474815845489502,explained_var_old:0.978497744,explained_var_new:0.982139230
output spend 0.00016839300224091858 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0049999909970210865 time
recovery_state_mcts_prob spend 0.2988191500044195 time
state_batch spend 0.0037096680025570095 time
mcts_probs_batch spend 0.007399479000014253 time
winner_batch spend 0.0002870739990612492 time
policy_value spend 0.24353918099950533 time
train_step spend 0.7061987559864065 time
policy_value spend 0.24177121301181614 time
train_step spend 0.7094623540033353 time
policy_value spend 0.2404898380045779 time
train_step spend 0.7065904199989745 time
policy_value spend 0.24083867800072767 time
train_step spend 0.707159582991153 time
policy_value spend 0.2411804720031796 time
train_step spend 0.7074488509970251 time
policy_value spend 0.24283497600117698 time
kl:0.09293,lr_multiplier:0.088,loss:2.842445135116577,entropy:3.4600002765655518,explained_var_old:0.988938034,explained_var_new:0.869682908
output spend 0.0001664019946474582 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004997109994292259 time
recovery_state_mcts_prob spend 0.2930131920002168 time
state_batch spend 0.004005877010058612 time
mcts_probs_batch spend 0.006903224988491274 time
winner_batch spend 0.00029286900826264173 time
policy_value spend 0.2412438489991473 time
train_step spend 0.7067311259888811 time
policy_value spend 0.24614405100874137 time
train_step spend 0.7316343870043056 time
policy_value spend 0.24105999400489964 time
train_step spend 0.7066450400016038 time
policy_value spend 0.24055082599807065 time
train_step spend 0.7106038499914575 time
policy_value spend 0.24036536100902595 time
kl:0.08564,lr_multiplier:0.088,loss:2.9338133335113525,entropy:3.582157611846924,explained_var_old:0.853547215,explained_var_new:0.980594575
output spend 0.00016898399917408824 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003967457989347167 time
recovery_state_mcts_prob spend 0.2903184230090119 time
state_batch spend 0.003750643998500891 time
mcts_probs_batch spend 0.007451693993061781 time
winner_batch spend 0.0002686000079847872 time
policy_value spend 0.24266925499250647 time
train_step spend 0.7068061110039707 time
policy_value spend 0.2416780689964071 time
train_step spend 0.7090001320029842 time
policy_value spend 0.24241607799194753 time
train_step spend 0.7063247140031308 time
policy_value spend 0.2413269160024356 time
train_step spend 0.7074571900011506 time
policy_value spend 0.24144881499523763 time
kl:0.09257,lr_multiplier:0.088,loss:2.835831880569458,entropy:3.4646847248077393,explained_var_old:0.958584070,explained_var_new:0.990675867
output spend 0.00016575900372117758 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004778319998877123 time
recovery_state_mcts_prob spend 0.3624135990103241 time
state_batch spend 0.004098773992154747 time
mcts_probs_batch spend 0.006504453995148651 time
winner_batch spend 0.0002711650013225153 time
policy_value spend 0.2457389610062819 time
train_step spend 0.710950797991245 time
policy_value spend 0.24548674600373488 time
train_step spend 0.708775949999108 time
policy_value spend 0.24483784100448247 time
train_step spend 0.7071435680118157 time
policy_value spend 0.24042817098961677 time
train_step spend 0.7079462469991995 time
policy_value spend 0.24107326001103502 time
kl:0.09378,lr_multiplier:0.088,loss:2.831305742263794,entropy:3.4644174575805664,explained_var_old:0.985743821,explained_var_new:0.994208515
output spend 0.00029635499231517315 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003835935000097379 time
recovery_state_mcts_prob spend 0.29967556899646297 time
state_batch spend 0.0035796440060948953 time
mcts_probs_batch spend 0.007429389996104874 time
winner_batch spend 0.00027117799618281424 time
policy_value spend 0.24184499301190954 time
train_step spend 0.7076127649925184 time
policy_value spend 0.24054179999802727 time
train_step spend 0.707002918003127 time
policy_value spend 0.24117868499888573 time
train_step spend 0.7082435479969718 time
policy_value spend 0.24042004000511952 time
train_step spend 0.707147162000183 time
policy_value spend 0.24090694800543133 time
kl:0.08606,lr_multiplier:0.088,loss:2.888040065765381,entropy:3.5061278343200684,explained_var_old:0.986120641,explained_var_new:0.982082486
output spend 0.00016647999291308224 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00478940099128522 time
recovery_state_mcts_prob spend 0.28599494000081904 time
state_batch spend 0.005080111004645005 time
mcts_probs_batch spend 0.007253149000462145 time
winner_batch spend 0.000298736005788669 time
policy_value spend 0.24288003399851732 time
train_step spend 0.7069001689960714 time
policy_value spend 0.2406073800084414 time
train_step spend 0.7067597190034576 time
policy_value spend 0.24149173000478186 time
train_step spend 0.7076062449923484 time
policy_value spend 0.24212087799969595 time
train_step spend 0.7062708369921893 time
policy_value spend 0.24954984300711658 time
kl:0.08940,lr_multiplier:0.088,loss:2.8518166542053223,entropy:3.484715700149536,explained_var_old:0.966447234,explained_var_new:0.945976555
output spend 0.00017472800391260535 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004648813992389478 time
recovery_state_mcts_prob spend 0.322576217004098 time
state_batch spend 0.0048896340013016015 time
mcts_probs_batch spend 0.023777848997269757 time
winner_batch spend 0.0006690930022159591 time
policy_value spend 0.2757616010057973 time
train_step spend 0.7396530400001211 time
policy_value spend 0.24069183999381494 time
train_step spend 0.7069588479935192 time
policy_value spend 0.24072222200629767 time
train_step spend 0.7059952869894914 time
policy_value spend 0.24228654900798574 time
train_step spend 0.7078339680010686 time
policy_value spend 0.24276953098888043 time
kl:0.08289,lr_multiplier:0.088,loss:2.840165138244629,entropy:3.430208683013916,explained_var_old:0.930989683,explained_var_new:0.991064191
output spend 0.00019845800125040114 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004699551995145157 time
recovery_state_mcts_prob spend 0.2941585090011358 time
state_batch spend 0.004228802004945464 time
mcts_probs_batch spend 0.007011328998487443 time
winner_batch spend 0.00026848199195228517 time
policy_value spend 0.24143250699853525 time
train_step spend 0.7080717749922769 time
policy_value spend 0.24762716999975964 time
train_step spend 0.7082190669898409 time
policy_value spend 0.24012430300354026 time
train_step spend 0.7064877040102147 time
policy_value spend 0.24056275299517438 time
train_step spend 0.7101167430082569 time
policy_value spend 0.2405146629898809 time
train_step spend 0.7075958089990309 time
policy_value spend 0.24038554000435397 time
kl:0.10387,lr_multiplier:0.088,loss:2.790637493133545,entropy:3.4005587100982666,explained_var_old:0.983057857,explained_var_new:0.992341101
output spend 0.0001652710052439943 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004962235005223192 time
recovery_state_mcts_prob spend 0.36425839900039136 time
state_batch spend 0.004455963004147634 time
mcts_probs_batch spend 0.008870801990269683 time
winner_batch spend 0.0003231200098525733 time
policy_value spend 0.24712341200211085 time
train_step spend 0.7153963279997697 time
policy_value spend 0.24208641500445083 time
train_step spend 0.70723855200049 time
policy_value spend 0.24191054100811016 time
train_step spend 0.7088141290005296 time
policy_value spend 0.2421328589989571 time
train_step spend 0.7070929350011284 time
policy_value spend 0.2416556960088201 time
train_step spend 0.7076325050002197 time
policy_value spend 0.24110443699464668 time
kl:0.09827,lr_multiplier:0.088,loss:2.844391345977783,entropy:3.4572038650512695,explained_var_old:0.981724501,explained_var_new:0.796797335
output spend 0.00016390100063290447 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004743448997032829 time
recovery_state_mcts_prob spend 0.2939446300006239 time
state_batch spend 0.004200900992145762 time
mcts_probs_batch spend 0.007948783997562714 time
winner_batch spend 0.0002858580119209364 time
policy_value spend 0.24312454999017064 time
train_step spend 0.7083124999917345 time
policy_value spend 0.24108355901262257 time
train_step spend 0.7077165000082459 time
policy_value spend 0.25727315098629333 time
train_step spend 0.7134217999991961 time
policy_value spend 0.24050936600542627 time
train_step spend 0.7074173569999402 time
policy_value spend 0.24501150099968072 time
kl:0.09580,lr_multiplier:0.088,loss:2.846330404281616,entropy:3.4385013580322266,explained_var_old:0.707756162,explained_var_new:0.981998324
output spend 0.0006695829943055287 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005277372998534702 time
recovery_state_mcts_prob spend 0.2961424950044602 time
state_batch spend 0.0034987010003533214 time
mcts_probs_batch spend 0.008212347005610354 time
winner_batch spend 0.0002573839883552864 time
policy_value spend 0.24237317399820313 time
train_step spend 0.7078394199925242 time
policy_value spend 0.24192103200766724 time
train_step spend 0.7077326220023679 time
policy_value spend 0.24256777299160603 time
train_step spend 0.7111926810030127 time
policy_value spend 0.24094517499906942 time
train_step spend 0.7079165019968059 time
policy_value spend 0.24109840599703602 time
train_step spend 0.7075542509992374 time
policy_value spend 0.24094113799219485 time
kl:0.11461,lr_multiplier:0.088,loss:2.7822201251983643,entropy:3.3705763816833496,explained_var_old:0.985160530,explained_var_new:0.990809619
output spend 0.00016350900114048272 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005003086000215262 time
recovery_state_mcts_prob spend 0.35882042300363537 time
state_batch spend 0.0048555889952695 time
mcts_probs_batch spend 0.007604615006130189 time
winner_batch spend 0.0002988420019391924 time
policy_value spend 0.24247380100132432 time
train_step spend 0.7067735400050879 time
policy_value spend 0.24201733099471312 time
train_step spend 0.7080751309986226 time
policy_value spend 0.24103207800362725 time
train_step spend 0.7070403809921117 time
policy_value spend 0.24095518501417246 time
train_step spend 0.7079613340029027 time
policy_value spend 0.24459869899146724 time
kl:0.08027,lr_multiplier:0.088,loss:2.816110372543335,entropy:3.433537483215332,explained_var_old:0.992446482,explained_var_new:0.985718966
output spend 0.00016223901184275746 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004888056995696388 time
recovery_state_mcts_prob spend 0.2922697329922812 time
state_batch spend 0.004292159006581642 time
mcts_probs_batch spend 0.00882157200248912 time
winner_batch spend 0.0002880769898183644 time
policy_value spend 0.24206145500647835 time
train_step spend 0.7072294060053537 time
policy_value spend 0.2601772600028198 time
train_step spend 0.708464258001186 time
policy_value spend 0.2402980360056972 time
train_step spend 0.7103249180072453 time
policy_value spend 0.24470670698792674 time
train_step spend 0.7258798490074696 time
policy_value spend 0.24013673099398147 time
train_step spend 0.7074455859983573 time
policy_value spend 0.24040185600460973 time
kl:0.09659,lr_multiplier:0.088,loss:2.8528642654418945,entropy:3.4594075679779053,explained_var_old:0.972991586,explained_var_new:0.986132264
output spend 0.0001633869978832081 time
已保存最新模型
current self-play batch: 200
load data begin
已加载数据
step i 46: 
random.sample spend 0.003966852993471548 time
recovery_state_mcts_prob spend 0.36582316900603473 time
state_batch spend 0.012134146993048489 time
mcts_probs_batch spend 0.027351982003892772 time
winner_batch spend 0.000373913993826136 time
policy_value spend 0.2484386450087186 time
train_step spend 0.7471227180067217 time
policy_value spend 0.2709290029888507 time
train_step spend 0.7005696790001821 time
policy_value spend 0.23640504998911638 time
train_step spend 0.7081845929933479 time
policy_value spend 0.24941715500608552 time
train_step spend 0.7111340869887499 time
policy_value spend 0.24018152701319195 time
kl:0.08205,lr_multiplier:0.088,loss:2.800722360610962,entropy:3.4163978099823,explained_var_old:0.987056255,explained_var_new:0.994352877
output spend 0.00016460000188089907 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0042965859902324155 time
recovery_state_mcts_prob spend 0.3387984490109375 time
state_batch spend 0.005098078996525146 time
mcts_probs_batch spend 0.008971358998678625 time
winner_batch spend 0.0005031030013924465 time
policy_value spend 0.24194747599540278 time
train_step spend 0.7072961850062711 time
policy_value spend 0.24200755699712317 time
train_step spend 0.7094902179960627 time
policy_value spend 0.2425648700009333 time
train_step spend 0.707241262003663 time
policy_value spend 0.24040909799805377 time
train_step spend 0.7079916060029063 time
policy_value spend 0.24015417500049807 time
train_step spend 0.7063249079947127 time
policy_value spend 0.24113771801057737 time
kl:0.10053,lr_multiplier:0.088,loss:2.8161637783050537,entropy:3.4202024936676025,explained_var_old:0.976185799,explained_var_new:0.988030255
output spend 0.0002559489948907867 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005855396011611447 time
recovery_state_mcts_prob spend 0.30323743699409533 time
state_batch spend 0.004013327998109162 time
mcts_probs_batch spend 0.015963377998559736 time
winner_batch spend 0.00028665900754276663 time
policy_value spend 0.24608335200173315 time
train_step spend 0.7093005479982821 time
policy_value spend 0.24290984199615195 time
train_step spend 0.7082327910029562 time
policy_value spend 0.24247584999829996 time
train_step spend 0.7083991449908353 time
policy_value spend 0.24154033200466074 time
train_step spend 0.707739871009835 time
policy_value spend 0.24156925399438478 time
kl:0.10028,lr_multiplier:0.088,loss:2.876997470855713,entropy:3.4864933490753174,explained_var_old:0.988201797,explained_var_new:0.992897153
output spend 0.00016581099771428853 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0043048439983977005 time
recovery_state_mcts_prob spend 0.28532279998762533 time
state_batch spend 0.004492126012337394 time
mcts_probs_batch spend 0.007113185987691395 time
winner_batch spend 0.00026792800053954124 time
policy_value spend 0.2513487070100382 time
train_step spend 0.7090237049997086 time
policy_value spend 0.24245172600785736 time
train_step spend 0.7107897719979519 time
policy_value spend 0.24319118600396905 time
train_step spend 0.7094878549978603 time
policy_value spend 0.23953007798991166 time
train_step spend 0.7070979249983793 time
policy_value spend 0.2410359230125323 time
kl:0.09029,lr_multiplier:0.088,loss:2.8984081745147705,entropy:3.5175976753234863,explained_var_old:0.974295378,explained_var_new:0.972075045
output spend 0.00017652100359555334 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004456156995729543 time
recovery_state_mcts_prob spend 0.2868209400039632 time
state_batch spend 0.003558930999133736 time
mcts_probs_batch spend 0.007495576006476767 time
winner_batch spend 0.00027654100267682225 time
policy_value spend 0.24417710499255918 time
train_step spend 0.7098178879969055 time
policy_value spend 0.24401123200368602 time
train_step spend 0.707806720994995 time
policy_value spend 0.242926004997571 time
train_step spend 0.7064011450129328 time
policy_value spend 0.24037820799276233 time
train_step spend 0.7067511700006435 time
policy_value spend 0.24016260099597275 time
kl:0.11118,lr_multiplier:0.088,loss:2.8970279693603516,entropy:3.501746654510498,explained_var_old:0.963040411,explained_var_new:0.981325209
output spend 0.00016492599388584495 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004135057999519631 time
recovery_state_mcts_prob spend 0.2910289329884108 time
state_batch spend 0.002494264001143165 time
mcts_probs_batch spend 0.007244723004987463 time
winner_batch spend 0.0002672690025065094 time
policy_value spend 0.24338110399548896 time
train_step spend 0.7084438210004009 time
policy_value spend 0.2429405040020356 time
train_step spend 0.7065429889917141 time
policy_value spend 0.24184360800427385 time
train_step spend 0.7110279519984033 time
policy_value spend 0.244922055004281 time
train_step spend 0.7062851990049239 time
policy_value spend 0.2409781999886036 time
train_step spend 0.7060292380047031 time
policy_value spend 0.2417389460024424 time
kl:0.10469,lr_multiplier:0.088,loss:2.8311891555786133,entropy:3.4326887130737305,explained_var_old:0.986990213,explained_var_new:0.993645787
output spend 0.0002167939965147525 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005934507003985345 time
recovery_state_mcts_prob spend 0.2958706890058238 time
state_batch spend 0.004155151997110806 time
mcts_probs_batch spend 0.014734140000655316 time
winner_batch spend 0.00026957999216392636 time
policy_value spend 0.2450425490096677 time
train_step spend 0.7085995840025134 time
policy_value spend 0.23996792199613992 time
train_step spend 0.7081380349991377 time
policy_value spend 0.2416646540077636 time
train_step spend 0.7071726030117134 time
policy_value spend 0.24050348899618257 time
train_step spend 0.7071363129944075 time
policy_value spend 0.24032640299992636 time
kl:0.09333,lr_multiplier:0.088,loss:2.7915611267089844,entropy:3.384439706802368,explained_var_old:0.983349621,explained_var_new:0.986909688
output spend 0.00016571699234191328 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0049050109955715016 time
recovery_state_mcts_prob spend 0.29006497499358375 time
state_batch spend 0.0036040080012753606 time
mcts_probs_batch spend 0.007483810011763126 time
winner_batch spend 0.0002824789989972487 time
policy_value spend 0.24229647699394263 time
train_step spend 0.7068847719929181 time
policy_value spend 0.2417266819975339 time
train_step spend 0.7067683810018934 time
policy_value spend 0.2405445990007138 time
train_step spend 0.7093001210014336 time
policy_value spend 0.24046596299740486 time
train_step spend 0.70709873099986 time
policy_value spend 0.24009425700933207 time
kl:0.08704,lr_multiplier:0.088,loss:2.903221845626831,entropy:3.5057895183563232,explained_var_old:0.984125257,explained_var_new:0.986473143
output spend 0.0001628720056032762 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005168456991668791 time
recovery_state_mcts_prob spend 0.2856673439964652 time
state_batch spend 0.0040938840102171525 time
mcts_probs_batch spend 0.006346517999190837 time
winner_batch spend 0.00026470900047570467 time
policy_value spend 0.24621974499314092 time
train_step spend 0.7099988859990845 time
policy_value spend 0.2405994380096672 time
train_step spend 0.7075873359863181 time
policy_value spend 0.2582996470009675 time
train_step spend 0.7133651249896502 time
policy_value spend 0.24176696701033507 time
train_step spend 0.7075740239961306 time
policy_value spend 0.253250455003581 time
kl:0.08322,lr_multiplier:0.088,loss:2.8572630882263184,entropy:3.4499175548553467,explained_var_old:0.979042590,explained_var_new:0.988720715
output spend 0.000658171993563883 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0045481830020435154 time
recovery_state_mcts_prob spend 0.30173875599575695 time
state_batch spend 0.0055240799993043765 time
mcts_probs_batch spend 0.008696981996763498 time
winner_batch spend 0.0003786260058404878 time
policy_value spend 0.242462094000075 time
train_step spend 0.7072355279960902 time
policy_value spend 0.24034688199753873 time
train_step spend 0.706385562007199 time
policy_value spend 0.24059320500236936 time
train_step spend 0.7080991650000215 time
policy_value spend 0.24025167801300995 time
train_step spend 0.7083309410081711 time
policy_value spend 0.24119692799285986 time
train_step spend 0.7071838619885966 time
policy_value spend 0.24110027101414744 time
kl:0.09143,lr_multiplier:0.088,loss:2.7724788188934326,entropy:3.3720591068267822,explained_var_old:0.989650369,explained_var_new:0.991959631
output spend 0.00016767099441494793 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004301063003367744 time
recovery_state_mcts_prob spend 0.38141965100658126 time
state_batch spend 0.004378035999252461 time
mcts_probs_batch spend 0.006599492990062572 time
winner_batch spend 0.0002748620026977733 time
policy_value spend 0.2419662629981758 time
train_step spend 0.7075688659970183 time
policy_value spend 0.24030421300267335 time
train_step spend 0.7073734989971854 time
policy_value spend 0.24131566600408405 time
train_step spend 0.7098139199952129 time
policy_value spend 0.24016249399574008 time
train_step spend 0.7071428149938583 time
policy_value spend 0.24107344300136901 time
kl:0.08036,lr_multiplier:0.088,loss:2.830003261566162,entropy:3.436626434326172,explained_var_old:0.992955804,explained_var_new:0.988748670
output spend 0.00016371699166484177 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004215657987515442 time
recovery_state_mcts_prob spend 0.29081603400118183 time
state_batch spend 0.002548435004428029 time
mcts_probs_batch spend 0.007863446997362189 time
winner_batch spend 0.00031471101101487875 time
policy_value spend 0.24215016099333297 time
train_step spend 0.7067663990019355 time
policy_value spend 0.24705934300436638 time
train_step spend 0.7069554789923131 time
policy_value spend 0.24150730400288012 time
train_step spend 0.7077017749979859 time
policy_value spend 0.2554032079933677 time
train_step spend 0.7066040859936038 time
policy_value spend 0.24049693200504407 time
kl:0.08399,lr_multiplier:0.088,loss:2.88177490234375,entropy:3.4716243743896484,explained_var_old:0.976862192,explained_var_new:0.963204861
output spend 0.0001658080000197515 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006700933998217806 time
recovery_state_mcts_prob spend 0.2799890150054125 time
state_batch spend 0.0020161879947409034 time
mcts_probs_batch spend 0.007556426004157402 time
winner_batch spend 0.0002905290020862594 time
policy_value spend 0.2426788349985145 time
train_step spend 0.7070188259967836 time
policy_value spend 0.24061735800933093 time
train_step spend 0.7063552229956258 time
policy_value spend 0.24092120000568684 time
train_step spend 0.7066566360008437 time
policy_value spend 0.24323173199081793 time
train_step spend 0.7079147510085022 time
policy_value spend 0.2409589079907164 time
kl:0.09573,lr_multiplier:0.088,loss:2.825894832611084,entropy:3.4165196418762207,explained_var_old:0.959368765,explained_var_new:0.992818296
output spend 0.00017158199625555426 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0039149749936768785 time
recovery_state_mcts_prob spend 0.370717247002176 time
state_batch spend 0.003501387996948324 time
mcts_probs_batch spend 0.007431819001794793 time
winner_batch spend 0.0002630420058267191 time
policy_value spend 0.24196960499102715 time
train_step spend 0.7083931350061903 time
policy_value spend 0.26771674200426787 time
train_step spend 0.7205488579929806 time
policy_value spend 0.24117584200575948 time
train_step spend 0.706842735002283 time
policy_value spend 0.24124977899191435 time
train_step spend 0.7098605740029598 time
policy_value spend 0.2409480979986256 time
kl:0.09420,lr_multiplier:0.088,loss:2.8310327529907227,entropy:3.449805736541748,explained_var_old:0.983969390,explained_var_new:0.988001466
output spend 0.00016543200763408095 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004616703998181038 time
recovery_state_mcts_prob spend 0.29943079700751696 time
state_batch spend 0.004617780999979004 time
mcts_probs_batch spend 0.014736084995092824 time
winner_batch spend 0.0002788139972835779 time
policy_value spend 0.2453778049966786 time
train_step spend 0.7089907570043579 time
policy_value spend 0.24360981599602383 time
train_step spend 0.7109860320051666 time
policy_value spend 0.24190673399425577 time
train_step spend 0.7062261190003483 time
policy_value spend 0.2528502729983302 time
train_step spend 0.709246386992163 time
policy_value spend 0.24196658699656837 time
kl:0.08649,lr_multiplier:0.088,loss:2.8245577812194824,entropy:3.4188966751098633,explained_var_old:0.993435919,explained_var_new:0.995403886
output spend 0.00016192501061595976 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005399667003075592 time
recovery_state_mcts_prob spend 0.2879669609974371 time
state_batch spend 0.002990861001308076 time
mcts_probs_batch spend 0.006561608999618329 time
winner_batch spend 0.0002881070104194805 time
policy_value spend 0.242579517987906 time
train_step spend 0.7074809379992075 time
policy_value spend 0.24327880000055302 time
train_step spend 0.7068453490064712 time
policy_value spend 0.24020392600505147 time
train_step spend 0.7069090779987164 time
policy_value spend 0.24046889699820895 time
kl:0.20276,lr_multiplier:0.088,loss:2.882258415222168,entropy:3.482048988342285,explained_var_old:0.985352516,explained_var_new:0.591870308
output spend 0.00017585000023245811 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004182076998404227 time
recovery_state_mcts_prob spend 0.29301268998824526 time
state_batch spend 0.005133566999575123 time
mcts_probs_batch spend 0.007199288011179306 time
winner_batch spend 0.0002868189912987873 time
policy_value spend 0.24260473001049832 time
train_step spend 0.7099336219980614 time
policy_value spend 0.24180275399703532 time
kl:0.19873,lr_multiplier:0.088,loss:3.084390878677368,entropy:3.543734550476074,explained_var_old:0.541197419,explained_var_new:0.472081125
output spend 0.00016188700101338327 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005719270004192367 time
recovery_state_mcts_prob spend 0.2895461309963139 time
state_batch spend 0.004736232993309386 time
mcts_probs_batch spend 0.00844824301020708 time
winner_batch spend 0.0002913149946834892 time
policy_value spend 0.24205878700013272 time
train_step spend 0.7077322900004219 time
policy_value spend 0.24158129800343886 time
kl:0.08291,lr_multiplier:0.088,loss:2.9960291385650635,entropy:3.4944376945495605,explained_var_old:0.497996926,explained_var_new:0.936399579
output spend 0.00016674501239322126 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005320151001797058 time
recovery_state_mcts_prob spend 0.29490604999591596 time
state_batch spend 0.004105995001737028 time
mcts_probs_batch spend 0.006339422005112283 time
winner_batch spend 0.00028131699946243316 time
policy_value spend 0.24251894699409604 time
train_step spend 0.7070452460029628 time
policy_value spend 0.24143480199563783 time
kl:0.14350,lr_multiplier:0.088,loss:2.950528860092163,entropy:3.5516810417175293,explained_var_old:0.927695096,explained_var_new:0.615833521
output spend 0.00016623199917376041 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003948993005906232 time
recovery_state_mcts_prob spend 0.30138898799486924 time
state_batch spend 0.004356250006821938 time
mcts_probs_batch spend 0.007612118992256001 time
winner_batch spend 0.00027264001255389303 time
policy_value spend 0.24308066398953088 time
train_step spend 0.7094256350101205 time
policy_value spend 0.24234353099018335 time
kl:0.13377,lr_multiplier:0.088,loss:2.9901158809661865,entropy:3.5633668899536133,explained_var_old:0.633277774,explained_var_new:0.557713866
output spend 0.0001647280005272478 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005634423010633327 time
recovery_state_mcts_prob spend 0.3761185319890501 time
state_batch spend 0.00197694000962656 time
mcts_probs_batch spend 0.011860725993756205 time
winner_batch spend 0.0002720479969866574 time
policy_value spend 0.24835767700278666 time
train_step spend 0.7104028720059432 time
policy_value spend 0.24120752899034414 time
train_step spend 0.7070419219962787 time
policy_value spend 0.2406340529996669 time
kl:0.19894,lr_multiplier:0.088,loss:2.988219738006592,entropy:3.610797882080078,explained_var_old:0.561096787,explained_var_new:0.577624679
output spend 0.00017268701049033552 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004941450999467634 time
recovery_state_mcts_prob spend 0.29322593299730215 time
state_batch spend 0.0036019769904669374 time
mcts_probs_batch spend 0.007543798012193292 time
winner_batch spend 0.0002618849975988269 time
policy_value spend 0.24258296900370624 time
train_step spend 0.7082463740080129 time
policy_value spend 0.24208391999127343 time
kl:0.09007,lr_multiplier:0.088,loss:2.977790117263794,entropy:3.6028552055358887,explained_var_old:0.561092138,explained_var_new:0.908516884
output spend 0.00021388899767771363 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0043202800006838515 time
recovery_state_mcts_prob spend 0.29506375300115906 time
state_batch spend 0.004126806001295336 time
mcts_probs_batch spend 0.006551648999447934 time
winner_batch spend 0.0003102689952356741 time
policy_value spend 0.2424041140038753 time
train_step spend 0.7066903280065162 time
policy_value spend 0.24120476499956567 time
kl:0.12537,lr_multiplier:0.088,loss:2.905580759048462,entropy:3.5183768272399902,explained_var_old:0.907827735,explained_var_new:0.926394403
output spend 0.00018749300215858966 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004033421995700337 time
recovery_state_mcts_prob spend 0.29376866901293397 time
state_batch spend 0.004122122991248034 time
mcts_probs_batch spend 0.012494894006522372 time
winner_batch spend 0.0002658540033735335 time
policy_value spend 0.2460346349980682 time
train_step spend 0.7067317490000278 time
policy_value spend 0.24268826399929821 time
train_step spend 0.7071523940103361 time
policy_value spend 0.24136583200015593 time
kl:0.13205,lr_multiplier:0.088,loss:2.934973955154419,entropy:3.5829312801361084,explained_var_old:0.930421293,explained_var_new:0.868561149
output spend 0.00018451499636285007 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005310298991389573 time
recovery_state_mcts_prob spend 0.2871638710057596 time
state_batch spend 0.0019430009997449815 time
mcts_probs_batch spend 0.007581849000416696 time
winner_batch spend 0.00026817900652531534 time
policy_value spend 0.24192809200030752 time
train_step spend 0.7083745819982141 time
policy_value spend 0.24050261999946088 time
train_step spend 0.7076925680012209 time
policy_value spend 0.24314051499823108 time
train_step spend 0.706989030004479 time
policy_value spend 0.2405647279956611 time
train_step spend 0.707020771005773 time
policy_value spend 0.2407184449984925 time
kl:0.08612,lr_multiplier:0.088,loss:2.873290777206421,entropy:3.5320000648498535,explained_var_old:0.814919949,explained_var_new:0.976892233
output spend 0.00016545401012990624 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004576530001941137 time
recovery_state_mcts_prob spend 0.3722874109953409 time
state_batch spend 0.0036060230049770325 time
mcts_probs_batch spend 0.008011805999558419 time
winner_batch spend 0.00032169399491976947 time
policy_value spend 0.24510443399776705 time
train_step spend 0.7089340130041819 time
policy_value spend 0.2415308420022484 time
train_step spend 0.7077482969907578 time
policy_value spend 0.26043014699826017 time
train_step spend 0.7077415589883458 time
policy_value spend 0.24107387200638186 time
kl:0.08523,lr_multiplier:0.088,loss:2.8366708755493164,entropy:3.47536563873291,explained_var_old:0.983260453,explained_var_new:0.975608170
output spend 0.0001710659998934716 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0051072119968011975 time
recovery_state_mcts_prob spend 0.2867048870102735 time
state_batch spend 0.004150586988544092 time
mcts_probs_batch spend 0.0066457320062909275 time
winner_batch spend 0.0003393179940758273 time
policy_value spend 0.2420435060048476 time
train_step spend 0.7072126020066207 time
policy_value spend 0.24148992699338123 time
train_step spend 0.7102519759937422 time
policy_value spend 0.24024066000129096 time
train_step spend 0.7065269830054604 time
policy_value spend 0.24058204400353134 time
kl:0.10144,lr_multiplier:0.088,loss:2.842311143875122,entropy:3.450711250305176,explained_var_old:0.962192655,explained_var_new:0.992921948
output spend 0.00023530899488832802 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006589799988432787 time
recovery_state_mcts_prob spend 0.28910732601070777 time
state_batch spend 0.003494917997159064 time
mcts_probs_batch spend 0.029113251002854668 time
winner_batch spend 0.00027611199766397476 time
policy_value spend 0.24215158900187816 time
train_step spend 0.7073432160104858 time
policy_value spend 0.24190772899601143 time
train_step spend 0.7066311090020463 time
policy_value spend 0.24015772600250784 time
train_step spend 0.7091590780037222 time
policy_value spend 0.24220250999496784 time
train_step spend 0.7076951619965257 time
policy_value spend 0.24049393899622373 time
train_step spend 0.707699220001814 time
policy_value spend 0.25430868499097414 time
kl:0.08749,lr_multiplier:0.088,loss:2.851243257522583,entropy:3.4740488529205322,explained_var_old:0.985306978,explained_var_new:0.968953133
output spend 0.0001671899954089895 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004251908001606353 time
recovery_state_mcts_prob spend 0.30441906199848745 time
state_batch spend 0.003635954999481328 time
mcts_probs_batch spend 0.007351883003138937 time
winner_batch spend 0.000264995003817603 time
policy_value spend 0.24247882400231902 time
train_step spend 0.7064056230010465 time
policy_value spend 0.24294346300303005 time
train_step spend 0.7076445259881439 time
policy_value spend 0.24141864301054738 time
train_step spend 0.7084168799920008 time
policy_value spend 0.24092053300410043 time
train_step spend 0.7066417850001017 time
policy_value spend 0.241333049008972 time
train_step spend 0.7062792380020255 time
policy_value spend 0.2411900839942973 time
kl:0.10197,lr_multiplier:0.088,loss:2.779259443283081,entropy:3.3953375816345215,explained_var_old:0.964431524,explained_var_new:0.974906921
output spend 0.00018627199460752308 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004542761002085172 time
recovery_state_mcts_prob spend 0.28184293999220245 time
state_batch spend 0.002403458012850024 time
mcts_probs_batch spend 0.011841282990644686 time
winner_batch spend 0.0002691380068426952 time
policy_value spend 0.2457391289935913 time
train_step spend 0.7087195920030354 time
policy_value spend 0.2405084159981925 time
train_step spend 0.7094014760077698 time
policy_value spend 0.24212217099557165 time
train_step spend 0.7070655089919455 time
policy_value spend 0.24071053801162634 time
train_step spend 0.7089101530000335 time
policy_value spend 0.24064556301163975 time
train_step spend 0.7065543330099899 time
policy_value spend 0.2407266910013277 time
kl:0.09024,lr_multiplier:0.088,loss:2.810539484024048,entropy:3.3854689598083496,explained_var_old:0.955791354,explained_var_new:0.981222212
output spend 0.00016496599710080773 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005158289000974037 time
recovery_state_mcts_prob spend 0.30632973900355864 time
state_batch spend 0.01303984499827493 time
mcts_probs_batch spend 0.014027643002918921 time
winner_batch spend 0.0006562579947058111 time
policy_value spend 0.2440750170062529 time
train_step spend 0.7072514189931098 time
policy_value spend 0.24187287500535604 time
train_step spend 0.7085183619929012 time
policy_value spend 0.24054625500866678 time
train_step spend 0.7065740609978093 time
policy_value spend 0.24712928700319026 time
train_step spend 0.7071458220016211 time
policy_value spend 0.24133215499750804 time
train_step spend 0.7064637730072718 time
policy_value spend 0.2406825029902393 time
kl:0.08424,lr_multiplier:0.088,loss:2.8392910957336426,entropy:3.4327592849731445,explained_var_old:0.979061723,explained_var_new:0.959585369
output spend 0.0001650569902267307 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004650571005186066 time
recovery_state_mcts_prob spend 0.2915678010031115 time
state_batch spend 0.0036197479930706322 time
mcts_probs_batch spend 0.007281511992914602 time
winner_batch spend 0.00029260601149871945 time
policy_value spend 0.2422973880020436 time
train_step spend 0.7064500039996346 time
policy_value spend 0.24863518700294662 time
train_step spend 0.7079068160091992 time
policy_value spend 0.24271107900131028 time
train_step spend 0.7102659789961763 time
policy_value spend 0.24307974500698037 time
train_step spend 0.7063266199984355 time
policy_value spend 0.24126768199494109 time
train_step spend 0.7066093350003939 time
policy_value spend 0.24047839498962276 time
kl:0.09593,lr_multiplier:0.088,loss:2.8618195056915283,entropy:3.4301321506500244,explained_var_old:0.949680030,explained_var_new:0.989875138
output spend 0.0001769600057741627 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003858363998006098 time
recovery_state_mcts_prob spend 0.2952356750029139 time
state_batch spend 0.002318650993402116 time
mcts_probs_batch spend 0.005443439993541688 time
winner_batch spend 0.0003010240034200251 time
policy_value spend 0.24172162800095975 time
train_step spend 0.7085240470041754 time
policy_value spend 0.24313821199757513 time
train_step spend 0.7078658289974555 time
policy_value spend 0.24097040299966466 time
train_step spend 0.706772663994343 time
policy_value spend 0.25039633399865124 time
train_step spend 0.7059992860013153 time
policy_value spend 0.24080271201091819 time
kl:0.08336,lr_multiplier:0.088,loss:2.775761365890503,entropy:3.357738494873047,explained_var_old:0.980218768,explained_var_new:0.987472773
output spend 0.0001714590034680441 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006724413004121743 time
recovery_state_mcts_prob spend 0.2887181449914351 time
state_batch spend 0.004452366003533825 time
mcts_probs_batch spend 0.01430445199366659 time
winner_batch spend 0.00030198700551409274 time
policy_value spend 0.26890216299216263 time
train_step spend 0.7120329669996863 time
policy_value spend 0.24307988400687464 time
train_step spend 0.708820606014342 time
policy_value spend 0.24079317299765535 time
train_step spend 0.7075708229967859 time
policy_value spend 0.2403542839892907 time
train_step spend 0.705875282001216 time
policy_value spend 0.24062030200730078 time
kl:0.08918,lr_multiplier:0.088,loss:2.8036651611328125,entropy:3.381077289581299,explained_var_old:0.990691066,explained_var_new:0.989723027
output spend 0.00016212300397455692 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0038120139943202958 time
recovery_state_mcts_prob spend 0.2897798860067269 time
state_batch spend 0.0035211490030633286 time
mcts_probs_batch spend 0.00772574199072551 time
winner_batch spend 0.0002794050087686628 time
policy_value spend 0.2457402949949028 time
train_step spend 0.7093841950118076 time
policy_value spend 0.24147933098720387 time
train_step spend 0.7078947440022603 time
policy_value spend 0.24192076199688017 time
train_step spend 0.7065774549992057 time
policy_value spend 0.24043540899583604 time
train_step spend 0.7074635549943196 time
policy_value spend 0.24072225100826472 time
kl:0.09661,lr_multiplier:0.088,loss:2.8544960021972656,entropy:3.4460654258728027,explained_var_old:0.991184890,explained_var_new:0.994749486
output spend 0.0001649470068514347 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004903626992017962 time
recovery_state_mcts_prob spend 0.2925016570079606 time
state_batch spend 0.0019873659912263975 time
mcts_probs_batch spend 0.007453238999005407 time
winner_batch spend 0.00026590800553094596 time
policy_value spend 0.24199821200454608 time
train_step spend 0.7081885910010897 time
policy_value spend 0.2443754320120206 time
train_step spend 0.7072873680008342 time
policy_value spend 0.24022603299818002 time
train_step spend 0.7088550429907627 time
policy_value spend 0.2407351580040995 time
train_step spend 0.7068736479996005 time
policy_value spend 0.24033284799952526 time
train_step spend 0.7077181399945403 time
policy_value spend 0.2402863910101587 time
kl:0.09983,lr_multiplier:0.088,loss:2.84576153755188,entropy:3.4454164505004883,explained_var_old:0.989678979,explained_var_new:0.996877968
output spend 0.00016599100490566343 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004047441994771361 time
recovery_state_mcts_prob spend 0.326119610996102 time
state_batch spend 0.003437673003645614 time
mcts_probs_batch spend 0.014718763006385416 time
winner_batch spend 0.00028149900026619434 time
policy_value spend 0.2466848449985264 time
train_step spend 0.7077239389909664 time
policy_value spend 0.24071045700111426 time
train_step spend 0.7096731100027682 time
policy_value spend 0.2417215599998599 time
train_step spend 0.7061801870004274 time
policy_value spend 0.2408159939950565 time
train_step spend 0.7071582359931199 time
policy_value spend 0.24122940500092227 time
train_step spend 0.706083127995953 time
policy_value spend 0.2413451470056316 time
kl:0.10333,lr_multiplier:0.088,loss:2.7590293884277344,entropy:3.3381171226501465,explained_var_old:0.983363867,explained_var_new:0.979690731
output spend 0.00022600099327974021 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004990161003661342 time
recovery_state_mcts_prob spend 0.3615377719979733 time
state_batch spend 0.003642874988145195 time
mcts_probs_batch spend 0.00737122401187662 time
winner_batch spend 0.00026379899645689875 time
policy_value spend 0.24194107500079554 time
train_step spend 0.7063332879915833 time
policy_value spend 0.24293237600068096 time
train_step spend 0.7088256049901247 time
policy_value spend 0.2400474710011622 time
train_step spend 0.7069299379945733 time
policy_value spend 0.24022054301167373 time
train_step spend 0.7070670840039384 time
policy_value spend 0.240127377997851 time
kl:0.08412,lr_multiplier:0.088,loss:2.863527536392212,entropy:3.4362497329711914,explained_var_old:0.976204574,explained_var_new:0.987145901
output spend 0.00016810699889902025 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0053784269985044375 time
recovery_state_mcts_prob spend 0.2905358639982296 time
state_batch spend 0.0035195289965486154 time
mcts_probs_batch spend 0.007551996997790411 time
winner_batch spend 0.00028656001086346805 time
policy_value spend 0.2431943279952975 time
train_step spend 0.7066178990062326 time
policy_value spend 0.25172884699713904 time
train_step spend 0.7114867009950103 time
policy_value spend 0.24142603600921575 time
train_step spend 0.7063294569961727 time
policy_value spend 0.24911001800501253 time
train_step spend 0.70766384700255 time
policy_value spend 0.24052965399459936 time
train_step spend 0.7069115579943173 time
policy_value spend 0.24275540000235196 time
kl:0.07934,lr_multiplier:0.088,loss:2.8056743144989014,entropy:3.3909740447998047,explained_var_old:0.985991240,explained_var_new:0.982060075
output spend 0.0004695609968621284 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0037001159944338724 time
recovery_state_mcts_prob spend 0.2932631279982161 time
state_batch spend 0.002137742005288601 time
mcts_probs_batch spend 0.007260519007104449 time
winner_batch spend 0.00031068199314177036 time
policy_value spend 0.24263044299732428 time
train_step spend 0.7066666250029812 time
policy_value spend 0.24397841199242976 time
train_step spend 0.7078813050029567 time
policy_value spend 0.24086576999980025 time
train_step spend 0.7058906840102281 time
policy_value spend 0.24359942899900489 time
train_step spend 0.7072925239917822 time
policy_value spend 0.2401877859956585 time
train_step spend 0.7067491829948267 time
policy_value spend 0.2403135420026956 time
kl:0.09484,lr_multiplier:0.088,loss:2.833763837814331,entropy:3.421924352645874,explained_var_old:0.976403892,explained_var_new:0.996747971
output spend 0.00016455900913570076 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00471431300684344 time
recovery_state_mcts_prob spend 0.36907748799421825 time
state_batch spend 0.0030148689984343946 time
mcts_probs_batch spend 0.008680004000780173 time
winner_batch spend 0.00027405899891164154 time
policy_value spend 0.24562805800815113 time
train_step spend 0.706752123995102 time
policy_value spend 0.24339347900240682 time
train_step spend 0.7084594059997471 time
policy_value spend 0.24112169799627736 time
train_step spend 0.7072533419996034 time
policy_value spend 0.24095432300237007 time
train_step spend 0.7074901059968397 time
policy_value spend 0.25353578399517573 time
kl:0.08661,lr_multiplier:0.088,loss:2.807569980621338,entropy:3.4030659198760986,explained_var_old:0.986044645,explained_var_new:0.988353789
output spend 0.00025759900745470077 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006022255009156652 time
recovery_state_mcts_prob spend 0.4104235229897313 time
state_batch spend 0.004280494002159685 time
mcts_probs_batch spend 0.0079771300079301 time
winner_batch spend 0.00028684399148914963 time
policy_value spend 0.2418995620100759 time
train_step spend 0.7071184579981491 time
policy_value spend 0.25458187800541054 time
train_step spend 0.7086531829991145 time
policy_value spend 0.2401328310079407 time
train_step spend 0.7063005870004417 time
policy_value spend 0.24040800900547765 time
train_step spend 0.706790768992505 time
policy_value spend 0.24002552300225943 time
kl:0.08589,lr_multiplier:0.088,loss:2.7907838821411133,entropy:3.3920862674713135,explained_var_old:0.974170029,explained_var_new:0.991278887
output spend 0.00016200498794205487 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004903736989945173 time
recovery_state_mcts_prob spend 0.2984562190104043 time
state_batch spend 0.0030545369954779744 time
mcts_probs_batch spend 0.0067859440023312345 time
winner_batch spend 0.0002692199923330918 time
policy_value spend 0.24267333101306576 time
train_step spend 0.7077071030071238 time
policy_value spend 0.24396045399771538 time
train_step spend 0.7125298900064081 time
policy_value spend 0.24139950799872167 time
train_step spend 0.7058292270085076 time
policy_value spend 0.24120967999624554 time
train_step spend 0.7072467630059691 time
policy_value spend 0.24077846299041994 time
kl:0.09388,lr_multiplier:0.088,loss:2.8049495220184326,entropy:3.391789197921753,explained_var_old:0.981952071,explained_var_new:0.985785365
output spend 0.00017491199832875282 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005266231004497968 time
recovery_state_mcts_prob spend 0.36638505299924873 time
state_batch spend 0.0019495570013532415 time
mcts_probs_batch spend 0.007162433001212776 time
winner_batch spend 0.0004090509901288897 time
policy_value spend 0.24439447300392203 time
train_step spend 0.7104326449916698 time
policy_value spend 0.24550332099897787 time
train_step spend 0.7109568750020117 time
policy_value spend 0.24480635800864547 time
train_step spend 0.7082573410007171 time
policy_value spend 0.24058892200991977 time
train_step spend 0.7069082379894098 time
policy_value spend 0.24038135701266583 time
train_step spend 0.7063178480020724 time
policy_value spend 0.2403783769987058 time
kl:0.08960,lr_multiplier:0.088,loss:2.763901948928833,entropy:3.324676275253296,explained_var_old:0.984769881,explained_var_new:0.991403401
output spend 0.00017428699356969446 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0048590649967081845 time
recovery_state_mcts_prob spend 0.28166167900781147 time
state_batch spend 0.0021546349889831617 time
mcts_probs_batch spend 0.006814438005676493 time
winner_batch spend 0.0003154029982397333 time
policy_value spend 0.2424278359976597 time
train_step spend 0.7093871200049762 time
policy_value spend 0.24077693800791167 time
train_step spend 0.7096415780106327 time
policy_value spend 0.2518229149864055 time
train_step spend 0.708405565994326 time
policy_value spend 0.24043284499202855 time
train_step spend 0.7071133449935587 time
policy_value spend 0.2506236070039449 time
kl:0.08502,lr_multiplier:0.088,loss:2.8191709518432617,entropy:3.411710262298584,explained_var_old:0.993051112,explained_var_new:0.995408177
output spend 0.0011644990008790046 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007160886991186999 time
recovery_state_mcts_prob spend 0.3099061750108376 time
state_batch spend 0.004638304002583027 time
mcts_probs_batch spend 0.009689271988463588 time
winner_batch spend 0.00029939600790385157 time
policy_value spend 0.24195355099800508 time
train_step spend 0.7074021939915838 time
policy_value spend 0.24100132900639437 time
train_step spend 0.7078848460078007 time
policy_value spend 0.2423813589994097 time
train_step spend 0.7058126199990511 time
policy_value spend 0.24181715700251516 time
train_step spend 0.7071170449926285 time
policy_value spend 0.24237497299327515 time
train_step spend 0.7061421340040397 time
policy_value spend 0.24087405399768613 time
kl:0.08707,lr_multiplier:0.088,loss:2.758596897125244,entropy:3.3391265869140625,explained_var_old:0.983407319,explained_var_new:0.978747725
output spend 0.0001642279967200011 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005040625997935422 time
recovery_state_mcts_prob spend 0.3625971170113189 time
state_batch spend 0.00455354098812677 time
mcts_probs_batch spend 0.013705274002859369 time
winner_batch spend 0.00039119800203479826 time
policy_value spend 0.24496534299396444 time
train_step spend 0.7103429210110335 time
policy_value spend 0.24203942299936898 time
train_step spend 0.70782034000149 time
policy_value spend 0.24029101899941452 time
train_step spend 0.7070995510002831 time
policy_value spend 0.2408384120062692 time
train_step spend 0.7073198260040954 time
policy_value spend 0.2411405759921763 time
kl:0.08678,lr_multiplier:0.088,loss:2.812708616256714,entropy:3.3792316913604736,explained_var_old:0.977539837,explained_var_new:0.995243132
output spend 0.0001642700080992654 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005361021991120651 time
recovery_state_mcts_prob spend 0.29881099400517996 time
state_batch spend 0.0037065670039737597 time
mcts_probs_batch spend 0.007459164000465535 time
winner_batch spend 0.0003131729899905622 time
policy_value spend 0.24198238999815658 time
train_step spend 0.7063688289927086 time
policy_value spend 0.25415435699687805 time
train_step spend 0.7104715919995215 time
policy_value spend 0.24062818799575325 time
train_step spend 0.7069425890076673 time
policy_value spend 0.24224717500328552 time
train_step spend 0.7119506059971172 time
policy_value spend 0.24112552400038112 time
train_step spend 0.7066758500004653 time
policy_value spend 0.24066040199249983 time
kl:0.09775,lr_multiplier:0.088,loss:2.826160430908203,entropy:3.4053690433502197,explained_var_old:0.980328798,explained_var_new:0.979027569
output spend 0.00019886399968527257 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004123815000639297 time
recovery_state_mcts_prob spend 0.293046378006693 time
state_batch spend 0.002929132999270223 time
mcts_probs_batch spend 0.016765474996645935 time
winner_batch spend 0.00030981800227891654 time
policy_value spend 0.2461992280004779 time
train_step spend 0.7087379050062736 time
policy_value spend 0.24333876099262852 time
train_step spend 0.7098021499987226 time
policy_value spend 0.24183947200071998 time
train_step spend 0.7063179469987517 time
policy_value spend 0.24126831500325352 time
train_step spend 0.7080514139961451 time
policy_value spend 0.24164990799908992 time
kl:0.08561,lr_multiplier:0.088,loss:2.8098394870758057,entropy:3.3831987380981445,explained_var_old:0.976894379,explained_var_new:0.988093317
output spend 0.00016428600065410137 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005326273996615782 time
recovery_state_mcts_prob spend 0.29180517300846986 time
state_batch spend 0.003775999997742474 time
mcts_probs_batch spend 0.015859777995501645 time
winner_batch spend 0.0002719589974731207 time
policy_value spend 0.24528319500677753 time
train_step spend 0.7072271829965757 time
policy_value spend 0.24301240000932012 time
train_step spend 0.7092641069903038 time
policy_value spend 0.2406553589971736 time
train_step spend 0.7070829480071552 time
policy_value spend 0.24483905998931732 time
train_step spend 0.7074705740087666 time
policy_value spend 0.2409976229973836 time
kl:0.08445,lr_multiplier:0.088,loss:2.841848611831665,entropy:3.423191547393799,explained_var_old:0.989619255,explained_var_new:0.991009831
output spend 0.00022067500685807317 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004504394994000904 time
recovery_state_mcts_prob spend 0.2987303390109446 time
state_batch spend 0.004373604999273084 time
mcts_probs_batch spend 0.006674365999060683 time
winner_batch spend 0.0002844019909389317 time
policy_value spend 0.25463181899976917 time
train_step spend 0.7153748349956004 time
policy_value spend 0.24046557299152482 time
train_step spend 0.7078742059966316 time
policy_value spend 0.24134401700575836 time
train_step spend 0.7068463649920886 time
policy_value spend 0.24041551900154445 time
train_step spend 0.706583254999714 time
policy_value spend 0.24116094199416693 time
train_step spend 0.7068094980058959 time
policy_value spend 0.24104692500259262 time
kl:0.09115,lr_multiplier:0.088,loss:2.8154146671295166,entropy:3.396305799484253,explained_var_old:0.993991256,explained_var_new:0.995335937
output spend 0.00017022200336214155 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00561525700322818 time
recovery_state_mcts_prob spend 0.2859352969971951 time
state_batch spend 0.003678755005239509 time
mcts_probs_batch spend 0.007360906995018013 time
winner_batch spend 0.00031532700813841075 time
policy_value spend 0.2423405869922135 time
train_step spend 0.7062404469907051 time
policy_value spend 0.2437073019973468 time
train_step spend 0.7107273959991289 time
policy_value spend 0.2416321339987917 time
train_step spend 0.7070289650000632 time
policy_value spend 0.24034409799787682 time
train_step spend 0.7064711470011389 time
policy_value spend 0.2408561229967745 time
train_step spend 0.7073089679906843 time
policy_value spend 0.2405740410031285 time
kl:0.09645,lr_multiplier:0.088,loss:2.8126213550567627,entropy:3.3840203285217285,explained_var_old:0.985642970,explained_var_new:0.993973076
output spend 0.0002307519898749888 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0048554819950368255 time
recovery_state_mcts_prob spend 0.2969167270057369 time
state_batch spend 0.002286995993927121 time
mcts_probs_batch spend 0.005437605999759398 time
winner_batch spend 0.00028721900889649987 time
policy_value spend 0.26216636000026483 time
train_step spend 0.7237829299992882 time
policy_value spend 0.24589282499800902 time
train_step spend 0.7095801810064586 time
policy_value spend 0.24173240800155327 time
train_step spend 0.7075879430049099 time
policy_value spend 0.24705750099383295 time
train_step spend 0.7096725680021336 time
policy_value spend 0.24054368599900045 time
kl:0.09911,lr_multiplier:0.088,loss:2.7670857906341553,entropy:3.360795497894287,explained_var_old:0.992452443,explained_var_new:0.993868530
output spend 0.00016780900477897376 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004572177000227384 time
recovery_state_mcts_prob spend 0.2886840610008221 time
state_batch spend 0.0019852050027111545 time
mcts_probs_batch spend 0.0062808209913782775 time
winner_batch spend 0.0002679020108189434 time
policy_value spend 0.2408433660020819 time
train_step spend 0.7080467519990634 time
policy_value spend 0.2407492850034032 time
train_step spend 0.7088929289893713 time
policy_value spend 0.24071796900534537 time
train_step spend 0.7085033399926033 time
policy_value spend 0.24120133100950625 time
train_step spend 0.7064159069996094 time
policy_value spend 0.2415762390010059 time
kl:0.08602,lr_multiplier:0.088,loss:2.7872204780578613,entropy:3.3939883708953857,explained_var_old:0.991501629,explained_var_new:0.996242166
output spend 0.00017180100257974118 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0047700090071884915 time
recovery_state_mcts_prob spend 0.357723512002849 time
state_batch spend 0.00426569399132859 time
mcts_probs_batch spend 0.007084437005687505 time
winner_batch spend 0.00026233599055558443 time
policy_value spend 0.2503115770086879 time
train_step spend 0.71196041899384 time
policy_value spend 0.24150178401032463 time
train_step spend 0.7071302450058283 time
policy_value spend 0.2411125539947534 time
train_step spend 0.7096344989986392 time
policy_value spend 0.24079826699744444 time
train_step spend 0.7068535529979272 time
policy_value spend 0.24054829400847666 time
kl:0.08139,lr_multiplier:0.088,loss:2.8051812648773193,entropy:3.3940138816833496,explained_var_old:0.980129361,explained_var_new:0.986516237
output spend 0.00018027100304607302 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00480494400835596 time
recovery_state_mcts_prob spend 0.31604403199162334 time
state_batch spend 0.0038776190049247816 time
mcts_probs_batch spend 0.016002314994693734 time
winner_batch spend 0.0002866770082619041 time
policy_value spend 0.24511852298746817 time
train_step spend 0.7092340590024833 time
policy_value spend 0.252008351002587 time
train_step spend 0.7090506189997541 time
policy_value spend 0.24344710500736255 time
train_step spend 0.7096696559892735 time
policy_value spend 0.261953324006754 time
train_step spend 0.7131725929939421 time
policy_value spend 0.24038669500441756 time
kl:0.10128,lr_multiplier:0.088,loss:2.7768337726593018,entropy:3.3595759868621826,explained_var_old:0.985253394,explained_var_new:0.993623197
output spend 0.0001977139909286052 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00783078299718909 time
recovery_state_mcts_prob spend 0.2934562810114585 time
state_batch spend 0.004077555000549182 time
mcts_probs_batch spend 0.014262147989938967 time
winner_batch spend 0.0002969670022139326 time
policy_value spend 0.2452449370030081 time
train_step spend 0.7068954429996666 time
policy_value spend 0.24297608798951842 time
train_step spend 0.707269394013565 time
policy_value spend 0.24000045699358452 time
train_step spend 0.7066846759989858 time
policy_value spend 0.24198293100926094 time
train_step spend 0.7081770269869594 time
policy_value spend 0.2409079840144841 time
kl:0.08290,lr_multiplier:0.088,loss:2.794508934020996,entropy:3.3831238746643066,explained_var_old:0.995019555,explained_var_new:0.998098314
output spend 0.0001902290096040815 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004258211003616452 time
recovery_state_mcts_prob spend 0.35988025000551715 time
state_batch spend 0.00392902699240949 time
mcts_probs_batch spend 0.007379230999504216 time
winner_batch spend 0.0003066079952986911 time
policy_value spend 0.24215420700784307 time
train_step spend 0.7061912949866382 time
policy_value spend 0.24220083700492978 time
train_step spend 0.707408296992071 time
policy_value spend 0.24070055900665466 time
train_step spend 0.7078222169948276 time
policy_value spend 0.24080171999230515 time
train_step spend 0.7101989680086263 time
policy_value spend 0.2401514479861362 time
train_step spend 0.7068093389971182 time
policy_value spend 0.24031807600113098 time
kl:0.08571,lr_multiplier:0.088,loss:2.806760787963867,entropy:3.3847556114196777,explained_var_old:0.998630404,explained_var_new:0.996969938
output spend 0.00018558200099505484 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004028718001791276 time
recovery_state_mcts_prob spend 0.2879998999997042 time
state_batch spend 0.018424893001792952 time
mcts_probs_batch spend 0.018816918003722094 time
winner_batch spend 0.0003008740022778511 time
policy_value spend 0.2438301619986305 time
train_step spend 0.7076030830066884 time
policy_value spend 0.24062707800476346 time
train_step spend 0.7071876499976497 time
policy_value spend 0.2585420840041479 time
train_step spend 0.7107390119927004 time
policy_value spend 0.2435625550133409 time
train_step spend 0.7072027639951557 time
policy_value spend 0.2513340790028451 time
train_step spend 0.7125242549955146 time
policy_value spend 0.24061873700702563 time
kl:0.09729,lr_multiplier:0.088,loss:2.8206191062927246,entropy:3.3904218673706055,explained_var_old:0.984809160,explained_var_new:0.991443098
output spend 0.00017115399532485753 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0040658149955561385 time
recovery_state_mcts_prob spend 0.30600249901181087 time
state_batch spend 0.003949694990296848 time
mcts_probs_batch spend 0.007553814008133486 time
winner_batch spend 0.00028924299112986773 time
policy_value spend 0.2423210900014965 time
train_step spend 0.7076094310032204 time
policy_value spend 0.24010892899241298 time
train_step spend 0.707121380008175 time
policy_value spend 0.24236209299124312 time
train_step spend 0.7078493660083041 time
policy_value spend 0.2404977650003275 time
train_step spend 0.7064974249951774 time
policy_value spend 0.24157029000343755 time
train_step spend 0.7073593230015831 time
policy_value spend 0.2414824379957281 time
kl:0.08643,lr_multiplier:0.088,loss:2.833233118057251,entropy:3.4227657318115234,explained_var_old:0.990055263,explained_var_new:0.999408126
output spend 0.00016716800746507943 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00476756900025066 time
recovery_state_mcts_prob spend 0.28297902099438943 time
state_batch spend 0.0034087249950971454 time
mcts_probs_batch spend 0.007588523003505543 time
winner_batch spend 0.00028464000206440687 time
policy_value spend 0.24162272199464496 time
train_step spend 0.7075574540067464 time
policy_value spend 0.24098870599118527 time
train_step spend 0.7091171310021309 time
policy_value spend 0.24135349500284065 time
train_step spend 0.7066205640003318 time
policy_value spend 0.2417069790099049 time
train_step spend 0.7073125579918269 time
policy_value spend 0.24120143199979793 time
kl:0.08131,lr_multiplier:0.088,loss:2.8446848392486572,entropy:3.418118953704834,explained_var_old:0.987465560,explained_var_new:0.993261278
output spend 0.0002305249945493415 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005323724006302655 time
recovery_state_mcts_prob spend 0.29344406399468426 time
state_batch spend 0.003838896009256132 time
mcts_probs_batch spend 0.00738947099307552 time
winner_batch spend 0.0002694470022106543 time
policy_value spend 0.24213100199995097 time
train_step spend 0.7106930059962906 time
policy_value spend 0.2414666330005275 time
train_step spend 0.706776669001556 time
policy_value spend 0.24146906900568865 time
train_step spend 0.7090925990050891 time
policy_value spend 0.2408871949883178 time
train_step spend 0.707574130006833 time
policy_value spend 0.2407327079999959 time
kl:0.08813,lr_multiplier:0.088,loss:2.834895610809326,entropy:3.420492172241211,explained_var_old:0.987798512,explained_var_new:0.992641091
output spend 0.00016790699737612158 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.009832454001298174 time
recovery_state_mcts_prob spend 0.3337842479959363 time
state_batch spend 0.0034478900051908568 time
mcts_probs_batch spend 0.0075141179986530915 time
winner_batch spend 0.00028276300872676075 time
policy_value spend 0.24260305499774404 time
train_step spend 0.7060717020067386 time
policy_value spend 0.24269458999333438 time
train_step spend 0.7063012239959789 time
policy_value spend 0.24098631800734438 time
train_step spend 0.7088110850017983 time
policy_value spend 0.24097647800226696 time
train_step spend 0.7064240379986586 time
policy_value spend 0.24035502600600012 time
train_step spend 0.7070292699936545 time
policy_value spend 0.24079959900700487 time
kl:0.09621,lr_multiplier:0.088,loss:2.805586814880371,entropy:3.35378360748291,explained_var_old:0.983738422,explained_var_new:0.971102953
output spend 0.0002075320080621168 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00505478099512402 time
recovery_state_mcts_prob spend 0.28050937700027134 time
state_batch spend 0.002505309006664902 time
mcts_probs_batch spend 0.012674793993937783 time
winner_batch spend 0.00026431500737089664 time
policy_value spend 0.24536487000295892 time
train_step spend 0.7069469510024646 time
policy_value spend 0.24153484700946137 time
train_step spend 0.7079813589953119 time
policy_value spend 0.24528612599533517 time
train_step spend 0.708158181005274 time
policy_value spend 0.24069065699586645 time
train_step spend 0.7063492000015685 time
policy_value spend 0.25126672399346717 time
kl:0.08442,lr_multiplier:0.088,loss:2.7293877601623535,entropy:3.2997403144836426,explained_var_old:0.981482327,explained_var_new:0.993032515
output spend 0.00044355899444781244 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0036390289897099137 time
recovery_state_mcts_prob spend 0.2884715289983433 time
state_batch spend 0.001943057999596931 time
mcts_probs_batch spend 0.007405624011880718 time
winner_batch spend 0.00027052999939769506 time
policy_value spend 0.24183533199538942 time
train_step spend 0.7077399839909049 time
policy_value spend 0.24042773200199008 time
train_step spend 0.7073978900007205 time
policy_value spend 0.2411746189900441 time
train_step spend 0.7098888219916262 time
policy_value spend 0.24031994301185478 time
train_step spend 0.7076215309934923 time
policy_value spend 0.2410289620020194 time
kl:0.08257,lr_multiplier:0.088,loss:2.8604044914245605,entropy:3.4306588172912598,explained_var_old:0.988754570,explained_var_new:0.998674512
output spend 0.00016320998838637024 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003972121994593181 time
recovery_state_mcts_prob spend 0.2895445890026167 time
state_batch spend 0.0034918879973702133 time
mcts_probs_batch spend 0.007419542002025992 time
winner_batch spend 0.0002755030000116676 time
policy_value spend 0.2426608100067824 time
train_step spend 0.7058419690001756 time
policy_value spend 0.2437667310005054 time
train_step spend 0.7070171419909457 time
policy_value spend 0.24099691600713413 time
train_step spend 0.7089633269933984 time
policy_value spend 0.24324648099718615 time
train_step spend 0.7068619870115072 time
policy_value spend 0.2402562939969357 time
train_step spend 0.706792677010526 time
policy_value spend 0.24050284500117414 time
kl:0.10541,lr_multiplier:0.088,loss:2.773442506790161,entropy:3.3448026180267334,explained_var_old:0.991223574,explained_var_new:0.994455338
output spend 0.00016241999401245266 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004040672996779904 time
recovery_state_mcts_prob spend 0.36104847000387963 time
state_batch spend 0.0018902720039477572 time
mcts_probs_batch spend 0.010782785000628792 time
winner_batch spend 0.0002722119970712811 time
policy_value spend 0.24551632499787956 time
train_step spend 0.7086843240103917 time
policy_value spend 0.24368356500053778 time
train_step spend 0.7154497349984013 time
policy_value spend 0.2431714800040936 time
train_step spend 0.708239486993989 time
policy_value spend 0.24027606401068624 time
train_step spend 0.7075564730039332 time
policy_value spend 0.2412545230035903 time
kl:0.08120,lr_multiplier:0.088,loss:2.7694027423858643,entropy:3.339247941970825,explained_var_old:0.983198464,explained_var_new:0.988205075
output spend 0.00017682899488136172 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003973407990997657 time
recovery_state_mcts_prob spend 0.2962428940081736 time
state_batch spend 0.0035716099955607206 time
mcts_probs_batch spend 0.007285004001460038 time
winner_batch spend 0.00026582500140648335 time
policy_value spend 0.24227369599975646 time
train_step spend 0.7119732460123487 time
policy_value spend 0.24143923899100628 time
train_step spend 0.7069296060071792 time
policy_value spend 0.24072112300200388 time
train_step spend 0.7104254509904422 time
policy_value spend 0.24029625600087456 time
train_step spend 0.706507729992154 time
policy_value spend 0.24105297900678124 time
train_step spend 0.7068190580030205 time
policy_value spend 0.2405686909914948 time
kl:0.09169,lr_multiplier:0.088,loss:2.764981985092163,entropy:3.319077491760254,explained_var_old:0.986257732,explained_var_new:0.973822951
output spend 0.00016542899538762867 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00425027399614919 time
recovery_state_mcts_prob spend 0.2797295360069256 time
state_batch spend 0.0019030730036320165 time
mcts_probs_batch spend 0.007525377994170412 time
winner_batch spend 0.00028326699975878 time
policy_value spend 0.2458595450007124 time
train_step spend 0.7095456450042548 time
policy_value spend 0.24047639800119214 time
train_step spend 0.7077291879977565 time
policy_value spend 0.24241608000011183 time
train_step spend 0.7079308760003187 time
policy_value spend 0.24194862598960754 time
train_step spend 0.7067606130003696 time
policy_value spend 0.2412803120096214 time
kl:0.08156,lr_multiplier:0.088,loss:2.7998955249786377,entropy:3.384286642074585,explained_var_old:0.987061739,explained_var_new:0.997982979
output spend 0.0001637940004002303 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006448801999795251 time
recovery_state_mcts_prob spend 0.29816651200235356 time
state_batch spend 0.004174094996415079 time
mcts_probs_batch spend 0.016097658008220606 time
winner_batch spend 0.00033544900361448526 time
policy_value spend 0.24595732099260204 time
train_step spend 0.7082362200017087 time
policy_value spend 0.2408417440019548 time
train_step spend 0.707042788999388 time
policy_value spend 0.24292797700036317 time
train_step spend 0.7104386430000886 time
policy_value spend 0.24066545099776704 time
train_step spend 0.7069079000066267 time
policy_value spend 0.2406665409944253 time
train_step spend 0.7069193839997752 time
policy_value spend 0.24039597499358933 time
kl:0.09684,lr_multiplier:0.088,loss:2.8219711780548096,entropy:3.404998779296875,explained_var_old:0.992527962,explained_var_new:0.992902875
output spend 0.00016662800044286996 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00478238399955444 time
recovery_state_mcts_prob spend 0.2972345510061132 time
state_batch spend 0.004162316006841138 time
mcts_probs_batch spend 0.006826991986599751 time
winner_batch spend 0.0002644090127432719 time
policy_value spend 0.24225224599649664 time
train_step spend 0.7060250079957768 time
policy_value spend 0.24504294000507798 time
train_step spend 0.7113132110098377 time
policy_value spend 0.24162864100071602 time
train_step spend 0.7083636820025276 time
policy_value spend 0.24395553200156428 time
train_step spend 0.7064663359924452 time
policy_value spend 0.24278593000781257 time
train_step spend 0.706985867000185 time
policy_value spend 0.24036687500483822 time
kl:0.10111,lr_multiplier:0.088,loss:2.8102223873138428,entropy:3.380138397216797,explained_var_old:0.990464151,explained_var_new:0.992462993
output spend 0.0002993780071847141 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004799506001290865 time
recovery_state_mcts_prob spend 0.28002918999118265 time
state_batch spend 0.0019519930065143853 time
mcts_probs_batch spend 0.00792841799557209 time
winner_batch spend 0.00034039499587379396 time
policy_value spend 0.24274374300148338 time
train_step spend 0.7093801979935961 time
policy_value spend 0.24188415000389796 time
train_step spend 0.7077373270003591 time
policy_value spend 0.24105157099256758 time
train_step spend 0.7073313600121764 time
policy_value spend 0.2444912359933369 time
train_step spend 0.7069112919998588 time
policy_value spend 0.24056963498878758 time
kl:0.08388,lr_multiplier:0.088,loss:2.8014254570007324,entropy:3.3512134552001953,explained_var_old:0.988250494,explained_var_new:0.993726373
output spend 0.00016756998957134783 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00537193899799604 time
recovery_state_mcts_prob spend 0.2829012729926035 time
state_batch spend 0.0020205180044285953 time
mcts_probs_batch spend 0.006798520000302233 time
winner_batch spend 0.0002661820035427809 time
policy_value spend 0.2429353329935111 time
train_step spend 0.7072420959884766 time
policy_value spend 0.2410013340122532 time
train_step spend 0.709224941994762 time
policy_value spend 0.24021530999743845 time
train_step spend 0.7069599379901774 time
policy_value spend 0.24051938000775408 time
train_step spend 0.7075541579979472 time
policy_value spend 0.2411459470022237 time
kl:0.09399,lr_multiplier:0.088,loss:2.8252172470092773,entropy:3.382741689682007,explained_var_old:0.985827208,explained_var_new:0.992012739
output spend 0.00016440299805253744 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003941682996810414 time
recovery_state_mcts_prob spend 0.382784757995978 time
state_batch spend 0.002713228008360602 time
mcts_probs_batch spend 0.006343172994093038 time
winner_batch spend 0.00027737799973692745 time
policy_value spend 0.24151103499752935 time
train_step spend 0.706254242992145 time
policy_value spend 0.24390436000248883 time
train_step spend 0.706207188006374 time
policy_value spend 0.24242013398907147 time
train_step spend 0.708143501993618 time
policy_value spend 0.24149637400114443 time
train_step spend 0.7064401529933093 time
policy_value spend 0.24149200899410062 time
kl:0.09139,lr_multiplier:0.088,loss:2.7937936782836914,entropy:3.36684513092041,explained_var_old:0.982267201,explained_var_new:0.869761586
output spend 0.00016495499585289508 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00480146799236536 time
recovery_state_mcts_prob spend 0.2917111590068089 time
state_batch spend 0.0020015149930259213 time
mcts_probs_batch spend 0.006278881002799608 time
winner_batch spend 0.00026980000257026404 time
policy_value spend 0.24087998899631202 time
train_step spend 0.7081197569932556 time
policy_value spend 0.24791257000470068 time
train_step spend 0.7078971119917696 time
policy_value spend 0.24086256900045555 time
train_step spend 0.7088935770007083 time
policy_value spend 0.24271575099555776 time
kl:0.08317,lr_multiplier:0.088,loss:2.7977027893066406,entropy:3.366077423095703,explained_var_old:0.868540049,explained_var_new:0.993484676
output spend 0.0004217179957777262 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004748352992464788 time
recovery_state_mcts_prob spend 0.28474809300678317 time
state_batch spend 0.002113170994562097 time
mcts_probs_batch spend 0.004859267006395385 time
winner_batch spend 0.0002733369910856709 time
policy_value spend 0.2408329840109218 time
train_step spend 0.7070742280047853 time
policy_value spend 0.24075193400494754 time
train_step spend 0.7070808049902553 time
policy_value spend 0.24088906600081827 time
train_step spend 0.7067827809951268 time
policy_value spend 0.24039860100310761 time
train_step spend 0.7089708830026211 time
policy_value spend 0.24240788299357519 time
kl:0.08589,lr_multiplier:0.088,loss:2.8101837635040283,entropy:3.3964669704437256,explained_var_old:0.989323437,explained_var_new:0.975951910
output spend 0.00021661099162884057 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0045812940079486 time
recovery_state_mcts_prob spend 0.294443920996855 time
state_batch spend 0.001999704007175751 time
mcts_probs_batch spend 0.008383990993024781 time
winner_batch spend 0.0002893049968406558 time
policy_value spend 0.24247685400769114 time
train_step spend 0.707050660988898 time
policy_value spend 0.2417170190019533 time
train_step spend 0.7074019589927047 time
policy_value spend 0.2417498120048549 time
train_step spend 0.7072784670017427 time
policy_value spend 0.2424277069949312 time
train_step spend 0.7064805080008227 time
policy_value spend 0.2418733130034525 time
kl:0.09904,lr_multiplier:0.088,loss:2.852771759033203,entropy:3.4196557998657227,explained_var_old:0.971148729,explained_var_new:0.968407333
output spend 0.00017852199380286038 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005141904010088183 time
recovery_state_mcts_prob spend 0.2904548340011388 time
state_batch spend 0.0035506799904396757 time
mcts_probs_batch spend 0.00760396099940408 time
winner_batch spend 0.0002765740064205602 time
policy_value spend 0.2622719840001082 time
train_step spend 0.713201502992888 time
policy_value spend 0.24042417600867338 time
train_step spend 0.7066657010000199 time
policy_value spend 0.24034356299671344 time
kl:0.11703,lr_multiplier:0.088,loss:2.8702423572540283,entropy:3.4247450828552246,explained_var_old:0.960806966,explained_var_new:0.342660427
output spend 0.00020957800734322518 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0042207689984934404 time
recovery_state_mcts_prob spend 0.3067000289884163 time
state_batch spend 0.0034539870102889836 time
mcts_probs_batch spend 0.015119167001103051 time
winner_batch spend 0.000291691001621075 time
policy_value spend 0.2457514189882204 time
train_step spend 0.7062350940104807 time
policy_value spend 0.2414235289907083 time
train_step spend 0.7082802380027715 time
policy_value spend 0.2410766370012425 time
kl:0.19334,lr_multiplier:0.088,loss:2.8683035373687744,entropy:3.438460350036621,explained_var_old:0.377549827,explained_var_new:0.708841205
output spend 0.0001690070057520643 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004518917994573712 time
recovery_state_mcts_prob spend 0.2905286800087197 time
state_batch spend 0.003596631999243982 time
mcts_probs_batch spend 0.0073941989976447076 time
winner_batch spend 0.0002614590048324317 time
policy_value spend 0.24172532100055832 time
train_step spend 0.7076968299952568 time
policy_value spend 0.24070257900166325 time
train_step spend 0.7063363320048666 time
policy_value spend 0.2401195260026725 time
kl:0.23698,lr_multiplier:0.088,loss:2.964620351791382,entropy:3.4506895542144775,explained_var_old:0.636660993,explained_var_new:0.170061052
output spend 0.00016294499801006168 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005260202000499703 time
recovery_state_mcts_prob spend 0.2919587430078536 time
state_batch spend 0.004320285996072926 time
mcts_probs_batch spend 0.006786921992897987 time
winner_batch spend 0.0002847779978765175 time
policy_value spend 0.24602314800722525 time
train_step spend 0.7090591019950807 time
policy_value spend 0.24542545300209895 time
kl:0.21953,lr_multiplier:0.088,loss:2.990532159805298,entropy:3.4723920822143555,explained_var_old:0.174991846,explained_var_new:-0.185054660
output spend 0.00023863300157245249 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004686353000579402 time
recovery_state_mcts_prob spend 0.2954514029988786 time
state_batch spend 0.003953694002120756 time
mcts_probs_batch spend 0.007825587003026158 time
winner_batch spend 0.00028238400409463793 time
policy_value spend 0.2443960449891165 time
train_step spend 0.7079767390096094 time
policy_value spend 0.24145762099942658 time
train_step spend 0.7106579579995014 time
policy_value spend 0.24237143900245428 time
kl:0.18775,lr_multiplier:0.088,loss:2.9044265747070312,entropy:3.4964113235473633,explained_var_old:-0.168347716,explained_var_new:0.849157453
output spend 0.00017182600277010351 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006370338989654556 time
recovery_state_mcts_prob spend 0.2887432810093742 time
state_batch spend 0.004111999995075166 time
mcts_probs_batch spend 0.0063568610057700425 time
winner_batch spend 0.0002851309982361272 time
policy_value spend 0.24178143100289162 time
train_step spend 0.7064967610058375 time
policy_value spend 0.24204189899319317 time
train_step spend 0.706976424989989 time
policy_value spend 0.24203157400188502 time
kl:0.13361,lr_multiplier:0.088,loss:2.889981269836426,entropy:3.5050835609436035,explained_var_old:0.784146249,explained_var_new:0.948665440
output spend 0.00018020400602836162 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005401792004704475 time
recovery_state_mcts_prob spend 0.2919756100018276 time
state_batch spend 0.0035863099910784513 time
mcts_probs_batch spend 0.0072166020108852535 time
winner_batch spend 0.00026473100297152996 time
policy_value spend 0.24198632998741232 time
train_step spend 0.7070023440028308 time
policy_value spend 0.24152239700197242 time
train_step spend 0.7069339339941507 time
policy_value spend 0.23994334200688172 time
kl:0.12272,lr_multiplier:0.088,loss:2.8911516666412354,entropy:3.482469081878662,explained_var_old:0.944544375,explained_var_new:0.908583403
output spend 0.0002098700060741976 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004477711991057731 time
recovery_state_mcts_prob spend 0.2836611460079439 time
state_batch spend 0.004054575998452492 time
mcts_probs_batch spend 0.013953868998214602 time
winner_batch spend 0.0002691300032893196 time
policy_value spend 0.25095777699607424 time
train_step spend 0.7079523470019922 time
policy_value spend 0.24218754800676834 time
train_step spend 0.708738686007564 time
policy_value spend 0.2553511829901254 time
kl:0.08717,lr_multiplier:0.088,loss:2.849879741668701,entropy:3.490851879119873,explained_var_old:0.898027420,explained_var_new:0.840143561
output spend 0.0003298999945400283 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00404814000648912 time
recovery_state_mcts_prob spend 0.2896703750011511 time
state_batch spend 0.003990161989349872 time
mcts_probs_batch spend 0.008270100006484427 time
winner_batch spend 0.0003005659964401275 time
policy_value spend 0.2421628940064693 time
train_step spend 0.7067559489951236 time
policy_value spend 0.24446197799989022 time
train_step spend 0.7075772909884108 time
policy_value spend 0.24031589200603776 time
train_step spend 0.7061590520024765 time
policy_value spend 0.24080395000055432 time
kl:0.11481,lr_multiplier:0.088,loss:2.804088592529297,entropy:3.418825149536133,explained_var_old:0.840269685,explained_var_new:0.993325591
output spend 0.0002257390005979687 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005646787001751363 time
recovery_state_mcts_prob spend 0.38967309999861754 time
state_batch spend 0.0019896650046575814 time
mcts_probs_batch spend 0.005119977999129333 time
winner_batch spend 0.00027662400680128485 time
policy_value spend 0.24162353499559686 time
train_step spend 0.7076422090030974 time
policy_value spend 0.24184308599797077 time
train_step spend 0.7066267920017708 time
policy_value spend 0.24057046200323384 time
train_step spend 0.707647207993432 time
policy_value spend 0.24080166600469965 time
train_step spend 0.7063906760013197 time
policy_value spend 0.24057603999972343 time
kl:0.09575,lr_multiplier:0.088,loss:2.891303539276123,entropy:3.45155930519104,explained_var_old:0.986821413,explained_var_new:0.856895030
output spend 0.00016734500241000205 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0048483660066267475 time
recovery_state_mcts_prob spend 0.2887682829896221 time
state_batch spend 0.0035470069997245446 time
mcts_probs_batch spend 0.008315752013004385 time
winner_batch spend 0.0002786639961414039 time
policy_value spend 0.2422309849935118 time
train_step spend 0.7077864370075986 time
policy_value spend 0.24404871198930778 time
train_step spend 0.7060638109978754 time
policy_value spend 0.24089835699123796 time
train_step spend 0.7067121400032192 time
policy_value spend 0.25663185300072655 time
train_step spend 0.7086341800022637 time
policy_value spend 0.24122338299639523 time
kl:0.09576,lr_multiplier:0.088,loss:2.8129923343658447,entropy:3.4008545875549316,explained_var_old:0.911014974,explained_var_new:0.980942070
output spend 0.00018939199799206108 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005196561993216164 time
recovery_state_mcts_prob spend 0.28379888500785455 time
state_batch spend 0.004538719993433915 time
mcts_probs_batch spend 0.007963887008372694 time
winner_batch spend 0.0002764939999906346 time
policy_value spend 0.242216971993912 time
train_step spend 0.7067666279908735 time
policy_value spend 0.24469066900201142 time
train_step spend 0.7082622379966779 time
policy_value spend 0.24103597601060756 time
train_step spend 0.7071736020006938 time
policy_value spend 0.24054276100650895 time
train_step spend 0.7071673960017506 time
policy_value spend 0.24056255799951032 time
train_step spend 0.7078381719911704 time
policy_value spend 0.2412519610079471 time
kl:0.08658,lr_multiplier:0.088,loss:2.807710647583008,entropy:3.3667991161346436,explained_var_old:0.968484461,explained_var_new:0.988438964
output spend 0.00017940500401891768 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004110904992558062 time
recovery_state_mcts_prob spend 0.3090472470066743 time
state_batch spend 0.0025784189929254353 time
mcts_probs_batch spend 0.010831246007001027 time
winner_batch spend 0.0002699939941521734 time
policy_value spend 0.24281109900039155 time
train_step spend 0.7088743240019539 time
policy_value spend 0.24481153700617142 time
train_step spend 0.7077774130011676 time
policy_value spend 0.24020804699102882 time
train_step spend 0.7062511660042219 time
policy_value spend 0.2629838720022235 time
train_step spend 0.7061419439996826 time
policy_value spend 0.24148256200714968 time
train_step spend 0.706299827012117 time
policy_value spend 0.24082612099300604 time
kl:0.08685,lr_multiplier:0.088,loss:2.8214151859283447,entropy:3.399890422821045,explained_var_old:0.980435729,explained_var_new:0.989217579
output spend 0.00017836700135376304 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0063387739937752485 time
recovery_state_mcts_prob spend 0.2951660780090606 time
state_batch spend 0.001948025994352065 time
mcts_probs_batch spend 0.005100245005451143 time
winner_batch spend 0.00029513699701055884 time
policy_value spend 0.24094313199748285 time
train_step spend 0.7069250240019755 time
policy_value spend 0.24228050600504503 time
train_step spend 0.7079540309932781 time
policy_value spend 0.24101354400045238 time
train_step spend 0.7071055619890103 time
policy_value spend 0.24080452200723812 time
train_step spend 0.70619303600688 time
policy_value spend 0.24125900999933947 time
train_step spend 0.7068215269973734 time
policy_value spend 0.2442576039902633 time
kl:0.08764,lr_multiplier:0.088,loss:2.8052806854248047,entropy:3.363621950149536,explained_var_old:0.974407136,explained_var_new:0.990067959
output spend 0.0001926480035763234 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004522813003859483 time
recovery_state_mcts_prob spend 0.374800473000505 time
state_batch spend 0.003512946001137607 time
mcts_probs_batch spend 0.0075763639906654134 time
winner_batch spend 0.000266716000624001 time
policy_value spend 0.24192086500988808 time
train_step spend 0.7076088649919257 time
policy_value spend 0.24231352501374204 time
train_step spend 0.7085080910037505 time
policy_value spend 0.2408719149971148 time
train_step spend 0.7068210569996154 time
policy_value spend 0.24025944800814614 time
train_step spend 0.7069663340080297 time
policy_value spend 0.24075137499312405 time
train_step spend 0.7065019669971662 time
policy_value spend 0.24038456700509414 time
kl:0.09189,lr_multiplier:0.088,loss:2.733430862426758,entropy:3.302894115447998,explained_var_old:0.994734466,explained_var_new:0.995798588
output spend 0.00016062799841165543 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004510859012953006 time
recovery_state_mcts_prob spend 0.2854301659972407 time
state_batch spend 0.004125050996663049 time
mcts_probs_batch spend 0.006985176994930953 time
winner_batch spend 0.000266025002929382 time
policy_value spend 0.2503550389956217 time
train_step spend 0.7096431999962078 time
policy_value spend 0.24220365600194782 time
train_step spend 0.7084508370026015 time
policy_value spend 0.2624527970037889 time
train_step spend 0.7064842490071896 time
policy_value spend 0.24107495999487583 time
train_step spend 0.7070510899939109 time
policy_value spend 0.24976846600475255 time
train_step spend 0.7149829539994244 time
policy_value spend 0.24062103799951728 time
kl:0.10456,lr_multiplier:0.088,loss:2.7716546058654785,entropy:3.3265035152435303,explained_var_old:0.987502515,explained_var_new:0.992029071
output spend 0.0001648070028750226 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004410855006426573 time
recovery_state_mcts_prob spend 0.2900722170015797 time
state_batch spend 0.0035636529937619343 time
mcts_probs_batch spend 0.007588513006339781 time
winner_batch spend 0.00026273100229445845 time
policy_value spend 0.241763052996248 time
train_step spend 0.7066306810011156 time
policy_value spend 0.2433400250010891 time
train_step spend 0.7084815990092466 time
policy_value spend 0.24063650199968833 time
train_step spend 0.7063254859967856 time
policy_value spend 0.24075473300763406 time
train_step spend 0.7066520649968879 time
policy_value spend 0.24027893599122763 time
train_step spend 0.7116940970008727 time
policy_value spend 0.2409650170011446 time
kl:0.09647,lr_multiplier:0.088,loss:2.845104455947876,entropy:3.4091219902038574,explained_var_old:0.991864562,explained_var_new:0.994187772
output spend 0.00016132000018842518 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005526121007278562 time
recovery_state_mcts_prob spend 0.3157509430020582 time
state_batch spend 0.004399579003802501 time
mcts_probs_batch spend 0.013449135993141681 time
winner_batch spend 0.0002795589971356094 time
policy_value spend 0.2448728570016101 time
train_step spend 0.7098115620028693 time
policy_value spend 0.24938380399544258 time
train_step spend 0.7085059100063518 time
policy_value spend 0.24017117999028414 time
train_step spend 0.707057936990168 time
policy_value spend 0.25274082500254735 time
train_step spend 0.7087658679956803 time
policy_value spend 0.24049088300671428 time
kl:0.08085,lr_multiplier:0.088,loss:2.7784152030944824,entropy:3.3355140686035156,explained_var_old:0.988005519,explained_var_new:0.993087888
output spend 0.00017390299763064831 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0049720620008884 time
recovery_state_mcts_prob spend 0.2831414389947895 time
state_batch spend 0.0036263450019760057 time
mcts_probs_batch spend 0.014157790006720461 time
winner_batch spend 0.00029940599051769823 time
policy_value spend 0.2633865850075381 time
train_step spend 0.7215289169980679 time
policy_value spend 0.2408965139911743 time
train_step spend 0.7091863719979301 time
policy_value spend 0.24076690099900588 time
train_step spend 0.7062133970030118 time
policy_value spend 0.24086761299986392 time
train_step spend 0.7069227939937264 time
policy_value spend 0.24195554900506977 time
train_step spend 0.7073599199939054 time
policy_value spend 0.24034603100153618 time
kl:0.08921,lr_multiplier:0.088,loss:2.709981679916382,entropy:3.2665817737579346,explained_var_old:0.993626058,explained_var_new:0.995149910
output spend 0.0001646089949645102 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004974126990418881 time
recovery_state_mcts_prob spend 0.2809613130084472 time
state_batch spend 0.0019540359935490415 time
mcts_probs_batch spend 0.006330468997475691 time
winner_batch spend 0.0002753480075625703 time
policy_value spend 0.24062241800129414 time
train_step spend 0.7076167929917574 time
policy_value spend 0.2430640719976509 time
train_step spend 0.7081756129919086 time
policy_value spend 0.24088047600525897 time
train_step spend 0.7073280299955513 time
policy_value spend 0.24078178900526837 time
train_step spend 0.7075519689969951 time
policy_value spend 0.24039724199974444 time
train_step spend 0.7075925969984382 time
policy_value spend 0.24032262299442664 time
kl:0.08901,lr_multiplier:0.088,loss:2.7448251247406006,entropy:3.3055667877197266,explained_var_old:0.987856746,explained_var_new:0.994092226
output spend 0.00016597799549344927 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00600912599475123 time
recovery_state_mcts_prob spend 0.2933854760049144 time
state_batch spend 0.004373079995275475 time
mcts_probs_batch spend 0.008307073003379628 time
winner_batch spend 0.0002893670025514439 time
policy_value spend 0.24362863900023513 time
train_step spend 0.7065546599915251 time
policy_value spend 0.24951384800078813 time
train_step spend 0.708641126009752 time
policy_value spend 0.2410595479886979 time
train_step spend 0.7058379160007462 time
policy_value spend 0.2542937780090142 time
train_step spend 0.7070245509967208 time
policy_value spend 0.24331268300011288 time
train_step spend 0.7105486600048607 time
policy_value spend 0.254455265996512 time
kl:0.08521,lr_multiplier:0.088,loss:2.7376105785369873,entropy:3.2787022590637207,explained_var_old:0.987383008,explained_var_new:0.990789175
output spend 0.0005141060100868344 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0052501919999485835 time
recovery_state_mcts_prob spend 0.3090128349867882 time
state_batch spend 0.0041706240008352324 time
mcts_probs_batch spend 0.013213386002462357 time
winner_batch spend 0.00027209600375499576 time
policy_value spend 0.24558295900351368 time
train_step spend 0.7081043490034062 time
policy_value spend 0.24214339299942367 time
train_step spend 0.707997584991972 time
policy_value spend 0.24090852600056678 time
train_step spend 0.7064408180012833 time
policy_value spend 0.24097813699336257 time
train_step spend 0.7071263710095081 time
policy_value spend 0.24068237699975725 time
train_step spend 0.7065639650099911 time
policy_value spend 0.2404582499875687 time
kl:0.10342,lr_multiplier:0.088,loss:2.8110854625701904,entropy:3.379526138305664,explained_var_old:0.996130884,explained_var_new:0.996576846
output spend 0.00017972500063478947 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005743509012972936 time
recovery_state_mcts_prob spend 0.3772780849976698 time
state_batch spend 0.003542042992194183 time
mcts_probs_batch spend 0.0077073380089132115 time
winner_batch spend 0.0002685189974727109 time
policy_value spend 0.24192176999349613 time
train_step spend 0.7073842629906721 time
policy_value spend 0.24209321501257364 time
train_step spend 0.7091250010125805 time
policy_value spend 0.24045350299275015 time
train_step spend 0.7063950329902582 time
policy_value spend 0.24005117701017298 time
train_step spend 0.7067661780019989 time
policy_value spend 0.24049880399252288 time
train_step spend 0.706656126989401 time
policy_value spend 0.24125803200877272 time
kl:0.09760,lr_multiplier:0.088,loss:2.798402786254883,entropy:3.348158836364746,explained_var_old:0.989741921,explained_var_new:0.992839277
output spend 0.00017267400107812136 time
已保存最新模型
current self-play batch: 300
load data begin
已加载数据
step i 46: 
random.sample spend 0.004872058008913882 time
recovery_state_mcts_prob spend 0.2839239470049506 time
state_batch spend 0.0023434569884557277 time
mcts_probs_batch spend 0.00879513900144957 time
winner_batch spend 0.0003401690046302974 time
policy_value spend 0.24467884500336368 time
train_step spend 0.7250918490026379 time
policy_value spend 0.25732824800070375 time
train_step spend 0.7391235810064245 time
policy_value spend 0.2429581420001341 time
train_step spend 0.7096236230136128 time
policy_value spend 0.2417726989951916 time
train_step spend 0.7064440840040334 time
policy_value spend 0.2507086919940775 time
train_step spend 0.7068534890131559 time
policy_value spend 0.24153350098640658 time
kl:0.08528,lr_multiplier:0.088,loss:2.7678513526916504,entropy:3.308748960494995,explained_var_old:0.988439798,explained_var_new:0.990670919
output spend 0.00019879000319633633 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0043993780127493665 time
recovery_state_mcts_prob spend 0.2912732179975137 time
state_batch spend 0.0034843339963117614 time
mcts_probs_batch spend 0.007472956000128761 time
winner_batch spend 0.00023025900009088218 time
policy_value spend 0.24371090199565515 time
train_step spend 0.7071562009950867 time
policy_value spend 0.24603853501321282 time
train_step spend 0.7070368169952417 time
policy_value spend 0.24070260100415908 time
train_step spend 0.7069747929926962 time
policy_value spend 0.2406720350118121 time
train_step spend 0.7067884779971791 time
policy_value spend 0.2401732459984487 time
train_step spend 0.7077725670096697 time
policy_value spend 0.2406181859987555 time
kl:0.09146,lr_multiplier:0.088,loss:2.8114874362945557,entropy:3.3432250022888184,explained_var_old:0.974863768,explained_var_new:0.978909612
output spend 0.00016986600530799478 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004370998009108007 time
recovery_state_mcts_prob spend 0.3037668199976906 time
state_batch spend 0.0036495340027613565 time
mcts_probs_batch spend 0.007291213987627998 time
winner_batch spend 0.0002697020099731162 time
policy_value spend 0.2413674339913996 time
train_step spend 0.7068884199979948 time
policy_value spend 0.24085406999802217 time
train_step spend 0.7069084549875697 time
policy_value spend 0.2409645570005523 time
train_step spend 0.7065885839983821 time
policy_value spend 0.242402799995034 time
train_step spend 0.7068119070027024 time
policy_value spend 0.2403825460060034 time
train_step spend 0.7097853379964363 time
policy_value spend 0.2402427670022007 time
kl:0.09734,lr_multiplier:0.088,loss:2.731250047683716,entropy:3.2891077995300293,explained_var_old:0.991713345,explained_var_new:0.995357811
output spend 0.0001729139912640676 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004488460996071808 time
recovery_state_mcts_prob spend 0.2948119240027154 time
state_batch spend 0.0035480179940350354 time
mcts_probs_batch spend 0.021304815003531985 time
winner_batch spend 0.0003290470049250871 time
policy_value spend 0.24587137799244374 time
train_step spend 0.7065898000000743 time
policy_value spend 0.24355817299510818 time
train_step spend 0.7070756739994977 time
policy_value spend 0.24057955198804848 time
train_step spend 0.706047646002844 time
policy_value spend 0.24125489599828143 time
train_step spend 0.7076567510084715 time
policy_value spend 0.24119920399971306 time
train_step spend 0.7066302789899055 time
policy_value spend 0.24099889901117422 time
kl:0.10331,lr_multiplier:0.088,loss:2.7742421627044678,entropy:3.3044538497924805,explained_var_old:0.990367591,explained_var_new:0.992552936
output spend 0.00018593900313135237 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005228187001193874 time
recovery_state_mcts_prob spend 0.35663342899351846 time
state_batch spend 0.0037912690022494644 time
mcts_probs_batch spend 0.007733339996775612 time
winner_batch spend 0.0003890100051648915 time
policy_value spend 0.2429478959966218 time
train_step spend 0.7075911270076176 time
policy_value spend 0.24199519999092445 time
train_step spend 0.7075163530098507 time
policy_value spend 0.24144689299282618 time
train_step spend 0.7074267429998145 time
policy_value spend 0.26295293899602257 time
train_step spend 0.7178891499934252 time
policy_value spend 0.2404338610067498 time
train_step spend 0.7071294630004559 time
policy_value spend 0.24074199200549629 time
kl:0.09754,lr_multiplier:0.088,loss:2.716806173324585,entropy:3.2607321739196777,explained_var_old:0.994478941,explained_var_new:0.997119963
output spend 0.00016694600344635546 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004667804008931853 time
recovery_state_mcts_prob spend 0.29350545299530495 time
state_batch spend 0.004619985003955662 time
mcts_probs_batch spend 0.007397301989840344 time
winner_batch spend 0.00030830700416117907 time
policy_value spend 0.24227198799781036 time
train_step spend 0.707171592002851 time
policy_value spend 0.24450773299031425 time
train_step spend 0.7082797390030464 time
policy_value spend 0.24231974499707576 time
train_step spend 0.7146247760101687 time
policy_value spend 0.24045948099228553 time
train_step spend 0.7131827610137407 time
policy_value spend 0.25245041398738977 time
kl:0.08113,lr_multiplier:0.088,loss:2.776880979537964,entropy:3.3255667686462402,explained_var_old:0.997879565,explained_var_new:0.999176979
output spend 0.000301388994557783 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0062387420039158314 time
recovery_state_mcts_prob spend 0.30558095600281376 time
state_batch spend 0.004046750997076742 time
mcts_probs_batch spend 0.008260937000159174 time
winner_batch spend 0.00032511400058865547 time
policy_value spend 0.2422532390046399 time
train_step spend 0.7068394630041439 time
policy_value spend 0.24127827100164723 time
train_step spend 0.7073223740007961 time
policy_value spend 0.24160467300680466 time
train_step spend 0.7087287499889499 time
policy_value spend 0.24055697600124404 time
train_step spend 0.70967141300207 time
policy_value spend 0.2428068409935804 time
kl:0.08606,lr_multiplier:0.088,loss:2.7560369968414307,entropy:3.287139654159546,explained_var_old:0.988333583,explained_var_new:0.991291106
output spend 0.00022059000912122428 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004865384995355271 time
recovery_state_mcts_prob spend 0.28398469400417525 time
state_batch spend 0.0024978699948405847 time
mcts_probs_batch spend 0.006309033007710241 time
winner_batch spend 0.00026902600075118244 time
policy_value spend 0.24175712099531665 time
train_step spend 0.7080821660056245 time
policy_value spend 0.24194873399392236 time
train_step spend 0.7069083280075574 time
policy_value spend 0.2403697099944111 time
train_step spend 0.7064677629969083 time
policy_value spend 0.24051862300257199 time
train_step spend 0.7088669880031375 time
policy_value spend 0.24035049400117714 time
kl:0.10138,lr_multiplier:0.088,loss:2.8225464820861816,entropy:3.393429756164551,explained_var_old:0.991747141,explained_var_new:0.995072365
output spend 0.00017089801258407533 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004793151005287655 time
recovery_state_mcts_prob spend 0.288779736001743 time
state_batch spend 0.0041168789903167635 time
mcts_probs_batch spend 0.007403324008919299 time
winner_batch spend 0.00041620399861130863 time
policy_value spend 0.28280673699919134 time
train_step spend 0.7200062680058181 time
policy_value spend 0.24066270899493247 time
train_step spend 0.7070475670043379 time
policy_value spend 0.2504456909955479 time
train_step spend 0.7088584619923495 time
policy_value spend 0.2404709050024394 time
train_step spend 0.7081287019973388 time
policy_value spend 0.24248776800232008 time
kl:0.08085,lr_multiplier:0.088,loss:2.816819906234741,entropy:3.387637138366699,explained_var_old:0.987207174,explained_var_new:0.993393660
output spend 0.00047900600475259125 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0041951780003728345 time
recovery_state_mcts_prob spend 0.29974125100125093 time
state_batch spend 0.0019951260037487373 time
mcts_probs_batch spend 0.004871854995144531 time
winner_batch spend 0.0002767929981928319 time
policy_value spend 0.24140054000599775 time
train_step spend 0.7050600420043338 time
policy_value spend 0.24064098599774297 time
train_step spend 0.7037610140105244 time
policy_value spend 0.24000073499337304 time
train_step spend 0.7050565430108691 time
policy_value spend 0.2394907609996153 time
train_step spend 0.7064935349917505 time
policy_value spend 0.24165614700177684 time
kl:0.10825,lr_multiplier:0.088,loss:2.8264479637145996,entropy:3.370415449142456,explained_var_old:0.987251341,explained_var_new:0.992782176
output spend 0.00018244900275021791 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004521588998613879 time
recovery_state_mcts_prob spend 0.28351121400191914 time
state_batch spend 0.0019203449919587001 time
mcts_probs_batch spend 0.0049452470120741054 time
winner_batch spend 0.0002695869916351512 time
policy_value spend 0.24198413200792857 time
train_step spend 0.7080199189949781 time
policy_value spend 0.24055881399544887 time
train_step spend 0.7078605499991681 time
policy_value spend 0.24043545000313316 time
train_step spend 0.7080797770031495 time
policy_value spend 0.2449861059867544 time
train_step spend 0.7073023869888857 time
policy_value spend 0.2400751120003406 time
train_step spend 0.7077970859972993 time
policy_value spend 0.24012000700167846 time
kl:0.09101,lr_multiplier:0.088,loss:2.8284873962402344,entropy:3.410111427307129,explained_var_old:0.984287202,explained_var_new:0.985514700
output spend 0.00016658499953337014 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0037360930000431836 time
recovery_state_mcts_prob spend 0.29235941599472426 time
state_batch spend 0.0022941829956835136 time
mcts_probs_batch spend 0.005549503999645822 time
winner_batch spend 0.00030227500246837735 time
policy_value spend 0.24158036999870092 time
train_step spend 0.7076359490019968 time
policy_value spend 0.24095969198970124 time
train_step spend 0.7071110170072643 time
policy_value spend 0.24146537599153817 time
train_step spend 0.7069047200056957 time
policy_value spend 0.24115390299994033 time
train_step spend 0.7070113509980729 time
policy_value spend 0.24303669299115427 time
kl:0.08856,lr_multiplier:0.088,loss:2.7465813159942627,entropy:3.3112902641296387,explained_var_old:0.981770813,explained_var_new:0.997308373
output spend 0.00017111600027419627 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004396611999254674 time
recovery_state_mcts_prob spend 0.28464950699708425 time
state_batch spend 0.005956897002761252 time
mcts_probs_batch spend 0.0207225359918084 time
winner_batch spend 0.0002862000110326335 time
policy_value spend 0.24205800298659597 time
train_step spend 0.7076657110010274 time
policy_value spend 0.241165532002924 time
train_step spend 0.7052054329979001 time
policy_value spend 0.23884862499835435 time
train_step spend 0.7026466489915038 time
policy_value spend 0.24029743899882305 time
train_step spend 0.7067091719945893 time
policy_value spend 0.24050335701031145 time
train_step spend 0.7094639360002475 time
policy_value spend 0.24038104999635834 time
kl:0.09032,lr_multiplier:0.088,loss:2.818845748901367,entropy:3.380746841430664,explained_var_old:0.986519217,explained_var_new:0.991395831
output spend 0.00016678200336173177 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004314567995606922 time
recovery_state_mcts_prob spend 0.31858942699909676 time
state_batch spend 0.0025305360031779855 time
mcts_probs_batch spend 0.006388520996551961 time
winner_batch spend 0.0002723100042203441 time
policy_value spend 0.24227652400441002 time
train_step spend 0.7076731730048778 time
policy_value spend 0.24649383999349084 time
train_step spend 0.7070984560123179 time
policy_value spend 0.24107583099976182 time
train_step spend 0.7070444799901452 time
policy_value spend 0.25100120100250933 time
train_step spend 0.711260541997035 time
policy_value spend 0.24219799001002684 time
train_step spend 0.7041228379966924 time
policy_value spend 0.23945396600174718 time
kl:0.09100,lr_multiplier:0.088,loss:2.674299478530884,entropy:3.199282646179199,explained_var_old:0.981436312,explained_var_new:0.990263999
output spend 0.0002787690027616918 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003801090002525598 time
recovery_state_mcts_prob spend 0.28310336099821143 time
state_batch spend 0.001989530006540008 time
mcts_probs_batch spend 0.00705211800232064 time
winner_batch spend 0.00026990799233317375 time
policy_value spend 0.24143208299938124 time
train_step spend 0.7071155669982545 time
policy_value spend 0.24157286500849295 time
train_step spend 0.7066148019948741 time
policy_value spend 0.241500577001716 time
train_step spend 0.707028941003955 time
policy_value spend 0.24350611299450975 time
train_step spend 0.707792753004469 time
policy_value spend 0.2410385240073083 time
train_step spend 0.7062426249904092 time
policy_value spend 0.240425732001313 time
kl:0.09288,lr_multiplier:0.088,loss:2.8288087844848633,entropy:3.3847947120666504,explained_var_old:0.993681014,explained_var_new:0.991746128
output spend 0.00017304498760495335 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005634717992506921 time
recovery_state_mcts_prob spend 0.35977705000550486 time
state_batch spend 0.001981959998374805 time
mcts_probs_batch spend 0.004963293002219871 time
winner_batch spend 0.00029986999288666993 time
policy_value spend 0.24295691899897065 time
train_step spend 0.7074885850015562 time
policy_value spend 0.24103912900318392 time
train_step spend 0.7066583990090294 time
policy_value spend 0.24043723999056965 time
train_step spend 0.7089662119979039 time
policy_value spend 0.24043732500285842 time
train_step spend 0.7069534750044113 time
policy_value spend 0.2453243280033348 time
train_step spend 0.7068308250018163 time
policy_value spend 0.24043901498953346 time
kl:0.10500,lr_multiplier:0.088,loss:2.8179898262023926,entropy:3.3689136505126953,explained_var_old:0.985938966,explained_var_new:0.992712975
output spend 0.00016738398699089885 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004874509002547711 time
recovery_state_mcts_prob spend 0.2867093249951722 time
state_batch spend 0.001951769008883275 time
mcts_probs_batch spend 0.004780007991939783 time
winner_batch spend 0.0002785440010484308 time
policy_value spend 0.24065984500339255 time
train_step spend 0.7064477310050279 time
policy_value spend 0.2420359169918811 time
train_step spend 0.7063806929945713 time
policy_value spend 0.24819688900606707 time
train_step spend 0.7082045890128938 time
policy_value spend 0.2416685739881359 time
train_step spend 0.7070997690025251 time
policy_value spend 0.24161132299923338 time
train_step spend 0.7059402219892945 time
policy_value spend 0.24086003500269726 time
kl:0.08771,lr_multiplier:0.088,loss:2.7408180236816406,entropy:3.287863254547119,explained_var_old:0.989771605,explained_var_new:0.993155956
output spend 0.0001729709911160171 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004458562005311251 time
recovery_state_mcts_prob spend 0.3473084759898484 time
state_batch spend 0.0037565860111499205 time
mcts_probs_batch spend 0.014069347991608083 time
winner_batch spend 0.00026978600362781435 time
policy_value spend 0.24926295700424816 time
train_step spend 0.71045191999292 time
policy_value spend 0.24169656600861344 time
train_step spend 0.7150348750001285 time
policy_value spend 0.24152529099956155 time
train_step spend 0.706738034990849 time
policy_value spend 0.2405188190023182 time
train_step spend 0.7065120420011226 time
policy_value spend 0.24140973899920937 time
kl:0.08972,lr_multiplier:0.088,loss:2.7706024646759033,entropy:3.3204288482666016,explained_var_old:0.989348471,explained_var_new:0.993540108
output spend 0.00017123999714385718 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005257863987935707 time
recovery_state_mcts_prob spend 0.2880873829999473 time
state_batch spend 0.003552766007487662 time
mcts_probs_batch spend 0.007639977993676439 time
winner_batch spend 0.00031558400951325893 time
policy_value spend 0.24135793799359817 time
train_step spend 0.7083438349945936 time
policy_value spend 0.24110590599593706 time
train_step spend 0.7091416269977344 time
policy_value spend 0.24392834700120147 time
train_step spend 0.7072626860026503 time
policy_value spend 0.24056341699906625 time
train_step spend 0.7071199290076038 time
policy_value spend 0.2511788709962275 time
kl:0.08732,lr_multiplier:0.088,loss:2.768948554992676,entropy:3.3277034759521484,explained_var_old:0.993287802,explained_var_new:0.989306211
output spend 0.0004309979995014146 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005346732999896631 time
recovery_state_mcts_prob spend 0.29097133300092537 time
state_batch spend 0.004492615000344813 time
mcts_probs_batch spend 0.008449573011603206 time
winner_batch spend 0.0003191419964423403 time
policy_value spend 0.242421861999901 time
train_step spend 0.707112115007476 time
policy_value spend 0.24050112499389797 time
train_step spend 0.7064816740021342 time
policy_value spend 0.2417711690068245 time
train_step spend 0.7078887940006098 time
policy_value spend 0.24061531099141575 time
train_step spend 0.7068133959983243 time
policy_value spend 0.24092778901103884 time
train_step spend 0.7059627389971865 time
policy_value spend 0.24082426399399992 time
kl:0.09235,lr_multiplier:0.088,loss:2.8419830799102783,entropy:3.396031618118286,explained_var_old:0.984533787,explained_var_new:0.996140182
output spend 0.00016670499462634325 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005102346010971814 time
recovery_state_mcts_prob spend 0.3843666530010523 time
state_batch spend 0.004179409996140748 time
mcts_probs_batch spend 0.013411216990789399 time
winner_batch spend 0.0002716070011956617 time
policy_value spend 0.24567284500517417 time
train_step spend 0.7070406370039564 time
policy_value spend 0.24337238499720115 time
train_step spend 0.7105760850099614 time
policy_value spend 0.24019189599493984 time
train_step spend 0.706470218996401 time
policy_value spend 0.24040876200888306 time
train_step spend 0.7076270690013189 time
policy_value spend 0.24005968098936137 time
train_step spend 0.7069902859948343 time
policy_value spend 0.24011200299719349 time
kl:0.10562,lr_multiplier:0.088,loss:2.773425579071045,entropy:3.2966296672821045,explained_var_old:0.991305470,explained_var_new:0.996221244
output spend 0.00016353199316654354 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004289959993911907 time
recovery_state_mcts_prob spend 0.3059156170056667 time
state_batch spend 0.0034986950049642473 time
mcts_probs_batch spend 0.007624171994393691 time
winner_batch spend 0.0002734419977059588 time
policy_value spend 0.24428232799982652 time
train_step spend 0.7078441250050673 time
policy_value spend 0.2447450749896234 time
train_step spend 0.7079402450035559 time
policy_value spend 0.2486446369875921 time
train_step spend 0.7101894739898853 time
policy_value spend 0.2408461930026533 time
train_step spend 0.7068762340059038 time
policy_value spend 0.2407068139873445 time
kl:0.09505,lr_multiplier:0.088,loss:2.757974147796631,entropy:3.2822024822235107,explained_var_old:0.994990230,explained_var_new:0.995911658
output spend 0.0004077030025655404 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004552757993224077 time
recovery_state_mcts_prob spend 0.28276908400584944 time
state_batch spend 0.0035143379936926067 time
mcts_probs_batch spend 0.007395405002171174 time
winner_batch spend 0.00028992599982302636 time
policy_value spend 0.2418851559923496 time
train_step spend 0.7065170449932339 time
policy_value spend 0.24212550799711607 time
train_step spend 0.7090108990087174 time
policy_value spend 0.2410361969959922 time
train_step spend 0.7065861070004757 time
policy_value spend 0.2407492569909664 time
train_step spend 0.7060960700036958 time
policy_value spend 0.24109288500039838 time
kl:0.08725,lr_multiplier:0.088,loss:2.7698423862457275,entropy:3.2947630882263184,explained_var_old:0.996107817,explained_var_new:0.997483194
output spend 0.00017250800738111138 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004998653996153735 time
recovery_state_mcts_prob spend 0.2888423900003545 time
state_batch spend 0.0036636500008171424 time
mcts_probs_batch spend 0.007279087003553286 time
winner_batch spend 0.0002672120026545599 time
policy_value spend 0.2429909439961193 time
train_step spend 0.7071938329900149 time
policy_value spend 0.24041215500619728 time
train_step spend 0.7088196039985633 time
policy_value spend 0.24275943700922653 time
train_step spend 0.7071480529994005 time
policy_value spend 0.24282243399647996 time
train_step spend 0.7068665370024974 time
policy_value spend 0.240438238994102 time
train_step spend 0.7066512490127934 time
policy_value spend 0.24027603199647274 time
kl:0.08921,lr_multiplier:0.088,loss:2.7031593322753906,entropy:3.2463347911834717,explained_var_old:0.993156493,explained_var_new:0.993751228
output spend 0.00016525799583178014 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004788186997757293 time
recovery_state_mcts_prob spend 0.3063308629934909 time
state_batch spend 0.004277815998648293 time
mcts_probs_batch spend 0.009744928000145592 time
winner_batch spend 0.0003573340072762221 time
policy_value spend 0.2431123279966414 time
train_step spend 0.7073522839928046 time
policy_value spend 0.24089593499957118 time
train_step spend 0.7114430800138507 time
policy_value spend 0.24127654399489984 time
train_step spend 0.7075272140064044 time
policy_value spend 0.2402926189970458 time
train_step spend 0.7067729800037341 time
policy_value spend 0.24081396199471783 time
train_step spend 0.7070968299958622 time
policy_value spend 0.24052891100291163 time
kl:0.09470,lr_multiplier:0.088,loss:2.7075612545013428,entropy:3.252699375152588,explained_var_old:0.993874907,explained_var_new:0.992006600
output spend 0.00020319399482104927 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004884748996119015 time
recovery_state_mcts_prob spend 0.38048728900321294 time
state_batch spend 0.0035240050056017935 time
mcts_probs_batch spend 0.014102348999585956 time
winner_batch spend 0.00027105699700769037 time
policy_value spend 0.2458462380018318 time
train_step spend 0.7094040619995212 time
policy_value spend 0.24095954799850006 time
train_step spend 0.7075962880044244 time
policy_value spend 0.2412025329977041 time
train_step spend 0.706449999997858 time
policy_value spend 0.24108097999123856 time
train_step spend 0.7068165009986842 time
policy_value spend 0.2412425859947689 time
kl:0.08178,lr_multiplier:0.088,loss:2.7243354320526123,entropy:3.254425048828125,explained_var_old:0.976552665,explained_var_new:0.987434328
output spend 0.00016730200150050223 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004804008000064641 time
recovery_state_mcts_prob spend 0.29720436000206973 time
state_batch spend 0.0038684099999954924 time
mcts_probs_batch spend 0.007260174010298215 time
winner_batch spend 0.00026515799982007593 time
policy_value spend 0.24426771399157587 time
train_step spend 0.7092364429990994 time
policy_value spend 0.30938160099321976 time
train_step spend 0.7585552300006384 time
policy_value spend 0.30976848999853246 time
train_step spend 0.7515403910074383 time
policy_value spend 0.3217229259898886 time
train_step spend 0.7588522739970358 time
policy_value spend 0.30345721400226466 time
kl:0.08103,lr_multiplier:0.088,loss:2.7581946849823,entropy:3.3092520236968994,explained_var_old:0.992834270,explained_var_new:0.995145977
output spend 0.01226594700710848 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.044882014000904746 time
recovery_state_mcts_prob spend 4.098813605000032 time
state_batch spend 0.03175218300020788 time
mcts_probs_batch spend 0.1741192810004577 time
winner_batch spend 0.0007875470037106425 time
policy_value spend 0.7248219999892171 time
train_step spend 0.7658162780135171 time
policy_value spend 0.33262239198666066 time
train_step spend 0.76742186100455 time
policy_value spend 0.3118286520038964 time
train_step spend 0.8236374469997827 time
policy_value spend 0.310222246000194 time
train_step spend 0.7385527139995247 time
policy_value spend 0.2693134899891447 time
kl:0.08581,lr_multiplier:0.088,loss:2.8287951946258545,entropy:3.396228313446045,explained_var_old:0.988225102,explained_var_new:0.989088774
output spend 0.0007135979976737872 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006542069997522049 time
recovery_state_mcts_prob spend 0.48365233700315 time
state_batch spend 0.005867130006663501 time
mcts_probs_batch spend 0.009970786995836534 time
winner_batch spend 0.0003392039943719283 time
policy_value spend 0.25322929400135763 time
train_step spend 0.7387013749976177 time
policy_value spend 0.2687495269929059 time
train_step spend 0.742038333992241 time
policy_value spend 0.25925473200913984 time
train_step spend 0.7647647200064966 time
policy_value spend 0.25257491299998946 time
train_step spend 0.7799467019940494 time
policy_value spend 0.2603408270078944 time
kl:0.08504,lr_multiplier:0.088,loss:2.770951986312866,entropy:3.269284248352051,explained_var_old:0.988460898,explained_var_new:0.990276396
output spend 0.0003004400059580803 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.012076465995050967 time
recovery_state_mcts_prob spend 1.0542858400003752 time
state_batch spend 0.021005314993089996 time
mcts_probs_batch spend 0.08178965801198501 time
winner_batch spend 0.001011903994367458 time
policy_value spend 0.3217457690043375 time
train_step spend 0.7372754549869569 time
policy_value spend 0.252216879001935 time
train_step spend 0.747763567007496 time
policy_value spend 0.26264481399266515 time
train_step spend 0.7121642749989405 time
policy_value spend 0.2431842730002245 time
train_step spend 0.7075129089935217 time
policy_value spend 0.24202257599972654 time
train_step spend 0.7061722079961328 time
policy_value spend 0.24217941700771917 time
kl:0.08926,lr_multiplier:0.088,loss:2.7576229572296143,entropy:3.2901625633239746,explained_var_old:0.986742318,explained_var_new:0.989084721
output spend 0.0002714989968808368 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0051936610107077286 time
recovery_state_mcts_prob spend 0.4167196509952191 time
state_batch spend 0.004130343004362658 time
mcts_probs_batch spend 0.015927453991025686 time
winner_batch spend 0.00027641101041808724 time
policy_value spend 0.24677221999445464 time
train_step spend 0.7132508549984777 time
policy_value spend 0.244461868001963 time
train_step spend 0.7102053410053486 time
policy_value spend 0.24310808899463154 time
train_step spend 0.7294273500010604 time
policy_value spend 0.24848380200273823 time
train_step spend 0.7317907300021034 time
policy_value spend 0.2432523460010998 time
train_step spend 0.7095386550063267 time
policy_value spend 0.24285826399864163 time
kl:0.09461,lr_multiplier:0.088,loss:2.7409584522247314,entropy:3.278548240661621,explained_var_old:0.990436316,explained_var_new:0.993565857
output spend 0.00019231099577154964 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.008259684997028671 time
recovery_state_mcts_prob spend 0.3116862759925425 time
state_batch spend 0.0020733849960379303 time
mcts_probs_batch spend 0.006588670003111474 time
winner_batch spend 0.0002676450094440952 time
policy_value spend 0.24166100699221715 time
train_step spend 0.7088186850014608 time
policy_value spend 0.24385955999605358 time
train_step spend 0.7100085279962514 time
policy_value spend 0.24028861000260804 time
train_step spend 0.7098309249995509 time
policy_value spend 0.2419905650021974 time
train_step spend 0.7090647550066933 time
policy_value spend 0.2401022410049336 time
train_step spend 0.7079220250016078 time
policy_value spend 0.25831458398897666 time
kl:0.09549,lr_multiplier:0.088,loss:2.8177297115325928,entropy:3.3827314376831055,explained_var_old:0.994796395,explained_var_new:0.995698750
output spend 0.00045029599277768284 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0041622419958002865 time
recovery_state_mcts_prob spend 0.554001110009267 time
state_batch spend 0.003373426996404305 time
mcts_probs_batch spend 0.007362820004345849 time
winner_batch spend 0.00028354399546515197 time
policy_value spend 0.242293546005385 time
train_step spend 0.7098561470047571 time
policy_value spend 0.261965125988354 time
train_step spend 0.7090807869972195 time
policy_value spend 0.24020800400467124 time
train_step spend 0.7094295300048543 time
policy_value spend 0.2520803369989153 time
train_step spend 0.7100723990006372 time
policy_value spend 0.24021849599375855 time
kl:0.09572,lr_multiplier:0.088,loss:2.7903406620025635,entropy:3.3307738304138184,explained_var_old:0.993558228,explained_var_new:0.993647218
output spend 0.000167192003573291 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004246712007443421 time
recovery_state_mcts_prob spend 0.3216232519916957 time
state_batch spend 0.0036788020079256967 time
mcts_probs_batch spend 0.007118018998880871 time
winner_batch spend 0.0002908489987021312 time
policy_value spend 0.24284808100492228 time
train_step spend 0.7093537369946716 time
policy_value spend 0.24282714400033 time
train_step spend 0.7101738519995706 time
policy_value spend 0.2410081940033706 time
train_step spend 0.7091039000079036 time
policy_value spend 0.2409807770018233 time
train_step spend 0.7099525230005383 time
policy_value spend 0.24096291299792938 time
kl:0.08110,lr_multiplier:0.088,loss:2.7354838848114014,entropy:3.2750120162963867,explained_var_old:0.987163365,explained_var_new:0.988690376
output spend 0.00022664500284008682 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00429574899317231 time
recovery_state_mcts_prob spend 0.3797873930016067 time
state_batch spend 0.0024410780024481937 time
mcts_probs_batch spend 0.007251484988955781 time
winner_batch spend 0.00034526700619608164 time
policy_value spend 0.2408690089941956 time
train_step spend 0.708767425006954 time
policy_value spend 0.2423155379947275 time
train_step spend 0.7099904799979413 time
policy_value spend 0.24245351800345816 time
train_step spend 0.7074481089948677 time
policy_value spend 0.24208857900521252 time
train_step spend 0.7075484800006961 time
policy_value spend 0.24222375299723353 time
kl:0.08871,lr_multiplier:0.088,loss:2.701040744781494,entropy:3.2324399948120117,explained_var_old:0.997615397,explained_var_new:0.997344732
output spend 0.0002331790019525215 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0038754639972466975 time
recovery_state_mcts_prob spend 0.32303745800163597 time
state_batch spend 0.006073775002732873 time
mcts_probs_batch spend 0.018016689995420165 time
winner_batch spend 0.00027448899345472455 time
policy_value spend 0.2747002880059881 time
train_step spend 0.7455133829935221 time
policy_value spend 0.2424534910096554 time
train_step spend 0.7082144140003948 time
policy_value spend 0.2418841509934282 time
train_step spend 0.7064753919985378 time
policy_value spend 0.24215633800486103 time
train_step spend 0.7075202380074188 time
policy_value spend 0.24047807999886572 time
kl:0.08812,lr_multiplier:0.088,loss:2.819334030151367,entropy:3.3765830993652344,explained_var_old:0.987425089,explained_var_new:0.989939213
output spend 0.00017627399938646704 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004724790007458068 time
recovery_state_mcts_prob spend 0.3122554329893319 time
state_batch spend 0.0040445960039505735 time
mcts_probs_batch spend 0.015967523999279365 time
winner_batch spend 0.00031508199754171073 time
policy_value spend 0.24696938101260457 time
train_step spend 0.7282711589941755 time
policy_value spend 0.24034664999635424 time
train_step spend 0.7067959069972858 time
policy_value spend 0.2415885660011554 time
train_step spend 0.7089850460033631 time
policy_value spend 0.24038943799678236 time
train_step spend 0.7075002290075645 time
policy_value spend 0.24056110800302122 time
train_step spend 0.7064699720067438 time
policy_value spend 0.24049999000271782 time
kl:0.10530,lr_multiplier:0.088,loss:2.7338151931762695,entropy:3.2911558151245117,explained_var_old:0.989208162,explained_var_new:0.993862212
output spend 0.00016994599718600512 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004176643997197971 time
recovery_state_mcts_prob spend 0.3228228280058829 time
state_batch spend 0.0038057269994169474 time
mcts_probs_batch spend 0.007880317003582604 time
winner_batch spend 0.00030643100035376847 time
policy_value spend 0.2420823509892216 time
train_step spend 0.7074644099920988 time
policy_value spend 0.24191995299770497 time
train_step spend 0.7095403489947785 time
policy_value spend 0.24977473200124223 time
train_step spend 0.7060841200000141 time
policy_value spend 0.24077080500137527 time
train_step spend 0.7071474620024674 time
policy_value spend 0.2424184690025868 time
train_step spend 0.706764682996436 time
policy_value spend 0.2410151880030753 time
kl:0.09108,lr_multiplier:0.088,loss:2.756866931915283,entropy:3.2945704460144043,explained_var_old:0.986588001,explained_var_new:0.985224247
output spend 0.0002031319891102612 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0062118570058373734 time
recovery_state_mcts_prob spend 0.30953926900110673 time
state_batch spend 0.004212714993627742 time
mcts_probs_batch spend 0.007079964008880779 time
winner_batch spend 0.0002748769911704585 time
policy_value spend 0.2413114939990919 time
train_step spend 0.708151133992942 time
policy_value spend 0.24569897500623483 time
train_step spend 0.7129824929870665 time
policy_value spend 0.2404002890107222 time
train_step spend 0.7071864479948999 time
policy_value spend 0.2726973530079704 time
train_step spend 0.7305417379975552 time
policy_value spend 0.26797338599862996 time
kl:0.08889,lr_multiplier:0.088,loss:2.729417324066162,entropy:3.235152244567871,explained_var_old:0.984354317,explained_var_new:0.989399791
output spend 0.0022715960076311603 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00633168600325007 time
recovery_state_mcts_prob spend 1.0250836289924337 time
state_batch spend 0.004228128003887832 time
mcts_probs_batch spend 0.013954062000266276 time
winner_batch spend 0.00027303799288347363 time
policy_value spend 0.2466808480094187 time
train_step spend 0.7115901969955303 time
policy_value spend 0.2633178170071915 time
train_step spend 0.7619880580023164 time
policy_value spend 0.2636590769980103 time
train_step spend 0.7298741909908131 time
policy_value spend 0.2564150500111282 time
train_step spend 0.7378697179956362 time
policy_value spend 0.24183283100137487 time
train_step spend 0.7101657519961009 time
policy_value spend 0.24280944300699048 time
kl:0.09321,lr_multiplier:0.088,loss:2.77180552482605,entropy:3.3194990158081055,explained_var_old:0.993443668,explained_var_new:0.993824899
output spend 0.00019126400002278388 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0037357109977165237 time
recovery_state_mcts_prob spend 0.33995501400204375 time
state_batch spend 0.003895492001902312 time
mcts_probs_batch spend 0.007297525997273624 time
winner_batch spend 0.00029152400384191424 time
policy_value spend 0.2416334529989399 time
train_step spend 0.7071809879998909 time
policy_value spend 0.24262013199040666 time
train_step spend 0.7221584479993908 time
policy_value spend 0.24137261901341844 time
train_step spend 0.7075807950022863 time
policy_value spend 0.24088268700870685 time
train_step spend 0.7159955500101205 time
policy_value spend 0.33868835499743 time
kl:0.08940,lr_multiplier:0.088,loss:2.770322799682617,entropy:3.336885929107666,explained_var_old:0.997226536,explained_var_new:0.999134302
output spend 0.0018848300096578896 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.05107111600227654 time
recovery_state_mcts_prob spend 5.2942771689995425 time
state_batch spend 0.017346906010061502 time
mcts_probs_batch spend 0.21460890899470542 time
winner_batch spend 0.0010440240002935752 time
policy_value spend 0.7240912270062836 time
train_step spend 0.9297639099968364 time
policy_value spend 0.32372178600053303 time
train_step spend 0.7542363020038465 time
policy_value spend 0.33879847900243476 time
train_step spend 0.7308029510022607 time
policy_value spend 0.2850400500028627 time
train_step spend 0.7594582019955851 time
policy_value spend 0.29165607600589283 time
train_step spend 0.7530219390027924 time
policy_value spend 0.280011556998943 time
kl:0.09021,lr_multiplier:0.088,loss:2.68877911567688,entropy:3.2204668521881104,explained_var_old:0.985130429,explained_var_new:0.990952551
output spend 0.0013878239988116547 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.025617374005378224 time
recovery_state_mcts_prob spend 2.061100635997718 time
state_batch spend 0.007134630999644287 time
mcts_probs_batch spend 0.03157519499654882 time
winner_batch spend 0.0003700399975059554 time
policy_value spend 0.5444629560079193 time
train_step spend 0.7139742170111276 time
policy_value spend 0.25833172199781984 time
train_step spend 0.7123667029954959 time
policy_value spend 0.24208436800108757 time
train_step spend 0.708442928007571 time
policy_value spend 0.24814743499155156 time
train_step spend 0.7074703380058054 time
policy_value spend 0.2444082250003703 time
train_step spend 0.707878355999128 time
policy_value spend 0.2549344500002917 time
kl:0.09169,lr_multiplier:0.088,loss:2.7800543308258057,entropy:3.3287172317504883,explained_var_old:0.978159666,explained_var_new:0.962628126
output spend 0.00040725299913901836 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00818939799501095 time
recovery_state_mcts_prob spend 0.44618825300130993 time
state_batch spend 0.004482172007556073 time
mcts_probs_batch spend 0.008829555998090655 time
winner_batch spend 0.0003201489889761433 time
policy_value spend 0.24526784699992277 time
train_step spend 0.73839522000344 time
policy_value spend 0.28116088500246406 time
train_step spend 0.7069540819938993 time
policy_value spend 0.24482056700799149 time
train_step spend 0.7089144440105883 time
policy_value spend 0.24512661599146668 time
train_step spend 0.7076898130035261 time
policy_value spend 0.24415835599938873 time
kl:0.09342,lr_multiplier:0.088,loss:2.7536675930023193,entropy:3.3165082931518555,explained_var_old:0.955899596,explained_var_new:0.992283583
output spend 0.00023658601276110858 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006159391006804071 time
recovery_state_mcts_prob spend 0.5677057190041523 time
state_batch spend 0.0058054559922311455 time
mcts_probs_batch spend 0.019995675000245683 time
winner_batch spend 0.0008948580070864409 time
policy_value spend 0.26429684899630956 time
train_step spend 0.7339186249882914 time
policy_value spend 0.2630522330000531 time
train_step spend 0.725706615994568 time
policy_value spend 0.2458669689949602 time
train_step spend 0.7101780680095544 time
policy_value spend 0.2420767879957566 time
train_step spend 0.7083904850005638 time
policy_value spend 0.24354824700276367 time
kl:0.10350,lr_multiplier:0.088,loss:2.742631673812866,entropy:3.2913193702697754,explained_var_old:0.986858368,explained_var_new:0.996052623
output spend 0.00017362501239404082 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004363625994301401 time
recovery_state_mcts_prob spend 1.2251606450008694 time
state_batch spend 0.010380417996202596 time
mcts_probs_batch spend 0.03230587500729598 time
winner_batch spend 0.00046595399908255786 time
policy_value spend 0.32990489999065176 time
train_step spend 0.7253484329994535 time
policy_value spend 0.2881713640090311 time
train_step spend 0.7083044290047837 time
policy_value spend 0.2627824499941198 time
train_step spend 0.7114949630049523 time
policy_value spend 0.29677661499590613 time
train_step spend 0.72284974399372 time
policy_value spend 0.24523166700964794 time
kl:0.08315,lr_multiplier:0.088,loss:2.763338565826416,entropy:3.3260302543640137,explained_var_old:0.989808500,explained_var_new:0.993078649
output spend 0.00023623000015504658 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004762119002407417 time
recovery_state_mcts_prob spend 0.30794405900815036 time
state_batch spend 0.0036968630010960624 time
mcts_probs_batch spend 0.0077733619982609525 time
winner_batch spend 0.00027709499408956617 time
policy_value spend 0.24500753699976485 time
train_step spend 0.7085294800053816 time
policy_value spend 0.2931488920003176 time
train_step spend 0.7145003280020319 time
policy_value spend 0.24129310200805776 time
train_step spend 0.7081860940088518 time
policy_value spend 0.26743409999471623 time
train_step spend 0.7119033389899414 time
policy_value spend 0.2478079400025308 time
kl:0.08445,lr_multiplier:0.088,loss:2.753432273864746,entropy:3.275069236755371,explained_var_old:0.975416303,explained_var_new:0.986444116
output spend 0.0003650559956440702 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00454521099163685 time
recovery_state_mcts_prob spend 0.3125425940088462 time
state_batch spend 0.003159582003718242 time
mcts_probs_batch spend 0.006551164988195524 time
winner_batch spend 0.00038899701030459255 time
policy_value spend 0.24187689198879525 time
train_step spend 0.7069781619939022 time
policy_value spend 0.24074823800765444 time
train_step spend 0.7098888909968082 time
policy_value spend 0.2409045489912387 time
train_step spend 0.7074645419925218 time
policy_value spend 0.24029731699556578 time
train_step spend 0.7074054199911188 time
policy_value spend 0.2411761440016562 time
kl:0.09372,lr_multiplier:0.088,loss:2.7960243225097656,entropy:3.350985050201416,explained_var_old:0.990009010,explained_var_new:0.945431173
output spend 0.00018282500968780369 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.019010584001080133 time
recovery_state_mcts_prob spend 0.3818532849982148 time
state_batch spend 0.002130046996171586 time
mcts_probs_batch spend 0.006271556005231105 time
winner_batch spend 0.0002841499954229221 time
policy_value spend 0.24165736100985669 time
train_step spend 0.7081647540035192 time
policy_value spend 0.24029716600489337 time
train_step spend 0.7104970799991861 time
policy_value spend 0.24011854600394145 time
train_step spend 0.706685736993677 time
policy_value spend 0.24015748899546452 time
train_step spend 0.7077380050031934 time
policy_value spend 0.2402523869968718 time
kl:0.09159,lr_multiplier:0.088,loss:2.7675745487213135,entropy:3.304027557373047,explained_var_old:0.958642304,explained_var_new:0.988155544
output spend 0.0001761820021783933 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004684357001679018 time
recovery_state_mcts_prob spend 0.31650740299664903 time
state_batch spend 0.006915353995282203 time
mcts_probs_batch spend 0.01949367100314703 time
winner_batch spend 0.00031453299743589014 time
policy_value spend 0.24616362000233494 time
train_step spend 0.7103677999984939 time
policy_value spend 0.24736142400070094 time
train_step spend 0.7087233849888435 time
policy_value spend 0.24260627100011334 time
train_step spend 0.7075653509964468 time
policy_value spend 0.24210203399707098 time
train_step spend 0.706345610000426 time
policy_value spend 0.24186877299507614 time
kl:0.09585,lr_multiplier:0.088,loss:2.7431540489196777,entropy:3.2646515369415283,explained_var_old:0.987329900,explained_var_new:0.972700775
output spend 0.00016889900143723935 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00414190799347125 time
recovery_state_mcts_prob spend 0.34851457001059316 time
state_batch spend 0.003825195992249064 time
mcts_probs_batch spend 0.015563502995064482 time
winner_batch spend 0.00026864001119975 time
policy_value spend 0.2882865999999922 time
train_step spend 0.7149821139901178 time
policy_value spend 0.24331009200250264 time
train_step spend 0.7066833790013334 time
policy_value spend 0.27516623098927084 time
train_step spend 0.7129915149998851 time
policy_value spend 0.24062687100376934 time
train_step spend 0.7062975029984955 time
policy_value spend 0.26229307299945503 time
kl:0.08583,lr_multiplier:0.088,loss:2.740915536880493,entropy:3.287998676300049,explained_var_old:0.973659515,explained_var_new:0.981827021
output spend 0.0005852850008523092 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005001947007258423 time
recovery_state_mcts_prob spend 0.3101401369931409 time
state_batch spend 0.0027591950056375936 time
mcts_probs_batch spend 0.006805034005083144 time
winner_batch spend 0.0003104599891230464 time
policy_value spend 0.24292120500467718 time
train_step spend 0.7095151529938448 time
policy_value spend 0.24082250200444832 time
train_step spend 0.7072315690020332 time
policy_value spend 0.24125069599540439 time
train_step spend 0.709427540001343 time
policy_value spend 0.24088427299284376 time
train_step spend 0.7070004190027248 time
policy_value spend 0.24126488198817242 time
train_step spend 0.7080242149968399 time
policy_value spend 0.2403397029993357 time
kl:0.08997,lr_multiplier:0.088,loss:2.803880214691162,entropy:3.330214500427246,explained_var_old:0.985534608,explained_var_new:0.996339500
output spend 0.00017977500101551414 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005607864004559815 time
recovery_state_mcts_prob spend 0.4619230809912551 time
state_batch spend 0.0021015940001234412 time
mcts_probs_batch spend 0.007394861007924192 time
winner_batch spend 0.00028154999017715454 time
policy_value spend 0.24481443100376055 time
train_step spend 0.7090305999881821 time
policy_value spend 0.241272970000864 time
train_step spend 0.7103349579992937 time
policy_value spend 0.24229744999320246 time
train_step spend 0.7095768370054429 time
policy_value spend 0.24157022198778577 time
train_step spend 0.7084419499879004 time
policy_value spend 0.24068561200692784 time
train_step spend 0.7067199919983977 time
policy_value spend 0.24121458300214726 time
kl:0.09017,lr_multiplier:0.088,loss:2.750394344329834,entropy:3.257366895675659,explained_var_old:0.979374945,explained_var_new:0.985607266
output spend 0.00018555999849922955 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0060213329998077825 time
recovery_state_mcts_prob spend 0.4911968450032873 time
state_batch spend 0.0036983519967179745 time
mcts_probs_batch spend 0.007501055995817296 time
winner_batch spend 0.00027839100221171975 time
policy_value spend 0.2434239419962978 time
train_step spend 0.7088918739900691 time
policy_value spend 0.2427993180026533 time
train_step spend 0.7077166140079498 time
policy_value spend 0.29118943998764735 time
train_step spend 0.7590815750008915 time
policy_value spend 0.2563835740002105 time
train_step spend 0.7139423649932723 time
policy_value spend 0.242416064007557 time
kl:0.08074,lr_multiplier:0.088,loss:2.789321184158325,entropy:3.32559871673584,explained_var_old:0.986500561,explained_var_new:0.987725616
output spend 0.00017234600090887398 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00566063700534869 time
recovery_state_mcts_prob spend 0.37641031299426686 time
state_batch spend 0.0040258049994008616 time
mcts_probs_batch spend 0.01687957500689663 time
winner_batch spend 0.0003069039958063513 time
policy_value spend 0.2469467490009265 time
train_step spend 0.7125483060081024 time
policy_value spend 0.24283784499857575 time
train_step spend 0.7349013130005915 time
policy_value spend 0.2426148189988453 time
train_step spend 0.7070627849898301 time
policy_value spend 0.24088832600682508 time
train_step spend 0.707027297001332 time
policy_value spend 0.24138996200053953 time
train_step spend 0.7075828249944607 time
policy_value spend 0.24261518300045282 time
kl:0.08865,lr_multiplier:0.088,loss:2.743253231048584,entropy:3.2585177421569824,explained_var_old:0.975670874,explained_var_new:0.985867858
output spend 0.00019653399067465216 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.003964235002058558 time
recovery_state_mcts_prob spend 0.44957805100420956 time
state_batch spend 0.002318600003491156 time
mcts_probs_batch spend 0.007739719992969185 time
winner_batch spend 0.0003370420017745346 time
policy_value spend 0.24594015600450803 time
train_step spend 0.7121606649889145 time
policy_value spend 0.24394698000105564 time
train_step spend 0.7082562499999767 time
policy_value spend 0.24612071400042623 time
train_step spend 0.7190411449992098 time
policy_value spend 0.24252525399788283 time
train_step spend 0.7105367159965681 time
policy_value spend 0.24623704999976326 time
kl:0.09112,lr_multiplier:0.088,loss:2.7540388107299805,entropy:3.2849674224853516,explained_var_old:0.985031307,explained_var_new:0.987875342
output spend 0.00018233399896416813 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004790170001797378 time
recovery_state_mcts_prob spend 0.33103914798994083 time
state_batch spend 0.004029389005154371 time
mcts_probs_batch spend 0.008154873998137191 time
winner_batch spend 0.00030973899993114173 time
policy_value spend 0.32537014900299255 time
train_step spend 0.7534478909947211 time
policy_value spend 0.24140281899599358 time
train_step spend 0.7077447710034903 time
policy_value spend 0.2595487439975841 time
train_step spend 0.7138334460032638 time
policy_value spend 0.24116485699778423 time
train_step spend 0.7073702850029804 time
policy_value spend 0.2715537089970894 time
kl:0.09794,lr_multiplier:0.088,loss:2.777083158493042,entropy:3.304152011871338,explained_var_old:0.980854154,explained_var_new:0.958121538
output spend 0.0003624420060077682 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00473689500358887 time
recovery_state_mcts_prob spend 0.421957147991634 time
state_batch spend 0.0038500960072269663 time
mcts_probs_batch spend 0.015382350000436418 time
winner_batch spend 0.00028910399123560637 time
policy_value spend 0.25667595300183166 time
train_step spend 0.7228497739997692 time
policy_value spend 0.2657348969951272 time
train_step spend 0.7111723989946768 time
policy_value spend 0.25121243299508933 time
train_step spend 0.7087222919944907 time
policy_value spend 0.27176989600411616 time
train_step spend 0.712435731998994 time
policy_value spend 0.24265334600931965 time
train_step spend 0.7069935780018568 time
policy_value spend 0.26106627700210083 time
kl:0.09966,lr_multiplier:0.088,loss:2.7357218265533447,entropy:3.2695508003234863,explained_var_old:0.954507172,explained_var_new:0.991150379
output spend 0.0006101189937908202 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007161700996221043 time
recovery_state_mcts_prob spend 0.4165851279976778 time
state_batch spend 0.008224106000852771 time
mcts_probs_batch spend 0.021074504009447992 time
winner_batch spend 0.00029993899806868285 time
policy_value spend 0.2461218129901681 time
train_step spend 0.7133057519968133 time
policy_value spend 0.25571644499723334 time
train_step spend 0.7106996929942397 time
policy_value spend 0.24109756700636353 time
train_step spend 0.707847290992504 time
policy_value spend 0.2555446400074288 time
train_step spend 0.7087800440058345 time
policy_value spend 0.24203058799321298 time
train_step spend 0.7090928679972421 time
policy_value spend 0.26152603200171143 time
kl:0.10294,lr_multiplier:0.088,loss:2.712332010269165,entropy:3.247159957885742,explained_var_old:0.997801721,explained_var_new:0.999575257
output spend 0.0003385029995115474 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005919727002037689 time
recovery_state_mcts_prob spend 0.395168969000224 time
state_batch spend 0.005138794993399642 time
mcts_probs_batch spend 0.008421844002441503 time
winner_batch spend 0.00029301100585144013 time
policy_value spend 0.24249535099079367 time
train_step spend 0.7076010900054825 time
policy_value spend 0.26716202999523375 time
train_step spend 0.7108719179959735 time
policy_value spend 0.241211836997536 time
train_step spend 0.7072534330072813 time
policy_value spend 0.2643855770002119 time
train_step spend 0.7148862390022259 time
policy_value spend 0.24296260900155175 time
train_step spend 0.7066070510045392 time
policy_value spend 0.2675489139946876 time
kl:0.10299,lr_multiplier:0.088,loss:2.7528531551361084,entropy:3.2641713619232178,explained_var_old:0.984556913,explained_var_new:0.990552902
output spend 0.0006176080059958622 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005450990007375367 time
recovery_state_mcts_prob spend 0.37337171999388374 time
state_batch spend 0.004700920995674096 time
mcts_probs_batch spend 0.007127883000066504 time
winner_batch spend 0.0002744759985944256 time
policy_value spend 0.24387054900580551 time
train_step spend 0.7088408179988619 time
policy_value spend 0.24916977000248153 time
train_step spend 0.7185054710134864 time
policy_value spend 0.24116623000008985 time
train_step spend 0.7093341270083329 time
policy_value spend 0.2629000029992312 time
train_step spend 0.7142646849970333 time
policy_value spend 0.24131370800023433 time
kl:0.08159,lr_multiplier:0.088,loss:2.81827449798584,entropy:3.3528366088867188,explained_var_old:0.986984134,explained_var_new:0.991377532
output spend 0.00018542299221735448 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004643922991817817 time
recovery_state_mcts_prob spend 0.44049232501129154 time
state_batch spend 0.004248137993272394 time
mcts_probs_batch spend 0.00835288199596107 time
winner_batch spend 0.00032247501076199114 time
policy_value spend 0.26312345699989237 time
train_step spend 0.7177251980028814 time
policy_value spend 0.2409975519985892 time
train_step spend 0.7072813989943825 time
policy_value spend 0.2412609680031892 time
train_step spend 0.7134727329976158 time
policy_value spend 0.24434177299553994 time
train_step spend 0.7101814250054304 time
policy_value spend 0.24245950298791286 time
kl:0.08085,lr_multiplier:0.088,loss:2.7871880531311035,entropy:3.328359365463257,explained_var_old:0.992504895,explained_var_new:0.982260168
output spend 0.00021018700499553233 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0051178760040784255 time
recovery_state_mcts_prob spend 0.390452195002581 time
state_batch spend 0.009376670990604907 time
mcts_probs_batch spend 0.026787851005792618 time
winner_batch spend 0.0003837889962596819 time
policy_value spend 0.2435000730038155 time
train_step spend 0.7069965789996786 time
policy_value spend 0.24274797999532893 time
train_step spend 0.7091624360036803 time
policy_value spend 0.2410598129936261 time
train_step spend 0.7278807659895392 time
policy_value spend 0.260151496011531 time
train_step spend 0.73913275700761 time
policy_value spend 0.24220019498898182 time
kl:0.08733,lr_multiplier:0.088,loss:2.8076117038726807,entropy:3.3417115211486816,explained_var_old:0.972891152,explained_var_new:0.988221884
output spend 0.0001795919961296022 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005686039992724545 time
recovery_state_mcts_prob spend 0.4326469369989354 time
state_batch spend 0.002692264999495819 time
mcts_probs_batch spend 0.013575949997175485 time
winner_batch spend 0.0003266920102760196 time
policy_value spend 0.24876757399761118 time
train_step spend 0.7067982260050485 time
policy_value spend 0.2452822649938753 time
train_step spend 0.7072804609924788 time
policy_value spend 0.24379698300617747 time
train_step spend 0.7092055059911218 time
policy_value spend 0.25663569499738514 time
train_step spend 0.7112604480062146 time
policy_value spend 0.24481138799455948 time
kl:0.09925,lr_multiplier:0.088,loss:2.7922451496124268,entropy:3.3219218254089355,explained_var_old:0.990671992,explained_var_new:0.994438887
output spend 0.00042293099977541715 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006098350990214385 time
recovery_state_mcts_prob spend 0.32937916000082623 time
state_batch spend 0.0020686030038632452 time
mcts_probs_batch spend 0.008117977005895227 time
winner_batch spend 0.0002962649887194857 time
policy_value spend 0.24325544000021182 time
train_step spend 0.70735448099731 time
policy_value spend 0.24727875499229413 time
train_step spend 0.7091050899907714 time
policy_value spend 0.24145621500792913 time
train_step spend 0.7084288059995743 time
policy_value spend 0.24163801700342447 time
train_step spend 0.7129610280098859 time
policy_value spend 0.24148263699316885 time
train_step spend 0.7071596280002268 time
policy_value spend 0.2413524529983988 time
kl:0.09776,lr_multiplier:0.088,loss:2.7516889572143555,entropy:3.2682650089263916,explained_var_old:0.990790606,explained_var_new:0.994361401
output spend 0.0001923460076795891 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005564225008129142 time
recovery_state_mcts_prob spend 0.5494643949932652 time
state_batch spend 0.0025264260038966313 time
mcts_probs_batch spend 0.012462013997719623 time
winner_batch spend 0.00030030599737074226 time
policy_value spend 0.2519239460089011 time
train_step spend 0.7143242559977807 time
policy_value spend 0.24082072400778998 time
train_step spend 0.7086715570039814 time
policy_value spend 0.25274152400379535 time
train_step spend 0.7158389910036931 time
policy_value spend 0.24234523400082253 time
train_step spend 0.7089009549963521 time
policy_value spend 0.24292117900040466 time
train_step spend 0.7103027230041334 time
policy_value spend 0.24184869299642742 time
kl:0.09304,lr_multiplier:0.088,loss:2.7173898220062256,entropy:3.235180139541626,explained_var_old:0.988124728,explained_var_new:0.993880570
output spend 0.00020279599993955344 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006455348993767984 time
recovery_state_mcts_prob spend 0.5349071910022758 time
state_batch spend 0.0021085589978611097 time
mcts_probs_batch spend 0.007519364007748663 time
winner_batch spend 0.0003912130050593987 time
policy_value spend 0.24583628198888618 time
train_step spend 0.708287649002159 time
policy_value spend 0.24732801600475796 time
train_step spend 0.7160645469994051 time
policy_value spend 0.24344137500156648 time
train_step spend 0.7087097079929663 time
policy_value spend 0.2411933640105417 time
train_step spend 0.7084321380098118 time
policy_value spend 0.24260146598680876 time
kl:0.10972,lr_multiplier:0.088,loss:2.80108642578125,entropy:3.3273067474365234,explained_var_old:0.987763882,explained_var_new:0.905829608
output spend 0.0002179589937441051 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005605001992080361 time
recovery_state_mcts_prob spend 0.3901533360040048 time
state_batch spend 0.002529353994759731 time
mcts_probs_batch spend 0.029758350006886758 time
winner_batch spend 0.0003709960001287982 time
policy_value spend 0.2431385879899608 time
train_step spend 0.7082102130079875 time
policy_value spend 0.2436915250000311 time
train_step spend 0.710117006994551 time
policy_value spend 0.24301819900574628 time
train_step spend 0.7083101429889211 time
policy_value spend 0.24106804400798865 time
kl:0.09614,lr_multiplier:0.088,loss:2.784222364425659,entropy:3.3121821880340576,explained_var_old:0.865113497,explained_var_new:0.984210968
output spend 0.0001897000038297847 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005880837008589879 time
recovery_state_mcts_prob spend 0.3395446859940421 time
state_batch spend 0.0021135080023668706 time
mcts_probs_batch spend 0.007669851998798549 time
winner_batch spend 0.0003742300032172352 time
policy_value spend 0.2495080069929827 time
train_step spend 0.7113655540015316 time
policy_value spend 0.2428695120033808 time
train_step spend 0.7080717099888716 time
policy_value spend 0.2412179350067163 time
kl:0.10222,lr_multiplier:0.088,loss:2.8258228302001953,entropy:3.3514373302459717,explained_var_old:0.988746047,explained_var_new:0.722159863
output spend 0.0001974259939743206 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0056494169984944165 time
recovery_state_mcts_prob spend 0.6512098189996323 time
state_batch spend 0.004441032011527568 time
mcts_probs_batch spend 0.01709948699863162 time
winner_batch spend 0.00031528099498245865 time
policy_value spend 0.25033158299629577 time
train_step spend 0.7147607939987211 time
policy_value spend 0.24106385500635952 time
kl:0.08339,lr_multiplier:0.088,loss:2.9064486026763916,entropy:3.414241313934326,explained_var_old:0.691154897,explained_var_new:0.564188719
output spend 0.00019016300211660564 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004390772999613546 time
recovery_state_mcts_prob spend 0.506347314993036 time
state_batch spend 0.0021123910119058564 time
mcts_probs_batch spend 0.006548923993250355 time
winner_batch spend 0.0002954049996333197 time
policy_value spend 0.24234482200699858 time
train_step spend 0.7104644259961788 time
policy_value spend 0.2420553080009995 time
train_step spend 0.7083719049987849 time
policy_value spend 0.2404591660015285 time
train_step spend 0.7104699799965601 time
policy_value spend 0.24767637100012507 time
kl:0.11880,lr_multiplier:0.088,loss:2.78466796875,entropy:3.339212656021118,explained_var_old:0.601413012,explained_var_new:0.895654321
output spend 0.0002817289932863787 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005466729999170639 time
recovery_state_mcts_prob spend 0.5008305689989356 time
state_batch spend 0.004075990000274032 time
mcts_probs_batch spend 0.008445498009677976 time
winner_batch spend 0.0003068959922529757 time
policy_value spend 0.24587921099737287 time
train_step spend 0.7122427529975539 time
policy_value spend 0.25338848899991717 time
train_step spend 0.7116578459972516 time
policy_value spend 0.24126380699453875 time
train_step spend 0.7080671959993197 time
policy_value spend 0.2415838199958671 time
train_step spend 0.7104902870050864 time
policy_value spend 0.24211186099273618 time
kl:0.08717,lr_multiplier:0.088,loss:2.784430503845215,entropy:3.3497509956359863,explained_var_old:0.879668713,explained_var_new:0.949518144
output spend 0.0002100690035149455 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004796542008989491 time
recovery_state_mcts_prob spend 0.4148681849910645 time
state_batch spend 0.004727712002932094 time
mcts_probs_batch spend 0.015119389005121775 time
winner_batch spend 0.00031633499020244926 time
policy_value spend 0.24623163900105283 time
train_step spend 0.7082906879950315 time
policy_value spend 0.2431783850042848 time
train_step spend 0.7071656979969703 time
policy_value spend 0.29067694999685045 time
train_step spend 0.7583259560051374 time
policy_value spend 0.2585429850005312 time
train_step spend 0.7177092929923674 time
policy_value spend 0.2429136139980983 time
kl:0.09317,lr_multiplier:0.088,loss:2.725048303604126,entropy:3.252443790435791,explained_var_old:0.951361001,explained_var_new:0.984399378
output spend 0.0001994179910980165 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004833265003981069 time
recovery_state_mcts_prob spend 0.4568163590010954 time
state_batch spend 0.003987210002378561 time
mcts_probs_batch spend 0.007933646003948525 time
winner_batch spend 0.0004084510001121089 time
policy_value spend 0.24465628199686762 time
train_step spend 0.7103978090017335 time
policy_value spend 0.24072517899912782 time
train_step spend 0.7074486299970886 time
policy_value spend 0.24159689800580963 time
train_step spend 0.7082934359932551 time
policy_value spend 0.24114985299820546 time
train_step spend 0.7081045280065155 time
policy_value spend 0.24531872000079602 time
kl:0.10124,lr_multiplier:0.088,loss:2.728588819503784,entropy:3.2633495330810547,explained_var_old:0.979736805,explained_var_new:0.989104629
output spend 0.00026130299374926835 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00924695300636813 time
recovery_state_mcts_prob spend 0.44281545699050184 time
state_batch spend 0.0021255710016703233 time
mcts_probs_batch spend 0.006608819996472448 time
winner_batch spend 0.0004923100059386343 time
policy_value spend 0.2525584739923943 time
train_step spend 0.7132790939940605 time
policy_value spend 0.24395949600148015 time
train_step spend 0.7083529759984231 time
policy_value spend 0.2419783050136175 time
train_step spend 0.708388640996418 time
policy_value spend 0.25929644399730023 time
kl:0.08199,lr_multiplier:0.088,loss:2.707395315170288,entropy:3.2385165691375732,explained_var_old:0.988613427,explained_var_new:0.978873551
output spend 0.0002985030005220324 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005141610003192909 time
recovery_state_mcts_prob spend 0.36826822499278933 time
state_batch spend 0.0024557060096412897 time
mcts_probs_batch spend 0.005425205992651172 time
winner_batch spend 0.00033429999893996865 time
policy_value spend 0.24224472099740524 time
train_step spend 0.7111188489943743 time
policy_value spend 0.2608633630006807 time
train_step spend 0.7087844449997647 time
policy_value spend 0.24078543599171098 time
train_step spend 0.7084257730020909 time
policy_value spend 0.26929104900045786 time
kl:0.08707,lr_multiplier:0.088,loss:2.8257758617401123,entropy:3.35109281539917,explained_var_old:0.980968535,explained_var_new:0.913391232
output spend 0.00037922301271464676 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006195337991812266 time
recovery_state_mcts_prob spend 0.41929375199833885 time
state_batch spend 0.002076668999507092 time
mcts_probs_batch spend 0.006697314005577937 time
winner_batch spend 0.0002894969948101789 time
policy_value spend 0.24163220199989155 time
train_step spend 0.7094510099996114 time
policy_value spend 0.2708560729952296 time
train_step spend 0.7157155629975023 time
policy_value spend 0.2409852300042985 time
train_step spend 0.7084032040002057 time
policy_value spend 0.2598158559994772 time
train_step spend 0.7118349429947557 time
policy_value spend 0.24117530100920703 time
kl:0.09567,lr_multiplier:0.088,loss:2.787951946258545,entropy:3.3497495651245117,explained_var_old:0.921094537,explained_var_new:0.879198253
output spend 0.00018280399672221392 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005065188001026399 time
recovery_state_mcts_prob spend 0.35648752299312036 time
state_batch spend 0.002341002007597126 time
mcts_probs_batch spend 0.005289262000587769 time
winner_batch spend 0.0003267159918323159 time
policy_value spend 0.2583227480063215 time
train_step spend 0.7363563070102828 time
policy_value spend 0.2422919219970936 time
train_step spend 0.7100381449999986 time
policy_value spend 0.2422138889960479 time
train_step spend 0.7102448270015884 time
policy_value spend 0.2410913259955123 time
train_step spend 0.7084954279998783 time
policy_value spend 0.24059653098811395 time
kl:0.09077,lr_multiplier:0.088,loss:2.7930819988250732,entropy:3.2863383293151855,explained_var_old:0.848422110,explained_var_new:0.987594187
output spend 0.00022868400264997035 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005420332992798649 time
recovery_state_mcts_prob spend 0.4095014180056751 time
state_batch spend 0.003981336994911544 time
mcts_probs_batch spend 0.008163733000401407 time
winner_batch spend 0.0002971399953821674 time
policy_value spend 0.24407829700794537 time
train_step spend 0.7095650910050608 time
policy_value spend 0.2418657539965352 time
train_step spend 0.7099093399883714 time
policy_value spend 0.24248655801056884 time
train_step spend 0.7077954510023119 time
policy_value spend 0.2421262160059996 time
train_step spend 0.7091216580010951 time
policy_value spend 0.24153299399768002 time
train_step spend 0.7073869199957699 time
policy_value spend 0.24416502300300635 time
kl:0.09370,lr_multiplier:0.088,loss:2.8086068630218506,entropy:3.336899757385254,explained_var_old:0.996206641,explained_var_new:0.998823643
output spend 0.00037892301043029875 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006695431991829537 time
recovery_state_mcts_prob spend 0.3356101990066236 time
state_batch spend 0.0020283310004742816 time
mcts_probs_batch spend 0.008072487995377742 time
winner_batch spend 0.00034350699570495635 time
policy_value spend 0.24392354900192004 time
train_step spend 0.7094576300005428 time
policy_value spend 0.24347246300021652 time
train_step spend 0.7090388590004295 time
policy_value spend 0.24354845299967565 time
train_step spend 0.7071130089898361 time
policy_value spend 0.24156332800339442 time
train_step spend 0.7076658369915094 time
policy_value spend 0.24245212599635124 time
train_step spend 0.7075461159984116 time
policy_value spend 0.24315350899996702 time
kl:0.08433,lr_multiplier:0.088,loss:2.7487921714782715,entropy:3.2545738220214844,explained_var_old:0.991762757,explained_var_new:0.994369686
output spend 0.00033301199437119067 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005515046999789774 time
recovery_state_mcts_prob spend 0.47992846099077724 time
state_batch spend 0.002683198996237479 time
mcts_probs_batch spend 0.010163401006138884 time
winner_batch spend 0.00042493299406487495 time
policy_value spend 0.25066796800820157 time
train_step spend 0.7104913459916133 time
policy_value spend 0.2448970109981019 time
train_step spend 0.7097360360057792 time
policy_value spend 0.24240298799122684 time
train_step spend 0.7107772620074684 time
policy_value spend 0.24095298699103296 time
train_step spend 0.7072414059948642 time
policy_value spend 0.24122155700752046 time
train_step spend 0.707729350993759 time
policy_value spend 0.24105380701075774 time
kl:0.09480,lr_multiplier:0.088,loss:2.779817819595337,entropy:3.303337574005127,explained_var_old:0.984774649,explained_var_new:0.985342622
output spend 0.00017122899589594454 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005641645999276079 time
recovery_state_mcts_prob spend 0.49775743699865416 time
state_batch spend 0.00420840599690564 time
mcts_probs_batch spend 0.00796685200475622 time
winner_batch spend 0.00029038998764008284 time
policy_value spend 0.2423467240005266 time
train_step spend 0.7095185660000425 time
policy_value spend 0.24475769299897365 time
train_step spend 0.7076908739982173 time
policy_value spend 0.24213436999707483 time
train_step spend 0.7084378420113353 time
policy_value spend 0.2408267979917582 time
train_step spend 0.7090125899994746 time
policy_value spend 0.24546233999717515 time
train_step spend 0.7083440179994795 time
policy_value spend 0.24133334500947967 time
kl:0.09189,lr_multiplier:0.088,loss:2.7172372341156006,entropy:3.2087106704711914,explained_var_old:0.976794839,explained_var_new:0.989812374
output spend 0.0002412390022072941 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.008167085004970431 time
recovery_state_mcts_prob spend 0.5680045799963409 time
state_batch spend 0.007709131998126395 time
mcts_probs_batch spend 0.00914719900174532 time
winner_batch spend 0.00037271999462973326 time
policy_value spend 0.26393228401138913 time
train_step spend 0.7466629699920304 time
policy_value spend 0.24676508200354874 time
train_step spend 0.7133444929932011 time
policy_value spend 0.2414147670060629 time
train_step spend 0.711697840000852 time
policy_value spend 0.24248433900356758 time
train_step spend 0.7098151060054079 time
policy_value spend 0.24413734799600206 time
kl:0.08088,lr_multiplier:0.088,loss:2.765639305114746,entropy:3.2906432151794434,explained_var_old:0.994445682,explained_var_new:0.996302664
output spend 0.0001961170055437833 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006279781999182887 time
recovery_state_mcts_prob spend 0.40402772898960393 time
state_batch spend 0.0021802320115966722 time
mcts_probs_batch spend 0.006868133990792558 time
winner_batch spend 0.0003107759985141456 time
policy_value spend 0.2427197080105543 time
train_step spend 0.7116163720056647 time
policy_value spend 0.24781979598628823 time
train_step spend 0.7097689679940231 time
policy_value spend 0.24103430099785328 time
train_step spend 0.7075711899960879 time
policy_value spend 0.24612096400232986 time
train_step spend 0.709004450996872 time
policy_value spend 0.24262286600423977 time
kl:0.08298,lr_multiplier:0.088,loss:2.797562599182129,entropy:3.3187310695648193,explained_var_old:0.989825964,explained_var_new:0.990743518
output spend 0.0002810769947245717 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004957925993949175 time
recovery_state_mcts_prob spend 0.36017731099855155 time
state_batch spend 0.003954063999117352 time
mcts_probs_batch spend 0.007623202007380314 time
winner_batch spend 0.00031986999965738505 time
policy_value spend 0.2977899089892162 time
train_step spend 0.7239983220060822 time
policy_value spend 0.24297993299842346 time
train_step spend 0.7104348880093312 time
policy_value spend 0.27779930899851024 time
train_step spend 0.7156913229991915 time
policy_value spend 0.24521635800192598 time
train_step spend 0.7101680919877253 time
policy_value spend 0.270048210004461 time
train_step spend 0.7090385519986739 time
policy_value spend 0.24064270900271367 time
kl:0.10316,lr_multiplier:0.088,loss:2.740359306335449,entropy:3.2708020210266113,explained_var_old:0.988607824,explained_var_new:0.995641530
output spend 0.0001802240003598854 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006391786999301985 time
recovery_state_mcts_prob spend 0.37977952499932144 time
state_batch spend 0.00425819399242755 time
mcts_probs_batch spend 0.008573572005843744 time
winner_batch spend 0.00037110700213816017 time
policy_value spend 0.25141314999200404 time
train_step spend 0.7322865320020355 time
policy_value spend 0.2438719749916345 time
train_step spend 0.709199588993215 time
policy_value spend 0.24160957100684755 time
train_step spend 0.710506910996628 time
policy_value spend 0.2423089380026795 time
train_step spend 0.7091687849897426 time
policy_value spend 0.24110452800232451 time
train_step spend 0.708611854002811 time
policy_value spend 0.24100788400392048 time
kl:0.09291,lr_multiplier:0.088,loss:2.742408275604248,entropy:3.2587051391601562,explained_var_old:0.988966405,explained_var_new:0.996396482
output spend 0.00027435900119598955 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007502779990318231 time
recovery_state_mcts_prob spend 0.41098380100447685 time
state_batch spend 0.002158383998903446 time
mcts_probs_batch spend 0.012195376009913161 time
winner_batch spend 0.0002975719980895519 time
policy_value spend 0.24574311600008514 time
train_step spend 0.7128764020017115 time
policy_value spend 0.24159554899961222 time
train_step spend 0.7086610489932355 time
policy_value spend 0.2421617200016044 time
train_step spend 0.7080089899973245 time
policy_value spend 0.24344440399727318 time
train_step spend 0.7091602319997037 time
policy_value spend 0.2453464680002071 time
kl:0.08605,lr_multiplier:0.088,loss:2.7849478721618652,entropy:3.3242990970611572,explained_var_old:0.994960487,explained_var_new:0.998026907
output spend 0.00030973899993114173 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00492254200798925 time
recovery_state_mcts_prob spend 0.470291763995192 time
state_batch spend 0.004541927992249839 time
mcts_probs_batch spend 0.008663918008096516 time
winner_batch spend 0.0003573790017981082 time
policy_value spend 0.2497328839963302 time
train_step spend 0.711681603002944 time
policy_value spend 0.2435940919967834 time
train_step spend 0.7094697120046476 time
policy_value spend 0.24141905100259464 time
train_step spend 0.7081782040040707 time
policy_value spend 0.24266754799464252 time
train_step spend 0.7070977469993522 time
policy_value spend 0.2419062720000511 time
train_step spend 0.707149046997074 time
policy_value spend 0.2417855649982812 time
kl:0.10065,lr_multiplier:0.088,loss:2.7713122367858887,entropy:3.309964656829834,explained_var_old:0.996660054,explained_var_new:0.999428868
output spend 0.0002790180005831644 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005922755997744389 time
recovery_state_mcts_prob spend 0.5356282510038 time
state_batch spend 0.004079353006090969 time
mcts_probs_batch spend 0.015599444988765754 time
winner_batch spend 0.0003623060038080439 time
policy_value spend 0.24723298000753857 time
train_step spend 0.7084326859912835 time
policy_value spend 0.24625120300333947 time
train_step spend 0.7075444200017955 time
policy_value spend 0.2424244129942963 time
train_step spend 0.7081095539906528 time
policy_value spend 0.24352420200011693 time
train_step spend 0.7092484219901962 time
policy_value spend 0.24110824400850106 time
kl:0.08224,lr_multiplier:0.088,loss:2.7037770748138428,entropy:3.2078380584716797,explained_var_old:0.993363440,explained_var_new:0.995426893
output spend 0.00020009100262541324 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004251460995874368 time
recovery_state_mcts_prob spend 0.33741117200406734 time
state_batch spend 0.003879377996781841 time
mcts_probs_batch spend 0.009096453999518417 time
winner_batch spend 0.00028134300373494625 time
policy_value spend 0.2446721830056049 time
train_step spend 0.7085379229974933 time
policy_value spend 0.24733822399866767 time
train_step spend 0.7093561949877767 time
policy_value spend 0.24095210400992073 time
train_step spend 0.7087665199942421 time
policy_value spend 0.2449266610055929 time
train_step spend 0.7073514670046279 time
policy_value spend 0.24081801499414723 time
train_step spend 0.7079089480102994 time
policy_value spend 0.24227371299639344 time
kl:0.09333,lr_multiplier:0.088,loss:2.7228827476501465,entropy:3.244588851928711,explained_var_old:0.979085982,explained_var_new:0.988637507
output spend 0.00024156400468200445 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005424104994744994 time
recovery_state_mcts_prob spend 0.3502501070033759 time
state_batch spend 0.004758277995279059 time
mcts_probs_batch spend 0.006954861004487611 time
winner_batch spend 0.00027037800464313477 time
policy_value spend 0.24330971599556506 time
train_step spend 0.7089892040094128 time
policy_value spend 0.27351566299330443 time
train_step spend 0.7104080690041883 time
policy_value spend 0.24113511499308515 time
train_step spend 0.7084113790042466 time
policy_value spend 0.2651058670016937 time
train_step spend 0.7113622970064171 time
policy_value spend 0.24263959800009616 time
kl:0.09898,lr_multiplier:0.088,loss:2.7576756477355957,entropy:3.2874083518981934,explained_var_old:0.990990520,explained_var_new:0.996861219
output spend 0.0003752880002139136 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.009218828010489233 time
recovery_state_mcts_prob spend 1.07412184200075 time
state_batch spend 0.004142265999689698 time
mcts_probs_batch spend 0.019505377000314184 time
winner_batch spend 0.0004385319916764274 time
policy_value spend 0.2719003039965173 time
train_step spend 0.721409958001459 time
policy_value spend 0.2418789000075776 time
train_step spend 0.7082172200025525 time
policy_value spend 0.24367053298919927 time
train_step spend 0.7081155790074263 time
policy_value spend 0.24099286399723496 time
train_step spend 0.7085880270024063 time
policy_value spend 0.24101774900918826 time
kl:0.09817,lr_multiplier:0.088,loss:2.718088388442993,entropy:3.240886688232422,explained_var_old:0.990178525,explained_var_new:0.993884802
output spend 0.00019104500825051218 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006152575006126426 time
recovery_state_mcts_prob spend 0.40943303098902106 time
state_batch spend 0.006809045007685199 time
mcts_probs_batch spend 0.0087170290062204 time
winner_batch spend 0.0003790849877987057 time
policy_value spend 0.24313391000032425 time
train_step spend 0.7096001539903227 time
policy_value spend 0.24205276599968784 time
train_step spend 0.7094398759945761 time
policy_value spend 0.2432892310025636 time
train_step spend 0.7074516739958199 time
policy_value spend 0.24215113400714472 time
train_step spend 0.707191038003657 time
policy_value spend 0.24194372099009342 time
kl:0.08331,lr_multiplier:0.088,loss:2.720449686050415,entropy:3.241079807281494,explained_var_old:0.983045995,explained_var_new:0.987737298
output spend 0.00018313400505576283 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00833568700181786 time
recovery_state_mcts_prob spend 0.514382144989213 time
state_batch spend 0.009565879998262972 time
mcts_probs_batch spend 0.01850993200787343 time
winner_batch spend 0.001195078992168419 time
policy_value spend 0.2516717550024623 time
train_step spend 0.7097986970038619 time
policy_value spend 0.2598582450009417 time
train_step spend 0.7346690380072687 time
policy_value spend 0.2421330229990417 time
train_step spend 0.70794255999499 time
policy_value spend 0.24197509500663728 time
train_step spend 0.7077055900008418 time
policy_value spend 0.24234419700223953 time
kl:0.08294,lr_multiplier:0.088,loss:2.8043406009674072,entropy:3.334481954574585,explained_var_old:0.985226393,explained_var_new:0.974912703
output spend 0.0001927090052049607 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007056004003970884 time
recovery_state_mcts_prob spend 0.39622597899870016 time
state_batch spend 0.006942891996004619 time
mcts_probs_batch spend 0.02273125400824938 time
winner_batch spend 0.000342938001267612 time
policy_value spend 0.2440546369907679 time
train_step spend 0.7103369219985325 time
policy_value spend 0.25587998000264633 time
train_step spend 0.7160358160035685 time
policy_value spend 0.24346147499454673 time
train_step spend 0.7256224459997611 time
policy_value spend 0.24645324000448454 time
train_step spend 0.7094688600045629 time
policy_value spend 0.24399698700290173 time
kl:0.08099,lr_multiplier:0.088,loss:2.713893175125122,entropy:3.227877616882324,explained_var_old:0.970418751,explained_var_new:0.978309333
output spend 0.00025758899573702365 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006798771995818242 time
recovery_state_mcts_prob spend 0.457810874999268 time
state_batch spend 0.011111533996881917 time
mcts_probs_batch spend 0.0366846050019376 time
winner_batch spend 0.0005025160062359646 time
policy_value spend 0.24739303199748974 time
train_step spend 0.7097549579921179 time
policy_value spend 0.2453089379996527 time
train_step spend 0.7140474290063139 time
policy_value spend 0.24692080600652844 time
train_step spend 0.7100359659962123 time
policy_value spend 0.24167391199443955 time
train_step spend 0.7095277860062197 time
policy_value spend 0.24606398699688725 time
train_step spend 0.7074197009933414 time
policy_value spend 0.24166709200653713 time
kl:0.08747,lr_multiplier:0.088,loss:2.7391412258148193,entropy:3.228839874267578,explained_var_old:0.975698113,explained_var_new:0.883329690
output spend 0.00030556399724446237 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00715457700425759 time
recovery_state_mcts_prob spend 0.33678648600471206 time
state_batch spend 0.0047445409873034805 time
mcts_probs_batch spend 0.006600213004276156 time
winner_batch spend 0.00030481199792120606 time
policy_value spend 0.2867419579997659 time
train_step spend 0.7284766040102113 time
policy_value spend 0.242573278999771 time
train_step spend 0.7089382150006713 time
policy_value spend 0.26784533000318334 time
train_step spend 0.7115454570011934 time
policy_value spend 0.2415283729933435 time
train_step spend 0.7087830860109534 time
policy_value spend 0.25953229499282315 time
kl:0.09694,lr_multiplier:0.088,loss:2.7531895637512207,entropy:3.2741706371307373,explained_var_old:0.926195323,explained_var_new:0.978313565
output spend 0.0004771270032506436 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0053992909961380064 time
recovery_state_mcts_prob spend 0.4183564760023728 time
state_batch spend 0.0038731819950044155 time
mcts_probs_batch spend 0.016892150000785477 time
winner_batch spend 0.0002896390069508925 time
policy_value spend 0.24709970399271697 time
train_step spend 0.7087313949887175 time
policy_value spend 0.27567931200610474 time
train_step spend 0.7130875209986698 time
policy_value spend 0.24120814799971413 time
train_step spend 0.7068965689977631 time
policy_value spend 0.26173841100535356 time
kl:0.09475,lr_multiplier:0.088,loss:2.762863874435425,entropy:3.273952007293701,explained_var_old:0.958417594,explained_var_new:0.916617393
output spend 0.0005106979951960966 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005912919994443655 time
recovery_state_mcts_prob spend 0.3697323630040046 time
state_batch spend 0.009554974996717647 time
mcts_probs_batch spend 0.033073015001718886 time
winner_batch spend 0.00036670800182037055 time
policy_value spend 0.24349147100292612 time
train_step spend 0.7080472219968215 time
policy_value spend 0.26576788899546955 time
train_step spend 0.710981376003474 time
policy_value spend 0.24596369700157084 time
train_step spend 0.7106644860032247 time
policy_value spend 0.267307254995103 time
kl:0.08627,lr_multiplier:0.088,loss:2.7604336738586426,entropy:3.289179801940918,explained_var_old:0.919968665,explained_var_new:0.990077198
output spend 0.0004998340009478852 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006649625007412396 time
recovery_state_mcts_prob spend 0.392557492988999 time
state_batch spend 0.0039287100080400705 time
mcts_probs_batch spend 0.00773584000125993 time
winner_batch spend 0.00028267200104892254 time
policy_value spend 0.24429192699608393 time
train_step spend 0.7100450889993226 time
policy_value spend 0.26464394699723925 time
train_step spend 0.7105057299922919 time
policy_value spend 0.24187001200334635 time
train_step spend 0.7101394519995665 time
policy_value spend 0.2655428190046223 time
train_step spend 0.7215999510081019 time
policy_value spend 0.2493319669883931 time
kl:0.10231,lr_multiplier:0.088,loss:2.763462543487549,entropy:3.2807915210723877,explained_var_old:0.977838576,explained_var_new:0.989938259
output spend 0.0007982719980645925 time
已保存最新模型
current self-play batch: 400
load data begin
已加载数据
step i 46: 
random.sample spend 0.006422148013371043 time
recovery_state_mcts_prob spend 0.7514324669900816 time
state_batch spend 0.005210385003010742 time
mcts_probs_batch spend 0.019429564999882132 time
winner_batch spend 0.00032537699735257775 time
policy_value spend 0.26576250900689047 time
train_step spend 0.7446792330010794 time
policy_value spend 0.24279805900005158 time
train_step spend 0.7217652660037857 time
policy_value spend 0.26562676500179805 time
train_step spend 0.7472806020086864 time
policy_value spend 0.24271342699648812 time
train_step spend 0.7124223989958409 time
policy_value spend 0.24144406100094784 time
kl:0.09113,lr_multiplier:0.088,loss:2.8071415424346924,entropy:3.3376829624176025,explained_var_old:0.988660753,explained_var_new:0.986228764
output spend 0.00024385900178458542 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005722357003833167 time
recovery_state_mcts_prob spend 0.40302509898901917 time
state_batch spend 0.00362107899854891 time
mcts_probs_batch spend 0.00908501900266856 time
winner_batch spend 0.00030050800705794245 time
policy_value spend 0.24602895499265287 time
train_step spend 0.7108017540012952 time
policy_value spend 0.2485736960079521 time
train_step spend 0.710672857996542 time
policy_value spend 0.24213951399724465 time
train_step spend 0.7114420080033597 time
policy_value spend 0.2465066259901505 time
train_step spend 0.7099309600016568 time
policy_value spend 0.24289205799868796 time
kl:0.09843,lr_multiplier:0.088,loss:2.842472553253174,entropy:3.365168571472168,explained_var_old:0.961387813,explained_var_new:0.987851739
output spend 0.00022831799287814647 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006337982005788945 time
recovery_state_mcts_prob spend 0.5035582440032158 time
state_batch spend 0.004212009996990673 time
mcts_probs_batch spend 0.006691557005979121 time
winner_batch spend 0.000283712986856699 time
policy_value spend 0.2511994090018561 time
train_step spend 0.7107217839948134 time
policy_value spend 0.24317147900001146 time
train_step spend 0.7097929230076261 time
policy_value spend 0.2410969490010757 time
train_step spend 0.7102795409882674 time
policy_value spend 0.24318130400206428 time
train_step spend 0.7089296680060215 time
policy_value spend 0.24158645799616352 time
kl:0.10017,lr_multiplier:0.088,loss:2.7674620151519775,entropy:3.294229745864868,explained_var_old:0.992678642,explained_var_new:0.993876636
output spend 0.00019964500097557902 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005321333999745548 time
recovery_state_mcts_prob spend 0.4244626269937726 time
state_batch spend 0.004270283010555431 time
mcts_probs_batch spend 0.017359138990286738 time
winner_batch spend 0.00030550900555681437 time
policy_value spend 0.2491187859995989 time
train_step spend 0.7141833410132676 time
policy_value spend 0.24194072699174285 time
train_step spend 0.7093711170018651 time
policy_value spend 0.24343581299763173 time
train_step spend 0.7113663000054657 time
policy_value spend 0.24352822599757928 time
train_step spend 0.7119772449950688 time
policy_value spend 0.24176786100724712 time
train_step spend 0.7083991839899682 time
policy_value spend 0.24214941200625617 time
kl:0.09587,lr_multiplier:0.088,loss:2.6945245265960693,entropy:3.2039918899536133,explained_var_old:0.983086705,explained_var_new:0.990558684
output spend 0.00017349600966554135 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0048753000010037795 time
recovery_state_mcts_prob spend 0.40173851599683985 time
state_batch spend 0.004412573005538434 time
mcts_probs_batch spend 0.006454977992689237 time
winner_batch spend 0.0002846320130629465 time
policy_value spend 0.24370586599980015 time
train_step spend 0.7106311279931106 time
policy_value spend 0.24537459800194483 time
train_step spend 0.7081474230071763 time
policy_value spend 0.24509946699254215 time
train_step spend 0.7259946379926987 time
policy_value spend 0.27344345800520387 time
train_step spend 0.7153516039979877 time
policy_value spend 0.2423711599985836 time
train_step spend 0.7081562660023337 time
policy_value spend 0.30556039699877147 time
kl:0.09610,lr_multiplier:0.088,loss:2.7814457416534424,entropy:3.2986202239990234,explained_var_old:0.989581883,explained_var_new:0.992470324
output spend 0.003450881995377131 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0074605039990274236 time
recovery_state_mcts_prob spend 0.485305189009523 time
state_batch spend 0.005193228003918193 time
mcts_probs_batch spend 0.00963678398693446 time
winner_batch spend 0.0003736380022019148 time
policy_value spend 0.25713089600321837 time
train_step spend 0.6978705719957361 time
policy_value spend 0.30709053701139055 time
train_step spend 0.8088655559986364 time
policy_value spend 0.24993722500221338 time
train_step spend 0.7514457229990512 time
policy_value spend 0.2674049999914132 time
train_step spend 0.7405410490027862 time
policy_value spend 0.310826676999568 time
train_step spend 0.7482288030005293 time
policy_value spend 0.25098569800320547 time
kl:0.09934,lr_multiplier:0.088,loss:2.7618520259857178,entropy:3.253403663635254,explained_var_old:0.980548620,explained_var_new:0.990907311
output spend 0.0003300989919807762 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007070303996442817 time
recovery_state_mcts_prob spend 0.5966929930000333 time
state_batch spend 0.0048938200052361935 time
mcts_probs_batch spend 0.013556158999563195 time
winner_batch spend 0.0002940760023193434 time
policy_value spend 0.2464421540062176 time
train_step spend 0.7104604190099053 time
policy_value spend 0.24541386400233023 time
train_step spend 0.7083115679997718 time
policy_value spend 0.2371722030075034 time
train_step spend 0.6968541020032717 time
policy_value spend 0.241447958003846 time
train_step spend 0.7103149799950188 time
policy_value spend 0.25610545500239823 time
kl:0.08225,lr_multiplier:0.088,loss:2.757438898086548,entropy:3.2632031440734863,explained_var_old:0.990022540,explained_var_new:0.990562022
output spend 0.00018428800103720278 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005377266992582008 time
recovery_state_mcts_prob spend 0.37151967000681907 time
state_batch spend 0.0039921909919939935 time
mcts_probs_batch spend 0.00745038699824363 time
winner_batch spend 0.00028505900991149247 time
policy_value spend 0.2439462759939488 time
train_step spend 0.7077350369945634 time
policy_value spend 0.2676945440034615 time
train_step spend 0.7130979179928545 time
policy_value spend 0.241334464008105 time
train_step spend 0.7074633190059103 time
policy_value spend 0.25093387700326275 time
train_step spend 0.7090030189865502 time
policy_value spend 0.24150240000744816 time
train_step spend 0.7075642039999366 time
policy_value spend 0.26766539699747227 time
kl:0.10682,lr_multiplier:0.088,loss:2.741821050643921,entropy:3.26444149017334,explained_var_old:0.988655865,explained_var_new:0.993258476
output spend 0.0003514299896778539 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007582955004181713 time
recovery_state_mcts_prob spend 0.43614861999230925 time
state_batch spend 0.0046699270023964345 time
mcts_probs_batch spend 0.014238207004382275 time
winner_batch spend 0.000297298000077717 time
policy_value spend 0.24523291499644984 time
train_step spend 0.7051573100034148 time
policy_value spend 0.3018096089945175 time
train_step spend 0.7102795079990756 time
policy_value spend 0.2422408650018042 time
train_step spend 0.7095169509993866 time
policy_value spend 0.2548209779924946 time
train_step spend 0.7102509760006797 time
policy_value spend 0.24203655098972376 time
kl:0.09785,lr_multiplier:0.088,loss:2.729196786880493,entropy:3.24828839302063,explained_var_old:0.994261324,explained_var_new:0.997494221
output spend 0.00020193700038362294 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004920285995467566 time
recovery_state_mcts_prob spend 0.3474367419985356 time
state_batch spend 0.0029484770057024434 time
mcts_probs_batch spend 0.006885523995151743 time
winner_batch spend 0.00031692800985183567 time
policy_value spend 0.2830358979990706 time
train_step spend 0.7471149140037596 time
policy_value spend 0.27995705998910125 time
train_step spend 0.7284531760087702 time
policy_value spend 0.2956833509961143 time
train_step spend 0.773351976997219 time
policy_value spend 0.25894496000546496 time
train_step spend 0.723520847997861 time
policy_value spend 0.25065488800464664 time
train_step spend 0.7086205119994702 time
policy_value spend 0.24647583499609027 time
kl:0.09447,lr_multiplier:0.088,loss:2.780405282974243,entropy:3.2781972885131836,explained_var_old:0.990766227,explained_var_new:0.992654324
output spend 0.0005434619961306453 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.027980936007224955 time
recovery_state_mcts_prob spend 0.5520193300035316 time
state_batch spend 0.002158645002054982 time
mcts_probs_batch spend 0.007316128991078585 time
winner_batch spend 0.0003263020043959841 time
policy_value spend 0.24302596900088247 time
train_step spend 0.7070392579917097 time
policy_value spend 0.24249614399741404 time
train_step spend 0.7080225710087689 time
policy_value spend 0.2641261989920167 time
train_step spend 0.7277334819955286 time
policy_value spend 0.2559216780064162 time
train_step spend 0.7235531669866759 time
policy_value spend 0.2554656560096191 time
kl:0.08673,lr_multiplier:0.088,loss:2.7599081993103027,entropy:3.2575759887695312,explained_var_old:0.981738210,explained_var_new:0.972442329
output spend 0.00040048299706541 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004875370999798179 time
recovery_state_mcts_prob spend 0.4685993210005108 time
state_batch spend 0.004297475999919698 time
mcts_probs_batch spend 0.00838102500711102 time
winner_batch spend 0.0003065249911742285 time
policy_value spend 0.2874733170028776 time
train_step spend 0.7227611999987857 time
policy_value spend 0.2451924670021981 time
train_step spend 0.7083702610107139 time
policy_value spend 0.25549383799079806 time
train_step spend 0.7284109840111341 time
policy_value spend 0.24254655798722524 time
train_step spend 0.714293256009114 time
policy_value spend 0.2824443839926971 time
kl:0.10086,lr_multiplier:0.088,loss:2.7473597526550293,entropy:3.2804861068725586,explained_var_old:0.974021733,explained_var_new:0.996710896
output spend 0.0008542299910914153 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005581363002420403 time
recovery_state_mcts_prob spend 0.49369675599155016 time
state_batch spend 0.005479792002006434 time
mcts_probs_batch spend 0.024316504001035355 time
winner_batch spend 0.0003292239998700097 time
policy_value spend 0.24687958300637547 time
train_step spend 0.7091362740029581 time
policy_value spend 0.2646499029942788 time
train_step spend 0.7171218669973314 time
policy_value spend 0.26398693599912804 time
train_step spend 0.7364110060007079 time
policy_value spend 0.2443467739940388 time
train_step spend 0.712251096003456 time
policy_value spend 0.24658653300139122 time
kl:0.08674,lr_multiplier:0.088,loss:2.72416090965271,entropy:3.2305755615234375,explained_var_old:0.990997732,explained_var_new:0.974692345
output spend 0.0003156789898639545 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004967714994563721 time
recovery_state_mcts_prob spend 0.5211901779985055 time
state_batch spend 0.003498999009025283 time
mcts_probs_batch spend 0.009431321988813579 time
winner_batch spend 0.00030791400058660656 time
policy_value spend 0.24542647501220927 time
train_step spend 0.7081716459942982 time
policy_value spend 0.2427380080043804 time
train_step spend 0.7086533969995799 time
policy_value spend 0.24142178600595798 time
train_step spend 0.7086134319979465 time
policy_value spend 0.24107231700327247 time
train_step spend 0.7074485449993517 time
policy_value spend 0.24397786500048824 time
kl:0.08313,lr_multiplier:0.088,loss:2.6665759086608887,entropy:3.185837745666504,explained_var_old:0.960355878,explained_var_new:0.993726134
output spend 0.00028834900876972824 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005759904001024552 time
recovery_state_mcts_prob spend 0.4292865699972026 time
state_batch spend 0.003008989995578304 time
mcts_probs_batch spend 0.009706113007268868 time
winner_batch spend 0.00048314599553123116 time
policy_value spend 0.2425043219991494 time
train_step spend 0.710950993001461 time
policy_value spend 0.24399728600110393 time
train_step spend 0.7253347670048242 time
policy_value spend 0.26288859800843056 time
train_step spend 0.7483953589980956 time
policy_value spend 0.24313742500089575 time
train_step spend 0.7115447370015318 time
policy_value spend 0.2430610540031921 time
kl:0.08755,lr_multiplier:0.088,loss:2.6466784477233887,entropy:3.1384286880493164,explained_var_old:0.988400459,explained_var_new:0.989982903
output spend 0.00029062900284770876 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.009322009995230474 time
recovery_state_mcts_prob spend 0.8119249540031888 time
state_batch spend 0.006954402997507714 time
mcts_probs_batch spend 0.009409373000380583 time
winner_batch spend 0.00035543099511414766 time
policy_value spend 0.27018818800570443 time
train_step spend 0.7403827289963374 time
policy_value spend 0.2575077590008732 time
train_step spend 0.731296084006317 time
policy_value spend 0.2560985359887127 time
train_step spend 0.7246452120016329 time
policy_value spend 0.2462904699932551 time
train_step spend 0.7122765469976002 time
policy_value spend 0.24469607599894516 time
kl:0.08344,lr_multiplier:0.088,loss:2.760869026184082,entropy:3.286533832550049,explained_var_old:0.986046970,explained_var_new:0.990867615
output spend 0.00035729700175579637 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005690335005056113 time
recovery_state_mcts_prob spend 0.4332158140023239 time
state_batch spend 0.005376781991799362 time
mcts_probs_batch spend 0.015415558009408414 time
winner_batch spend 0.0003134649887215346 time
policy_value spend 0.25321536300180014 time
train_step spend 0.7114606899995124 time
policy_value spend 0.24451175400463399 time
train_step spend 0.7077913340035593 time
policy_value spend 0.24233695399016142 time
train_step spend 0.7133628419978777 time
policy_value spend 0.24343987500469666 time
train_step spend 0.7120114529971033 time
policy_value spend 0.24191051001253072 time
train_step spend 0.7097316169965779 time
policy_value spend 0.2418562520033447 time
kl:0.10066,lr_multiplier:0.088,loss:2.7484586238861084,entropy:3.2773444652557373,explained_var_old:0.995145142,explained_var_new:0.995627105
output spend 0.00019920799240935594 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004841339003178291 time
recovery_state_mcts_prob spend 0.45439113600878045 time
state_batch spend 0.004304595000576228 time
mcts_probs_batch spend 0.009209721989464015 time
winner_batch spend 0.0003493390104267746 time
policy_value spend 0.24274762999266386 time
train_step spend 0.7090560719952919 time
policy_value spend 0.2438602120091673 time
train_step spend 0.7081847070076037 time
policy_value spend 0.24049605100299232 time
train_step spend 0.7091290219977964 time
policy_value spend 0.24763051500485744 time
train_step spend 0.7125459130038507 time
policy_value spend 0.24138341700017918 time
kl:0.09371,lr_multiplier:0.088,loss:2.730158805847168,entropy:3.2510058879852295,explained_var_old:0.989740789,explained_var_new:0.995965004
output spend 0.00019364600302651525 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.019951788999605924 time
recovery_state_mcts_prob spend 0.5179673449893016 time
state_batch spend 0.002169364001019858 time
mcts_probs_batch spend 0.02413665800122544 time
winner_batch spend 0.0003599150077207014 time
policy_value spend 0.24805425100203138 time
train_step spend 0.7112930529983714 time
policy_value spend 0.2430851840035757 time
train_step spend 0.7112598850071663 time
policy_value spend 0.24234788000467233 time
train_step spend 0.7086395040096249 time
policy_value spend 0.2439181549998466 time
train_step spend 0.7132853279908886 time
policy_value spend 0.24450244900071993 time
kl:0.09408,lr_multiplier:0.088,loss:2.709927797317505,entropy:3.21340012550354,explained_var_old:0.975148678,explained_var_new:0.985601902
output spend 0.00020638300338760018 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006946741996216588 time
recovery_state_mcts_prob spend 0.5735010240023257 time
state_batch spend 0.004329225004767068 time
mcts_probs_batch spend 0.01475161500275135 time
winner_batch spend 0.00031962699722498655 time
policy_value spend 0.24961397200240754 time
train_step spend 0.7107790729933186 time
policy_value spend 0.24234864801110234 time
train_step spend 0.7086648789991159 time
policy_value spend 0.24241672598873265 time
train_step spend 0.7103722089959774 time
policy_value spend 0.2461889410042204 time
train_step spend 0.7117281059909146 time
policy_value spend 0.24100756501138676 time
kl:0.08731,lr_multiplier:0.088,loss:2.7308199405670166,entropy:3.256770133972168,explained_var_old:0.985261977,explained_var_new:0.990471244
output spend 0.0001899719936773181 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005883896999876015 time
recovery_state_mcts_prob spend 0.38886012700095307 time
state_batch spend 0.006254407009691931 time
mcts_probs_batch spend 0.010245455996482633 time
winner_batch spend 0.0004999910015612841 time
policy_value spend 0.24854050599969923 time
train_step spend 0.707916404993739 time
policy_value spend 0.24833624600432813 time
train_step spend 0.7077155479928479 time
policy_value spend 0.24250487200333737 time
train_step spend 0.7075832720001927 time
policy_value spend 0.24541483499342576 time
train_step spend 0.7114849510107888 time
policy_value spend 0.24149803699401673 time
kl:0.08344,lr_multiplier:0.088,loss:2.819244623184204,entropy:3.3158011436462402,explained_var_old:0.981856108,explained_var_new:0.982466400
output spend 0.00026200000138487667 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0068405739875743166 time
recovery_state_mcts_prob spend 0.5758073270117166 time
state_batch spend 0.0031674469937570393 time
mcts_probs_batch spend 0.005899531999602914 time
winner_batch spend 0.0004435050068423152 time
policy_value spend 0.2452357539877994 time
train_step spend 0.7171828919963446 time
policy_value spend 0.24307213800784666 time
train_step spend 0.7072220690024551 time
policy_value spend 0.24133056899881922 time
train_step spend 0.7081398540030932 time
policy_value spend 0.2478290559956804 time
train_step spend 0.7101223950012354 time
policy_value spend 0.24406445000204258 time
kl:0.09555,lr_multiplier:0.088,loss:2.7303054332733154,entropy:3.2385525703430176,explained_var_old:0.982782900,explained_var_new:0.988294482
output spend 0.0008618019928690046 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0054978109983494505 time
recovery_state_mcts_prob spend 0.3705160679965047 time
state_batch spend 0.0023758170136716217 time
mcts_probs_batch spend 0.0077105319942347705 time
winner_batch spend 0.0003470230003586039 time
policy_value spend 0.24578167700383347 time
train_step spend 0.7083550980023574 time
policy_value spend 0.24170001500169747 time
train_step spend 0.7078845249925507 time
policy_value spend 0.2431268549989909 time
train_step spend 0.7074432380031794 time
policy_value spend 0.2460929799999576 time
kl:0.08487,lr_multiplier:0.088,loss:2.7683191299438477,entropy:3.277254104614258,explained_var_old:0.989222944,explained_var_new:0.989554584
output spend 0.00032372800342272967 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007763639005133882 time
recovery_state_mcts_prob spend 0.42293769599928055 time
state_batch spend 0.006301772998995148 time
mcts_probs_batch spend 0.009515504993032664 time
winner_batch spend 0.00035117100924253464 time
policy_value spend 0.24361355399014428 time
train_step spend 0.7077197790058563 time
policy_value spend 0.2439397299895063 time
train_step spend 0.7085629079956561 time
policy_value spend 0.24261295099859126 time
train_step spend 0.7081190349999815 time
policy_value spend 0.24366586399264634 time
kl:0.08176,lr_multiplier:0.088,loss:2.782045841217041,entropy:3.309403896331787,explained_var_old:0.988383532,explained_var_new:0.990409195
output spend 0.00022026999795343727 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004367429995909333 time
recovery_state_mcts_prob spend 0.43636198999593034 time
state_batch spend 0.007842127000913024 time
mcts_probs_batch spend 0.013427219004370272 time
winner_batch spend 0.00045755700557492673 time
policy_value spend 0.24642837699502707 time
train_step spend 0.7085378420015331 time
policy_value spend 0.24266884299868252 time
train_step spend 0.707617204010603 time
policy_value spend 0.24596491298871115 time
train_step spend 0.7088628500059713 time
policy_value spend 0.2438464469887549 time
kl:0.08287,lr_multiplier:0.088,loss:2.719871759414673,entropy:3.2161474227905273,explained_var_old:0.986373723,explained_var_new:0.988766372
output spend 0.0003129279939457774 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006098376994486898 time
recovery_state_mcts_prob spend 0.3571317669993732 time
state_batch spend 0.0020707530056824908 time
mcts_probs_batch spend 0.008414347990765236 time
winner_batch spend 0.00032626801112201065 time
policy_value spend 0.24291717598680407 time
train_step spend 0.7083138769958168 time
policy_value spend 0.24907139799324796 time
train_step spend 0.7102199569926597 time
policy_value spend 0.24359130300581455 time
train_step spend 0.7081484180089319 time
policy_value spend 0.2422154679952655 time
kl:0.08321,lr_multiplier:0.088,loss:2.8078534603118896,entropy:3.309746265411377,explained_var_old:0.984438539,explained_var_new:0.945058584
output spend 0.00032330599788110703 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005503692009369843 time
recovery_state_mcts_prob spend 0.4825307949940907 time
state_batch spend 0.003351546998601407 time
mcts_probs_batch spend 0.01784583300468512 time
winner_batch spend 0.0004139480006415397 time
policy_value spend 0.2475288090063259 time
train_step spend 0.7080856480024522 time
policy_value spend 0.2414626449899515 time
train_step spend 0.7084753910021391 time
policy_value spend 0.2436427399952663 time
train_step spend 0.7089108299987856 time
policy_value spend 0.24268643600225914 time
train_step spend 0.7078712799993809 time
policy_value spend 0.24279592500533909 time
kl:0.09316,lr_multiplier:0.088,loss:2.7975170612335205,entropy:3.3260862827301025,explained_var_old:0.924974203,explained_var_new:0.992151558
output spend 0.00023820600472390652 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005355914996471256 time
recovery_state_mcts_prob spend 0.36003825200896244 time
state_batch spend 0.0039537589909741655 time
mcts_probs_batch spend 0.007661492010811344 time
winner_batch spend 0.0002907639864133671 time
policy_value spend 0.2447230420075357 time
train_step spend 0.7078304540045792 time
policy_value spend 0.2458144840056775 time
train_step spend 0.7106943209946621 time
policy_value spend 0.24112479100585915 time
train_step spend 0.7103878599882592 time
policy_value spend 0.241579242006992 time
train_step spend 0.7070315609889803 time
policy_value spend 0.24107954300416168 time
kl:0.10259,lr_multiplier:0.088,loss:2.75957989692688,entropy:3.2653934955596924,explained_var_old:0.991640091,explained_var_new:0.989260077
output spend 0.00017658600700087845 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0061149700050009415 time
recovery_state_mcts_prob spend 0.5034096819872502 time
state_batch spend 0.0022223039995878935 time
mcts_probs_batch spend 0.009264838008675724 time
winner_batch spend 0.00032405999081674963 time
policy_value spend 0.24265256299986504 time
train_step spend 0.708340148004936 time
policy_value spend 0.2507686909957556 time
train_step spend 0.7143469329894288 time
policy_value spend 0.24412940900947433 time
train_step spend 0.7167899900086923 time
policy_value spend 0.2433647599973483 time
train_step spend 0.7076145360042574 time
policy_value spend 0.24256887099181768 time
kl:0.09012,lr_multiplier:0.088,loss:2.7448818683624268,entropy:3.2582859992980957,explained_var_old:0.976861954,explained_var_new:0.993049920
output spend 0.00023738598974887282 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006235977009055205 time
recovery_state_mcts_prob spend 0.34994181999354623 time
state_batch spend 0.003978466003900394 time
mcts_probs_batch spend 0.007736622006632388 time
winner_batch spend 0.00028814499091822654 time
policy_value spend 0.24573049200989772 time
train_step spend 0.710775660991203 time
policy_value spend 0.24567140500585083 time
train_step spend 0.7087239570100792 time
policy_value spend 0.2410840289958287 time
train_step spend 0.7094279189914232 time
policy_value spend 0.2425717279984383 time
train_step spend 0.707532981003169 time
policy_value spend 0.2412108580028871 time
kl:0.08015,lr_multiplier:0.088,loss:2.725184679031372,entropy:3.2373788356781006,explained_var_old:0.991800606,explained_var_new:0.992212534
output spend 0.00019446900114417076 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006411424998077564 time
recovery_state_mcts_prob spend 0.5337213040038478 time
state_batch spend 0.0024490009964210913 time
mcts_probs_batch spend 0.014740162994712591 time
winner_batch spend 0.0003139260079478845 time
policy_value spend 0.2549737189983716 time
train_step spend 0.7167651260097045 time
policy_value spend 0.24104191399237607 time
train_step spend 0.7093747600010829 time
policy_value spend 0.24216519000765402 time
train_step spend 0.7090773469972191 time
policy_value spend 0.24430910899536684 time
train_step spend 0.7099022120091831 time
policy_value spend 0.24536384499515407 time
kl:0.08891,lr_multiplier:0.088,loss:2.746594190597534,entropy:3.2494826316833496,explained_var_old:0.987041712,explained_var_new:0.990837634
output spend 0.00024190699332393706 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006342471999232657 time
recovery_state_mcts_prob spend 0.41959972100448795 time
state_batch spend 0.00374397799896542 time
mcts_probs_batch spend 0.007640676005394198 time
winner_batch spend 0.0003209970018360764 time
policy_value spend 0.24273462798737455 time
train_step spend 0.7077385629963828 time
policy_value spend 0.2426602180057671 time
train_step spend 0.7079025419952814 time
policy_value spend 0.24153125900193118 time
train_step spend 0.7072352079994744 time
policy_value spend 0.26120787000400014 time
train_step spend 0.7114845059986692 time
policy_value spend 0.24068153501139022 time
train_step spend 0.7087193129991647 time
policy_value spend 0.26320236700121313 time
kl:0.09873,lr_multiplier:0.088,loss:2.7584731578826904,entropy:3.2481775283813477,explained_var_old:0.992216229,explained_var_new:0.995865524
output spend 0.0003799900005105883 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006774313995265402 time
recovery_state_mcts_prob spend 0.4427226050029276 time
state_batch spend 0.004661655999370851 time
mcts_probs_batch spend 0.01854332299262751 time
winner_batch spend 0.00032116600777953863 time
policy_value spend 0.24651315600203816 time
train_step spend 0.707555726999999 time
policy_value spend 0.2669873539998662 time
train_step spend 0.709025083007873 time
policy_value spend 0.24484167598711792 time
train_step spend 0.7098061959986808 time
policy_value spend 0.2623815129918512 time
train_step spend 0.7116986140026711 time
policy_value spend 0.24161539100168739 time
train_step spend 0.7085354559967527 time
policy_value spend 0.2646885730064241 time
kl:0.09818,lr_multiplier:0.088,loss:2.784111499786377,entropy:3.3125946521759033,explained_var_old:0.987691939,explained_var_new:0.989421666
output spend 0.00029649499629158527 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006728972002747469 time
recovery_state_mcts_prob spend 0.4004679529898567 time
state_batch spend 0.0023199930001283064 time
mcts_probs_batch spend 0.005048860009992495 time
winner_batch spend 0.00034190400037914515 time
policy_value spend 0.24139771799673326 time
train_step spend 0.70803926201188 time
policy_value spend 0.2607010130013805 time
train_step spend 0.717532176990062 time
policy_value spend 0.24133903499750886 time
train_step spend 0.7078795400011586 time
policy_value spend 0.25985850299184676 time
train_step spend 0.7140896940109087 time
policy_value spend 0.24231227400014177 time
kl:0.09073,lr_multiplier:0.088,loss:2.793067693710327,entropy:3.2690305709838867,explained_var_old:0.982813835,explained_var_new:0.981369317
output spend 0.00017446099082008004 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005976133004878648 time
recovery_state_mcts_prob spend 0.34941175699350424 time
state_batch spend 0.010029791999841109 time
mcts_probs_batch spend 0.028960651005036198 time
winner_batch spend 0.00035441300133243203 time
policy_value spend 0.244537495993427 time
train_step spend 0.7191117420006776 time
policy_value spend 0.3893232250120491 time
train_step spend 0.7563822090014582 time
policy_value spend 0.3513767449912848 time
train_step spend 0.7583478289889172 time
policy_value spend 0.35471946600591764 time
train_step spend 0.8044211240048753 time
policy_value spend 0.3393877380003687 time
kl:0.08808,lr_multiplier:0.088,loss:2.814059019088745,entropy:3.3240818977355957,explained_var_old:0.984692931,explained_var_new:0.991833568
output spend 0.009812434989726171 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.050651095996727236 time
recovery_state_mcts_prob spend 5.68417930600117 time
state_batch spend 0.028921204997459427 time
mcts_probs_batch spend 0.2697642840066692 time
winner_batch spend 0.0008609539945609868 time
policy_value spend 0.7342326929938281 time
train_step spend 0.7929472000105307 time
policy_value spend 0.3388637179887155 time
train_step spend 0.7616295089974301 time
policy_value spend 0.2565693719952833 time
train_step spend 0.7225475849991199 time
policy_value spend 0.2435775860067224 time
train_step spend 0.7263422510004602 time
policy_value spend 0.2445999560004566 time
kl:0.08455,lr_multiplier:0.088,loss:2.7366538047790527,entropy:3.2381691932678223,explained_var_old:0.993933499,explained_var_new:0.999378622
output spend 0.00043444700713735074 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006221882998943329 time
recovery_state_mcts_prob spend 0.512159967009211 time
state_batch spend 0.005306841994752176 time
mcts_probs_batch spend 0.019603716995334253 time
winner_batch spend 0.0003673510072985664 time
policy_value spend 0.2513830279931426 time
train_step spend 0.7135982259933371 time
policy_value spend 0.24795460401219316 time
train_step spend 0.7091056349891005 time
policy_value spend 0.2428435640031239 time
train_step spend 0.713058731998899 time
policy_value spend 0.26931088700075634 time
train_step spend 0.7484471009956906 time
policy_value spend 0.24231922799663153 time
kl:0.09257,lr_multiplier:0.088,loss:2.68985915184021,entropy:3.1961681842803955,explained_var_old:0.988349974,explained_var_new:0.990332127
output spend 0.00023504400451201946 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005939394002780318 time
recovery_state_mcts_prob spend 0.5384956839989172 time
state_batch spend 0.012293689011130482 time
mcts_probs_batch spend 0.020512511997367255 time
winner_batch spend 0.0007559049990959466 time
policy_value spend 0.2486908900027629 time
train_step spend 0.7094256799900904 time
policy_value spend 0.2432719089993043 time
train_step spend 0.7084676029917318 time
policy_value spend 0.2454969690006692 time
train_step spend 0.7095880059932824 time
policy_value spend 0.2417871610086877 time
train_step spend 0.7140207370102871 time
policy_value spend 0.2411454179964494 time
kl:0.08233,lr_multiplier:0.088,loss:2.798377513885498,entropy:3.292358636856079,explained_var_old:0.978824377,explained_var_new:0.975653410
output spend 0.0003403679875191301 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004973130999132991 time
recovery_state_mcts_prob spend 0.39907042200502474 time
state_batch spend 0.004403156999615021 time
mcts_probs_batch spend 0.00669252299121581 time
winner_batch spend 0.000261295004747808 time
policy_value spend 0.25045880100515205 time
train_step spend 0.754769655992277 time
policy_value spend 0.2525689890026115 time
train_step spend 0.7119959099945845 time
policy_value spend 0.24233329700655304 time
train_step spend 0.7077012490044581 time
policy_value spend 0.25321620499016717 time
train_step spend 0.7129493530082982 time
policy_value spend 0.24055954298819415 time
kl:0.09365,lr_multiplier:0.088,loss:2.7642533779144287,entropy:3.249023914337158,explained_var_old:0.974708974,explained_var_new:0.985802174
output spend 0.00019945099484175444 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0038818890025140718 time
recovery_state_mcts_prob spend 0.3328246689925436 time
state_batch spend 0.006588186995941214 time
mcts_probs_batch spend 0.017863906003185548 time
winner_batch spend 0.0003247679997002706 time
policy_value spend 0.24584709299961105 time
train_step spend 0.7076926640002057 time
policy_value spend 0.2433808060013689 time
train_step spend 0.7108828369964613 time
policy_value spend 0.24247085901151877 time
train_step spend 0.7071298630035017 time
policy_value spend 0.2415411789988866 time
train_step spend 0.7071764339925721 time
policy_value spend 0.24274446100753266 time
kl:0.08211,lr_multiplier:0.088,loss:2.739708423614502,entropy:3.234463691711426,explained_var_old:0.992326081,explained_var_new:0.994856656
output spend 0.00017179299902636558 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007500883002649061 time
recovery_state_mcts_prob spend 0.38723887599189766 time
state_batch spend 0.0021014009980717674 time
mcts_probs_batch spend 0.010810164007125422 time
winner_batch spend 0.0002693309943424538 time
policy_value spend 0.24659708399849478 time
train_step spend 0.7082476170035079 time
policy_value spend 0.24133401300059631 time
train_step spend 0.7098305570107186 time
policy_value spend 0.24185483600012958 time
train_step spend 0.7083151980041293 time
policy_value spend 0.24082878199988045 time
train_step spend 0.7088673929974902 time
policy_value spend 0.2406500170036452 time
kl:0.08934,lr_multiplier:0.088,loss:2.778480291366577,entropy:3.283781051635742,explained_var_old:0.996158540,explained_var_new:0.997682333
output spend 0.00016581499949097633 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004039808001834899 time
recovery_state_mcts_prob spend 0.30439275699609425 time
state_batch spend 0.0038959299999987707 time
mcts_probs_batch spend 0.006740697004715912 time
winner_batch spend 0.00026715399872045964 time
policy_value spend 0.24246014299569651 time
train_step spend 0.7071351679915097 time
policy_value spend 0.24244760800502263 time
train_step spend 0.708410859995638 time
policy_value spend 0.24167563099763356 time
train_step spend 0.7086241560027702 time
policy_value spend 0.2459197059943108 time
train_step spend 0.7079266630025813 time
policy_value spend 0.2414398950058967 time
kl:0.08474,lr_multiplier:0.088,loss:2.792335271835327,entropy:3.3151183128356934,explained_var_old:0.993951201,explained_var_new:0.998167634
output spend 0.00016830798995215446 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005447778006782755 time
recovery_state_mcts_prob spend 0.308817236989853 time
state_batch spend 0.005250066009466536 time
mcts_probs_batch spend 0.00817477999953553 time
winner_batch spend 0.000357924000127241 time
policy_value spend 0.24310457899991889 time
train_step spend 0.708156553999288 time
policy_value spend 0.24088150900206529 time
train_step spend 0.7077189690025989 time
policy_value spend 0.3079162899957737 time
train_step spend 0.7150986100023147 time
policy_value spend 0.256844142000773 time
train_step spend 0.7078074359887978 time
policy_value spend 0.24066954301088117 time
train_step spend 0.7080398930120282 time
policy_value spend 0.24065404299471993 time
kl:0.09808,lr_multiplier:0.088,loss:2.7377371788024902,entropy:3.249506950378418,explained_var_old:0.980412722,explained_var_new:0.987846076
output spend 0.0002381270023761317 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005744669993873686 time
recovery_state_mcts_prob spend 0.31127657199976966 time
state_batch spend 0.003978036998887546 time
mcts_probs_batch spend 0.012646582996239886 time
winner_batch spend 0.0002922870044130832 time
policy_value spend 0.24580212000000756 time
train_step spend 0.7179455580044305 time
policy_value spend 0.2412676649983041 time
train_step spend 0.7088804390077712 time
policy_value spend 0.24236670100071933 time
train_step spend 0.7074357490055263 time
policy_value spend 0.2412331100058509 time
kl:0.08334,lr_multiplier:0.088,loss:2.7550735473632812,entropy:3.2884464263916016,explained_var_old:0.993584156,explained_var_new:0.995613217
output spend 0.00017241599562112242 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00498713600973133 time
recovery_state_mcts_prob spend 0.2945174659980694 time
state_batch spend 0.004197314992779866 time
mcts_probs_batch spend 0.006160962002468295 time
winner_batch spend 0.0006504979974124581 time
policy_value spend 0.2428097730007721 time
train_step spend 0.7150844980060356 time
policy_value spend 0.24172366999846417 time
train_step spend 0.7082275889988523 time
policy_value spend 0.2413767919933889 time
train_step spend 0.7072135259950301 time
policy_value spend 0.24495388100331184 time
train_step spend 0.7096584899991285 time
policy_value spend 0.24117070899228565 time
kl:0.10970,lr_multiplier:0.088,loss:2.7357380390167236,entropy:3.2331504821777344,explained_var_old:0.997023642,explained_var_new:0.991379559
output spend 0.00016940099885687232 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0035673560050781816 time
recovery_state_mcts_prob spend 0.3014841889962554 time
state_batch spend 0.008378526006708853 time
mcts_probs_batch spend 0.01909928499662783 time
winner_batch spend 0.0003087069926550612 time
policy_value spend 0.24520454301091377 time
train_step spend 0.7093743199948221 time
policy_value spend 0.24212799599627033 time
train_step spend 0.7081957990012597 time
policy_value spend 0.24087958500604145 time
train_step spend 0.7093148009880679 time
policy_value spend 0.2414653590094531 time
train_step spend 0.7118430080008693 time
policy_value spend 0.2410318620095495 time
kl:0.08571,lr_multiplier:0.088,loss:2.7384376525878906,entropy:3.239428997039795,explained_var_old:0.990826786,explained_var_new:0.996071219
output spend 0.00017606301116757095 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006432022011722438 time
recovery_state_mcts_prob spend 0.2991402899933746 time
state_batch spend 0.0051319979975232854 time
mcts_probs_batch spend 0.015170327998930588 time
winner_batch spend 0.00040622100641485304 time
policy_value spend 0.2467172210017452 time
train_step spend 0.7072644259897061 time
policy_value spend 0.24317603000963572 time
train_step spend 0.7072306980116991 time
policy_value spend 0.2841478689952055 time
train_step spend 0.7239120599988382 time
policy_value spend 0.26068397000199184 time
train_step spend 0.7169578640023246 time
policy_value spend 0.2470840439927997 time
kl:0.08686,lr_multiplier:0.088,loss:2.774585008621216,entropy:3.2973575592041016,explained_var_old:0.992105246,explained_var_new:0.995754182
output spend 0.00028475500585045666 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006271912992815487 time
recovery_state_mcts_prob spend 0.4682464549987344 time
state_batch spend 0.007035947011900134 time
mcts_probs_batch spend 0.010595588988508098 time
winner_batch spend 0.00037771501229144633 time
policy_value spend 0.2456883519917028 time
train_step spend 0.7276805870060343 time
policy_value spend 0.2603017719957279 time
train_step spend 0.7452112210012274 time
policy_value spend 0.2433257689990569 time
train_step spend 0.722276348999003 time
policy_value spend 0.312021817007917 time
train_step spend 0.7492031739966478 time
policy_value spend 0.3083270830102265 time
kl:0.08209,lr_multiplier:0.088,loss:2.752519130706787,entropy:3.2779464721679688,explained_var_old:0.992669284,explained_var_new:0.995921135
output spend 0.01243571400118526 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.06769332799012773 time
recovery_state_mcts_prob spend 4.474876735999715 time
state_batch spend 0.015843430010136217 time
mcts_probs_batch spend 0.05438368799514137 time
winner_batch spend 0.0008582479931646958 time
policy_value spend 0.6359445580019383 time
train_step spend 0.8972920609958237 time
policy_value spend 0.2925237269955687 time
train_step spend 0.7608329080103431 time
policy_value spend 0.2778200390021084 time
train_step spend 0.7418745309987571 time
policy_value spend 0.24928873499447946 time
train_step spend 0.7178042500017909 time
policy_value spend 0.24648283199348953 time
kl:0.08654,lr_multiplier:0.088,loss:2.720633029937744,entropy:3.214705467224121,explained_var_old:0.992668927,explained_var_new:0.992467940
output spend 0.00041477399645373225 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0052710529998876154 time
recovery_state_mcts_prob spend 0.6659444380056811 time
state_batch spend 0.0064503309986321256 time
mcts_probs_batch spend 0.012039816996548325 time
winner_batch spend 0.00044221500866115093 time
policy_value spend 0.2477376079914393 time
train_step spend 0.7177076759980991 time
policy_value spend 0.24693843300337903 time
train_step spend 0.715339825997944 time
policy_value spend 0.2492041799996514 time
train_step spend 0.7647174019948579 time
policy_value spend 0.26029297400964424 time
train_step spend 0.7281885380070889 time
policy_value spend 0.2609089780016802 time
kl:0.10639,lr_multiplier:0.088,loss:2.705918550491333,entropy:3.2168564796447754,explained_var_old:0.998231769,explained_var_new:0.999452472
output spend 0.0012273400061530992 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.008343123001395725 time
recovery_state_mcts_prob spend 0.865966187993763 time
state_batch spend 0.011156726002809592 time
mcts_probs_batch spend 0.031068099007825367 time
winner_batch spend 0.0006599969929084182 time
policy_value spend 0.29477807400689926 time
train_step spend 0.7688751289970241 time
policy_value spend 0.25568841499625705 time
train_step spend 0.7346407110017026 time
policy_value spend 0.2565218560048379 time
train_step spend 0.7358302659995388 time
policy_value spend 0.2608095680043334 time
train_step spend 0.7527113599935547 time
policy_value spend 0.2678651700116461 time
kl:0.09535,lr_multiplier:0.088,loss:2.757272720336914,entropy:3.271507740020752,explained_var_old:0.972872555,explained_var_new:0.984377921
output spend 0.00170615800016094 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007315801994991489 time
recovery_state_mcts_prob spend 0.6353631130041322 time
state_batch spend 0.009248110000044107 time
mcts_probs_batch spend 0.009361183998407796 time
winner_batch spend 0.0004403729981277138 time
policy_value spend 0.25159282599634025 time
train_step spend 0.7148002149915555 time
policy_value spend 0.24322952500369865 time
train_step spend 0.7078741620061919 time
policy_value spend 0.24336196099466179 time
train_step spend 0.7091114300128538 time
policy_value spend 0.2431339069880778 time
kl:0.08754,lr_multiplier:0.088,loss:2.838726043701172,entropy:3.368377447128296,explained_var_old:0.988400280,explained_var_new:0.994289637
output spend 0.00024423400464002043 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004645385997719131 time
recovery_state_mcts_prob spend 0.2938403010048205 time
state_batch spend 0.004310478994739242 time
mcts_probs_batch spend 0.0068128130078548566 time
winner_batch spend 0.00027184099599253386 time
policy_value spend 0.2438218390016118 time
train_step spend 0.6905877859971952 time
policy_value spend 0.22287709600641392 time
train_step spend 0.6509860389924143 time
policy_value spend 0.2817964600108098 time
train_step spend 0.7464903579966631 time
policy_value spend 0.24208546899899375 time
train_step spend 0.709046511008637 time
policy_value spend 0.24119824598892592 time
kl:0.10856,lr_multiplier:0.088,loss:2.783716917037964,entropy:3.2969517707824707,explained_var_old:0.994774461,explained_var_new:0.995154560
output spend 0.00017067800217773765 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004117074000532739 time
recovery_state_mcts_prob spend 0.3086751910013845 time
state_batch spend 0.004092816001502797 time
mcts_probs_batch spend 0.007900792988948524 time
winner_batch spend 0.0002972410002257675 time
policy_value spend 0.24923786699946504 time
train_step spend 0.7165711840061704 time
policy_value spend 0.26644125499296933 time
train_step spend 0.7520914800115861 time
policy_value spend 0.29629969799134415 time
train_step spend 0.7183747560047777 time
policy_value spend 0.24159125199366827 time
train_step spend 0.708795161001035 time
policy_value spend 0.23951609499636106 time
train_step spend 0.7033496240037493 time
policy_value spend 0.23998028799542226 time
kl:0.09490,lr_multiplier:0.088,loss:2.7263596057891846,entropy:3.2363665103912354,explained_var_old:0.996303916,explained_var_new:0.989169478
output spend 0.00016716499521862715 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005945807992247865 time
recovery_state_mcts_prob spend 0.3073226130072726 time
state_batch spend 0.004295616992749274 time
mcts_probs_batch spend 0.013799394000670873 time
winner_batch spend 0.0002757150068646297 time
policy_value spend 0.24469650399987586 time
train_step spend 0.7075668860052247 time
policy_value spend 0.24264463300642092 time
train_step spend 0.7115221090061823 time
policy_value spend 0.24093803499999922 time
train_step spend 0.7082427910063416 time
policy_value spend 0.2440240440046182 time
train_step spend 0.7574247870070394 time
policy_value spend 0.24073954399500508 time
kl:0.09405,lr_multiplier:0.088,loss:2.692018985748291,entropy:3.183307647705078,explained_var_old:0.983482897,explained_var_new:0.993737161
output spend 0.00026804399385582656 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0052696710044983774 time
recovery_state_mcts_prob spend 0.32213793399569113 time
state_batch spend 0.004202750002150424 time
mcts_probs_batch spend 0.007986944998265244 time
winner_batch spend 0.0003161930071655661 time
policy_value spend 0.2434722539910581 time
train_step spend 0.7088218500139192 time
policy_value spend 0.2419499549869215 time
train_step spend 0.7092668859986588 time
policy_value spend 0.24213747199974023 time
train_step spend 0.7070301680068951 time
policy_value spend 0.24083763000089675 time
train_step spend 0.7078892499994254 time
policy_value spend 0.24040559100103565 time
kl:0.09272,lr_multiplier:0.088,loss:2.7638039588928223,entropy:3.2592804431915283,explained_var_old:0.983716130,explained_var_new:0.989770353
output spend 0.00024869399203453213 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004432653993717395 time
recovery_state_mcts_prob spend 0.28906243400706444 time
state_batch spend 0.004380902988486923 time
mcts_probs_batch spend 0.006992239010287449 time
winner_batch spend 0.0002882269909605384 time
policy_value spend 0.24188387500180397 time
train_step spend 0.7092583139892668 time
policy_value spend 0.24204816900601145 time
train_step spend 0.7088173459924292 time
policy_value spend 0.24281855201115832 time
train_step spend 0.7086688379931729 time
policy_value spend 0.24158655900100712 time
train_step spend 0.708607855005539 time
policy_value spend 0.24237395499949344 time
train_step spend 0.7079165820032358 time
policy_value spend 0.27291483599401545 time
kl:0.09692,lr_multiplier:0.088,loss:2.789663314819336,entropy:3.2723495960235596,explained_var_old:0.980102956,explained_var_new:0.973582923
output spend 0.0003082340117543936 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004019964995677583 time
recovery_state_mcts_prob spend 0.3425245329999598 time
state_batch spend 0.0020576060051098466 time
mcts_probs_batch spend 0.007040743992547505 time
winner_batch spend 0.0002758530026767403 time
policy_value spend 0.26006035300088115 time
train_step spend 0.7275686960056191 time
policy_value spend 0.24283258699870203 time
train_step spend 0.7172795619990211 time
policy_value spend 0.24082037000334822 time
train_step spend 0.7072330109949689 time
policy_value spend 0.24134608700114768 time
train_step spend 0.7080645819951314 time
policy_value spend 0.2406891050050035 time
kl:0.11196,lr_multiplier:0.088,loss:2.717161178588867,entropy:3.22104549407959,explained_var_old:0.987168312,explained_var_new:0.996337771
output spend 0.0002122169971698895 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004554855011519976 time
recovery_state_mcts_prob spend 0.292523527998128 time
state_batch spend 0.004733750989544205 time
mcts_probs_batch spend 0.006601787012186833 time
winner_batch spend 0.00028112299332860857 time
policy_value spend 0.25050959999498446 time
train_step spend 0.7095033129880903 time
policy_value spend 0.24151719600195065 time
train_step spend 0.7096449259988731 time
policy_value spend 0.24293154598854017 time
train_step spend 0.7080383100110339 time
policy_value spend 0.24212728098791558 time
train_step spend 0.7083193430007668 time
policy_value spend 0.24076868599513546 time
kl:0.09073,lr_multiplier:0.088,loss:2.7561757564544678,entropy:3.260467052459717,explained_var_old:0.988883972,explained_var_new:0.993437648
output spend 0.0002159529976779595 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004090632006409578 time
recovery_state_mcts_prob spend 0.30021757699432783 time
state_batch spend 0.005368541009374894 time
mcts_probs_batch spend 0.01668736999272369 time
winner_batch spend 0.0008102110004983842 time
policy_value spend 0.24551478499779478 time
train_step spend 0.7092551399982767 time
policy_value spend 0.33301971000037156 time
train_step spend 0.7177482240076642 time
policy_value spend 0.2528078059986001 time
train_step spend 0.7120753930066712 time
policy_value spend 0.2423331049940316 time
train_step spend 0.710724765987834 time
policy_value spend 0.2429394800128648 time
kl:0.09415,lr_multiplier:0.088,loss:2.7016994953155518,entropy:3.2003836631774902,explained_var_old:0.993555307,explained_var_new:0.991002440
output spend 0.00016838801093399525 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004857224994339049 time
recovery_state_mcts_prob spend 0.3053097060037544 time
state_batch spend 0.004406836989801377 time
mcts_probs_batch spend 0.007175823004217818 time
winner_batch spend 0.0002716669987421483 time
policy_value spend 0.24121590799768455 time
train_step spend 0.708509521005908 time
policy_value spend 0.24752875900594518 time
train_step spend 0.707641382003203 time
policy_value spend 0.24297004599065986 time
train_step spend 0.7106370059918845 time
policy_value spend 0.25592325800971594 time
train_step spend 0.7102172940067248 time
policy_value spend 0.2400320619926788 time
train_step spend 0.707557967005414 time
policy_value spend 0.24638399700052105 time
kl:0.08972,lr_multiplier:0.088,loss:2.718432903289795,entropy:3.2090048789978027,explained_var_old:0.982252002,explained_var_new:0.990839660
output spend 0.0007498560007661581 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005906815989874303 time
recovery_state_mcts_prob spend 0.2914448110095691 time
state_batch spend 0.0038155270012794062 time
mcts_probs_batch spend 0.015531863988144323 time
winner_batch spend 0.00028422400646377355 time
policy_value spend 0.24542048599687405 time
train_step spend 0.71170271000301 time
policy_value spend 0.24181462099659257 time
train_step spend 0.7115194810030516 time
policy_value spend 0.24245098399114795 time
train_step spend 0.7076787799887825 time
policy_value spend 0.2402664410037687 time
train_step spend 0.7087926999956835 time
policy_value spend 0.2413946599990595 time
train_step spend 0.707689137008856 time
policy_value spend 0.24046042498957831 time
kl:0.09483,lr_multiplier:0.088,loss:2.72725248336792,entropy:3.2120108604431152,explained_var_old:0.987609506,explained_var_new:0.990148127
output spend 0.00021705898689106107 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004614318007952534 time
recovery_state_mcts_prob spend 0.3836412509990623 time
state_batch spend 0.003688999990117736 time
mcts_probs_batch spend 0.007082556010573171 time
winner_batch spend 0.0002636909921420738 time
policy_value spend 0.24157320099766366 time
train_step spend 0.7078316699917195 time
policy_value spend 0.24277985699882265 time
train_step spend 0.7091198449925287 time
policy_value spend 0.24084249100997113 time
train_step spend 0.7079811750008957 time
policy_value spend 0.2409404270001687 time
train_step spend 0.7080314560007537 time
policy_value spend 0.24207544499950018 time
kl:0.09452,lr_multiplier:0.088,loss:2.7843947410583496,entropy:3.2815842628479004,explained_var_old:0.995448351,explained_var_new:0.996131003
output spend 0.00027323899848852307 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004156890005106106 time
recovery_state_mcts_prob spend 0.29427804399165325 time
state_batch spend 0.0022379040019586682 time
mcts_probs_batch spend 0.018509770001401193 time
winner_batch spend 0.0002909110044129193 time
policy_value spend 0.2424201669928152 time
train_step spend 0.7074645349930506 time
policy_value spend 0.2742893870017724 time
train_step spend 0.7131242340110475 time
policy_value spend 0.2418688729958376 time
train_step spend 0.7076560559944483 time
policy_value spend 0.27171985400491394 time
train_step spend 0.7145165759866359 time
policy_value spend 0.24074451600608882 time
kl:0.08560,lr_multiplier:0.088,loss:2.7463786602020264,entropy:3.2346136569976807,explained_var_old:0.990070939,explained_var_new:0.989236176
output spend 0.00019178799993824214 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004211047998978756 time
recovery_state_mcts_prob spend 0.32802278899180237 time
state_batch spend 0.004527031996985897 time
mcts_probs_batch spend 0.013249441006337292 time
winner_batch spend 0.0003946590004488826 time
policy_value spend 0.24508610200427938 time
train_step spend 0.7076129569904879 time
policy_value spend 0.2422192710073432 time
train_step spend 0.708529190000263 time
policy_value spend 0.24165783199714497 time
train_step spend 0.7075285030005034 time
policy_value spend 0.24088219201075844 time
train_step spend 0.7067233689886052 time
policy_value spend 0.24101083700952586 time
kl:0.09288,lr_multiplier:0.088,loss:2.770017623901367,entropy:3.2693209648132324,explained_var_old:0.988746464,explained_var_new:0.992485404
output spend 0.00017623600433580577 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007577392010716721 time
recovery_state_mcts_prob spend 0.3099418569909176 time
state_batch spend 0.0020942219998687506 time
mcts_probs_batch spend 0.006775215995730832 time
winner_batch spend 0.00031089200638234615 time
policy_value spend 0.24234862500452437 time
train_step spend 0.7083820629923139 time
policy_value spend 0.24071415100479499 time
train_step spend 0.7075815390126081 time
policy_value spend 0.24214685399783775 time
train_step spend 0.7089202699862653 time
policy_value spend 0.2406044610106619 time
train_step spend 0.7070788779965369 time
policy_value spend 0.24059049499919638 time
kl:0.08220,lr_multiplier:0.088,loss:2.763638496398926,entropy:3.2612857818603516,explained_var_old:0.987652779,explained_var_new:0.991070449
output spend 0.00017506099538877606 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004585896997014061 time
recovery_state_mcts_prob spend 0.3047707130026538 time
state_batch spend 0.004458057999727316 time
mcts_probs_batch spend 0.006575485997018404 time
winner_batch spend 0.0002809750003507361 time
policy_value spend 0.25806926299992483 time
train_step spend 0.7444791999878362 time
policy_value spend 0.24201696400996298 time
train_step spend 0.711109698007931 time
policy_value spend 0.24079823298961855 time
train_step spend 0.7125980389973847 time
policy_value spend 0.24377934999938589 time
train_step spend 0.7085371199937072 time
policy_value spend 0.2415572330064606 time
kl:0.10485,lr_multiplier:0.088,loss:2.8131303787231445,entropy:3.320143699645996,explained_var_old:0.973601520,explained_var_new:0.987063766
output spend 0.00021684300736524165 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006704295010422356 time
recovery_state_mcts_prob spend 0.3599324099923251 time
state_batch spend 0.00607807699998375 time
mcts_probs_batch spend 0.0215306949976366 time
winner_batch spend 0.0004344949993537739 time
policy_value spend 0.2875577410013648 time
train_step spend 0.7187518900027499 time
policy_value spend 0.25681239798723254 time
train_step spend 0.7087654039933113 time
policy_value spend 0.2500310200121021 time
train_step spend 0.7082570760103408 time
policy_value spend 0.24349703099869657 time
kl:0.08565,lr_multiplier:0.088,loss:2.769015312194824,entropy:3.2666399478912354,explained_var_old:0.994502902,explained_var_new:0.947945178
output spend 0.0002453070046612993 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00416045100428164 time
recovery_state_mcts_prob spend 0.2884478509949986 time
state_batch spend 0.002221423012088053 time
mcts_probs_batch spend 0.007296451993170194 time
winner_batch spend 0.0002687640080694109 time
policy_value spend 0.2423401629930595 time
train_step spend 0.717409327000496 time
policy_value spend 0.24101442900428083 time
train_step spend 0.7077490869996836 time
policy_value spend 0.2402819380076835 time
train_step spend 0.7097828510013642 time
policy_value spend 0.24086955100938212 time
train_step spend 0.7078181700053392 time
policy_value spend 0.24311358999693766 time
kl:0.08958,lr_multiplier:0.088,loss:2.7699167728424072,entropy:3.2768125534057617,explained_var_old:0.939527333,explained_var_new:0.990384102
output spend 0.00021237200417090207 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005502984000486322 time
recovery_state_mcts_prob spend 0.4399293070018757 time
state_batch spend 0.0037469349917955697 time
mcts_probs_batch spend 0.007493269004044123 time
winner_batch spend 0.0003801700077019632 time
policy_value spend 0.24804197099001613 time
train_step spend 0.7082700859900797 time
policy_value spend 0.24176510400138795 time
train_step spend 0.7082251960091526 time
policy_value spend 0.24076368799433112 time
train_step spend 0.7074956029973691 time
policy_value spend 0.24038425300386734 time
train_step spend 0.7079763829970034 time
policy_value spend 0.24078102900239173 time
kl:0.09533,lr_multiplier:0.088,loss:2.774738073348999,entropy:3.276677370071411,explained_var_old:0.992669642,explained_var_new:0.992962956
output spend 0.0003248919965699315 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004409140005009249 time
recovery_state_mcts_prob spend 0.39212607000081334 time
state_batch spend 0.005016961004002951 time
mcts_probs_batch spend 0.009379864000948146 time
winner_batch spend 0.00034353299997746944 time
policy_value spend 0.24409499499597587 time
train_step spend 0.7092786569992313 time
policy_value spend 0.24212516799161676 time
train_step spend 0.7086543680052273 time
policy_value spend 0.24131011599092744 time
train_step spend 0.7084675610094564 time
policy_value spend 0.2433730919874506 time
train_step spend 0.7075686729949666 time
policy_value spend 0.24154875800013542 time
kl:0.08140,lr_multiplier:0.088,loss:2.7228639125823975,entropy:3.221290111541748,explained_var_old:0.992699802,explained_var_new:0.994459927
output spend 0.00019043800421059132 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0045730760029982775 time
recovery_state_mcts_prob spend 0.3191820350039052 time
state_batch spend 0.002079266996588558 time
mcts_probs_batch spend 0.019803856004728004 time
winner_batch spend 0.0003113860002486035 time
policy_value spend 0.2654539700015448 time
train_step spend 0.7197475629945984 time
policy_value spend 0.24645740100822877 time
train_step spend 0.7161553339974489 time
policy_value spend 0.27099931800330523 time
train_step spend 0.7181409959885059 time
policy_value spend 0.2432159170130035 time
train_step spend 0.7146556810039328 time
policy_value spend 0.2589214829931734 time
kl:0.10789,lr_multiplier:0.088,loss:2.766475200653076,entropy:3.282866954803467,explained_var_old:0.990433276,explained_var_new:0.993780077
output spend 0.0003668910067062825 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.008313205005833879 time
recovery_state_mcts_prob spend 0.36381710998830386 time
state_batch spend 0.006710418005241081 time
mcts_probs_batch spend 0.018093197999405675 time
winner_batch spend 0.0003521629987517372 time
policy_value spend 0.24944169400259852 time
train_step spend 0.7199851869954728 time
policy_value spend 0.24313679100305308 time
train_step spend 0.7145975650055334 time
policy_value spend 0.2432201469928259 time
train_step spend 0.7130287360050716 time
policy_value spend 0.24297671599197201 time
train_step spend 0.7140735110006062 time
policy_value spend 0.24316404899582267 time
kl:0.10425,lr_multiplier:0.088,loss:2.8005642890930176,entropy:3.322312355041504,explained_var_old:0.987523913,explained_var_new:0.992683291
output spend 0.00017813000886235386 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004955274998792447 time
recovery_state_mcts_prob spend 0.2957134530006442 time
state_batch spend 0.004053568001836538 time
mcts_probs_batch spend 0.007846495995181613 time
winner_batch spend 0.0003152530116494745 time
policy_value spend 0.2467564699909417 time
train_step spend 0.7169610840064706 time
policy_value spend 0.2451661899976898 time
train_step spend 0.7133839960006298 time
policy_value spend 0.24184906599111855 time
train_step spend 0.7110530950012617 time
policy_value spend 0.2421964940003818 time
train_step spend 0.7113166299968725 time
policy_value spend 0.24510521499905735 time
kl:0.10116,lr_multiplier:0.088,loss:2.809925079345703,entropy:3.309414863586426,explained_var_old:0.988172233,explained_var_new:0.982726038
output spend 0.00018485100008547306 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006389771006070077 time
recovery_state_mcts_prob spend 0.5099505450052675 time
state_batch spend 0.004218276997562498 time
mcts_probs_batch spend 0.0067958049912704155 time
winner_batch spend 0.0002721130003919825 time
policy_value spend 0.24363181200169493 time
train_step spend 0.7139130039868178 time
policy_value spend 0.2418177880026633 time
train_step spend 0.710223802991095 time
policy_value spend 0.24234751700714696 time
train_step spend 0.7104851600015536 time
policy_value spend 0.24133867700584233 time
train_step spend 0.7109843290090794 time
policy_value spend 0.24310754898760933 time
kl:0.08292,lr_multiplier:0.088,loss:2.731684446334839,entropy:3.224404811859131,explained_var_old:0.985929489,explained_var_new:0.993345201
output spend 0.0002441589895170182 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00463103900256101 time
recovery_state_mcts_prob spend 0.32319548100349493 time
state_batch spend 0.003985496994573623 time
mcts_probs_batch spend 0.007323509009438567 time
winner_batch spend 0.0003468669892754406 time
policy_value spend 0.2438168049993692 time
train_step spend 0.7102025119966129 time
policy_value spend 0.27137633800157346 time
train_step spend 0.7103125590074342 time
policy_value spend 0.2516395769926021 time
train_step spend 0.7400405670050532 time
policy_value spend 0.27856799100118224 time
train_step spend 0.7263793669990264 time
policy_value spend 0.2429765389970271 time
kl:0.09085,lr_multiplier:0.088,loss:2.7074286937713623,entropy:3.1743850708007812,explained_var_old:0.985711217,explained_var_new:0.988017142
output spend 0.00021003499568905681 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004270599005394615 time
recovery_state_mcts_prob spend 0.34888185300223995 time
state_batch spend 0.00423289299942553 time
mcts_probs_batch spend 0.016384443995775655 time
winner_batch spend 0.00030194300052244216 time
policy_value spend 0.28986376500688493 time
train_step spend 0.7279469439963577 time
policy_value spend 0.24126566399354488 time
train_step spend 0.7109485069959192 time
policy_value spend 0.26702393499726895 time
train_step spend 0.7209247610007878 time
policy_value spend 0.24151166899537202 time
train_step spend 0.7074675949988887 time
policy_value spend 0.2661473019979894 time
kl:0.08553,lr_multiplier:0.088,loss:2.7769582271575928,entropy:3.2850494384765625,explained_var_old:0.987126648,explained_var_new:0.988273263
output spend 0.0005592469969997182 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004286894996766932 time
recovery_state_mcts_prob spend 0.30273382099403534 time
state_batch spend 0.003983665999840014 time
mcts_probs_batch spend 0.007300820012460463 time
winner_batch spend 0.00027919399144593626 time
policy_value spend 0.2417594169965014 time
train_step spend 0.7055049430055078 time
policy_value spend 0.24366541700146627 time
train_step spend 0.7086408579925774 time
policy_value spend 0.2401132749946555 time
train_step spend 0.7058155389968306 time
policy_value spend 0.24042940700019244 time
train_step spend 0.7074949369998649 time
policy_value spend 0.23998223400849383 time
kl:0.08046,lr_multiplier:0.088,loss:2.844869375228882,entropy:3.367563247680664,explained_var_old:0.991212904,explained_var_new:0.997648597
output spend 0.00017369700071867555 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005646525998599827 time
recovery_state_mcts_prob spend 0.2988471650023712 time
state_batch spend 0.0019777880079345778 time
mcts_probs_batch spend 0.007308494998142123 time
winner_batch spend 0.0002861219982150942 time
policy_value spend 0.2412361710012192 time
train_step spend 0.7080083769978955 time
policy_value spend 0.2414038519927999 time
train_step spend 0.7089009580085985 time
policy_value spend 0.23367036299896426 time
train_step spend 0.6493868039979134 time
policy_value spend 0.22094332400592975 time
train_step spend 0.6490406329976395 time
policy_value spend 0.23641477301134728 time
kl:0.08135,lr_multiplier:0.088,loss:2.7641823291778564,entropy:3.2642531394958496,explained_var_old:0.989568353,explained_var_new:0.995171249
output spend 0.00017821299843490124 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004193390996078961 time
recovery_state_mcts_prob spend 0.4243758560041897 time
state_batch spend 0.013782998998067342 time
mcts_probs_batch spend 0.020084342002519406 time
winner_batch spend 0.0006407229957403615 time
policy_value spend 0.24731822099420242 time
train_step spend 0.7084437330049695 time
policy_value spend 0.24116895999759436 time
train_step spend 0.7093122329970356 time
policy_value spend 0.2481085890030954 time
train_step spend 0.7102170750004007 time
policy_value spend 0.24292404600419104 time
train_step spend 0.7087504689989146 time
policy_value spend 0.2441717510082526 time
kl:0.08675,lr_multiplier:0.088,loss:2.7491040229797363,entropy:3.2447543144226074,explained_var_old:0.992459714,explained_var_new:0.991078913
output spend 0.00032962100522127 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00559251599770505 time
recovery_state_mcts_prob spend 0.3127982090081787 time
state_batch spend 0.0036781559902010486 time
mcts_probs_batch spend 0.007942103009554558 time
winner_batch spend 0.00030518099083565176 time
policy_value spend 0.24288939200050663 time
train_step spend 0.7084260910050943 time
policy_value spend 0.24635850499907974 time
train_step spend 0.7183118620014284 time
policy_value spend 0.24225822600419633 time
train_step spend 0.7104631999973208 time
policy_value spend 0.24416772500262596 time
train_step spend 0.7259384710050654 time
policy_value spend 0.2419285630021477 time
kl:0.09993,lr_multiplier:0.088,loss:2.7681455612182617,entropy:3.2591753005981445,explained_var_old:0.984586895,explained_var_new:0.993150055
output spend 0.00017745599325280637 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004813002989976667 time
recovery_state_mcts_prob spend 0.3393044280091999 time
state_batch spend 0.00939834798919037 time
mcts_probs_batch spend 0.026064714009407908 time
winner_batch spend 0.0003294549969723448 time
policy_value spend 0.24651302699930966 time
train_step spend 0.7089097889984259 time
policy_value spend 0.24173866400087718 time
train_step spend 0.7085559139959514 time
policy_value spend 0.24372928400407545 time
train_step spend 0.7140038960060338 time
policy_value spend 0.24096938699949533 time
train_step spend 0.7083925770130008 time
policy_value spend 0.24085695098619908 time
kl:0.09226,lr_multiplier:0.088,loss:2.731576919555664,entropy:3.2346572875976562,explained_var_old:0.988590181,explained_var_new:0.987055779
output spend 0.00017211100202985108 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.029932340010418557 time
recovery_state_mcts_prob spend 0.4125854789890582 time
state_batch spend 0.0037848860083613545 time
mcts_probs_batch spend 0.013623748993268237 time
winner_batch spend 0.0002700890036066994 time
policy_value spend 0.24644293400342576 time
train_step spend 0.7123493390099611 time
policy_value spend 0.2402525959914783 time
train_step spend 0.7084753979870584 time
policy_value spend 0.24140264101151843 time
train_step spend 0.710333499009721 time
policy_value spend 0.24059271399164572 time
train_step spend 0.7072690130007686 time
policy_value spend 0.2412327960046241 time
kl:0.09410,lr_multiplier:0.088,loss:2.735517978668213,entropy:3.253157377243042,explained_var_old:0.979095340,explained_var_new:0.991825283
output spend 0.00018543600162956864 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006746457002009265 time
recovery_state_mcts_prob spend 0.33293412800412625 time
state_batch spend 0.0036913209914928302 time
mcts_probs_batch spend 0.007789778013830073 time
winner_batch spend 0.0003141939960187301 time
policy_value spend 0.24264301199582405 time
train_step spend 0.7086561679898296 time
policy_value spend 0.24049899401143193 time
train_step spend 0.7080347000010079 time
policy_value spend 0.24134480999782681 time
train_step spend 0.7081863909988897 time
policy_value spend 0.24381758199888282 time
train_step spend 0.7093669089954346 time
policy_value spend 0.2414227219996974 time
kl:0.09004,lr_multiplier:0.088,loss:2.655477285385132,entropy:3.1329503059387207,explained_var_old:0.993455350,explained_var_new:0.995707631
output spend 0.00017312300042249262 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.006924275992787443 time
recovery_state_mcts_prob spend 0.3704962769988924 time
state_batch spend 0.004531434009550139 time
mcts_probs_batch spend 0.008293032995425165 time
winner_batch spend 0.00030017799872439355 time
policy_value spend 0.24276499700499699 time
train_step spend 0.7077593799913302 time
policy_value spend 0.24176313600037247 time
train_step spend 0.7074889319919748 time
policy_value spend 0.25708053100970574 time
train_step spend 0.7089469130005455 time
policy_value spend 0.24157986900536343 time
train_step spend 0.7288362389954273 time
policy_value spend 0.2765346210071584 time
train_step spend 0.7251239220058778 time
policy_value spend 0.24593173299217597 time
kl:0.09882,lr_multiplier:0.088,loss:2.7088708877563477,entropy:3.1771955490112305,explained_var_old:0.986063182,explained_var_new:0.986480534
output spend 0.0003180439962306991 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.01122903601208236 time
recovery_state_mcts_prob spend 0.39976707099413034 time
state_batch spend 0.005003020996809937 time
mcts_probs_batch spend 0.02072739500727039 time
winner_batch spend 0.00034965999657288194 time
policy_value spend 0.27232051799364854 time
train_step spend 0.7468784700031392 time
policy_value spend 0.2469830699992599 time
train_step spend 0.7195430660067359 time
policy_value spend 0.2630222779989708 time
train_step spend 0.721136487001786 time
policy_value spend 0.24352221199660562 time
train_step spend 0.7154300429974683 time
policy_value spend 0.26096903999859933 time
kl:0.08443,lr_multiplier:0.088,loss:2.7359750270843506,entropy:3.2453818321228027,explained_var_old:0.993155420,explained_var_new:0.986119032
output spend 0.00036872200143989176 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0060893400077475235 time
recovery_state_mcts_prob spend 0.33271539999987 time
state_batch spend 0.004676257987739518 time
mcts_probs_batch spend 0.010540635004872456 time
winner_batch spend 0.00040893000550568104 time
policy_value spend 0.24611574999289587 time
train_step spend 0.7193130209925584 time
policy_value spend 0.24424938000447582 time
train_step spend 0.7206296079966705 time
policy_value spend 0.2478698880004231 time
train_step spend 0.714933500988991 time
policy_value spend 0.24427703600667883 time
train_step spend 0.7168206040078076 time
policy_value spend 0.24188570099067874 time
kl:0.08009,lr_multiplier:0.088,loss:2.738463878631592,entropy:3.2446112632751465,explained_var_old:0.978156865,explained_var_new:0.988157392
output spend 0.00017883301188703626 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0062654599896632135 time
recovery_state_mcts_prob spend 0.3605682750057895 time
state_batch spend 0.002423113997792825 time
mcts_probs_batch spend 0.007752364996122196 time
winner_batch spend 0.0003121410118183121 time
policy_value spend 0.2446309879887849 time
train_step spend 0.7093418559961719 time
policy_value spend 0.24269716801063623 time
train_step spend 0.709127645008266 time
policy_value spend 0.24222505299258046 time
train_step spend 0.7095186700025806 time
policy_value spend 0.24408605899952818 time
train_step spend 0.7084111029980704 time
policy_value spend 0.2420896499970695 time
kl:0.08307,lr_multiplier:0.088,loss:2.756404399871826,entropy:3.252384662628174,explained_var_old:0.985132396,explained_var_new:0.993803382
output spend 0.00020698200387414545 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004332017997512594 time
recovery_state_mcts_prob spend 0.4377828450087691 time
state_batch spend 0.002078912002616562 time
mcts_probs_batch spend 0.0075034740002593026 time
winner_batch spend 0.000578135994146578 time
policy_value spend 0.24908223100646865 time
train_step spend 0.7105025430064416 time
policy_value spend 0.23817239399068058 time
train_step spend 0.6974057369952789 time
policy_value spend 0.2375205400021514 time
train_step spend 0.6975919210090069 time
policy_value spend 0.2390177999914158 time
train_step spend 0.6998966760002077 time
policy_value spend 0.236988938995637 time
kl:0.09209,lr_multiplier:0.088,loss:2.7454779148101807,entropy:3.230593204498291,explained_var_old:0.993586183,explained_var_new:0.993779063
output spend 0.00018319000082556158 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007908712010248564 time
recovery_state_mcts_prob spend 0.4388414259883575 time
state_batch spend 0.003672303006169386 time
mcts_probs_batch spend 0.013303876999998465 time
winner_batch spend 0.00029812799766659737 time
policy_value spend 0.24288278599851765 time
train_step spend 0.7003169499948854 time
policy_value spend 0.23724538100941572 time
train_step spend 0.7081525789981242 time
policy_value spend 0.24150309099059086 time
train_step spend 0.7089769029989839 time
policy_value spend 0.24439347599400207 time
train_step spend 0.7125688749947585 time
policy_value spend 0.24130373599473387 time
train_step spend 0.6992808770010015 time
policy_value spend 0.24412038999435026 time
kl:0.10155,lr_multiplier:0.088,loss:2.7527379989624023,entropy:3.2437100410461426,explained_var_old:0.993642926,explained_var_new:0.994489729
output spend 0.00018261600052937865 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.008557526001823135 time
recovery_state_mcts_prob spend 0.43017826399591286 time
state_batch spend 0.0046593709994340315 time
mcts_probs_batch spend 0.00708678099908866 time
winner_batch spend 0.00027577701257541776 time
policy_value spend 0.23891404799360316 time
train_step spend 0.6986920519993873 time
policy_value spend 0.24130060800234787 time
train_step spend 0.698324816999957 time
policy_value spend 0.23864397600118537 time
train_step spend 0.7037865719903493 time
policy_value spend 0.24829754800884984 time
train_step spend 0.699874149999232 time
policy_value spend 0.2463562969933264 time
kl:0.09034,lr_multiplier:0.088,loss:2.790219783782959,entropy:3.273139476776123,explained_var_old:0.992724240,explained_var_new:0.993993461
output spend 0.00018289199215359986 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.0046158699988154694 time
recovery_state_mcts_prob spend 0.34923098000581376 time
state_batch spend 0.003895183006534353 time
mcts_probs_batch spend 0.010519598989048973 time
winner_batch spend 0.0003845550090773031 time
policy_value spend 0.2938720189995365 time
train_step spend 0.7425669750082307 time
policy_value spend 0.2471109809994232 time
train_step spend 0.7159232870035339 time
policy_value spend 0.24205358199833427 time
train_step spend 0.7138314000039827 time
policy_value spend 0.24292618499021046 time
train_step spend 0.7063499539945042 time
policy_value spend 0.2419923249981366 time
train_step spend 0.7060625010053627 time
policy_value spend 0.24013215900049545 time
kl:0.09588,lr_multiplier:0.088,loss:2.6966426372528076,entropy:3.1731202602386475,explained_var_old:0.994293094,explained_var_new:0.995677173
output spend 0.00028911900881212205 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.004456266004126519 time
recovery_state_mcts_prob spend 0.3413554440048756 time
state_batch spend 0.004634715995052829 time
mcts_probs_batch spend 0.008457100004306994 time
winner_batch spend 0.0003542359918355942 time
policy_value spend 0.24644276101025753 time
train_step spend 0.714085225990857 time
policy_value spend 0.24596485801157542 time
train_step spend 0.7149772759876214 time
policy_value spend 0.24591533200873528 time
train_step spend 0.7168541029968765 time
policy_value spend 0.24241087700647768 time
train_step spend 0.7126313240005402 time
policy_value spend 0.23808261500380468 time
kl:0.09346,lr_multiplier:0.088,loss:2.757107973098755,entropy:3.244469165802002,explained_var_old:0.994292378,explained_var_new:0.994309843
output spend 0.00017710699466988444 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005659604998072609 time
recovery_state_mcts_prob spend 0.5065971379954135 time
state_batch spend 0.002633937998325564 time
mcts_probs_batch spend 0.006342534994473681 time
winner_batch spend 0.0002751870051724836 time
policy_value spend 0.2393366220057942 time
train_step spend 0.6975469379976857 time
policy_value spend 0.23850799800129607 time
train_step spend 0.6973225440015085 time
policy_value spend 0.23791333900589962 time
train_step spend 0.7137251269887201 time
policy_value spend 0.24110939900856465 time
train_step spend 0.7100709469959838 time
policy_value spend 0.24138930499611888 time
kl:0.08996,lr_multiplier:0.088,loss:2.6733922958374023,entropy:3.1715023517608643,explained_var_old:0.995002151,explained_var_new:0.998544455
output spend 0.00019062700448557734 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007256270007928833 time
recovery_state_mcts_prob spend 0.3491702280007303 time
state_batch spend 0.002232883998658508 time
mcts_probs_batch spend 0.007386544006294571 time
winner_batch spend 0.0002830039884429425 time
policy_value spend 0.32997995799814817 time
train_step spend 0.833553586009657 time
policy_value spend 0.25905506999697536 time
train_step spend 0.720359320010175 time
policy_value spend 0.24263489799341187 time
train_step spend 0.7058838770026341 time
policy_value spend 0.23983310100447852 time
train_step spend 0.7005626730096992 time
policy_value spend 0.23869124399789143 time
kl:0.08434,lr_multiplier:0.088,loss:2.766491651535034,entropy:3.273280143737793,explained_var_old:0.993794382,explained_var_new:0.993980765
output spend 0.00018890299543272704 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005941508003161289 time
recovery_state_mcts_prob spend 0.5272062699950766 time
state_batch spend 0.004454642999917269 time
mcts_probs_batch spend 0.018038145994069055 time
winner_batch spend 0.0003067540092160925 time
policy_value spend 0.24347467999905348 time
train_step spend 0.702282867001486 time
policy_value spend 0.24062948000209872 time
train_step spend 0.7083723909890978 time
policy_value spend 0.2414769180031726 time
train_step spend 0.7109706449991791 time
policy_value spend 0.24188311799662188 time
train_step spend 0.7094639829883818 time
policy_value spend 0.2411139070027275 time
kl:0.09142,lr_multiplier:0.088,loss:2.7066307067871094,entropy:3.202399492263794,explained_var_old:0.992814362,explained_var_new:0.999772787
output spend 0.00018818999524228275 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00623376299336087 time
recovery_state_mcts_prob spend 0.3917488669976592 time
state_batch spend 0.004039521008962765 time
mcts_probs_batch spend 0.007518290003645234 time
winner_batch spend 0.0003372679930180311 time
policy_value spend 0.24204833300609607 time
train_step spend 0.704221840001992 time
policy_value spend 0.24266904099204112 time
train_step spend 0.7030356049945112 time
policy_value spend 0.23890985100297257 time
train_step spend 0.7041559089993825 time
policy_value spend 0.2479038149904227 time
train_step spend 0.7029690799972741 time
policy_value spend 0.24062879300618079 time
train_step spend 0.706473748999997 time
policy_value spend 0.24486141400120687 time
kl:0.09858,lr_multiplier:0.088,loss:2.802095651626587,entropy:3.2812981605529785,explained_var_old:0.982780159,explained_var_new:0.987776339
output spend 0.0002598879946162924 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.00474649500392843 time
recovery_state_mcts_prob spend 0.38213577499845996 time
state_batch spend 0.0025448429951211438 time
mcts_probs_batch spend 0.007822381012374535 time
winner_batch spend 0.0003626569960033521 time
policy_value spend 0.25014983299479354 time
train_step spend 0.7283837040013168 time
policy_value spend 0.27084506599931046 time
train_step spend 0.7284008800052106 time
policy_value spend 0.2475718740024604 time
train_step spend 0.717431012992165 time
policy_value spend 0.27186386100947857 time
train_step spend 0.7154504799982533 time
policy_value spend 0.2461821970064193 time
kl:0.08302,lr_multiplier:0.088,loss:2.767988920211792,entropy:3.269057035446167,explained_var_old:0.988881767,explained_var_new:0.994563997
output spend 0.0002537539985496551 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.007680688999244012 time
recovery_state_mcts_prob spend 0.4309949599992251 time
state_batch spend 0.004206685000099242 time
mcts_probs_batch spend 0.021502848991076462 time
winner_batch spend 0.00037500901089515537 time
policy_value spend 0.27609997800027486 time
train_step spend 0.7153030210029101 time
policy_value spend 0.24394957500044256 time
train_step spend 0.7165150100045139 time
policy_value spend 0.27675261499825865 time
train_step spend 0.7190750079898862 time
policy_value spend 0.2433583490055753 time
train_step spend 0.7138015529926633 time
policy_value spend 0.2689744090021122 time
kl:0.08571,lr_multiplier:0.088,loss:2.8096702098846436,entropy:3.2848103046417236,explained_var_old:0.986105323,explained_var_new:0.984986246
output spend 0.0003840889985440299 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005216625999310054 time
recovery_state_mcts_prob spend 0.4154419050028082 time
state_batch spend 0.004754825989948586 time
mcts_probs_batch spend 0.008701245009433478 time
winner_batch spend 0.000312876989482902 time
policy_value spend 0.24498539901105687 time
train_step spend 0.7082595109968679 time
policy_value spend 0.2550024840020342 time
train_step spend 0.6996037170029012 time
policy_value spend 0.24013282598752994 time
train_step spend 0.6997373849881114 time
policy_value spend 0.2562347180064535 time
train_step spend 0.7168792140000733 time
policy_value spend 0.24221575299452525 time
kl:0.09343,lr_multiplier:0.088,loss:2.790759801864624,entropy:3.2962918281555176,explained_var_old:0.988478720,explained_var_new:0.994285941
output spend 0.00019235600484535098 time
已保存最新模型
current self-play batch: 500
load data begin
已加载数据
step i 46: 
random.sample spend 0.0069318970054155216 time
recovery_state_mcts_prob spend 0.6742647670034785 time
state_batch spend 0.011908204993233085 time
mcts_probs_batch spend 0.02842378499917686 time
winner_batch spend 0.00039957200351636857 time
policy_value spend 0.2871810060023563 time
train_step spend 0.7565250259940512 time
policy_value spend 0.242501209009788 time
train_step spend 0.7166788000031374 time
policy_value spend 0.24234929600788746 time
train_step spend 0.7122487910091877 time
policy_value spend 0.2647148799878778 time
train_step spend 0.7446855409943964 time
policy_value spend 0.2384634900081437 time
kl:0.09560,lr_multiplier:0.088,loss:2.7721383571624756,entropy:3.263730525970459,explained_var_old:0.985954583,explained_var_new:0.986435950
output spend 0.00019573999452404678 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005310337000992149 time
recovery_state_mcts_prob spend 0.3862454589980189 time
state_batch spend 0.003645249002147466 time
mcts_probs_batch spend 0.01420381900970824 time
winner_batch spend 0.00028198999643791467 time
policy_value spend 0.24811732600210235 time
train_step spend 0.7007208169961814 time
policy_value spend 0.24357422499451786 time
train_step spend 0.7123850229982054 time
policy_value spend 0.25524837999546435 time
train_step spend 0.7112441189965466 time
policy_value spend 0.2408979210013058 time
train_step spend 0.7101496120012598 time
policy_value spend 0.25259358999028336 time
kl:0.11178,lr_multiplier:0.088,loss:2.7113003730773926,entropy:3.189471483230591,explained_var_old:0.988829374,explained_var_new:0.993185043
output spend 0.0008657660073367879 time
已保存最新模型
load data begin
已加载数据
step i 46: 
random.sample spend 0.005718875996535644 time
recovery_state_mcts_prob spend 0.44675357500091195 time
state_batch spend 0.0034773720108205453 time
mcts_probs_batch spend 0.007403320996672846 time
winner_batch spend 0.0002794259926304221 time
policy_value spend 0.24698104200069793 time

quit
