模型路径不存在, 从零开始训练
load data begin
已加载数据
step i 372: 
random.sample spend 0.005707174001145177 time
recovery_state_mcts_prob spend 0.2801323629973922 time
state_batch spend 0.007799609003996011 time
mcts_probs_batch spend 0.019965768995461985 time
winner_batch spend 0.00023074600176187232 time
policy_value spend 0.5207967189999181 time
train_step spend 0.8683020249955007 time
policy_value spend 0.22850060099881375 time
train_step spend 0.6312370649975492 time
policy_value spend 0.2134379600029206 time
train_step spend 0.6272219640013645 time
policy_value spend 0.2132879819982918 time
train_step spend 0.6264913289996912 time
policy_value spend 0.21286811400204897 time
train_step spend 0.6294363260021782 time
policy_value spend 0.2131496479996713 time
kl:0.00308,lr_multiplier:1.500,loss:8.213958740234375,entropy:7.562230587005615,explained_var_old:-0.001928687,explained_var_new:0.001751482
output spend 0.00020605600002454594 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.021556172003329266 time
recovery_state_mcts_prob spend 0.272079570000642 time
state_batch spend 0.0065832589971250854 time
mcts_probs_batch spend 0.01597244499862427 time
winner_batch spend 0.00029237700073281303 time
policy_value spend 0.22205411300092237 time
train_step spend 0.6618408110007294 time
policy_value spend 0.22120937599538593 time
train_step spend 0.6289945129974512 time
policy_value spend 0.2126155750011094 time
train_step spend 0.6256739069940522 time
policy_value spend 0.21250972300185822 time
train_step spend 0.6259758759988472 time
policy_value spend 0.21287070000107633 time
train_step spend 0.6253172869983246 time
policy_value spend 0.21311776999937138 time
kl:0.00130,lr_multiplier:2.250,loss:7.999526023864746,entropy:7.562559127807617,explained_var_old:0.002184153,explained_var_new:0.002073467
output spend 0.00019018700550077483 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00804045900440542 time
recovery_state_mcts_prob spend 0.26642340099351713 time
state_batch spend 0.00199395800154889 time
mcts_probs_batch spend 0.005818520003231242 time
winner_batch spend 0.000281173997791484 time
policy_value spend 0.21602281800005585 time
train_step spend 0.6270429820069694 time
policy_value spend 0.2127677259995835 time
train_step spend 0.6272019530006219 time
policy_value spend 0.2154670489981072 time
train_step spend 0.6264985509988037 time
policy_value spend 0.21281756299867993 time
train_step spend 0.6261799040003098 time
policy_value spend 0.21290770500490908 time
train_step spend 0.6269718670009752 time
policy_value spend 0.21327444499911508 time
kl:0.00096,lr_multiplier:3.375,loss:7.816837787628174,entropy:7.561127662658691,explained_var_old:0.001997411,explained_var_new:0.023650825
output spend 0.00019841900211758912 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007013657996139955 time
recovery_state_mcts_prob spend 0.2700161120010307 time
state_batch spend 0.00214533200050937 time
mcts_probs_batch spend 0.004940054001053795 time
winner_batch spend 0.000385760999051854 time
policy_value spend 0.2128842349993647 time
train_step spend 0.6274210889969254 time
policy_value spend 0.21320614100113744 time
train_step spend 0.626632593004615 time
policy_value spend 0.21312875599687686 time
train_step spend 0.6271106280037202 time
policy_value spend 0.21399609799846075 time
train_step spend 0.6267994820009335 time
policy_value spend 0.2139035460058949 time
train_step spend 0.6272334570021485 time
policy_value spend 0.21427024999866262 time
kl:0.00121,lr_multiplier:5.062,loss:7.795797824859619,entropy:7.557927131652832,explained_var_old:0.023430884,explained_var_new:0.099141002
output spend 0.00016531300207134336 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01931986300041899 time
recovery_state_mcts_prob spend 0.26961062499321997 time
state_batch spend 0.0018973309997818433 time
mcts_probs_batch spend 0.004861262001213618 time
winner_batch spend 0.0003525400024955161 time
policy_value spend 0.21363792700140039 time
train_step spend 0.6300633450009627 time
policy_value spend 0.21417591199860908 time
train_step spend 0.6287932380000711 time
policy_value spend 0.21441223400324816 time
train_step spend 0.629041652995511 time
policy_value spend 0.21511397100402974 time
train_step spend 0.6299407719998271 time
policy_value spend 0.21406979000312276 time
train_step spend 0.6296202839948819 time
policy_value spend 0.21518625800672453 time
kl:0.00202,lr_multiplier:7.594,loss:7.759273529052734,entropy:7.552753925323486,explained_var_old:0.095267892,explained_var_new:0.241771638
output spend 0.00018025500321527943 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007376210996881127 time
recovery_state_mcts_prob spend 0.2708435649983585 time
state_batch spend 0.0022979920031502843 time
mcts_probs_batch spend 0.0055412829970009625 time
winner_batch spend 0.0003259389995946549 time
policy_value spend 0.2140881180021097 time
train_step spend 0.6298187720021815 time
policy_value spend 0.2148031879987684 time
train_step spend 0.6298407080030302 time
policy_value spend 0.21500575399841182 time
train_step spend 0.6307660120000946 time
policy_value spend 0.21525443100108532 time
train_step spend 0.6299993459979305 time
policy_value spend 0.21557241999835242 time
train_step spend 0.6317160570033593 time
policy_value spend 0.2140186899996479 time
kl:0.00303,lr_multiplier:11.391,loss:7.653876781463623,entropy:7.545377254486084,explained_var_old:0.248931527,explained_var_new:0.440497100
output spend 0.0001898480040836148 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007276087002537679 time
recovery_state_mcts_prob spend 0.2822087509994162 time
state_batch spend 0.0019199770031264052 time
mcts_probs_batch spend 0.006087784000555985 time
winner_batch spend 0.00031595999462297186 time
policy_value spend 0.21526053200068418 time
train_step spend 0.6312858089950169 time
policy_value spend 0.21628041999792913 time
train_step spend 0.631119783000031 time
policy_value spend 0.21481866499379976 time
train_step spend 0.6322607239999343 time
policy_value spend 0.21495223400415853 time
train_step spend 0.6302838539995719 time
policy_value spend 0.21537769099813886 time
train_step spend 0.631801395000366 time
policy_value spend 0.21487283400347224 time
kl:0.00448,lr_multiplier:11.391,loss:7.588712692260742,entropy:7.5377349853515625,explained_var_old:0.439150691,explained_var_new:0.571478605
output spend 0.00016607900033704937 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00776700099959271 time
recovery_state_mcts_prob spend 0.2727100789998076 time
state_batch spend 0.0020760690022143535 time
mcts_probs_batch spend 0.004944095999235287 time
winner_batch spend 0.00032284999906551093 time
policy_value spend 0.21454756599996472 time
train_step spend 0.6294467490006355 time
policy_value spend 0.21528717200271785 time
train_step spend 0.6297650840060669 time
policy_value spend 0.21453972399467602 time
train_step spend 0.6308356800000183 time
policy_value spend 0.21393673599959584 time
train_step spend 0.629130740002438 time
policy_value spend 0.21870746099739335 time
train_step spend 0.6301069080000161 time
policy_value spend 0.21578043999761576 time
kl:0.00573,lr_multiplier:11.391,loss:7.576217174530029,entropy:7.523983001708984,explained_var_old:0.534564614,explained_var_new:0.581624627
output spend 0.00014904500130796805 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0150191700013238 time
recovery_state_mcts_prob spend 0.26888682499702554 time
state_batch spend 0.0019054770018556155 time
mcts_probs_batch spend 0.004942079998727422 time
winner_batch spend 0.00032386500242864713 time
policy_value spend 0.21556831999623682 time
train_step spend 0.6305122440026025 time
policy_value spend 0.21610494700144045 time
train_step spend 0.6300636640007724 time
policy_value spend 0.21471317300165538 time
train_step spend 0.6304767049950897 time
policy_value spend 0.21517671800393146 time
train_step spend 0.630105061994982 time
policy_value spend 0.2151470890021301 time
train_step spend 0.6299212700032513 time
policy_value spend 0.2161204129952239 time
kl:0.00608,lr_multiplier:11.391,loss:7.528347015380859,entropy:7.5122456550598145,explained_var_old:0.585599184,explained_var_new:0.603683352
output spend 0.00015682299999753013 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008415650001552422 time
recovery_state_mcts_prob spend 0.2745175809977809 time
state_batch spend 0.001966390002053231 time
mcts_probs_batch spend 0.007536010998592246 time
winner_batch spend 0.00036781800008611754 time
policy_value spend 0.2153247630049009 time
train_step spend 0.6303226719974191 time
policy_value spend 0.21884815399971558 time
train_step spend 0.6309433200003696 time
policy_value spend 0.2143693109974265 time
train_step spend 0.6296324680006364 time
policy_value spend 0.2151075959991431 time
train_step spend 0.6298601849994157 time
policy_value spend 0.21504827799799386 time
train_step spend 0.6299249209987465 time
policy_value spend 0.2149878370037186 time
kl:0.00507,lr_multiplier:11.391,loss:7.3822245597839355,entropy:7.499565124511719,explained_var_old:0.658819914,explained_var_new:0.668275476
output spend 0.00015071399684529752 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013621843005239498 time
recovery_state_mcts_prob spend 0.2707902229958563 time
state_batch spend 0.0023030980009934865 time
mcts_probs_batch spend 0.012904208997497335 time
winner_batch spend 0.00035664200549945235 time
policy_value spend 0.21573198499390855 time
train_step spend 0.6326853249993292 time
policy_value spend 0.22015049600304337 time
train_step spend 0.6311880170032964 time
policy_value spend 0.21650060099636903 time
train_step spend 0.6321653380000498 time
policy_value spend 0.21559202400385402 time
train_step spend 0.631893225996464 time
policy_value spend 0.21672361699893372 time
train_step spend 0.633044381000218 time
policy_value spend 0.21611408200260485 time
kl:0.00353,lr_multiplier:11.391,loss:7.340071678161621,entropy:7.482587814331055,explained_var_old:0.677509546,explained_var_new:0.685235739
output spend 0.00015061099838931113 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007904769001470413 time
recovery_state_mcts_prob spend 0.2712026840017643 time
state_batch spend 0.0027328619980835356 time
mcts_probs_batch spend 0.009272467999835499 time
winner_batch spend 0.0003644989992608316 time
policy_value spend 0.21743145300570177 time
train_step spend 0.6327581539953826 time
policy_value spend 0.21631367400550516 time
train_step spend 0.6320726520061726 time
policy_value spend 0.21738776299753226 time
train_step spend 0.633464587997878 time
policy_value spend 0.2167268850025721 time
train_step spend 0.6341615310011548 time
policy_value spend 0.2165890149990446 time
train_step spend 0.6326623130007647 time
policy_value spend 0.21645165300287772 time
kl:0.00268,lr_multiplier:11.391,loss:7.309455871582031,entropy:7.46903133392334,explained_var_old:0.668721139,explained_var_new:0.675818324
output spend 0.00015357699885498732 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.015265464004187379 time
recovery_state_mcts_prob spend 0.272264211998845 time
state_batch spend 0.0019005220019607805 time
mcts_probs_batch spend 0.0064017199983936734 time
winner_batch spend 0.00032434400054626167 time
policy_value spend 0.21668104900163598 time
train_step spend 0.6322903649997897 time
policy_value spend 0.21964776000095299 time
train_step spend 0.6329589450033382 time
policy_value spend 0.21567039899673546 time
train_step spend 0.6330506349986535 time
policy_value spend 0.21556091800448485 time
train_step spend 0.6325624040036928 time
policy_value spend 0.21633059500163654 time
train_step spend 0.6325912739994237 time
policy_value spend 0.21581366600003093 time
kl:0.00246,lr_multiplier:11.391,loss:7.317471027374268,entropy:7.447796821594238,explained_var_old:0.627863288,explained_var_new:0.635196328
output spend 0.00015184299991233274 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008397907004109584 time
recovery_state_mcts_prob spend 0.2741356359983911 time
state_batch spend 0.0019834240010823123 time
mcts_probs_batch spend 0.006131693997303955 time
winner_batch spend 0.00031173499883152544 time
policy_value spend 0.21643618500092998 time
train_step spend 0.6348731050020433 time
policy_value spend 0.2159569739960716 time
train_step spend 0.6313485879945802 time
policy_value spend 0.21537681000336306 time
train_step spend 0.6317787389998557 time
policy_value spend 0.21546389200375415 time
train_step spend 0.6317745560008916 time
policy_value spend 0.21589913700154284 time
train_step spend 0.6314356540024164 time
policy_value spend 0.21591801599424798 time
kl:0.00212,lr_multiplier:11.391,loss:7.188260555267334,entropy:7.427094459533691,explained_var_old:0.681153178,explained_var_new:0.687617600
output spend 0.0001632290004636161 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012420890998328105 time
recovery_state_mcts_prob spend 0.27217559600103414 time
state_batch spend 0.001992751997022424 time
mcts_probs_batch spend 0.008839351001370233 time
winner_batch spend 0.0003085130010731518 time
policy_value spend 0.21610404400416883 time
train_step spend 0.6323672939979588 time
policy_value spend 0.2185197930011782 time
train_step spend 0.6319231119996402 time
policy_value spend 0.21603182000399102 time
train_step spend 0.6316900409947266 time
policy_value spend 0.21582689600472804 time
train_step spend 0.6317546850041253 time
policy_value spend 0.21634841000195593 time
train_step spend 0.6309122640013811 time
policy_value spend 0.21613442799571203 time
kl:0.00165,lr_multiplier:11.391,loss:7.22731351852417,entropy:7.40787410736084,explained_var_old:0.602614880,explained_var_new:0.610103726
output spend 0.00019653199706226587 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00916068099468248 time
recovery_state_mcts_prob spend 0.2712886730005266 time
state_batch spend 0.0020158690022071823 time
mcts_probs_batch spend 0.006745909995515831 time
winner_batch spend 0.0003245230036554858 time
policy_value spend 0.21703078899736283 time
train_step spend 0.6313423120009247 time
policy_value spend 0.21531005400174763 time
train_step spend 0.6311503050019382 time
policy_value spend 0.21608378800010541 time
train_step spend 0.6316777009997168 time
policy_value spend 0.21565490400098497 time
train_step spend 0.631574400998943 time
policy_value spend 0.2169405730019207 time
train_step spend 0.6315515040041646 time
policy_value spend 0.21608340300008422 time
kl:0.00111,lr_multiplier:11.391,loss:7.202425003051758,entropy:7.387478828430176,explained_var_old:0.633982599,explained_var_new:0.643602669
output spend 0.00014695199934067205 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012225033999129664 time
recovery_state_mcts_prob spend 0.27288884700101335 time
state_batch spend 0.0019903970023733564 time
mcts_probs_batch spend 0.00644332399679115 time
winner_batch spend 0.00031325499730883166 time
policy_value spend 0.21764749400608707 time
train_step spend 0.6348026070045307 time
policy_value spend 0.2162410379969515 time
train_step spend 0.6332595909989323 time
policy_value spend 0.21805215300264535 time
train_step spend 0.6344959979978739 time
policy_value spend 0.2162741560023278 time
train_step spend 0.6338882819982246 time
policy_value spend 0.21617115200206172 time
train_step spend 0.6328887350027799 time
policy_value spend 0.21648694299801718 time
kl:0.00120,lr_multiplier:11.391,loss:7.089208602905273,entropy:7.376262664794922,explained_var_old:0.695296764,explained_var_new:0.702920198
output spend 0.0002011600008700043 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007887264997407328 time
recovery_state_mcts_prob spend 0.27408903399918927 time
state_batch spend 0.0023890400043455884 time
mcts_probs_batch spend 0.004681465994508471 time
winner_batch spend 0.0003251040034228936 time
policy_value spend 0.21644995899987407 time
train_step spend 0.6335432260020752 time
policy_value spend 0.21688799999537878 time
train_step spend 0.633515344998159 time
policy_value spend 0.21710755900130607 time
train_step spend 0.636701704999723 time
policy_value spend 0.21675821800454287 time
train_step spend 0.633475966998958 time
policy_value spend 0.21562479300337145 time
train_step spend 0.6335541670050588 time
policy_value spend 0.21625984399724985 time
kl:0.00093,lr_multiplier:11.391,loss:7.130760669708252,entropy:7.3563079833984375,explained_var_old:0.606508732,explained_var_new:0.617514193
output spend 0.00015707199781900272 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01593062600295525 time
recovery_state_mcts_prob spend 0.27142148499842733 time
state_batch spend 0.002282991998072248 time
mcts_probs_batch spend 0.005048938000982162 time
winner_batch spend 0.0003443989990046248 time
policy_value spend 0.2160157309990609 time
train_step spend 0.6332192669942742 time
policy_value spend 0.21672183800546918 time
train_step spend 0.6331611770001473 time
policy_value spend 0.2165345410030568 time
train_step spend 0.6336290789986379 time
policy_value spend 0.2162821680030902 time
train_step spend 0.6342931219987804 time
policy_value spend 0.21677939600340324 time
train_step spend 0.6345749629981583 time
policy_value spend 0.2168277900054818 time
kl:0.00077,lr_multiplier:11.391,loss:7.054235935211182,entropy:7.333056449890137,explained_var_old:0.662763476,explained_var_new:0.673188448
output spend 0.00014761700003873557 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008202525998058263 time
recovery_state_mcts_prob spend 0.2717510319998837 time
state_batch spend 0.002129779000824783 time
mcts_probs_batch spend 0.004777212998305913 time
winner_batch spend 0.00032583300344413146 time
policy_value spend 0.21546825399855152 time
train_step spend 0.632329149004363 time
policy_value spend 0.21585820199834416 time
train_step spend 0.6325728220035671 time
policy_value spend 0.21625362500344636 time
train_step spend 0.6313735349976923 time
policy_value spend 0.21653261400206247 time
train_step spend 0.6325639550050255 time
policy_value spend 0.21563529499690048 time
train_step spend 0.6317747659995803 time
policy_value spend 0.21619052099413238 time
kl:0.00095,lr_multiplier:11.391,loss:6.990333080291748,entropy:7.31524658203125,explained_var_old:0.678840756,explained_var_new:0.691384435
output spend 0.00018124700000043958 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01347677300509531 time
recovery_state_mcts_prob spend 0.27158249499916565 time
state_batch spend 0.0019630609967862256 time
mcts_probs_batch spend 0.016396717001043726 time
winner_batch spend 0.0003192610020050779 time
policy_value spend 0.21908482599974377 time
train_step spend 0.6321618990041316 time
policy_value spend 0.22023562699905597 time
train_step spend 0.63331936999748 time
policy_value spend 0.21612452500266954 time
train_step spend 0.6315268309990643 time
policy_value spend 0.2132626460006577 time
train_step spend 0.6259160209956462 time
policy_value spend 0.2128259680030169 time
train_step spend 0.6248157500012894 time
policy_value spend 0.2130173420009669 time
kl:0.00088,lr_multiplier:11.391,loss:7.021178245544434,entropy:7.292324542999268,explained_var_old:0.641408741,explained_var_new:0.654664338
output spend 0.00017070199828594923 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008453169000858907 time
recovery_state_mcts_prob spend 0.2667741709956317 time
state_batch spend 0.0019298780025565065 time
mcts_probs_batch spend 0.00656013499974506 time
winner_batch spend 0.0003216320037608966 time
policy_value spend 0.2140247899951646 time
train_step spend 0.624155345998588 time
policy_value spend 0.21616671299852896 time
train_step spend 0.6239358489983715 time
policy_value spend 0.21320636300515616 time
train_step spend 0.6246896930024377 time
policy_value spend 0.21287862499593757 time
train_step spend 0.6240347600032692 time
policy_value spend 0.21352602499973727 time
train_step spend 0.6242150449979817 time
policy_value spend 0.21335375600028783 time
kl:0.00063,lr_multiplier:11.391,loss:6.942574501037598,entropy:7.272727966308594,explained_var_old:0.672250032,explained_var_new:0.686160803
output spend 0.00014860100054647774 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.015536594000877813 time
recovery_state_mcts_prob spend 0.2653959260060219 time
state_batch spend 0.0022599799995077774 time
mcts_probs_batch spend 0.0066181079964735545 time
winner_batch spend 0.00031558699993183836 time
policy_value spend 0.21715713400044478 time
train_step spend 0.6354317290024483 time
policy_value spend 0.21796253800130216 time
train_step spend 0.6375583769986406 time
policy_value spend 0.21728282700496493 time
train_step spend 0.6348865839972859 time
policy_value spend 0.21605373499915004 time
train_step spend 0.6364823719995911 time
policy_value spend 0.21707904900540598 time
train_step spend 0.6341553460006253 time
policy_value spend 0.21685298800002784 time
kl:0.00069,lr_multiplier:11.391,loss:6.941192150115967,entropy:7.255179405212402,explained_var_old:0.653532624,explained_var_new:0.669051111
output spend 0.00015332399925682694 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01855654700193554 time
recovery_state_mcts_prob spend 0.281009926002298 time
state_batch spend 0.00198123199515976 time
mcts_probs_batch spend 0.004869320000580046 time
winner_batch spend 0.00033362700196448714 time
policy_value spend 0.21652315399842337 time
train_step spend 0.6365253159965505 time
policy_value spend 0.2167186619990389 time
train_step spend 0.6345622469962109 time
policy_value spend 0.21700360900285887 time
train_step spend 0.6352519239953835 time
policy_value spend 0.21803056000499055 time
train_step spend 0.6349442070059013 time
policy_value spend 0.2168975499953376 time
train_step spend 0.6388240330052213 time
policy_value spend 0.21730001700052526 time
kl:0.00079,lr_multiplier:11.391,loss:6.879364490509033,entropy:7.228528022766113,explained_var_old:0.676679969,explained_var_new:0.692517519
output spend 0.00015149299724726006 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009378827999171335 time
recovery_state_mcts_prob spend 0.2758508740007528 time
state_batch spend 0.0018712700039031915 time
mcts_probs_batch spend 0.005111702994327061 time
winner_batch spend 0.0003839750061160885 time
policy_value spend 0.21579117499641143 time
train_step spend 0.6348113280037069 time
policy_value spend 0.21747497099568136 time
train_step spend 0.6346400769980391 time
policy_value spend 0.21735334300319664 time
train_step spend 0.6357546459985315 time
policy_value spend 0.21793032500136178 time
train_step spend 0.6354640980061959 time
policy_value spend 0.21668263799801935 time
train_step spend 0.6356283710047137 time
policy_value spend 0.21729345199855743 time
kl:0.00088,lr_multiplier:11.391,loss:6.861600399017334,entropy:7.221311569213867,explained_var_old:0.692683697,explained_var_new:0.707297444
output spend 0.00015398400137200952 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00922442199953366 time
recovery_state_mcts_prob spend 0.2903796979953768 time
state_batch spend 0.0019539880013326183 time
mcts_probs_batch spend 0.005017043004045263 time
winner_batch spend 0.0003698739965329878 time
policy_value spend 0.21570554900245043 time
train_step spend 0.6330436389980605 time
policy_value spend 0.21665994800423505 time
train_step spend 0.6335850020041107 time
policy_value spend 0.217086967000796 time
train_step spend 0.6342509379974217 time
policy_value spend 0.2167719360004412 time
train_step spend 0.634100272996875 time
policy_value spend 0.21895757200400112 time
train_step spend 0.6345602230067016 time
policy_value spend 0.21679249499720754 time
kl:0.00078,lr_multiplier:11.391,loss:6.865591526031494,entropy:7.195517539978027,explained_var_old:0.672574520,explained_var_new:0.687539339
output spend 0.00015659299970138818 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0082763230020646 time
recovery_state_mcts_prob spend 0.27292219199443934 time
state_batch spend 0.0018980550012202002 time
mcts_probs_batch spend 0.0045858830053475685 time
winner_batch spend 0.0006308550000539981 time
policy_value spend 0.21885130099690286 time
train_step spend 0.6355293320011697 time
policy_value spend 0.21710142599476967 time
train_step spend 0.6345936009965953 time
policy_value spend 0.21825289600383257 time
train_step spend 0.634532363001199 time
policy_value spend 0.2164341030002106 time
train_step spend 0.6327735209997627 time
policy_value spend 0.2165410269954009 time
train_step spend 0.6320399090036517 time
policy_value spend 0.2181730910015176 time
kl:0.00062,lr_multiplier:11.391,loss:6.837172508239746,entropy:7.188515663146973,explained_var_old:0.681760192,explained_var_new:0.699116409
output spend 0.00020047800353495404 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.017293343000346795 time
recovery_state_mcts_prob spend 0.27471019299991895 time
state_batch spend 0.0019907739988411777 time
mcts_probs_batch spend 0.007028321000689175 time
winner_batch spend 0.0003568399988580495 time
policy_value spend 0.2165548709963332 time
train_step spend 0.6329440120025538 time
policy_value spend 0.21853170399845112 time
train_step spend 0.6329908080006135 time
policy_value spend 0.215964475995861 time
train_step spend 0.6333537820028141 time
policy_value spend 0.21660407300078077 time
train_step spend 0.6327827560016885 time
policy_value spend 0.21690162499726284 time
train_step spend 0.6328846019969205 time
policy_value spend 0.2163836820036522 time
kl:0.00077,lr_multiplier:11.391,loss:6.806957244873047,entropy:7.167436599731445,explained_var_old:0.665497184,explained_var_new:0.685442984
output spend 0.00015266000264091417 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01698432800185401 time
recovery_state_mcts_prob spend 0.2744592839953839 time
state_batch spend 0.0020169679992250167 time
mcts_probs_batch spend 0.005596904004050884 time
winner_batch spend 0.00031512499845121056 time
policy_value spend 0.21746186199743534 time
train_step spend 0.6372890329948859 time
policy_value spend 0.2167329410003731 time
train_step spend 0.635430042995722 time
policy_value spend 0.21702588100015419 time
train_step spend 0.6357228490014677 time
policy_value spend 0.2169266159980907 time
train_step spend 0.6352604109997628 time
policy_value spend 0.21772352000698447 time
train_step spend 0.635592339996947 time
policy_value spend 0.21783958900050493 time
kl:0.00083,lr_multiplier:11.391,loss:6.819528579711914,entropy:7.160459518432617,explained_var_old:0.658373356,explained_var_new:0.678976476
output spend 0.00015021400031400844 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010024701005022507 time
recovery_state_mcts_prob spend 0.2757102429968654 time
state_batch spend 0.001912485997308977 time
mcts_probs_batch spend 0.005119988003571052 time
winner_batch spend 0.0003104429997620173 time
policy_value spend 0.22030673699919134 time
train_step spend 0.6352373530025943 time
policy_value spend 0.2168434970008093 time
train_step spend 0.6357901419978589 time
policy_value spend 0.21708221299923025 time
train_step spend 0.6355226159939775 time
policy_value spend 0.21779930300544947 time
train_step spend 0.6367478239990305 time
policy_value spend 0.2172835870005656 time
train_step spend 0.6378517379998812 time
policy_value spend 0.21765259400126524 time
kl:0.00066,lr_multiplier:11.391,loss:6.774688243865967,entropy:7.134746074676514,explained_var_old:0.646804571,explained_var_new:0.676381588
output spend 0.00015039400022942573 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.014733695999893826 time
recovery_state_mcts_prob spend 0.2730429829971399 time
state_batch spend 0.0019079160047112964 time
mcts_probs_batch spend 0.008699006997630931 time
winner_batch spend 0.00034539499756647274 time
policy_value spend 0.22104072599904612 time
train_step spend 0.6381191149994265 time
policy_value spend 0.22124151400203118 time
train_step spend 0.6374253800022416 time
policy_value spend 0.2172159979963908 time
train_step spend 0.6368644800022594 time
policy_value spend 0.21785682500194525 time
train_step spend 0.637181050995423 time
policy_value spend 0.21848414400301408 time
train_step spend 0.6378594909983804 time
policy_value spend 0.21763806699891575 time
kl:0.00096,lr_multiplier:11.391,loss:6.711487770080566,entropy:7.115233421325684,explained_var_old:0.682162285,explained_var_new:0.720430315
output spend 0.00015396299568237737 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011495935003040358 time
recovery_state_mcts_prob spend 0.27310438900167355 time
state_batch spend 0.001937955996254459 time
mcts_probs_batch spend 0.005979419001960196 time
winner_batch spend 0.00043138000182807446 time
policy_value spend 0.21292208499653498 time
train_step spend 0.6244961549964501 time
policy_value spend 0.21289401299873134 time
train_step spend 0.6234787840003264 time
policy_value spend 0.2131914229976246 time
train_step spend 0.6223211629985599 time
policy_value spend 0.2130606880018604 time
train_step spend 0.6224132549978094 time
policy_value spend 0.21301935500378022 time
train_step spend 0.6231293079981697 time
policy_value spend 0.2129636060053599 time
kl:0.00059,lr_multiplier:11.391,loss:6.688265800476074,entropy:7.1004791259765625,explained_var_old:0.726832271,explained_var_new:0.758165181
output spend 0.00014986799942562357 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007900399999925867 time
recovery_state_mcts_prob spend 0.26676111000415403 time
state_batch spend 0.0018144429996027611 time
mcts_probs_batch spend 0.0057585419999668375 time
winner_batch spend 0.00033508599881315604 time
policy_value spend 0.21330602600210113 time
train_step spend 0.6231524940012605 time
policy_value spend 0.21364864299539477 time
train_step spend 0.6231928140041418 time
policy_value spend 0.21251623499847483 time
train_step spend 0.626843550002377 time
policy_value spend 0.21706034499948146 time
train_step spend 0.6340031239960808 time
policy_value spend 0.21733459900133312 time
train_step spend 0.6347880819957936 time
policy_value spend 0.21785931500198785 time
kl:0.00083,lr_multiplier:11.391,loss:6.639551639556885,entropy:7.09079647064209,explained_var_old:0.740807652,explained_var_new:0.764907241
output spend 0.00015499199798796326 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01077813700248953 time
recovery_state_mcts_prob spend 0.2743232770008035 time
state_batch spend 0.0020040079980390146 time
mcts_probs_batch spend 0.005850335001014173 time
winner_batch spend 0.0003186639951309189 time
policy_value spend 0.21606459200120298 time
train_step spend 0.6355521259974921 time
policy_value spend 0.21854839700245066 time
train_step spend 0.6337279709987342 time
policy_value spend 0.21695853800338227 time
train_step spend 0.6336750480040791 time
policy_value spend 0.21661820999725023 time
train_step spend 0.6350424400006887 time
policy_value spend 0.2178399679978611 time
train_step spend 0.6350626540006488 time
policy_value spend 0.2169394949960406 time
kl:0.00057,lr_multiplier:11.391,loss:6.621739387512207,entropy:7.060713291168213,explained_var_old:0.712303340,explained_var_new:0.742863655
output spend 0.00020284699712647125 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011331552996125538 time
recovery_state_mcts_prob spend 0.26826466000056826 time
state_batch spend 0.0019383629987714812 time
mcts_probs_batch spend 0.004898161001619883 time
winner_batch spend 0.00031467500230064616 time
policy_value spend 0.21742713500134414 time
train_step spend 0.636714893997123 time
policy_value spend 0.21749526200437685 time
train_step spend 0.6366123760017217 time
policy_value spend 0.21772109299490694 time
train_step spend 0.6387717359975795 time
policy_value spend 0.2175575459987158 time
train_step spend 0.6380044580000686 time
policy_value spend 0.21803334500145866 time
train_step spend 0.6389510230001179 time
policy_value spend 0.21799518400075613 time
kl:0.00168,lr_multiplier:11.391,loss:6.608938694000244,entropy:7.053630828857422,explained_var_old:0.755837142,explained_var_new:0.782657623
output spend 0.00014987000031396747 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012228666004375555 time
recovery_state_mcts_prob spend 0.27759733999846503 time
state_batch spend 0.0022252479975577444 time
mcts_probs_batch spend 0.004956996999680996 time
winner_batch spend 0.0003364430012879893 time
policy_value spend 0.2173670230040443 time
train_step spend 0.6370699629987939 time
policy_value spend 0.21758592699916335 time
train_step spend 0.6358796990025439 time
policy_value spend 0.21863582499645418 time
train_step spend 0.6426961789984489 time
policy_value spend 0.22173452399874805 time
train_step spend 0.6498040180013049 time
policy_value spend 0.22208537600090494 time
train_step spend 0.6506829959980678 time
policy_value spend 0.2222298699998646 time
kl:0.00125,lr_multiplier:11.391,loss:6.572437286376953,entropy:7.029396057128906,explained_var_old:0.726002336,explained_var_new:0.753066003
output spend 0.0001571259999764152 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008355778001714498 time
recovery_state_mcts_prob spend 0.28835379100200953 time
state_batch spend 0.0024760279993643053 time
mcts_probs_batch spend 0.004815906002477277 time
winner_batch spend 0.00037478999729501083 time
policy_value spend 0.2219946780023747 time
train_step spend 0.6490742839960149 time
policy_value spend 0.22174812400044175 time
train_step spend 0.649760726999375 time
policy_value spend 0.2226476299983915 time
train_step spend 0.6497783699960564 time
policy_value spend 0.22217184500186704 time
train_step spend 0.649366119003389 time
policy_value spend 0.22275165599421598 time
train_step spend 0.6498742190015037 time
policy_value spend 0.22210993899352616 time
kl:0.00111,lr_multiplier:11.391,loss:6.590587615966797,entropy:7.024054527282715,explained_var_old:0.760175586,explained_var_new:0.788806856
output spend 0.0001671900026849471 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009991284998250194 time
recovery_state_mcts_prob spend 0.2585072729998501 time
state_batch spend 0.0017696150025585666 time
mcts_probs_batch spend 0.005343199001799803 time
winner_batch spend 0.0002827139978762716 time
policy_value spend 0.2048107950031408 time
train_step spend 0.5999344220035709 time
policy_value spend 0.2045977710004081 time
train_step spend 0.5997718020007596 time
policy_value spend 0.2051698809955269 time
train_step spend 0.5997016960027395 time
policy_value spend 0.20511261600040598 time
train_step spend 0.5998733669985086 time
policy_value spend 0.20510809700499522 time
train_step spend 0.61183822699968 time
policy_value spend 0.21753124299721094 time
kl:0.00070,lr_multiplier:11.391,loss:6.585944175720215,entropy:6.9953484535217285,explained_var_old:0.709429622,explained_var_new:0.742501259
output spend 0.0001577059956616722 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0142150540050352 time
recovery_state_mcts_prob spend 0.27155448199482635 time
state_batch spend 0.0018699370048125274 time
mcts_probs_batch spend 0.006576487998245284 time
winner_batch spend 0.00030589599919039756 time
policy_value spend 0.21883691800030647 time
train_step spend 0.6378030630003195 time
policy_value spend 0.21924529600073583 time
train_step spend 0.6375483049996546 time
policy_value spend 0.21856361399841262 time
train_step spend 0.6335805179987801 time
policy_value spend 0.21565967000060482 time
train_step spend 0.630878046998987 time
policy_value spend 0.21603055000014137 time
train_step spend 0.6307261800029664 time
policy_value spend 0.21597366700007115 time
kl:0.00093,lr_multiplier:11.391,loss:6.552460193634033,entropy:6.987519264221191,explained_var_old:0.712249756,explained_var_new:0.764000535
output spend 0.00018492300296202302 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009569510999426711 time
recovery_state_mcts_prob spend 0.26365976499801036 time
state_batch spend 0.0019207240038667805 time
mcts_probs_batch spend 0.006498668000858743 time
winner_batch spend 0.00030560400045942515 time
policy_value spend 0.21919210699707037 time
train_step spend 0.6314503900066484 time
policy_value spend 0.21721711099962704 time
train_step spend 0.6301886630026274 time
policy_value spend 0.21588434500154108 time
train_step spend 0.6311978769954294 time
policy_value spend 0.2163733140041586 time
train_step spend 0.6317876829998568 time
policy_value spend 0.21888796699931845 time
train_step spend 0.6305295409983955 time
policy_value spend 0.21687004800332943 time
kl:0.00072,lr_multiplier:11.391,loss:6.560291290283203,entropy:6.982446670532227,explained_var_old:0.746263206,explained_var_new:0.790650904
output spend 0.00014461999671766534 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008021970999834593 time
recovery_state_mcts_prob spend 0.27897928099991987 time
state_batch spend 0.001978828993742354 time
mcts_probs_batch spend 0.006403901999874506 time
winner_batch spend 0.00031077800667844713 time
policy_value spend 0.21890375299699372 time
train_step spend 0.6392690800057608 time
policy_value spend 0.2171278199966764 time
train_step spend 0.6371544530047686 time
policy_value spend 0.21822704399528448 time
train_step spend 0.6378602199984016 time
policy_value spend 0.2186738320015138 time
train_step spend 0.6386003239967977 time
policy_value spend 0.218194676002895 time
train_step spend 0.6392741380041116 time
policy_value spend 0.21822242999769514 time
kl:0.00066,lr_multiplier:11.391,loss:6.521762371063232,entropy:6.966264724731445,explained_var_old:0.757683516,explained_var_new:0.802897274
output spend 0.0001518970020697452 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009781624001334421 time
recovery_state_mcts_prob spend 0.29259288500179537 time
state_batch spend 0.002066371998807881 time
mcts_probs_batch spend 0.004661067003326025 time
winner_batch spend 0.000334588999976404 time
policy_value spend 0.2177277029986726 time
train_step spend 0.6382819990030839 time
policy_value spend 0.21742022500257008 time
train_step spend 0.6377434250025544 time
policy_value spend 0.21827464800298912 time
train_step spend 0.6511563969979761 time
policy_value spend 0.22557531100028427 time
train_step spend 0.6589619890000904 time
policy_value spend 0.22694518399657682 time
train_step spend 0.6611579059972428 time
policy_value spend 0.2257385230041109 time
kl:0.00114,lr_multiplier:11.391,loss:6.4967217445373535,entropy:6.957879066467285,explained_var_old:0.750704587,explained_var_new:0.797695100
output spend 0.00015615499432897195 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.014205275001586415 time
recovery_state_mcts_prob spend 0.2765454519976629 time
state_batch spend 0.0020300860051065683 time
mcts_probs_batch spend 0.004793535998032894 time
winner_batch spend 0.00031993299489840865 time
policy_value spend 0.22468330100673484 time
train_step spend 0.6588797020012862 time
policy_value spend 0.22526467499847058 time
train_step spend 0.6607181240033242 time
policy_value spend 0.22532270300143864 time
train_step spend 0.6597592510006507 time
policy_value spend 0.22582336299819872 time
train_step spend 0.6601163230006932 time
policy_value spend 0.22535203100414947 time
train_step spend 0.6591521399968769 time
policy_value spend 0.21701124499668367 time
kl:0.00059,lr_multiplier:11.391,loss:6.416223526000977,entropy:6.933470249176025,explained_var_old:0.811061323,explained_var_new:0.847578287
output spend 0.000263173998973798 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.018749012997432146 time
recovery_state_mcts_prob spend 0.2625651199996355 time
state_batch spend 0.0020725360009237193 time
mcts_probs_batch spend 0.004242695998982526 time
winner_batch spend 0.0002883850029320456 time
policy_value spend 0.20476233899535146 time
train_step spend 0.6010118680060259 time
policy_value spend 0.20499094099795911 time
train_step spend 0.5998737409972819 time
policy_value spend 0.2048230770014925 time
train_step spend 0.6008569689947763 time
policy_value spend 0.20641588200669503 time
train_step spend 0.6020930760059855 time
policy_value spend 0.20557544499752112 time
train_step spend 0.6002778289985145 time
policy_value spend 0.2053538300024229 time
kl:0.00070,lr_multiplier:11.391,loss:6.484240531921387,entropy:6.918763160705566,explained_var_old:0.742363214,explained_var_new:0.790007710
output spend 0.0001444590016035363 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00976661199820228 time
recovery_state_mcts_prob spend 0.2587275409969152 time
state_batch spend 0.0018492250019335188 time
mcts_probs_batch spend 0.006786470003135037 time
winner_batch spend 0.000320826999086421 time
policy_value spend 0.20536089899542276 time
train_step spend 0.6001911330022267 time
policy_value spend 0.20694321699556895 time
train_step spend 0.6001062550058123 time
policy_value spend 0.20543639899551636 time
train_step spend 0.6127410560002318 time
policy_value spend 0.21425622400420252 time
train_step spend 0.6272973320010351 time
policy_value spend 0.21472515300411033 time
train_step spend 0.6275352820011904 time
policy_value spend 0.21519322699896293 time
kl:0.00110,lr_multiplier:11.391,loss:6.397671222686768,entropy:6.8957839012146,explained_var_old:0.773840845,explained_var_new:0.833841920
output spend 0.00022156399791128933 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010388830000010785 time
recovery_state_mcts_prob spend 0.26771246799762594 time
state_batch spend 0.001866217004135251 time
mcts_probs_batch spend 0.006679628000711091 time
winner_batch spend 0.00029762699705315754 time
policy_value spend 0.21405430199956754 time
train_step spend 0.6306150829987018 time
policy_value spend 0.21515003999957116 time
train_step spend 0.627419500000542 time
policy_value spend 0.214193093997892 time
train_step spend 0.6273426219995599 time
policy_value spend 0.21445615700213239 time
train_step spend 0.6272882980047143 time
policy_value spend 0.21397756099759135 time
train_step spend 0.6262803299978259 time
policy_value spend 0.2145713040008559 time
kl:0.00085,lr_multiplier:11.391,loss:6.390613079071045,entropy:6.880049705505371,explained_var_old:0.806550741,explained_var_new:0.847728908
output spend 0.0001485070024500601 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010066009002912324 time
recovery_state_mcts_prob spend 0.27985351999814156 time
state_batch spend 0.00223509000352351 time
mcts_probs_batch spend 0.0060059489987907 time
winner_batch spend 0.00041620199772296473 time
policy_value spend 0.21927665100520244 time
train_step spend 0.6411420069998712 time
policy_value spend 0.22074842599977273 time
train_step spend 0.6418476089966134 time
policy_value spend 0.22499551700457232 time
train_step spend 0.6411116549934377 time
policy_value spend 0.21949524999945424 time
train_step spend 0.6420264650005265 time
policy_value spend 0.21925303399621043 time
train_step spend 0.6412079180008732 time
policy_value spend 0.21924757099623093 time
kl:0.00062,lr_multiplier:11.391,loss:6.390015602111816,entropy:6.870816230773926,explained_var_old:0.799024999,explained_var_new:0.845363259
output spend 0.00015034600073704496 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.014639102999353781 time
recovery_state_mcts_prob spend 0.27647096200234955 time
state_batch spend 0.0024100540031213313 time
mcts_probs_batch spend 0.006668345995421987 time
winner_batch spend 0.0003068510050070472 time
policy_value spend 0.2198147169983713 time
train_step spend 0.6416850960013107 time
policy_value spend 0.22039525100262836 time
train_step spend 0.6424169410020113 time
policy_value spend 0.21951253999577602 time
train_step spend 0.6568589750022511 time
policy_value spend 0.2278176079998957 time
train_step spend 0.6672459080000408 time
policy_value spend 0.22833462199923815 time
train_step spend 0.6685264039988397 time
policy_value spend 0.22853570500592468 time
kl:0.00151,lr_multiplier:11.391,loss:6.355239391326904,entropy:6.853799819946289,explained_var_old:0.816843867,explained_var_new:0.858301580
output spend 0.00015627899847459048 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009824664994084742 time
recovery_state_mcts_prob spend 0.29133458400610834 time
state_batch spend 0.0020701989997178316 time
mcts_probs_batch spend 0.005946689998381771 time
winner_batch spend 0.00032159999682335183 time
policy_value spend 0.22844075700413669 time
train_step spend 0.6683141020039329 time
policy_value spend 0.22824696899624541 time
train_step spend 0.6681316710019019 time
policy_value spend 0.2293228900016402 time
train_step spend 0.6679993150028167 time
policy_value spend 0.228747866996855 time
train_step spend 0.667903806999675 time
policy_value spend 0.2287990830009221 time
train_step spend 0.6674359219978214 time
policy_value spend 0.21725283799605677 time
kl:0.00075,lr_multiplier:11.391,loss:6.336761474609375,entropy:6.834407806396484,explained_var_old:0.814848304,explained_var_new:0.855403662
output spend 0.00014055399515200406 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008014093000383582 time
recovery_state_mcts_prob spend 0.2619002729989006 time
state_batch spend 0.0017403020028723404 time
mcts_probs_batch spend 0.0055570349941262975 time
winner_batch spend 0.0003072840045206249 time
policy_value spend 0.20440714700089302 time
train_step spend 0.6020198440019158 time
policy_value spend 0.20514369400189025 time
train_step spend 0.6016527579995454 time
policy_value spend 0.2051664089958649 time
train_step spend 0.599910221004393 time
policy_value spend 0.2062559109981521 time
train_step spend 0.6012877140019555 time
policy_value spend 0.20555309399787802 time
train_step spend 0.6009784380003111 time
policy_value spend 0.20450131600227905 time
kl:0.00103,lr_multiplier:11.391,loss:6.341646671295166,entropy:6.8266448974609375,explained_var_old:0.809451580,explained_var_new:0.857486606
output spend 0.00015987700317054987 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011075464994064532 time
recovery_state_mcts_prob spend 0.257781011001498 time
state_batch spend 0.0018241040015709586 time
mcts_probs_batch spend 0.0067290570004843175 time
winner_batch spend 0.00028819599538110197 time
policy_value spend 0.2050828770006774 time
train_step spend 0.601003474999743 time
policy_value spend 0.20590904299751855 time
train_step spend 0.5997413539953413 time
policy_value spend 0.20878364400414284 time
train_step spend 0.6059933290016488 time
policy_value spend 0.2088531810004497 time
train_step spend 0.6119031999987783 time
policy_value spend 0.20995537799899466 time
train_step spend 0.611352968000574 time
policy_value spend 0.20874598799855448 time
kl:0.00101,lr_multiplier:11.391,loss:6.37570858001709,entropy:6.824009418487549,explained_var_old:0.825411201,explained_var_new:0.869003117
output spend 0.00015441799769178033 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.016553844994632527 time
recovery_state_mcts_prob spend 0.26255305500671966 time
state_batch spend 0.0018891419967985712 time
mcts_probs_batch spend 0.006882437002786901 time
winner_batch spend 0.00034226099523948506 time
policy_value spend 0.2095744949983782 time
train_step spend 0.6107862720018602 time
policy_value spend 0.20953882100002375 time
train_step spend 0.6106447400015895 time
policy_value spend 0.20866114499949617 time
train_step spend 0.6110431420020177 time
policy_value spend 0.2088567629980389 time
train_step spend 0.6113305629987735 time
policy_value spend 0.20859902799566044 time
train_step spend 0.6105898820023867 time
policy_value spend 0.20960314799594926 time
kl:0.00060,lr_multiplier:11.391,loss:6.324816703796387,entropy:6.814042091369629,explained_var_old:0.829096317,explained_var_new:0.874280095
output spend 0.00014846900012344122 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008031928002310451 time
recovery_state_mcts_prob spend 0.274054099994828 time
state_batch spend 0.0018547750005382113 time
mcts_probs_batch spend 0.007313051006349269 time
winner_batch spend 0.00035179799306206405 time
policy_value spend 0.22134860799997114 time
train_step spend 0.645423063004273 time
policy_value spend 0.22277117599878693 time
train_step spend 0.6462922610007809 time
policy_value spend 0.22126066600321792 time
train_step spend 0.6461020019996795 time
policy_value spend 0.22114639000210445 time
train_step spend 0.6479455329972552 time
policy_value spend 0.22163052100222558 time
train_step spend 0.6462814929982414 time
policy_value spend 0.2214287000024342 time
kl:0.00344,lr_multiplier:11.391,loss:6.302569389343262,entropy:6.79930305480957,explained_var_old:0.827255845,explained_var_new:0.871357381
output spend 0.0001532300011604093 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009207757997501176 time
recovery_state_mcts_prob spend 0.27821195300202817 time
state_batch spend 0.001974718994461 time
mcts_probs_batch spend 0.007126700002118014 time
winner_batch spend 0.0003400290006538853 time
policy_value spend 0.22070572299708147 time
train_step spend 0.6471796789992368 time
policy_value spend 0.22153813500335673 time
train_step spend 0.6480440849991282 time
policy_value spend 0.2221396309978445 time
train_step spend 0.6570577660022536 time
policy_value spend 0.22810652299813228 time
train_step spend 0.6674886780019733 time
policy_value spend 0.22855030099890428 time
train_step spend 0.6670503919958719 time
policy_value spend 0.22799018400110072 time
kl:0.00113,lr_multiplier:11.391,loss:6.299610614776611,entropy:6.787176132202148,explained_var_old:0.872674644,explained_var_new:0.908992708
output spend 0.00015458499547094107 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00811712400172837 time
recovery_state_mcts_prob spend 0.2864741969970055 time
state_batch spend 0.001968418000615202 time
mcts_probs_batch spend 0.006594594997295644 time
winner_batch spend 0.0003145619994029403 time
policy_value spend 0.22919769000145607 time
train_step spend 0.6677362779955729 time
policy_value spend 0.2299722390016541 time
train_step spend 0.6689554140029941 time
policy_value spend 0.22835532599856379 time
train_step spend 0.6677691099976073 time
policy_value spend 0.22799847200076329 time
train_step spend 0.667272550999769 time
policy_value spend 0.22851732599519892 time
train_step spend 0.6670998789995792 time
policy_value spend 0.22859005999634974 time
kl:0.00292,lr_multiplier:11.391,loss:6.241682529449463,entropy:6.782416343688965,explained_var_old:0.865884662,explained_var_new:0.903388560
output spend 0.00023329300165642053 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008417920005740598 time
recovery_state_mcts_prob spend 0.25629557600041153 time
state_batch spend 0.0018697299965424463 time
mcts_probs_batch spend 0.005966361997707281 time
winner_batch spend 0.0002955900054075755 time
policy_value spend 0.2051076879943139 time
train_step spend 0.6015291559961042 time
policy_value spend 0.2047746759999427 time
train_step spend 0.6000905209948542 time
policy_value spend 0.20557084000029135 time
train_step spend 0.6009357430011733 time
policy_value spend 0.20538715799921192 time
train_step spend 0.6009061189979548 time
policy_value spend 0.20522946400160436 time
train_step spend 0.6025756759991054 time
policy_value spend 0.20550453000032576 time
kl:0.00182,lr_multiplier:11.391,loss:6.29713773727417,entropy:6.778505325317383,explained_var_old:0.847153604,explained_var_new:0.891743183
output spend 0.0001433669967809692 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006776162997994106 time
recovery_state_mcts_prob spend 0.26067439100006595 time
state_batch spend 0.0017231870006071404 time
mcts_probs_batch spend 0.006805712000641506 time
winner_batch spend 0.0003031009982805699 time
policy_value spend 0.2051784100040095 time
train_step spend 0.6002678279983229 time
policy_value spend 0.20612253500439692 time
train_step spend 0.6012815740032238 time
policy_value spend 0.20494735299871536 time
train_step spend 0.607290047002607 time
policy_value spend 0.2091409940039739 time
train_step spend 0.612726979998115 time
policy_value spend 0.2098527979978826 time
train_step spend 0.6126315820001764 time
policy_value spend 0.20964013000047999 time
kl:0.00175,lr_multiplier:11.391,loss:6.217428684234619,entropy:6.7353715896606445,explained_var_old:0.849386513,explained_var_new:0.895567834
output spend 0.0001408929965691641 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013071326997305732 time
recovery_state_mcts_prob spend 0.26682763999997405 time
state_batch spend 0.002266481998958625 time
mcts_probs_batch spend 0.008651307005493436 time
winner_batch spend 0.0002998429990839213 time
policy_value spend 0.21000278899737168 time
train_step spend 0.6126422169982106 time
policy_value spend 0.21139519599819323 time
train_step spend 0.612381449995155 time
policy_value spend 0.20931849100452382 time
train_step spend 0.6114530999984709 time
policy_value spend 0.20917723700404167 time
train_step spend 0.61200375000044 time
policy_value spend 0.20939445400290424 time
train_step spend 0.6124786520013004 time
policy_value spend 0.20948455399775412 time
kl:0.00082,lr_multiplier:11.391,loss:6.199911594390869,entropy:6.732587814331055,explained_var_old:0.888451636,explained_var_new:0.925592482
output spend 0.00018095000268658623 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007413129998894874 time
recovery_state_mcts_prob spend 0.26800346900563454 time
state_batch spend 0.0018405149967293255 time
mcts_probs_batch spend 0.007228889000543859 time
winner_batch spend 0.0003201040017302148 time
policy_value spend 0.2212390909990063 time
train_step spend 0.6475781109984382 time
policy_value spend 0.2216090650035767 time
train_step spend 0.6790616110010887 time
policy_value spend 0.23819766499946127 time
train_step spend 0.6779340490029426 time
policy_value spend 0.2331516330013983 time
train_step spend 0.6746958199946675 time
policy_value spend 0.2227350480025052 time
train_step spend 0.668333369998436 time
policy_value spend 0.2334894079976948 time
kl:0.00192,lr_multiplier:11.391,loss:6.184037208557129,entropy:6.729267120361328,explained_var_old:0.886429608,explained_var_new:0.923344493
output spend 0.00017769600526662543 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.016250531996774953 time
recovery_state_mcts_prob spend 0.31034006800473435 time
state_batch spend 0.00223841499973787 time
mcts_probs_batch spend 0.005358567999792285 time
winner_batch spend 0.00034992799919564277 time
policy_value spend 0.22172607600077754 time
train_step spend 0.6509483389963862 time
policy_value spend 0.24264949000644265 time
train_step spend 0.6905226209928514 time
policy_value spend 0.22927458300546277 time
train_step spend 0.6783769850007957 time
policy_value spend 0.23309783599688672 time
train_step spend 0.6939599660036038 time
policy_value spend 0.24577159299951745 time
train_step spend 0.6942801699988195 time
policy_value spend 0.23418110299826367 time
kl:0.00457,lr_multiplier:11.391,loss:6.206547260284424,entropy:6.707551956176758,explained_var_old:0.895256460,explained_var_new:0.926860511
output spend 0.00020939399837516248 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008554202999221161 time
recovery_state_mcts_prob spend 0.29334663700137753 time
state_batch spend 0.00220199600153137 time
mcts_probs_batch spend 0.016905608994420618 time
winner_batch spend 0.0003214860043954104 time
policy_value spend 0.23320588399656117 time
train_step spend 0.6704331710061524 time
policy_value spend 0.23047668299841462 time
train_step spend 0.6681515059972298 time
policy_value spend 0.22806980799941812 time
train_step spend 0.6685413300001528 time
policy_value spend 0.22847349700168706 time
train_step spend 0.6684733509973739 time
policy_value spend 0.22877880400483264 time
train_step spend 0.6426818530017044 time
policy_value spend 0.20598519899795065 time
kl:0.00096,lr_multiplier:11.391,loss:6.160980224609375,entropy:6.681069850921631,explained_var_old:0.865487814,explained_var_new:0.907167614
output spend 0.00014138400001684204 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007470586002455093 time
recovery_state_mcts_prob spend 0.2565457909950055 time
state_batch spend 0.0017876940037240274 time
mcts_probs_batch spend 0.0051347769986023195 time
winner_batch spend 0.0002815589978126809 time
policy_value spend 0.20565575200453168 time
train_step spend 0.6022164250025526 time
policy_value spend 0.20586767699569464 time
train_step spend 0.6013939850017778 time
policy_value spend 0.20616232800239231 time
train_step spend 0.603015039996535 time
policy_value spend 0.20487445199978538 time
train_step spend 0.6025401670049177 time
policy_value spend 0.20534727799531538 time
train_step spend 0.6019260670000222 time
policy_value spend 0.20587141599389724 time
kl:0.01035,lr_multiplier:11.391,loss:6.2221879959106445,entropy:6.693962097167969,explained_var_old:0.868032277,explained_var_new:0.911672711
output spend 0.00018543099577073008 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007800259001669474 time
recovery_state_mcts_prob spend 0.2538125589999254 time
state_batch spend 0.0017436919952160679 time
mcts_probs_batch spend 0.006386492001183797 time
winner_batch spend 0.00038144800055306405 time
policy_value spend 0.20586583499971312 time
train_step spend 0.6023958799996763 time
policy_value spend 0.20541859100194415 time
train_step spend 0.6017438560011215 time
policy_value spend 0.2083219350024592 time
train_step spend 0.6145108040000196 time
policy_value spend 0.2091995800001314 time
train_step spend 0.6143278309973539 time
policy_value spend 0.2098607459993218 time
train_step spend 0.6145351109953481 time
policy_value spend 0.21002016700367676 time
kl:0.00188,lr_multiplier:11.391,loss:6.172654628753662,entropy:6.678682804107666,explained_var_old:0.888345778,explained_var_new:0.920345306
output spend 0.00016031599807320163 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007960198003274854 time
recovery_state_mcts_prob spend 0.28174733799824025 time
state_batch spend 0.001853914000093937 time
mcts_probs_batch spend 0.0118924690032145 time
winner_batch spend 0.00029661200096597895 time
policy_value spend 0.21348969199607382 time
train_step spend 0.615915516995301 time
policy_value spend 0.21051506799994968 time
train_step spend 0.6143543270009104 time
policy_value spend 0.2105410860021948 time
train_step spend 0.6141904879987123 time
policy_value spend 0.20968009400530718 time
train_step spend 0.6145803750041523 time
policy_value spend 0.21008197499759262 time
train_step spend 0.6200446000002557 time
policy_value spend 0.2191551529977005 time
kl:0.00474,lr_multiplier:11.391,loss:6.154867172241211,entropy:6.6642632484436035,explained_var_old:0.884047151,explained_var_new:0.919462621
output spend 0.00015326900029322132 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01008963899948867 time
recovery_state_mcts_prob spend 0.2711592269988614 time
state_batch spend 0.0018744140033959411 time
mcts_probs_batch spend 0.016733178999857046 time
winner_batch spend 0.000306594003632199 time
policy_value spend 0.2237329019990284 time
train_step spend 0.6434078359961859 time
policy_value spend 0.2242217029997846 time
train_step spend 0.6447863080029492 time
policy_value spend 0.21991293499741005 time
train_step spend 0.6447594709970872 time
policy_value spend 0.22089400600088993 time
train_step spend 0.6454957679961808 time
policy_value spend 0.22107414600031916 time
train_step spend 0.6475917330026277 time
policy_value spend 0.22164597399387276 time
kl:0.00370,lr_multiplier:11.391,loss:6.183500289916992,entropy:6.670003890991211,explained_var_old:0.868766367,explained_var_new:0.919510126
output spend 0.00015053799870656803 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0077800399958505295 time
recovery_state_mcts_prob spend 0.2853366520066629 time
state_batch spend 0.0021393459974206053 time
mcts_probs_batch spend 0.005726937000872567 time
winner_batch spend 0.0002982629957841709 time
policy_value spend 0.22098325499973726 time
train_step spend 0.6466088969973498 time
policy_value spend 0.2201647440015222 time
train_step spend 0.6454287450033007 time
policy_value spend 0.22852785099530593 time
train_step spend 0.6780853489981382 time
policy_value spend 0.2327522300038254 time
train_step spend 0.6794973370051594 time
policy_value spend 0.23241932899691164 time
train_step spend 0.6775315090053482 time
policy_value spend 0.23270497799967416 time
kl:0.00099,lr_multiplier:11.391,loss:6.13459587097168,entropy:6.6554131507873535,explained_var_old:0.911361456,explained_var_new:0.946774065
output spend 0.00017501199909020215 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009077937000256497 time
recovery_state_mcts_prob spend 0.2939769279983011 time
state_batch spend 0.002076029995805584 time
mcts_probs_batch spend 0.006028514006175101 time
winner_batch spend 0.0003486619971226901 time
policy_value spend 0.23198851999768522 time
train_step spend 0.658805121005571 time
policy_value spend 0.21865688099933323 time
train_step spend 0.6427502160004224 time
policy_value spend 0.21908863700082293 time
train_step spend 0.6400599449989386 time
policy_value spend 0.21898856800544308 time
train_step spend 0.6389436789977481 time
policy_value spend 0.219432397003402 time
train_step spend 0.6336297349989763 time
policy_value spend 0.21229889599635499 time
kl:0.00104,lr_multiplier:11.391,loss:6.0861101150512695,entropy:6.641109466552734,explained_var_old:0.908329725,explained_var_new:0.948065102
output spend 0.00018679700588108972 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011949136998737231 time
recovery_state_mcts_prob spend 0.2622403560017119 time
state_batch spend 0.0019431800028542057 time
mcts_probs_batch spend 0.005440875997010153 time
winner_batch spend 0.0002896860023611225 time
policy_value spend 0.21240289099660004 time
train_step spend 0.6200808270004927 time
policy_value spend 0.21284091800043825 time
train_step spend 0.6196897689951584 time
policy_value spend 0.21150645000307122 time
train_step spend 0.6196638610053924 time
policy_value spend 0.21239458499621833 time
train_step spend 0.62158470400027 time
policy_value spend 0.21201800900598755 time
train_step spend 0.6201126060041133 time
policy_value spend 0.2121334659968852 time
kl:0.00498,lr_multiplier:11.391,loss:6.122869968414307,entropy:6.636136054992676,explained_var_old:0.911965072,explained_var_new:0.942142725
output spend 0.00014506099978461862 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010067984003399033 time
recovery_state_mcts_prob spend 0.26685469599760836 time
state_batch spend 0.001909342005092185 time
mcts_probs_batch spend 0.005375363994971849 time
winner_batch spend 0.0003178109982400201 time
policy_value spend 0.21222904400201514 time
train_step spend 0.6203003789996728 time
policy_value spend 0.2122589729988249 time
train_step spend 0.6182612080010585 time
policy_value spend 0.20813396599987755 time
train_step spend 0.6067583249969175 time
policy_value spend 0.2078884750008001 time
train_step spend 0.607918776004226 time
policy_value spend 0.20793037799739977 time
train_step spend 0.6119465610026964 time
policy_value spend 0.20795250299852341 time
kl:0.00200,lr_multiplier:11.391,loss:6.130910873413086,entropy:6.64511775970459,explained_var_old:0.936415792,explained_var_new:0.959627688
output spend 0.00014365600509336218 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011238894003327005 time
recovery_state_mcts_prob spend 0.26796589299920015 time
state_batch spend 0.0023298300002352335 time
mcts_probs_batch spend 0.005387138997321017 time
winner_batch spend 0.00031430600211024284 time
policy_value spend 0.20815338799729943 time
train_step spend 0.6076516860048287 time
policy_value spend 0.2080645230016671 time
train_step spend 0.6074908549999236 time
policy_value spend 0.20755743100016844 time
train_step spend 0.6165891309938161 time
policy_value spend 0.2185294500013697 time
train_step spend 0.6402481189943501 time
policy_value spend 0.21833912100555608 time
train_step spend 0.6459451030023047 time
policy_value spend 0.21853062199807027 time
kl:0.00312,lr_multiplier:11.391,loss:6.056161880493164,entropy:6.618383884429932,explained_var_old:0.910290956,explained_var_new:0.941156983
output spend 0.00014994000230217353 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012268503000086639 time
recovery_state_mcts_prob spend 0.2689301800055546 time
state_batch spend 0.001956100997631438 time
mcts_probs_batch spend 0.005877768999198452 time
winner_batch spend 0.0003094909989158623 time
policy_value spend 0.21949054599826923 time
train_step spend 0.6409085300037987 time
policy_value spend 0.21868089999770746 time
train_step spend 0.6406138129968895 time
policy_value spend 0.21934546499687713 time
train_step spend 0.6404050600031042 time
policy_value spend 0.219477876999008 time
train_step spend 0.640905259999272 time
policy_value spend 0.21912294199864846 time
train_step spend 0.6399511760027963 time
policy_value spend 0.21907381100027123 time
kl:0.00229,lr_multiplier:11.391,loss:6.1302170753479,entropy:6.6218767166137695,explained_var_old:0.907827139,explained_var_new:0.939881146
output spend 0.00014883800031384453 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008447830005025025 time
recovery_state_mcts_prob spend 0.27832777699950384 time
state_batch spend 0.0018734259938355535 time
mcts_probs_batch spend 0.005600742006208748 time
winner_batch spend 0.00031325699819717556 time
policy_value spend 0.22318523399735568 time
train_step spend 0.6413858879968757 time
policy_value spend 0.22347575200546999 time
train_step spend 0.6421710659997188 time
policy_value spend 0.23027856499538757 time
train_step spend 0.6724279940026463 time
policy_value spend 0.23024694599735085 time
train_step spend 0.6737771020052605 time
policy_value spend 0.22994198199739913 time
train_step spend 0.6732518979988527 time
policy_value spend 0.23077138300141087 time
kl:0.00088,lr_multiplier:11.391,loss:6.135152816772461,entropy:6.607012748718262,explained_var_old:0.907438993,explained_var_new:0.940111518
output spend 0.00015669600543333218 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010392243995738681 time
recovery_state_mcts_prob spend 0.28443234600126743 time
state_batch spend 0.001936123997438699 time
mcts_probs_batch spend 0.006438166004954837 time
winner_batch spend 0.00035671499790623784 time
policy_value spend 0.2304169940034626 time
train_step spend 0.6606695099981152 time
policy_value spend 0.21907506699790247 time
train_step spend 0.6393290390042239 time
policy_value spend 0.2186187190018245 time
train_step spend 0.6395427919997019 time
policy_value spend 0.21886768800322898 time
train_step spend 0.6397616770045715 time
policy_value spend 0.21848643200064544 time
train_step spend 0.6297378680028487 time
policy_value spend 0.20955723299994133 time
kl:0.00220,lr_multiplier:11.391,loss:6.117161273956299,entropy:6.604330062866211,explained_var_old:0.923632920,explained_var_new:0.950839758
output spend 0.0001760240047588013 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009646104997955263 time
recovery_state_mcts_prob spend 0.26204112300183624 time
state_batch spend 0.0018094369952450506 time
mcts_probs_batch spend 0.004253443003108259 time
winner_batch spend 0.00028605000261450186 time
policy_value spend 0.20952724699600367 time
train_step spend 0.6144791869955952 time
policy_value spend 0.21038539500295883 time
train_step spend 0.6163306110029225 time
policy_value spend 0.21026411400089273 time
train_step spend 0.6153763170004822 time
policy_value spend 0.2110574119942612 time
train_step spend 0.6153026960018906 time
policy_value spend 0.20982432500022696 time
train_step spend 0.6145071940045455 time
policy_value spend 0.20955571300146403 time
kl:0.00269,lr_multiplier:11.391,loss:6.090742111206055,entropy:6.605639457702637,explained_var_old:0.925234675,explained_var_new:0.955291927
output spend 0.0001592110056662932 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007265257001563441 time
recovery_state_mcts_prob spend 0.2698845409977366 time
state_batch spend 0.002250563004054129 time
mcts_probs_batch spend 0.004387093998957425 time
winner_batch spend 0.00031320199923356995 time
policy_value spend 0.20849525700032245 time
train_step spend 0.6147456250037067 time
policy_value spend 0.2131286009971518 time
train_step spend 0.6201405999963754 time
policy_value spend 0.21206786599941552 time
train_step spend 0.6196359800014761 time
policy_value spend 0.21260661399719538 time
train_step spend 0.6213266850027139 time
policy_value spend 0.2121984369950951 time
train_step spend 0.6201675109987264 time
policy_value spend 0.21321689099568175 time
kl:0.00077,lr_multiplier:11.391,loss:6.107219696044922,entropy:6.605130195617676,explained_var_old:0.930625916,explained_var_new:0.951929986
output spend 0.00014558400289388373 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.014191802001732867 time
recovery_state_mcts_prob spend 0.26412064600299345 time
state_batch spend 0.0018130210009985603 time
mcts_probs_batch spend 0.004617345999577083 time
winner_batch spend 0.0002947529937955551 time
policy_value spend 0.21171303600567626 time
train_step spend 0.6196756830031518 time
policy_value spend 0.2113226469955407 time
train_step spend 0.6222660019993782 time
policy_value spend 0.21278267500019865 time
train_step spend 0.6210989110040828 time
policy_value spend 0.2118241839998518 time
train_step spend 0.619922399004281 time
policy_value spend 0.21612172699678922 time
train_step spend 0.6408867760037538 time
policy_value spend 0.21792246100085322 time
kl:0.00260,lr_multiplier:11.391,loss:6.032052040100098,entropy:6.57016658782959,explained_var_old:0.928951204,explained_var_new:0.953235209
output spend 0.00015346799773396924 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007425405005051289 time
recovery_state_mcts_prob spend 0.28330921099404804 time
state_batch spend 0.0018761080063995905 time
mcts_probs_batch spend 0.005713660997571424 time
winner_batch spend 0.0003010680011357181 time
policy_value spend 0.21786139899631962 time
train_step spend 0.6373708889950649 time
policy_value spend 0.21737452300294535 time
train_step spend 0.6372228149994044 time
policy_value spend 0.21680759199807653 time
train_step spend 0.6375285390022327 time
policy_value spend 0.2172751830003108 time
train_step spend 0.6387118439961341 time
policy_value spend 0.21873060899815755 time
train_step spend 0.6380063179967692 time
policy_value spend 0.21693515199876856 time
kl:0.00212,lr_multiplier:11.391,loss:6.10303258895874,entropy:6.577234268188477,explained_var_old:0.907640398,explained_var_new:0.950390577
output spend 0.00015042400627862662 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008665970002766699 time
recovery_state_mcts_prob spend 0.27905691799969645 time
state_batch spend 0.0018700200016610324 time
mcts_probs_batch spend 0.0048784669997985475 time
winner_batch spend 0.00047297000128310174 time
policy_value spend 0.23562866599968402 time
train_step spend 0.6647990349956672 time
policy_value spend 0.21936560799804283 time
train_step spend 0.64276100799907 time
policy_value spend 0.22137175900570583 time
train_step spend 0.6492438790010056 time
policy_value spend 0.2226662929970189 time
train_step spend 0.6501543710037367 time
policy_value spend 0.22172304999548942 time
train_step spend 0.648841052003263 time
policy_value spend 0.22202644599747146 time
kl:0.00080,lr_multiplier:11.391,loss:6.080248832702637,entropy:6.576696872711182,explained_var_old:0.929001749,explained_var_new:0.956233919
output spend 0.00015918599819997326 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008220175004680641 time
recovery_state_mcts_prob spend 0.2850400419993093 time
state_batch spend 0.0018578960007289425 time
mcts_probs_batch spend 0.005632005995721556 time
winner_batch spend 0.0003408249976928346 time
policy_value spend 0.22357959200598998 time
train_step spend 0.650251910003135 time
policy_value spend 0.2233241750000161 time
train_step spend 0.6536168190068565 time
policy_value spend 0.22312719399633352 time
train_step spend 0.6502199320020736 time
policy_value spend 0.22197489799873438 time
train_step spend 0.6502346659981413 time
policy_value spend 0.22248830599710345 time
train_step spend 0.6302669260039693 time
policy_value spend 0.20568334099516505 time
kl:0.00167,lr_multiplier:11.391,loss:6.080867767333984,entropy:6.56758975982666,explained_var_old:0.904077590,explained_var_new:0.939244866
output spend 0.00015440399874933064 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011963760000071488 time
recovery_state_mcts_prob spend 0.2658272729968303 time
state_batch spend 0.0018017420006799512 time
mcts_probs_batch spend 0.005311840002832469 time
winner_batch spend 0.00028623000252991915 time
policy_value spend 0.20634911699744407 time
train_step spend 0.6029995319986483 time
policy_value spend 0.20575421299872687 time
train_step spend 0.6029861389979487 time
policy_value spend 0.2060050729996874 time
train_step spend 0.6022121350033558 time
policy_value spend 0.20638569100265158 time
train_step spend 0.6023380550032016 time
policy_value spend 0.20676205399649916 time
train_step spend 0.6028460899979109 time
policy_value spend 0.20583729600184597 time
kl:0.00343,lr_multiplier:11.391,loss:6.043453216552734,entropy:6.561001300811768,explained_var_old:0.932543218,explained_var_new:0.955687106
output spend 0.00014220500452211127 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007492586999433115 time
recovery_state_mcts_prob spend 0.27117574300064007 time
state_batch spend 0.0018186759989475831 time
mcts_probs_batch spend 0.005628168997645844 time
winner_batch spend 0.00028406600176822394 time
policy_value spend 0.20596300900069764 time
train_step spend 0.6315494800001034 time
policy_value spend 0.2188979560014559 time
train_step spend 0.6398243539952091 time
policy_value spend 0.21785859500232618 time
train_step spend 0.6372864799996023 time
policy_value spend 0.21915002999594435 time
train_step spend 0.6389931879966753 time
policy_value spend 0.21816254399891477 time
train_step spend 0.6383258740024758 time
policy_value spend 0.21777400599967223 time
kl:0.00181,lr_multiplier:11.391,loss:6.058813571929932,entropy:6.552488327026367,explained_var_old:0.927623689,explained_var_new:0.954863250
output spend 0.0001707479968899861 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007873775000916794 time
recovery_state_mcts_prob spend 0.27485921700281324 time
state_batch spend 0.0018259040007251315 time
mcts_probs_batch spend 0.0049303379928460345 time
winner_batch spend 0.00030342400714289397 time
policy_value spend 0.2171846299970639 time
train_step spend 0.6373216829961166 time
policy_value spend 0.21817827300401405 time
train_step spend 0.6373496980013442 time
policy_value spend 0.21782140400318895 time
train_step spend 0.6382253819974721 time
policy_value spend 0.21782023800187744 time
train_step spend 0.6388879630030715 time
policy_value spend 0.21775397999590496 time
train_step spend 0.6387431240000296 time
policy_value spend 0.21910017899790546 time
kl:0.00779,lr_multiplier:11.391,loss:5.996668815612793,entropy:6.533536911010742,explained_var_old:0.928880453,explained_var_new:0.958243132
output spend 0.00017019200458889827 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012680423002166208 time
recovery_state_mcts_prob spend 0.27536158499424346 time
state_batch spend 0.0019536850013537332 time
mcts_probs_batch spend 0.004626289002771955 time
winner_batch spend 0.00030738899658899754 time
policy_value spend 0.21836108600109583 time
train_step spend 0.6441637030002312 time
policy_value spend 0.2196225500010769 time
train_step spend 0.6403572909985087 time
policy_value spend 0.21998757300025318 time
train_step spend 0.6407638090022374 time
policy_value spend 0.21923275500012096 time
train_step spend 0.6408215209958144 time
policy_value spend 0.21889513199857902 time
train_step spend 0.6409715890040388 time
policy_value spend 0.21891736499674153 time
kl:0.00126,lr_multiplier:11.391,loss:6.059047698974609,entropy:6.535000324249268,explained_var_old:0.909130394,explained_var_new:0.943456173
output spend 0.00016340699949068949 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011919682001462206 time
recovery_state_mcts_prob spend 0.27499009299936006 time
state_batch spend 0.0019212359984521754 time
mcts_probs_batch spend 0.004693775001214817 time
winner_batch spend 0.00030282600346254185 time
policy_value spend 0.21757994299696293 time
train_step spend 0.6409657330004848 time
policy_value spend 0.21920526099711424 time
train_step spend 0.6475201130015193 time
policy_value spend 0.2259289700014051 time
train_step spend 0.6619344740029192 time
policy_value spend 0.2279727009954513 time
train_step spend 0.6625442260046839 time
policy_value spend 0.2266260600008536 time
train_step spend 0.6615473210040363 time
policy_value spend 0.22633690999646205 time
kl:0.00092,lr_multiplier:11.391,loss:6.069733619689941,entropy:6.547743320465088,explained_var_old:0.944932938,explained_var_new:0.966248512
output spend 0.00021688999549951404 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008821226998406928 time
recovery_state_mcts_prob spend 0.29005725999741117 time
state_batch spend 0.002162492004572414 time
mcts_probs_batch spend 0.005935250999755226 time
winner_batch spend 0.0003584890000638552 time
policy_value spend 0.22502970899950014 time
train_step spend 0.6608320660016034 time
policy_value spend 0.22618055500061018 time
train_step spend 0.6470268639968708 time
policy_value spend 0.21878728000592673 time
train_step spend 0.6404039850021945 time
policy_value spend 0.21875334499782184 time
train_step spend 0.6409969129963429 time
policy_value spend 0.218896420999954 time
train_step spend 0.6326444639998954 time
policy_value spend 0.21483992299909005 time
kl:0.00665,lr_multiplier:11.391,loss:6.050426006317139,entropy:6.5482306480407715,explained_var_old:0.936099291,explained_var_new:0.956672072
output spend 0.00015465699834749103 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008504568002535962 time
recovery_state_mcts_prob spend 0.2697975039991434 time
state_batch spend 0.001907632002257742 time
mcts_probs_batch spend 0.004438881995156407 time
winner_batch spend 0.0003435660037212074 time
policy_value spend 0.21776355499605415 time
train_step spend 0.6276392349973321 time
policy_value spend 0.21938460700039286 time
train_step spend 0.6286806019998039 time
policy_value spend 0.21503211399976863 time
train_step spend 0.627919140002632 time
policy_value spend 0.21507537699653767 time
train_step spend 0.6280424219949055 time
policy_value spend 0.21492117100569885 time
train_step spend 0.6280697649999638 time
policy_value spend 0.21457094999641413 time
kl:0.00304,lr_multiplier:11.391,loss:6.04035758972168,entropy:6.519918441772461,explained_var_old:0.951813996,explained_var_new:0.969808459
output spend 0.00028836799901910126 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009928301005857065 time
recovery_state_mcts_prob spend 0.2979436940004234 time
state_batch spend 0.003050511993933469 time
mcts_probs_batch spend 0.017684252001345158 time
winner_batch spend 0.0003409909986658022 time
policy_value spend 0.21826718200463802 time
train_step spend 0.6323192039999412 time
policy_value spend 0.2144347419962287 time
train_step spend 0.6087522300003911 time
policy_value spend 0.2065553619977436 time
train_step spend 0.6046154900031979 time
policy_value spend 0.2062120260015945 time
train_step spend 0.6045680399984121 time
policy_value spend 0.20703784800571157 time
train_step spend 0.6051707189981244 time
policy_value spend 0.20681080599752022 time
kl:0.00208,lr_multiplier:11.391,loss:5.986662864685059,entropy:6.524350166320801,explained_var_old:0.943268299,explained_var_new:0.970572710
output spend 0.00014409900177270174 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01178961800178513 time
recovery_state_mcts_prob spend 0.25816805900103645 time
state_batch spend 0.0017213289975188673 time
mcts_probs_batch spend 0.006841909998911433 time
winner_batch spend 0.0002968160042655654 time
policy_value spend 0.2061487569953897 time
train_step spend 0.6064915739989374 time
policy_value spend 0.21234385600109817 time
train_step spend 0.6409047960041789 time
policy_value spend 0.21886513999925228 time
train_step spend 0.6400742010009708 time
policy_value spend 0.2189160540001467 time
train_step spend 0.6398608739982592 time
policy_value spend 0.2195889869981329 time
train_step spend 0.6414211859955685 time
policy_value spend 0.21844557700387668 time
kl:0.00420,lr_multiplier:11.391,loss:6.017643451690674,entropy:6.527310371398926,explained_var_old:0.931952417,explained_var_new:0.959313035
output spend 0.0001557140058139339 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007889124004577752 time
recovery_state_mcts_prob spend 0.275432271999307 time
state_batch spend 0.0022290329943643883 time
mcts_probs_batch spend 0.004831819001992699 time
winner_batch spend 0.00030531400261679664 time
policy_value spend 0.21827142799884314 time
train_step spend 0.6405627820058726 time
policy_value spend 0.21871191399986856 time
train_step spend 0.6408121380009106 time
policy_value spend 0.2186997099997825 time
train_step spend 0.6407826860013301 time
policy_value spend 0.22004780099814525 time
train_step spend 0.6408858379945741 time
policy_value spend 0.2189655469992431 time
train_step spend 0.6404018960020039 time
policy_value spend 0.21915987199463416 time
kl:0.00486,lr_multiplier:11.391,loss:5.985137939453125,entropy:6.506527423858643,explained_var_old:0.936950624,explained_var_new:0.960945010
output spend 0.00015143999917199835 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008593313003075309 time
recovery_state_mcts_prob spend 0.27332973900047364 time
state_batch spend 0.001833981994423084 time
mcts_probs_batch spend 0.006573226004547905 time
winner_batch spend 0.0003075560016441159 time
policy_value spend 0.21849515699432231 time
train_step spend 0.6396974689996568 time
policy_value spend 0.22050828699866543 time
train_step spend 0.6549833980025141 time
policy_value spend 0.22595091100083664 time
train_step spend 0.6629698109973106 time
policy_value spend 0.22726600900205085 time
train_step spend 0.6638987579935929 time
policy_value spend 0.22611428900563624 time
train_step spend 0.6622325829957845 time
policy_value spend 0.2272444699992775 time
kl:0.00138,lr_multiplier:11.391,loss:6.015732765197754,entropy:6.509225845336914,explained_var_old:0.958302677,explained_var_new:0.978187621
output spend 0.00015670500579290092 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007890886001405306 time
recovery_state_mcts_prob spend 0.294424268999137 time
state_batch spend 0.002293811005074531 time
mcts_probs_batch spend 0.007282439997652546 time
winner_batch spend 0.0003240000005462207 time
policy_value spend 0.22702041999582434 time
train_step spend 0.6475953849949292 time
policy_value spend 0.2193785220006248 time
train_step spend 0.6389844970035483 time
policy_value spend 0.2190273679952952 time
train_step spend 0.6404598490044009 time
policy_value spend 0.21886991000064882 time
train_step spend 0.6403047970015905 time
policy_value spend 0.2183677799985162 time
train_step spend 0.6170933399989735 time
policy_value spend 0.21014755599753698 time
kl:0.00905,lr_multiplier:11.391,loss:6.002222061157227,entropy:6.508707046508789,explained_var_old:0.938868463,explained_var_new:0.965508938
output spend 0.00020066500292159617 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012684405999607407 time
recovery_state_mcts_prob spend 0.27418822099571116 time
state_batch spend 0.0019553570018615574 time
mcts_probs_batch spend 0.006833696003013756 time
winner_batch spend 0.0002999639982590452 time
policy_value spend 0.2101673450015369 time
train_step spend 0.6158401869979571 time
policy_value spend 0.21079806399939116 time
train_step spend 0.6167241139992257 time
policy_value spend 0.2110617779981112 time
train_step spend 0.6161820079942117 time
policy_value spend 0.21045516400045017 time
train_step spend 0.6169290589969023 time
policy_value spend 0.21009472500008997 time
train_step spend 0.6161738520022482 time
policy_value spend 0.21055315400008112 time
kl:0.00243,lr_multiplier:11.391,loss:5.944372177124023,entropy:6.496649265289307,explained_var_old:0.956719041,explained_var_new:0.972521305
output spend 0.00018642899522092193 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008897867999621667 time
recovery_state_mcts_prob spend 0.26479633900453337 time
state_batch spend 0.002590805001091212 time
mcts_probs_batch spend 0.007017450996499974 time
winner_batch spend 0.0003033579996554181 time
policy_value spend 0.2182729769992875 time
train_step spend 0.6410577690039645 time
policy_value spend 0.2188193069960107 time
train_step spend 0.6376792150040274 time
policy_value spend 0.21860336299869232 time
train_step spend 0.637905736999528 time
policy_value spend 0.21824881200154778 time
train_step spend 0.6387825060010073 time
policy_value spend 0.2226532729982864 time
train_step spend 0.6383856290049152 time
policy_value spend 0.21832135699514765 time
kl:0.00141,lr_multiplier:11.391,loss:5.9567646980285645,entropy:6.4995269775390625,explained_var_old:0.960540473,explained_var_new:0.976161838
output spend 0.0001952439997694455 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007770568001433276 time
recovery_state_mcts_prob spend 0.2714978440053528 time
state_batch spend 0.0018274769972776994 time
mcts_probs_batch spend 0.007484615998691879 time
winner_batch spend 0.0002757379988906905 time
policy_value spend 0.21885032700083684 time
train_step spend 0.6379860939996433 time
policy_value spend 0.21776388899888843 time
train_step spend 0.638798381005472 time
policy_value spend 0.21920255499571795 time
train_step spend 0.6392949950022739 time
policy_value spend 0.21835249699506676 time
train_step spend 0.6397659340000246 time
policy_value spend 0.21794952000345802 time
train_step spend 0.637470850997488 time
policy_value spend 0.2181670740028494 time
kl:0.00170,lr_multiplier:11.391,loss:5.934501647949219,entropy:6.468268871307373,explained_var_old:0.949478090,explained_var_new:0.969286442
output spend 0.00016968900308711454 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0073451530042802915 time
recovery_state_mcts_prob spend 0.2801292599979206 time
state_batch spend 0.0018692459998419508 time
mcts_probs_batch spend 0.006428211003367323 time
winner_batch spend 0.00032836199534358457 time
policy_value spend 0.21766284500336042 time
train_step spend 0.6358812570033479 time
policy_value spend 0.21920787899580318 time
train_step spend 0.635784545003844 time
policy_value spend 0.21775880100176437 time
train_step spend 0.6393266259983648 time
policy_value spend 0.2170318930002395 time
train_step spend 0.6395114629995078 time
policy_value spend 0.21735557300416986 time
train_step spend 0.6362366699977429 time
policy_value spend 0.21806893900065916 time
kl:0.00215,lr_multiplier:11.391,loss:5.956602096557617,entropy:6.4800896644592285,explained_var_old:0.947913587,explained_var_new:0.972630560
output spend 0.00014936999650672078 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00895701000263216 time
recovery_state_mcts_prob spend 0.2717250579953543 time
state_batch spend 0.0019861110049532726 time
mcts_probs_batch spend 0.006972935996600427 time
winner_batch spend 0.00039657299930695444 time
policy_value spend 0.21820997900067596 time
train_step spend 0.6368037009960972 time
policy_value spend 0.217195087003347 time
train_step spend 0.6376717260063742 time
policy_value spend 0.21825212599651422 time
train_step spend 0.6379297250023228 time
policy_value spend 0.21793260800041026 time
train_step spend 0.6384466220042668 time
policy_value spend 0.21837677599978633 time
train_step spend 0.6380565939980443 time
policy_value spend 0.21826429200154962 time
kl:0.00586,lr_multiplier:11.391,loss:5.937829971313477,entropy:6.4696149826049805,explained_var_old:0.947921038,explained_var_new:0.961195469
output spend 0.00014746699889656156 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008134900002914947 time
recovery_state_mcts_prob spend 0.2735659850004595 time
state_batch spend 0.0020417539999471046 time
mcts_probs_batch spend 0.00632570699963253 time
winner_batch spend 0.0002973219961859286 time
policy_value spend 0.21839127500425093 time
train_step spend 0.6387663549976423 time
policy_value spend 0.2194465529973968 time
train_step spend 0.63808956000139 time
policy_value spend 0.21825327199621825 time
train_step spend 0.6384820989987929 time
policy_value spend 0.2198446780021186 time
train_step spend 0.6384663709977758 time
policy_value spend 0.2179588440048974 time
train_step spend 0.6295927329992992 time
policy_value spend 0.21470223499636631 time
kl:0.00106,lr_multiplier:11.391,loss:5.929945468902588,entropy:6.471090316772461,explained_var_old:0.957309842,explained_var_new:0.980233073
output spend 0.00014892400213284418 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007795343997713644 time
recovery_state_mcts_prob spend 0.2739047409995692 time
state_batch spend 0.0019601570020313375 time
mcts_probs_batch spend 0.007367325997620355 time
winner_batch spend 0.0003657690031104721 time
policy_value spend 0.2168308439941029 time
train_step spend 0.629116434000025 time
policy_value spend 0.21667558300396195 time
train_step spend 0.6309190850006416 time
policy_value spend 0.21579239800485084 time
train_step spend 0.6301967119943583 time
policy_value spend 0.2158745490014553 time
train_step spend 0.631016642000759 time
policy_value spend 0.21514407599897822 time
train_step spend 0.6308198799961247 time
policy_value spend 0.21529763500439003 time
kl:0.00173,lr_multiplier:11.391,loss:5.923123359680176,entropy:6.4639129638671875,explained_var_old:0.955161512,explained_var_new:0.976962745
output spend 0.00016602600226178765 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007465232003596611 time
recovery_state_mcts_prob spend 0.26621949399850564 time
state_batch spend 0.002275502003612928 time
mcts_probs_batch spend 0.005066508994787 time
winner_batch spend 0.0003256510026403703 time
policy_value spend 0.2156915410014335 time
train_step spend 0.6311762379991706 time
policy_value spend 0.215678882006614 time
train_step spend 0.6314201679997495 time
policy_value spend 0.2153742489972501 time
train_step spend 0.6314298519937438 time
policy_value spend 0.21595682100451086 time
train_step spend 0.6316735579966917 time
policy_value spend 0.21547068800282432 time
train_step spend 0.6314007300024969 time
policy_value spend 0.21599655699537834 time
kl:0.00508,lr_multiplier:11.391,loss:5.9195966720581055,entropy:6.448853015899658,explained_var_old:0.961966217,explained_var_new:0.982015491
output spend 0.00017448700236855075 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007365707999269944 time
recovery_state_mcts_prob spend 0.26772361199982697 time
state_batch spend 0.0019227209995733574 time
mcts_probs_batch spend 0.007066791004035622 time
winner_batch spend 0.0003160759952152148 time
policy_value spend 0.21582668700284557 time
train_step spend 0.6308881169970846 time
policy_value spend 0.21738316499977373 time
train_step spend 0.6311841440037824 time
policy_value spend 0.21566290699411184 time
train_step spend 0.6308619629999157 time
policy_value spend 0.21503094999934547 time
train_step spend 0.6307013929981622 time
policy_value spend 0.21587292000185698 time
train_step spend 0.6387324660026934 time
policy_value spend 0.21805817799759097 time
kl:0.00382,lr_multiplier:11.391,loss:5.924029350280762,entropy:6.453209400177002,explained_var_old:0.951142788,explained_var_new:0.966874123
output spend 0.00015130399697227404 time
已保存最新模型
current self-play batch: 100
load data begin
已加载数据
step i 372: 
random.sample spend 0.008369031995243859 time
recovery_state_mcts_prob spend 0.27470959900529124 time
state_batch spend 0.0018424199952278286 time
mcts_probs_batch spend 0.006831101003626827 time
winner_batch spend 0.0002927780005848035 time
policy_value spend 0.22065109699906316 time
train_step spend 0.676661805002368 time
policy_value spend 0.22331697399931727 time
train_step spend 0.6415399920006166 time
policy_value spend 0.21833561899984488 time
train_step spend 0.6378523320017848 time
policy_value spend 0.21721875699586235 time
train_step spend 0.6383844920055708 time
policy_value spend 0.21843133799848147 time
train_step spend 0.6378544270046405 time
policy_value spend 0.21785633199760923 time
kl:0.00157,lr_multiplier:11.391,loss:5.9600701332092285,entropy:6.460262775421143,explained_var_old:0.955349445,explained_var_new:0.975388706
output spend 0.00015930100198602304 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007422686001518741 time
recovery_state_mcts_prob spend 0.2838072739978088 time
state_batch spend 0.001860046002548188 time
mcts_probs_batch spend 0.01223487899551401 time
winner_batch spend 0.00031521000346401706 time
policy_value spend 0.22108745399600593 time
train_step spend 0.6391425339970738 time
policy_value spend 0.22350443500181427 time
train_step spend 0.6408292300038738 time
policy_value spend 0.21872378900297917 time
train_step spend 0.6403974409986404 time
policy_value spend 0.21841294500336517 time
train_step spend 0.6409368460008409 time
policy_value spend 0.21874953700171318 time
train_step spend 0.641028104997531 time
policy_value spend 0.21850332300527953 time
kl:0.01042,lr_multiplier:11.391,loss:5.927107810974121,entropy:6.445511341094971,explained_var_old:0.952899873,explained_var_new:0.971735358
output spend 0.00014990399358794093 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010106537003593985 time
recovery_state_mcts_prob spend 0.28182039699458983 time
state_batch spend 0.0021372700066422112 time
mcts_probs_batch spend 0.006554456995218061 time
winner_batch spend 0.00030731400329386815 time
policy_value spend 0.2211736069948529 time
train_step spend 0.6422459719979088 time
policy_value spend 0.21837396300543332 time
train_step spend 0.6407125539990375 time
policy_value spend 0.21933870700013358 time
train_step spend 0.640345025996794 time
policy_value spend 0.21928227999887895 time
train_step spend 0.6369977990034386 time
policy_value spend 0.21262142599880463 time
train_step spend 0.621136330999434 time
policy_value spend 0.21226669000316178 time
kl:0.01036,lr_multiplier:11.391,loss:5.8879547119140625,entropy:6.430721282958984,explained_var_old:0.945412993,explained_var_new:0.963147521
output spend 0.00015731900202808902 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.014613343999371864 time
recovery_state_mcts_prob spend 0.2819286260055378 time
state_batch spend 0.0019743449956877157 time
mcts_probs_batch spend 0.0063840150032774545 time
winner_batch spend 0.0003364489966770634 time
policy_value spend 0.21384511100040982 time
train_step spend 0.6241243519980344 time
policy_value spend 0.21386300900485367 time
train_step spend 0.6249829590014997 time
policy_value spend 0.2121350630040979 time
train_step spend 0.6203687220040592 time
policy_value spend 0.21191446200100472 time
train_step spend 0.6215745709996554 time
policy_value spend 0.21251602499978617 time
train_step spend 0.6207239430004847 time
policy_value spend 0.2120837299953564 time
kl:0.00350,lr_multiplier:11.391,loss:5.939111709594727,entropy:6.446850776672363,explained_var_old:0.951505482,explained_var_new:0.972064912
output spend 0.00014993100194260478 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007277274002262857 time
recovery_state_mcts_prob spend 0.2637021199989249 time
state_batch spend 0.001831419998779893 time
mcts_probs_batch spend 0.006120664998888969 time
winner_batch spend 0.0003082160037592985 time
policy_value spend 0.21215322399802972 time
train_step spend 0.6228044419985963 time
policy_value spend 0.21578137799951946 time
train_step spend 0.6323416739978711 time
policy_value spend 0.21607451100135222 time
train_step spend 0.6320556539940299 time
policy_value spend 0.21596886200131848 time
train_step spend 0.6346567220025463 time
policy_value spend 0.21618166400003247 time
train_step spend 0.6322971990011865 time
policy_value spend 0.21648657699552132 time
kl:0.03175,lr_multiplier:11.391,loss:5.943376064300537,entropy:6.437014102935791,explained_var_old:0.964694262,explained_var_new:0.981437683
output spend 0.00015739200171083212 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009832910996919964 time
recovery_state_mcts_prob spend 0.274469976000546 time
state_batch spend 0.0018256830007885583 time
mcts_probs_batch spend 0.004505514996708371 time
winner_batch spend 0.00031115800084080547 time
policy_value spend 0.21587088399974164 time
train_step spend 0.6325000599972554 time
policy_value spend 0.21730698500323342 time
train_step spend 0.6324496679953882 time
policy_value spend 0.21581894600240048 time
train_step spend 0.6321687699964968 time
policy_value spend 0.22448678799992194 time
train_step spend 0.6322722190016066 time
policy_value spend 0.2188252679989091 time
train_step spend 0.6399666479992447 time
policy_value spend 0.2187954080000054 time
kl:0.01108,lr_multiplier:11.391,loss:5.91581392288208,entropy:6.433030128479004,explained_var_old:0.963580489,explained_var_new:0.980917037
output spend 0.0001607790036359802 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007527631998527795 time
recovery_state_mcts_prob spend 0.28519564300222555 time
state_batch spend 0.0018033359956461936 time
mcts_probs_batch spend 0.008736927004065365 time
winner_batch spend 0.0003076389984926209 time
policy_value spend 0.21754869599681115 time
train_step spend 0.6408759329933673 time
policy_value spend 0.2212967240047874 time
train_step spend 0.6396113829978276 time
policy_value spend 0.21806448500137776 time
train_step spend 0.6407099110001582 time
policy_value spend 0.21898528299789177 time
train_step spend 0.6413619559971266 time
policy_value spend 0.2194356580002932 time
train_step spend 0.6421451959977276 time
policy_value spend 0.218876642997202 time
kl:0.00314,lr_multiplier:11.391,loss:5.875536918640137,entropy:6.428326606750488,explained_var_old:0.956359029,explained_var_new:0.977542162
output spend 0.00014914100029272959 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007616905997565482 time
recovery_state_mcts_prob spend 0.2767196029963088 time
state_batch spend 0.0018755130004137754 time
mcts_probs_batch spend 0.00515674000052968 time
winner_batch spend 0.00036153900146018714 time
policy_value spend 0.21818379499745788 time
train_step spend 0.644543918002455 time
policy_value spend 0.22248592199321138 time
train_step spend 0.6485606440037373 time
policy_value spend 0.22178269899450243 time
train_step spend 0.6481782689952524 time
policy_value spend 0.22171146100299666 time
train_step spend 0.6484560329990927 time
policy_value spend 0.22188172900496284 time
train_step spend 0.647933901003853 time
policy_value spend 0.22174280799663393 time
kl:0.00522,lr_multiplier:11.391,loss:5.943139553070068,entropy:6.438138484954834,explained_var_old:0.945341647,explained_var_new:0.967011750
output spend 0.00018804799765348434 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008020075998501852 time
recovery_state_mcts_prob spend 0.2855067779964884 time
state_batch spend 0.0020452250028029084 time
mcts_probs_batch spend 0.004979413002729416 time
winner_batch spend 0.0003218749989173375 time
policy_value spend 0.22116482199635357 time
train_step spend 0.6475264259934193 time
policy_value spend 0.22136849800153868 time
train_step spend 0.6482853650013567 time
policy_value spend 0.22299246599868638 time
train_step spend 0.6474568590056151 time
policy_value spend 0.22124428899405757 time
train_step spend 0.6447102060046745 time
policy_value spend 0.21801150999817764 time
train_step spend 0.6393095179955708 time
policy_value spend 0.21833565500128316 time
kl:0.00164,lr_multiplier:11.391,loss:5.934530735015869,entropy:6.436651706695557,explained_var_old:0.971143544,explained_var_new:0.982743859
output spend 0.00017514500359538943 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012689638002484571 time
recovery_state_mcts_prob spend 0.2793804429966258 time
state_batch spend 0.0019614550037658773 time
mcts_probs_batch spend 0.0072671430025366135 time
winner_batch spend 0.0003780009938054718 time
policy_value spend 0.2220452700057649 time
train_step spend 0.641398569001467 time
policy_value spend 0.21861401799833402 time
train_step spend 0.6396903929999098 time
policy_value spend 0.21845971600123448 time
train_step spend 0.6389105440030107 time
policy_value spend 0.21775751899986062 time
train_step spend 0.6394806009993772 time
policy_value spend 0.2184588449963485 time
train_step spend 0.6393608560028952 time
policy_value spend 0.2219370370003162 time
kl:0.01644,lr_multiplier:11.391,loss:5.883468151092529,entropy:6.426555633544922,explained_var_old:0.961505830,explained_var_new:0.977807462
output spend 0.0001651839993428439 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01920513999357354 time
recovery_state_mcts_prob spend 0.27692108600604115 time
state_batch spend 0.001924345997394994 time
mcts_probs_batch spend 0.006606788003409747 time
winner_batch spend 0.0003485209963400848 time
policy_value spend 0.2186239150032634 time
train_step spend 0.6371231390003231 time
policy_value spend 0.22055166899372125 time
train_step spend 0.636696560002747 time
policy_value spend 0.21701445999497082 time
train_step spend 0.6366087439964758 time
policy_value spend 0.21717301700118696 time
train_step spend 0.6361542020022171 time
policy_value spend 0.2172742089969688 time
train_step spend 0.6370379670042894 time
policy_value spend 0.21788938499958022 time
kl:0.02855,lr_multiplier:11.391,loss:5.8505425453186035,entropy:6.416316986083984,explained_var_old:0.972803891,explained_var_new:0.987651765
output spend 0.00016242000128841028 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008314705999509897 time
recovery_state_mcts_prob spend 0.27016202500090003 time
state_batch spend 0.0021582300032605417 time
mcts_probs_batch spend 0.007740699002170004 time
winner_batch spend 0.000312477997795213 time
policy_value spend 0.2174372450026567 time
train_step spend 0.6355653869977687 time
policy_value spend 0.2220838100038236 time
train_step spend 0.6360802809940651 time
policy_value spend 0.21695301700674463 time
train_step spend 0.6359522040002048 time
policy_value spend 0.21713481599726947 time
train_step spend 0.6365667580030276 time
policy_value spend 0.2166524889980792 time
train_step spend 0.6402898330052267 time
policy_value spend 0.21749465799803147 time
kl:0.00611,lr_multiplier:11.391,loss:5.857393741607666,entropy:6.405032634735107,explained_var_old:0.956558824,explained_var_new:0.981586993
output spend 0.0004059799975948408 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007617007999215275 time
recovery_state_mcts_prob spend 0.2844269190027262 time
state_batch spend 0.0018923219977295958 time
mcts_probs_batch spend 0.0069846390033490025 time
winner_batch spend 0.00029405099485302344 time
policy_value spend 0.2180961030026083 time
train_step spend 0.6372153210031684 time
policy_value spend 0.21721557699493133 time
train_step spend 0.6356656049974845 time
policy_value spend 0.2178138349991059 time
train_step spend 0.6362221480012522 time
policy_value spend 0.21721545399486786 time
train_step spend 0.6363753869954962 time
policy_value spend 0.21713882600306533 time
train_step spend 0.6369196169980569 time
policy_value spend 0.21735007200186374 time
kl:0.00394,lr_multiplier:11.391,loss:5.865179061889648,entropy:6.3942084312438965,explained_var_old:0.949444175,explained_var_new:0.968669534
output spend 0.000150685002154205 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010045219998573884 time
recovery_state_mcts_prob spend 0.28507841999817174 time
state_batch spend 0.001877122005680576 time
mcts_probs_batch spend 0.0045366899939836 time
winner_batch spend 0.0003026930062333122 time
policy_value spend 0.21692601699760417 time
train_step spend 0.6359119949993328 time
policy_value spend 0.2166388360055862 time
train_step spend 0.6358593039985863 time
policy_value spend 0.21685553900169907 time
train_step spend 0.636478779000754 time
policy_value spend 0.2168477629966219 time
train_step spend 0.6359919089954928 time
policy_value spend 0.21698783100146102 time
train_step spend 0.6362203120006598 time
policy_value spend 0.21759928800020134 time
kl:0.00964,lr_multiplier:11.391,loss:5.83699369430542,entropy:6.385495185852051,explained_var_old:0.953272641,explained_var_new:0.971224785
output spend 0.00015020600403659046 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010156345000723377 time
recovery_state_mcts_prob spend 0.2895055870030774 time
state_batch spend 0.0018913149979198352 time
mcts_probs_batch spend 0.004960331003530882 time
winner_batch spend 0.00032273899705614895 time
policy_value spend 0.21820270900207106 time
train_step spend 0.6357417010003701 time
policy_value spend 0.21834928899625083 time
train_step spend 0.6354249099968001 time
policy_value spend 0.21771970400004648 time
train_step spend 0.6381335180049064 time
policy_value spend 0.21722081099869683 time
train_step spend 0.6375496789987665 time
policy_value spend 0.21733041800325736 time
train_step spend 0.6367160119989421 time
policy_value spend 0.21805424399644835 time
kl:0.00134,lr_multiplier:11.391,loss:5.836655616760254,entropy:6.391411781311035,explained_var_old:0.957718909,explained_var_new:0.972363353
output spend 0.00017508499877294526 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01340468800481176 time
recovery_state_mcts_prob spend 0.27870931499637663 time
state_batch spend 0.0022870149987284094 time
mcts_probs_batch spend 0.004806333003216423 time
winner_batch spend 0.00037423900357680395 time
policy_value spend 0.21694905699405354 time
train_step spend 0.6355617470035213 time
policy_value spend 0.21680647500033956 time
train_step spend 0.6360106790016289 time
policy_value spend 0.21737407400360098 time
train_step spend 0.6361690959965927 time
policy_value spend 0.21813008000026457 time
train_step spend 0.6607573869987391 time
policy_value spend 0.23006802800227888 time
train_step spend 0.6469431780060404 time
policy_value spend 0.2199059079939616 time
kl:0.00234,lr_multiplier:11.391,loss:5.858982563018799,entropy:6.391919136047363,explained_var_old:0.968777835,explained_var_new:0.978733122
output spend 0.0001603519995114766 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011010723996150773 time
recovery_state_mcts_prob spend 0.27892145900113974 time
state_batch spend 0.0018948740034829825 time
mcts_probs_batch spend 0.004896626000117976 time
winner_batch spend 0.0003059980008401908 time
policy_value spend 0.21643003699864494 time
train_step spend 0.6380162740024389 time
policy_value spend 0.21733676699659554 time
train_step spend 0.6369773830010672 time
policy_value spend 0.21802855499845464 time
train_step spend 0.6364815589986392 time
policy_value spend 0.21710707199963508 time
train_step spend 0.6361392530016019 time
policy_value spend 0.2178033879972645 time
train_step spend 0.6367989290010883 time
policy_value spend 0.21768011099629803 time
kl:0.00226,lr_multiplier:11.391,loss:5.829376697540283,entropy:6.379022598266602,explained_var_old:0.963602245,explained_var_new:0.980629504
output spend 0.00014893000479787588 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007377178997558076 time
recovery_state_mcts_prob spend 0.2772440150001785 time
state_batch spend 0.001829386004828848 time
mcts_probs_batch spend 0.0068243559944676235 time
winner_batch spend 0.00032791600096970797 time
policy_value spend 0.21822981999866897 time
train_step spend 0.6361381969982176 time
policy_value spend 0.21858717500435887 time
train_step spend 0.6370489349937998 time
policy_value spend 0.21740302600665018 time
train_step spend 0.6365513319979073 time
policy_value spend 0.21972862999973586 time
train_step spend 0.6381724750026478 time
policy_value spend 0.21890061299927766 time
train_step spend 0.6391632710001431 time
policy_value spend 0.21821059600188164 time
kl:0.00082,lr_multiplier:11.391,loss:5.857931613922119,entropy:6.383326530456543,explained_var_old:0.962425351,explained_var_new:0.983654499
output spend 0.00016016000154195353 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.015071096997417044 time
recovery_state_mcts_prob spend 0.2739541030023247 time
state_batch spend 0.0018137969964300282 time
mcts_probs_batch spend 0.006869208002171945 time
winner_batch spend 0.000312169999233447 time
policy_value spend 0.21828275499865413 time
train_step spend 0.6368118770042202 time
policy_value spend 0.21883222199539887 time
train_step spend 0.6378860699987854 time
policy_value spend 0.21772230899659917 time
train_step spend 0.6371755979998852 time
policy_value spend 0.22672557800251525 time
train_step spend 0.7373406640035682 time
policy_value spend 0.23183994599821744 time
train_step spend 0.7441118529968662 time
policy_value spend 0.21885896899766522 time
kl:0.00451,lr_multiplier:11.391,loss:5.911166191101074,entropy:6.400430679321289,explained_var_old:0.969227254,explained_var_new:0.980725944
output spend 0.00015349699970101938 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008301188005134463 time
recovery_state_mcts_prob spend 0.2725055060000159 time
state_batch spend 0.001834053997299634 time
mcts_probs_batch spend 0.0164862230012659 time
winner_batch spend 0.0003439249994698912 time
policy_value spend 0.21949001799657708 time
train_step spend 0.6353435019991593 time
policy_value spend 0.22201104700070573 time
train_step spend 0.634877985001367 time
policy_value spend 0.21716575499885948 time
train_step spend 0.6347109970010933 time
policy_value spend 0.21722393000527518 time
train_step spend 0.6370073110010708 time
policy_value spend 0.21763012500014156 time
train_step spend 0.635715328004153 time
policy_value spend 0.21759893799753627 time
kl:0.02281,lr_multiplier:11.391,loss:5.805646896362305,entropy:6.3834967613220215,explained_var_old:0.963123441,explained_var_new:0.982608020
output spend 0.00015219199849525467 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012133905998780392 time
recovery_state_mcts_prob spend 0.2816995440007304 time
state_batch spend 0.0018613540014484897 time
mcts_probs_batch spend 0.007568569999421015 time
winner_batch spend 0.0004348920047050342 time
policy_value spend 0.22741276399756316 time
train_step spend 0.6575395740001113 time
policy_value spend 0.22965776599448873 time
train_step spend 0.6505721380017349 time
policy_value spend 0.21905221899942262 time
train_step spend 0.6353073600039352 time
policy_value spend 0.21683528600260615 time
train_step spend 0.6363852149952436 time
policy_value spend 0.21698396599822445 time
train_step spend 0.6366469540007529 time
policy_value spend 0.2176045879969024 time
kl:0.00696,lr_multiplier:11.391,loss:5.806741237640381,entropy:6.372600555419922,explained_var_old:0.968444645,explained_var_new:0.979473829
output spend 0.00016302400035783648 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013448418998450506 time
recovery_state_mcts_prob spend 0.2726252110005589 time
state_batch spend 0.0018812199996318668 time
mcts_probs_batch spend 0.007128860997909214 time
winner_batch spend 0.00035019300412386656 time
policy_value spend 0.21803176699904725 time
train_step spend 0.6354689159998088 time
policy_value spend 0.21829677899950184 time
train_step spend 0.6365282049955567 time
policy_value spend 0.21731651500158478 time
train_step spend 0.6373479110043263 time
policy_value spend 0.21798914799728664 time
train_step spend 0.6374885569966864 time
policy_value spend 0.21776483199937502 time
train_step spend 0.6357298860020819 time
policy_value spend 0.21765052800037665 time
kl:0.00136,lr_multiplier:11.391,loss:5.75506591796875,entropy:6.344987869262695,explained_var_old:0.964272857,explained_var_new:0.977153301
output spend 0.00014930900215404108 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0071135210018837824 time
recovery_state_mcts_prob spend 0.27942649200122105 time
state_batch spend 0.0018229940033052117 time
mcts_probs_batch spend 0.007044644997222349 time
winner_batch spend 0.00030331600282806903 time
policy_value spend 0.21898387399414787 time
train_step spend 0.6359253499977058 time
policy_value spend 0.2174081670018495 time
train_step spend 0.6362087430024985 time
policy_value spend 0.21741683699656278 time
train_step spend 0.6360463349992642 time
policy_value spend 0.2170521349980845 time
train_step spend 0.6372607660014182 time
policy_value spend 0.21744034699804615 time
train_step spend 0.6365112030034652 time
policy_value spend 0.21747194299678085 time
kl:0.00191,lr_multiplier:11.391,loss:5.881624221801758,entropy:6.370578289031982,explained_var_old:0.955705285,explained_var_new:0.973721921
output spend 0.0003180290004820563 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01091718300449429 time
recovery_state_mcts_prob spend 0.2773756440001307 time
state_batch spend 0.00220982499740785 time
mcts_probs_batch spend 0.006204365003213752 time
winner_batch spend 0.00035977099469164386 time
policy_value spend 0.2182061130006332 time
train_step spend 0.6360280709996005 time
policy_value spend 0.21895400100038387 time
train_step spend 0.6395496130062384 time
policy_value spend 0.21705558999383356 time
train_step spend 0.6439851309987716 time
policy_value spend 0.21728308300225763 time
train_step spend 0.6379303519934183 time
policy_value spend 0.21717041400552262 time
train_step spend 0.6370135489996755 time
policy_value spend 0.21708260600280482 time
kl:0.00814,lr_multiplier:11.391,loss:5.824806213378906,entropy:6.351177215576172,explained_var_old:0.956032276,explained_var_new:0.974126101
output spend 0.0001688289994490333 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011379398994904477 time
recovery_state_mcts_prob spend 0.279702306004765 time
state_batch spend 0.0017961849953280762 time
mcts_probs_batch spend 0.0164722960034851 time
winner_batch spend 0.0003021160009666346 time
policy_value spend 0.22039328800019575 time
train_step spend 0.6377665329928277 time
policy_value spend 0.22179492100258358 time
train_step spend 0.6363834540024982 time
policy_value spend 0.2186470550004742 time
train_step spend 0.636114772001747 time
policy_value spend 0.2177439930019318 time
train_step spend 0.6373080539997318 time
policy_value spend 0.21765644500555936 time
train_step spend 0.6361633420019643 time
policy_value spend 0.2181258729979163 time
kl:0.00796,lr_multiplier:11.391,loss:5.805603504180908,entropy:6.355775833129883,explained_var_old:0.975212991,explained_var_new:0.989234924
output spend 0.00015426900063175708 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012727982000797056 time
recovery_state_mcts_prob spend 0.2709861740004271 time
state_batch spend 0.0018169059985666536 time
mcts_probs_batch spend 0.006760882002708968 time
winner_batch spend 0.0002877890001400374 time
policy_value spend 0.2172291109964135 time
train_step spend 0.6362945000000764 time
policy_value spend 0.21735051100404235 time
train_step spend 0.6356959629993071 time
policy_value spend 0.21762483900238294 time
train_step spend 0.6350905720028095 time
policy_value spend 0.21684189499501372 time
train_step spend 0.6349134400006733 time
policy_value spend 0.21740936399874045 time
train_step spend 0.6361373760009883 time
policy_value spend 0.21726880300411722 time
kl:0.00521,lr_multiplier:11.391,loss:5.843653678894043,entropy:6.369128227233887,explained_var_old:0.964925170,explained_var_new:0.980159104
output spend 0.0001947209966601804 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010315143001207616 time
recovery_state_mcts_prob spend 0.2860130310000386 time
state_batch spend 0.002306859998498112 time
mcts_probs_batch spend 0.00549942900397582 time
winner_batch spend 0.0003259489967604168 time
policy_value spend 0.21704260200203862 time
train_step spend 0.6365005810002913 time
policy_value spend 0.21757239100406878 time
train_step spend 0.6369569480011705 time
policy_value spend 0.21667745000013383 time
train_step spend 0.6370341209985781 time
policy_value spend 0.217057683999883 time
train_step spend 0.6362467639992246 time
policy_value spend 0.2166812760042376 time
train_step spend 0.6368385070018121 time
policy_value spend 0.21783370900084265 time
kl:0.00184,lr_multiplier:11.391,loss:5.856389999389648,entropy:6.347007751464844,explained_var_old:0.962641060,explained_var_new:0.976717234
output spend 0.0001771079987520352 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009092299995245412 time
recovery_state_mcts_prob spend 0.26745737199962605 time
state_batch spend 0.002028683004027698 time
mcts_probs_batch spend 0.004586031995131634 time
winner_batch spend 0.0003004770042025484 time
policy_value spend 0.21630555499723414 time
train_step spend 0.6367084180019447 time
policy_value spend 0.21680564499547472 time
train_step spend 0.6358486120007001 time
policy_value spend 0.21839553299651016 time
train_step spend 0.6364860329995281 time
policy_value spend 0.21884012300142786 time
train_step spend 0.6365040090022376 time
policy_value spend 0.2172653210000135 time
train_step spend 0.6360146920051193 time
policy_value spend 0.21735785399505403 time
kl:0.01623,lr_multiplier:11.391,loss:5.854854106903076,entropy:6.365692615509033,explained_var_old:0.970891774,explained_var_new:0.982781708
output spend 0.00014771199494134635 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01239455099857878 time
recovery_state_mcts_prob spend 0.26740838499972597 time
state_batch spend 0.001856504000897985 time
mcts_probs_batch spend 0.004732490997412242 time
winner_batch spend 0.0003099650057265535 time
policy_value spend 0.21786165500088828 time
train_step spend 0.6360415279996232 time
policy_value spend 0.21834967299946584 time
train_step spend 0.6380035649999627 time
policy_value spend 0.2180499649984995 time
train_step spend 0.6360858309999458 time
policy_value spend 0.21755192899581743 time
train_step spend 0.6363603159988998 time
policy_value spend 0.2174874530028319 time
train_step spend 0.6360726440034341 time
policy_value spend 0.21712951399968006 time
kl:0.03372,lr_multiplier:11.391,loss:5.800400733947754,entropy:6.342766284942627,explained_var_old:0.953114510,explained_var_new:0.970863461
output spend 0.00028342199948383495 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.017599033999431413 time
recovery_state_mcts_prob spend 0.2905115290050162 time
state_batch spend 0.0020887439968646504 time
mcts_probs_batch spend 0.005059016002633143 time
winner_batch spend 0.00029962899861857295 time
policy_value spend 0.22900339600164443 time
train_step spend 0.6535041480019572 time
policy_value spend 0.21814161299698753 time
train_step spend 0.636758253996959 time
policy_value spend 0.21815439000056358 time
train_step spend 0.6362820509966696 time
policy_value spend 0.21880134900129633 time
train_step spend 0.6444408859970281 time
policy_value spend 0.2175020470021991 time
train_step spend 0.6361451359989587 time
policy_value spend 0.21739832800085424 time
kl:0.01475,lr_multiplier:11.391,loss:5.774726390838623,entropy:6.330412864685059,explained_var_old:0.965378582,explained_var_new:0.982335627
output spend 0.00014929199824109674 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00993946300150128 time
recovery_state_mcts_prob spend 0.2745303839983535 time
state_batch spend 0.0018027219994110055 time
mcts_probs_batch spend 0.006203459997777827 time
winner_batch spend 0.00030726499971933663 time
policy_value spend 0.22071507800137624 time
train_step spend 0.638736301996687 time
policy_value spend 0.2176068970002234 time
train_step spend 0.6373083910002606 time
policy_value spend 0.21779482700367225 time
train_step spend 0.637253116001375 time
policy_value spend 0.21815646100003505 time
train_step spend 0.6365604349994101 time
policy_value spend 0.21850930900109233 time
train_step spend 0.636279785001534 time
policy_value spend 0.2181733589968644 time
kl:0.00675,lr_multiplier:11.391,loss:5.753453731536865,entropy:6.325592041015625,explained_var_old:0.969115078,explained_var_new:0.980437279
output spend 0.00015003599401097745 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010803277997183613 time
recovery_state_mcts_prob spend 0.28233812100370415 time
state_batch spend 0.001839653996285051 time
mcts_probs_batch spend 0.0061825099983252585 time
winner_batch spend 0.0002997310002683662 time
policy_value spend 0.21807768300641328 time
train_step spend 0.6360931000017445 time
policy_value spend 0.21694838799885474 time
train_step spend 0.6346192529963446 time
policy_value spend 0.21769743900222238 time
train_step spend 0.6347328219999326 time
policy_value spend 0.21679614599997876 time
train_step spend 0.6357296100031817 time
policy_value spend 0.21728091599652544 time
train_step spend 0.6351135959994281 time
policy_value spend 0.21711865500401473 time
kl:0.00250,lr_multiplier:11.391,loss:5.81074857711792,entropy:6.322024345397949,explained_var_old:0.963933229,explained_var_new:0.982765734
output spend 0.00015284999972209334 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009679199996753596 time
recovery_state_mcts_prob spend 0.27204615699884016 time
state_batch spend 0.00184188800631091 time
mcts_probs_batch spend 0.006509696999273729 time
winner_batch spend 0.0003245150001021102 time
policy_value spend 0.21830541699455353 time
train_step spend 0.6365867929998785 time
policy_value spend 0.21686689300258877 time
train_step spend 0.6349792070031981 time
policy_value spend 0.2188758490010514 time
train_step spend 0.6361773720054771 time
policy_value spend 0.21796553599415347 time
train_step spend 0.6380546759974095 time
policy_value spend 0.2170009699984803 time
train_step spend 0.6367584359977627 time
policy_value spend 0.21773493699583923 time
kl:0.00137,lr_multiplier:11.391,loss:5.745186805725098,entropy:6.324804306030273,explained_var_old:0.958579898,explained_var_new:0.975625813
output spend 0.00015970999811543152 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012139045000367332 time
recovery_state_mcts_prob spend 0.2686881320041721 time
state_batch spend 0.0018167259986512363 time
mcts_probs_batch spend 0.004528049998043571 time
winner_batch spend 0.00029759899916825816 time
policy_value spend 0.2160443890024908 time
train_step spend 0.6356173160020262 time
policy_value spend 0.21743476499977987 time
train_step spend 0.6353841180025483 time
policy_value spend 0.21714842400251655 time
train_step spend 0.6359880289965076 time
policy_value spend 0.21704826500354102 time
train_step spend 0.6351574880027329 time
policy_value spend 0.21742355799506186 time
train_step spend 0.6361065529999905 time
policy_value spend 0.21756654099590378 time
kl:0.00247,lr_multiplier:11.391,loss:5.8169755935668945,entropy:6.3292460441589355,explained_var_old:0.974175870,explained_var_new:0.991748393
output spend 0.00015140799951041117 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00928817100066226 time
recovery_state_mcts_prob spend 0.2752557300045737 time
state_batch spend 0.0018639829941093922 time
mcts_probs_batch spend 0.005984338000416756 time
winner_batch spend 0.0003332780033815652 time
policy_value spend 0.21844995799619937 time
train_step spend 0.6358556710038101 time
policy_value spend 0.21866664799745195 time
train_step spend 0.6352396739966935 time
policy_value spend 0.21736182700260542 time
train_step spend 0.6354684389953036 time
policy_value spend 0.21794848200079286 time
train_step spend 0.6371740430040518 time
policy_value spend 0.2176233999998658 time
train_step spend 0.6357322670010035 time
policy_value spend 0.21782448299927637 time
kl:0.00172,lr_multiplier:11.391,loss:5.816636562347412,entropy:6.3500142097473145,explained_var_old:0.969095588,explained_var_new:0.983612716
output spend 0.00017154499801108614 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012357298997812904 time
recovery_state_mcts_prob spend 0.2825427280040458 time
state_batch spend 0.001877743998193182 time
mcts_probs_batch spend 0.007947767997393385 time
winner_batch spend 0.0003117419983027503 time
policy_value spend 0.2208003030027612 time
train_step spend 0.6360511610037065 time
policy_value spend 0.2212644229948637 time
train_step spend 0.6363670249993447 time
policy_value spend 0.2172555340002873 time
train_step spend 0.636750279001717 time
policy_value spend 0.21746256200276548 time
train_step spend 0.6373598680002033 time
policy_value spend 0.21760617200197885 time
train_step spend 0.6361608860024717 time
policy_value spend 0.21820327199384337 time
kl:0.00833,lr_multiplier:11.391,loss:5.748660087585449,entropy:6.307363510131836,explained_var_old:0.960594893,explained_var_new:0.979742050
output spend 0.00021109599765622988 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013249855001049582 time
recovery_state_mcts_prob spend 0.27314668700273614 time
state_batch spend 0.0017699289965094067 time
mcts_probs_batch spend 0.007337908005865756 time
winner_batch spend 0.00030313799652503803 time
policy_value spend 0.21837077700183727 time
train_step spend 0.637854533000791 time
policy_value spend 0.21790821299509844 time
train_step spend 0.6367924579972168 time
policy_value spend 0.21760717000142904 time
train_step spend 0.6372048939956585 time
policy_value spend 0.2172129250029684 time
train_step spend 0.6371226859992021 time
policy_value spend 0.21753522300423356 time
train_step spend 0.6370324730014545 time
policy_value spend 0.21745810299762525 time
kl:0.00401,lr_multiplier:11.391,loss:5.7256317138671875,entropy:6.325084686279297,explained_var_old:0.969326496,explained_var_new:0.978234351
output spend 0.000183660005859565 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012119036000513006 time
recovery_state_mcts_prob spend 0.28915210899867816 time
state_batch spend 0.0019626389985205606 time
mcts_probs_batch spend 0.011865676002344117 time
winner_batch spend 0.0003076430002693087 time
policy_value spend 0.22015480599657167 time
train_step spend 0.6357569090032484 time
policy_value spend 0.22104533099627588 time
train_step spend 0.634746689000167 time
policy_value spend 0.21962525800336152 time
train_step spend 0.6503330589985126 time
policy_value spend 0.2300975960024516 time
train_step spend 0.6634254420059733 time
policy_value spend 0.21764669199910713 time
train_step spend 0.6382002700047451 time
policy_value spend 0.21675146799680078 time
kl:0.00286,lr_multiplier:11.391,loss:5.72409200668335,entropy:6.3234429359436035,explained_var_old:0.960026145,explained_var_new:0.981211126
output spend 0.00015581399929942563 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008890652003174182 time
recovery_state_mcts_prob spend 0.2652217539944104 time
state_batch spend 0.00228325100033544 time
mcts_probs_batch spend 0.0067309299993212335 time
winner_batch spend 0.00029092100157868117 time
policy_value spend 0.2170156220017816 time
train_step spend 0.6365535349978018 time
policy_value spend 0.21683041399955982 time
train_step spend 0.6349828609963879 time
policy_value spend 0.21730462300183717 time
train_step spend 0.6358059220001451 time
policy_value spend 0.21714109699678374 time
train_step spend 0.6360363109997706 time
policy_value spend 0.21693277400481747 time
train_step spend 0.6373333689989522 time
policy_value spend 0.21867673999804538 time
kl:0.00324,lr_multiplier:11.391,loss:5.754120826721191,entropy:6.309533596038818,explained_var_old:0.962353170,explained_var_new:0.978727043
output spend 0.0001501380029367283 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0148104969994165 time
recovery_state_mcts_prob spend 0.2821126339986222 time
state_batch spend 0.0018925249969470315 time
mcts_probs_batch spend 0.006343667999317404 time
winner_batch spend 0.0002943390063592233 time
policy_value spend 0.21707181799865793 time
train_step spend 0.6363982170005329 time
policy_value spend 0.21729212899663253 time
train_step spend 0.6350975570021546 time
policy_value spend 0.21811728600005154 time
train_step spend 0.6363374089996796 time
policy_value spend 0.21750851099932333 time
train_step spend 0.6364951799987466 time
policy_value spend 0.21769607000169344 time
train_step spend 0.6355839879979612 time
policy_value spend 0.2174359420023393 time
kl:0.00212,lr_multiplier:11.391,loss:5.732974529266357,entropy:6.3104705810546875,explained_var_old:0.968780339,explained_var_new:0.983731508
output spend 0.00014818999625276774 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008168341002601665 time
recovery_state_mcts_prob spend 0.2712093719965196 time
state_batch spend 0.0018383310016361065 time
mcts_probs_batch spend 0.013915834999352228 time
winner_batch spend 0.00031128300179261714 time
policy_value spend 0.22067655799764907 time
train_step spend 0.6372894189989893 time
policy_value spend 0.21742750999692362 time
train_step spend 0.6355053650040645 time
policy_value spend 0.21762523699726444 time
train_step spend 0.634485061003943 time
policy_value spend 0.2172117869995418 time
train_step spend 0.6360699549986748 time
policy_value spend 0.217348405996745 time
train_step spend 0.6364985719992546 time
policy_value spend 0.21720555100182537 time
kl:0.00143,lr_multiplier:11.391,loss:5.72303581237793,entropy:6.300343990325928,explained_var_old:0.971770465,explained_var_new:0.983711302
output spend 0.00015608000103384256 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009464353999646846 time
recovery_state_mcts_prob spend 0.274715642000956 time
state_batch spend 0.0023063119951984845 time
mcts_probs_batch spend 0.007409187004668638 time
winner_batch spend 0.0003176119935233146 time
policy_value spend 0.21859640500042588 time
train_step spend 0.6368816510002944 time
policy_value spend 0.21682784800213994 time
train_step spend 0.6362529519974487 time
policy_value spend 0.2185015739960363 time
train_step spend 0.636405213001126 time
policy_value spend 0.2172704740005429 time
train_step spend 0.6373400929951458 time
policy_value spend 0.21823395200044615 time
train_step spend 0.636221156004467 time
policy_value spend 0.21772202199645108 time
kl:0.00528,lr_multiplier:11.391,loss:5.750884532928467,entropy:6.294079780578613,explained_var_old:0.970973313,explained_var_new:0.978670299
output spend 0.00015237399929901585 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0073128299991367385 time
recovery_state_mcts_prob spend 0.27388925799459685 time
state_batch spend 0.0017263860063394532 time
mcts_probs_batch spend 0.012288849997275975 time
winner_batch spend 0.00032651399669703096 time
policy_value spend 0.2215792870047153 time
train_step spend 0.635950044998026 time
policy_value spend 0.22174985599849606 time
train_step spend 0.6356024400010938 time
policy_value spend 0.2173706960020354 time
train_step spend 0.6364977749981335 time
policy_value spend 0.21778751999954693 time
train_step spend 0.6369256329999189 time
policy_value spend 0.21917776400368894 time
train_step spend 0.6360871600045357 time
policy_value spend 0.2174407290003728 time
kl:0.00294,lr_multiplier:11.391,loss:5.715145587921143,entropy:6.28138542175293,explained_var_old:0.965041578,explained_var_new:0.984451175
output spend 0.00014672300312668085 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007775460006087087 time
recovery_state_mcts_prob spend 0.28416202499647625 time
state_batch spend 0.0019952840011683293 time
mcts_probs_batch spend 0.006076808997022454 time
winner_batch spend 0.00030137900466797873 time
policy_value spend 0.21755394199863076 time
train_step spend 0.6349642920031329 time
policy_value spend 0.21722311800112948 time
train_step spend 0.634937575996446 time
policy_value spend 0.2173981570012984 time
train_step spend 0.6358468940015882 time
policy_value spend 0.2165919170001871 time
train_step spend 0.6352800809982 time
policy_value spend 0.21712007300084224 time
train_step spend 0.6347508109975024 time
policy_value spend 0.21723381099582184 time
kl:0.00296,lr_multiplier:11.391,loss:5.744007110595703,entropy:6.287437438964844,explained_var_old:0.972642660,explained_var_new:0.984433174
output spend 0.0001599160023033619 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007075307999912184 time
recovery_state_mcts_prob spend 0.27258835599786835 time
state_batch spend 0.0017947930027730763 time
mcts_probs_batch spend 0.006646141999226529 time
winner_batch spend 0.0002953200018964708 time
policy_value spend 0.21819645699724788 time
train_step spend 0.6373020719984197 time
policy_value spend 0.21706378200178733 time
train_step spend 0.6362873440011754 time
policy_value spend 0.21721944800083293 time
train_step spend 0.6356614980031736 time
policy_value spend 0.21694498199940426 time
train_step spend 0.6366616110026371 time
policy_value spend 0.21776753500307677 time
train_step spend 0.6349896989995614 time
policy_value spend 0.2171586690019467 time
kl:0.00193,lr_multiplier:11.391,loss:5.765120506286621,entropy:6.312464237213135,explained_var_old:0.964464366,explained_var_new:0.982606828
output spend 0.00015530399832641706 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009766547998879105 time
recovery_state_mcts_prob spend 0.27531550799903926 time
state_batch spend 0.0019030499970540404 time
mcts_probs_batch spend 0.004633715005184058 time
winner_batch spend 0.0003566710001905449 time
policy_value spend 0.2167045549940667 time
train_step spend 0.6354155619992525 time
policy_value spend 0.21753593900211854 time
train_step spend 0.636097989998234 time
policy_value spend 0.2168407520002802 time
train_step spend 0.635209059000772 time
policy_value spend 0.2241436469994369 time
train_step spend 0.6398215160006657 time
policy_value spend 0.21772809499816503 time
train_step spend 0.6358504840027308 time
policy_value spend 0.21770705800008727 time
kl:0.00336,lr_multiplier:11.391,loss:5.690524578094482,entropy:6.284130573272705,explained_var_old:0.976231754,explained_var_new:0.987891436
output spend 0.00014767899847356603 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008819602000585292 time
recovery_state_mcts_prob spend 0.28414856099698227 time
state_batch spend 0.0018912550003733486 time
mcts_probs_batch spend 0.004704468003183138 time
winner_batch spend 0.0003154379955958575 time
policy_value spend 0.21793033800349804 time
train_step spend 0.6692784449987812 time
policy_value spend 0.23023325800022576 time
train_step spend 0.639286361001723 time
policy_value spend 0.2182961649959907 time
train_step spend 0.6359462890031864 time
policy_value spend 0.21750733199587557 time
train_step spend 0.6363957950015902 time
policy_value spend 0.2183027509963722 time
train_step spend 0.6363995920037269 time
policy_value spend 0.21668087800208014 time
kl:0.00917,lr_multiplier:11.391,loss:5.7682366371154785,entropy:6.283003807067871,explained_var_old:0.970524549,explained_var_new:0.980717003
output spend 0.00015280699881259352 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009477077001065481 time
recovery_state_mcts_prob spend 0.28031730499787955 time
state_batch spend 0.0017680070013739169 time
mcts_probs_batch spend 0.0047906070030876435 time
winner_batch spend 0.0003177699982188642 time
policy_value spend 0.2168027629959397 time
train_step spend 0.6354752509942045 time
policy_value spend 0.2176725390017964 time
train_step spend 0.6384728909979458 time
policy_value spend 0.2176831629985827 time
train_step spend 0.6360749360028422 time
policy_value spend 0.21806716400169535 time
train_step spend 0.6373263290006435 time
policy_value spend 0.21830063500237884 time
train_step spend 0.6379583809975884 time
policy_value spend 0.21744111500447616 time
kl:0.00372,lr_multiplier:11.391,loss:5.749722957611084,entropy:6.298104286193848,explained_var_old:0.969579399,explained_var_new:0.984062374
output spend 0.00014597499830415472 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008826595003483817 time
recovery_state_mcts_prob spend 0.2777165539955604 time
state_batch spend 0.0018441979991621338 time
mcts_probs_batch spend 0.006396303004294168 time
winner_batch spend 0.00031257599766831845 time
policy_value spend 0.21791399199719308 time
train_step spend 0.6367643490011687 time
policy_value spend 0.21851621299720136 time
train_step spend 0.6369289549984387 time
policy_value spend 0.21811801200237824 time
train_step spend 0.6368856469998718 time
policy_value spend 0.21809876900078962 time
train_step spend 0.6370681740008877 time
policy_value spend 0.21734741600084817 time
train_step spend 0.637575727996591 time
policy_value spend 0.2178870830030064 time
kl:0.00277,lr_multiplier:11.391,loss:5.7637200355529785,entropy:6.298531532287598,explained_var_old:0.976700962,explained_var_new:0.993210316
output spend 0.00015026700566522777 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007390860999294091 time
recovery_state_mcts_prob spend 0.26901860799989663 time
state_batch spend 0.0018721879969234578 time
mcts_probs_batch spend 0.005671395003446378 time
winner_batch spend 0.0004530000005615875 time
policy_value spend 0.2171133439987898 time
train_step spend 0.636396509995393 time
policy_value spend 0.21779351599980146 time
train_step spend 0.6357688890057034 time
policy_value spend 0.21750091799913207 time
train_step spend 0.638603764004074 time
policy_value spend 0.21745892699982505 time
train_step spend 0.6356047419976676 time
policy_value spend 0.21687539399863454 time
train_step spend 0.6370212199981324 time
policy_value spend 0.2173985920017003 time
kl:0.00908,lr_multiplier:11.391,loss:5.695847988128662,entropy:6.2831926345825195,explained_var_old:0.967496037,explained_var_new:0.978012562
output spend 0.00016114499885588884 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007516183002735488 time
recovery_state_mcts_prob spend 0.27470305300084874 time
state_batch spend 0.0017708899977151304 time
mcts_probs_batch spend 0.00577067700214684 time
winner_batch spend 0.00046292499609990045 time
policy_value spend 0.21672852300252998 time
train_step spend 0.6357456889963942 time
policy_value spend 0.21793581800011452 time
train_step spend 0.6354954259950318 time
policy_value spend 0.21738142699905438 time
train_step spend 0.6353060980036389 time
policy_value spend 0.21747132200107444 time
train_step spend 0.637054132996127 time
policy_value spend 0.21805760700226529 time
train_step spend 0.6352823289998923 time
policy_value spend 0.21750263700232608 time
kl:0.00174,lr_multiplier:11.391,loss:5.7331671714782715,entropy:6.297837734222412,explained_var_old:0.968784451,explained_var_new:0.979779899
output spend 0.00014916000509401783 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008011874000658281 time
recovery_state_mcts_prob spend 0.2821439859981183 time
state_batch spend 0.002129622000211384 time
mcts_probs_batch spend 0.006679186997644138 time
winner_batch spend 0.0002960359997814521 time
policy_value spend 0.2165704500002903 time
train_step spend 0.6360484220058424 time
policy_value spend 0.21873872599826427 time
train_step spend 0.6350517600003514 time
policy_value spend 0.21741937800106825 time
train_step spend 0.6353838540017023 time
policy_value spend 0.21669978599675233 time
train_step spend 0.636329843000567 time
policy_value spend 0.21742017699580174 time
train_step spend 0.6361903289944166 time
policy_value spend 0.21825142800662434 time
kl:0.00993,lr_multiplier:11.391,loss:5.770699501037598,entropy:6.289834499359131,explained_var_old:0.973045707,explained_var_new:0.984876692
output spend 0.00020833000598940998 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012072389996319544 time
recovery_state_mcts_prob spend 0.2774818390025757 time
state_batch spend 0.0017770140038919635 time
mcts_probs_batch spend 0.015917272998194676 time
winner_batch spend 0.00029230099607957527 time
policy_value spend 0.22119091400236357 time
train_step spend 0.6363611449996824 time
policy_value spend 0.21775983199768234 time
train_step spend 0.63658943700284 time
policy_value spend 0.21810247599933064 time
train_step spend 0.6353683039997122 time
policy_value spend 0.2177046770011657 time
train_step spend 0.6360286479975912 time
policy_value spend 0.21813175799616147 time
train_step spend 0.6374842279983568 time
policy_value spend 0.21747152299940353 time
kl:0.00758,lr_multiplier:11.391,loss:5.713894367218018,entropy:6.280333995819092,explained_var_old:0.963375330,explained_var_new:0.979861498
output spend 0.00019738600531127304 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009775503000128083 time
recovery_state_mcts_prob spend 0.272141385001305 time
state_batch spend 0.001815629999327939 time
mcts_probs_batch spend 0.006168680003611371 time
winner_batch spend 0.0002866289942176081 time
policy_value spend 0.21829668500140542 time
train_step spend 0.6359845089973533 time
policy_value spend 0.21786109999811742 time
train_step spend 0.6375374790004571 time
policy_value spend 0.21737213100277586 time
train_step spend 0.6365174509992357 time
policy_value spend 0.21755407400632976 time
train_step spend 0.6377901300002122 time
policy_value spend 0.21731296600046335 time
train_step spend 0.6373261190019548 time
policy_value spend 0.21790597200015327 time
kl:0.00968,lr_multiplier:11.391,loss:5.6495819091796875,entropy:6.280694007873535,explained_var_old:0.977012455,explained_var_new:0.988121867
output spend 0.00017265899805352092 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007067594000545796 time
recovery_state_mcts_prob spend 0.28397546899941517 time
state_batch spend 0.0022169160001794808 time
mcts_probs_batch spend 0.007018566997430753 time
winner_batch spend 0.0002964450031868182 time
policy_value spend 0.21839802600152325 time
train_step spend 0.6384670219995314 time
policy_value spend 0.21779237699956866 time
train_step spend 0.6367656810034532 time
policy_value spend 0.21782915399671765 time
train_step spend 0.6371114220019081 time
policy_value spend 0.21766393999860156 time
train_step spend 0.6380029319989262 time
policy_value spend 0.22760398000536952 time
train_step spend 0.6588677760009887 time
policy_value spend 0.23034530299628386 time
kl:0.00171,lr_multiplier:11.391,loss:5.72764253616333,entropy:6.279203414916992,explained_var_old:0.976129413,explained_var_new:0.988226831
output spend 0.0002231580001534894 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009163066999462899 time
recovery_state_mcts_prob spend 0.28114741099852836 time
state_batch spend 0.0018547770014265552 time
mcts_probs_batch spend 0.004607210001267958 time
winner_batch spend 0.0002931459966930561 time
policy_value spend 0.2181672470032936 time
train_step spend 0.6365832849987783 time
policy_value spend 0.2171344120069989 time
train_step spend 0.637521017997642 time
policy_value spend 0.2174250289972406 time
train_step spend 0.6373199100053171 time
policy_value spend 0.21789833199727582 time
train_step spend 0.6376625760021852 time
policy_value spend 0.21826703399710823 time
train_step spend 0.6379631030067685 time
policy_value spend 0.2182204099954106 time
kl:0.00354,lr_multiplier:11.391,loss:5.676037311553955,entropy:6.286924839019775,explained_var_old:0.972054780,explained_var_new:0.991657436
output spend 0.000224426003114786 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007081748997734394 time
recovery_state_mcts_prob spend 0.26982212000439176 time
state_batch spend 0.0019407989966566674 time
mcts_probs_batch spend 0.005868706997716799 time
winner_batch spend 0.00029290800011949614 time
policy_value spend 0.21693609400244895 time
train_step spend 0.6385159330020542 time
policy_value spend 0.21985253499587998 time
train_step spend 0.6349840920011047 time
policy_value spend 0.21718967199558392 time
train_step spend 0.635464895000041 time
policy_value spend 0.21758565500203986 time
train_step spend 0.6356163079981343 time
policy_value spend 0.21721615699789254 time
train_step spend 0.6351547529993695 time
policy_value spend 0.2176997560018208 time
kl:0.01017,lr_multiplier:11.391,loss:5.648510932922363,entropy:6.252450942993164,explained_var_old:0.979352951,explained_var_new:0.990242958
output spend 0.0001999870000872761 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010652709002897609 time
recovery_state_mcts_prob spend 0.2757944420009153 time
state_batch spend 0.0018102009998983704 time
mcts_probs_batch spend 0.012242523000168148 time
winner_batch spend 0.00033759699726942927 time
policy_value spend 0.21672825000132434 time
train_step spend 0.6364180430027773 time
policy_value spend 0.21619121799449204 time
train_step spend 0.6357984909991501 time
policy_value spend 0.21776690499973483 time
train_step spend 0.6354691550004645 time
policy_value spend 0.21733864000270842 time
train_step spend 0.6364959079946857 time
policy_value spend 0.21740439800487366 time
train_step spend 0.6361946699980763 time
policy_value spend 0.217337039000995 time
kl:0.01638,lr_multiplier:11.391,loss:5.634084224700928,entropy:6.241109848022461,explained_var_old:0.975312591,explained_var_new:0.983628571
output spend 0.00016262200369965285 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006922067004779819 time
recovery_state_mcts_prob spend 0.27560001899837516 time
state_batch spend 0.0017929680034285411 time
mcts_probs_batch spend 0.006154041999252513 time
winner_batch spend 0.00034644699917407706 time
policy_value spend 0.21590024099714356 time
train_step spend 0.6367957629990997 time
policy_value spend 0.21770664300129283 time
train_step spend 0.6343785149947507 time
policy_value spend 0.21743568999954732 time
train_step spend 0.6358521540023503 time
policy_value spend 0.2170205009970232 time
train_step spend 0.6352274599994416 time
policy_value spend 0.21713822800666094 time
train_step spend 0.6348389060003683 time
policy_value spend 0.217699504995835 time
kl:0.00483,lr_multiplier:11.391,loss:5.713807106018066,entropy:6.240055084228516,explained_var_old:0.976337433,explained_var_new:0.983311832
output spend 0.00014619199646404013 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0084267659985926 time
recovery_state_mcts_prob spend 0.27640802699897904 time
state_batch spend 0.0018059659996652044 time
mcts_probs_batch spend 0.004926171000988688 time
winner_batch spend 0.0003232099988963455 time
policy_value spend 0.21716195900080493 time
train_step spend 0.6360524179981439 time
policy_value spend 0.21866400099679595 time
train_step spend 0.6373751249993802 time
policy_value spend 0.21818735599663341 time
train_step spend 0.637750337999023 time
policy_value spend 0.2181364019998 time
train_step spend 0.6390151569939917 time
policy_value spend 0.21798391700576758 time
train_step spend 0.6374622759976774 time
policy_value spend 0.217598845003522 time
kl:0.00339,lr_multiplier:11.391,loss:5.6610565185546875,entropy:6.246057510375977,explained_var_old:0.973742843,explained_var_new:0.986330211
output spend 0.0001902069998322986 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008227102996897884 time
recovery_state_mcts_prob spend 0.28040691400383366 time
state_batch spend 0.0018940730005851947 time
mcts_probs_batch spend 0.0066038799996022135 time
winner_batch spend 0.00027656399470288306 time
policy_value spend 0.2192540540054324 time
train_step spend 0.6392386950028595 time
policy_value spend 0.22000273999583442 time
train_step spend 0.6372069329954684 time
policy_value spend 0.21824902100343024 time
train_step spend 0.6378385849966435 time
policy_value spend 0.21753618700313382 time
train_step spend 0.6377782940035104 time
policy_value spend 0.21850685100071132 time
train_step spend 0.6391831360015203 time
policy_value spend 0.21828064900182653 time
kl:0.00475,lr_multiplier:11.391,loss:5.654242515563965,entropy:6.232636451721191,explained_var_old:0.967508793,explained_var_new:0.979164124
output spend 0.00014800200005993247 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007942641001136508 time
recovery_state_mcts_prob spend 0.2713938379965839 time
state_batch spend 0.0022491760028060526 time
mcts_probs_batch spend 0.016771187001722865 time
winner_batch spend 0.0003026199992746115 time
policy_value spend 0.22160605999670224 time
train_step spend 0.6404163979968871 time
policy_value spend 0.21760906300187344 time
train_step spend 0.6387996720004594 time
policy_value spend 0.21827576299983775 time
train_step spend 0.6379078870013473 time
policy_value spend 0.2182568869975512 time
train_step spend 0.6385145120002562 time
policy_value spend 0.2187765440030489 time
train_step spend 0.6379129830020247 time
policy_value spend 0.2183022359968163 time
kl:0.00168,lr_multiplier:11.391,loss:5.652505397796631,entropy:6.2366838455200195,explained_var_old:0.975891829,explained_var_new:0.985485554
output spend 0.00019985400285804644 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012904989998787642 time
recovery_state_mcts_prob spend 0.2800961280008778 time
state_batch spend 0.0017997399991145357 time
mcts_probs_batch spend 0.005553045004489832 time
winner_batch spend 0.0002823210015776567 time
policy_value spend 0.21811791299842298 time
train_step spend 0.6394228739954997 time
policy_value spend 0.21754199800489005 time
train_step spend 0.6367791660013609 time
policy_value spend 0.21784345399646554 time
train_step spend 0.6362127259999397 time
policy_value spend 0.2172007789995405 time
train_step spend 0.6376417389983544 time
policy_value spend 0.21835229999851435 time
train_step spend 0.6359026869977242 time
policy_value spend 0.21853079800348496 time
kl:0.00309,lr_multiplier:11.391,loss:5.6275739669799805,entropy:6.23528528213501,explained_var_old:0.980402946,explained_var_new:0.988174617
output spend 0.0001948120043380186 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007244733002153225 time
recovery_state_mcts_prob spend 0.2734533269976964 time
state_batch spend 0.0018531570021877997 time
mcts_probs_batch spend 0.005760569998528808 time
winner_batch spend 0.0007022179997875355 time
policy_value spend 0.22499538699776167 time
train_step spend 0.6584313190032844 time
policy_value spend 0.22979151499748696 time
train_step spend 0.6522162639957969 time
policy_value spend 0.21821948000433622 time
train_step spend 0.6371270610034117 time
policy_value spend 0.217215855998802 time
train_step spend 0.6349984919943381 time
policy_value spend 0.21698110500437906 time
train_step spend 0.6356105399972876 time
policy_value spend 0.21672982400195906 time
kl:0.00168,lr_multiplier:11.391,loss:5.668966293334961,entropy:6.262956619262695,explained_var_old:0.984790921,explained_var_new:0.989794195
output spend 0.00025256400112994015 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007886229002906475 time
recovery_state_mcts_prob spend 0.2723744000031729 time
state_batch spend 0.0019025239962502383 time
mcts_probs_batch spend 0.0060108410034445114 time
winner_batch spend 0.00029055999766569585 time
policy_value spend 0.216191831001197 time
train_step spend 0.6359928730016691 time
policy_value spend 0.2179074000014225 time
train_step spend 0.6364765259932028 time
policy_value spend 0.21756567300326424 time
train_step spend 0.6356956939998781 time
policy_value spend 0.21697102399775758 time
train_step spend 0.6344738240004517 time
policy_value spend 0.21752327000285732 time
train_step spend 0.6351200729986886 time
policy_value spend 0.2167580910027027 time
kl:0.00587,lr_multiplier:11.391,loss:5.648349761962891,entropy:6.239274501800537,explained_var_old:0.986302793,explained_var_new:0.994837701
output spend 0.00014822000230196863 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007426042997394688 time
recovery_state_mcts_prob spend 0.279596776003018 time
state_batch spend 0.0019061999992118217 time
mcts_probs_batch spend 0.004987038002582267 time
winner_batch spend 0.00032420399656984955 time
policy_value spend 0.2168829630027176 time
train_step spend 0.6352705319950473 time
policy_value spend 0.21815505500126164 time
train_step spend 0.6371538550010882 time
policy_value spend 0.21814492200064706 time
train_step spend 0.6379170440050075 time
policy_value spend 0.2181572289991891 time
train_step spend 0.6367382400057977 time
policy_value spend 0.21793442499620141 time
train_step spend 0.6373643219994847 time
policy_value spend 0.21800949400494574 time
kl:0.00274,lr_multiplier:11.391,loss:5.649438858032227,entropy:6.255582809448242,explained_var_old:0.973390281,explained_var_new:0.986478388
output spend 0.00015023400192148983 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008690130001923535 time
recovery_state_mcts_prob spend 0.271717998002714 time
state_batch spend 0.0018926859993371181 time
mcts_probs_batch spend 0.005553748000238556 time
winner_batch spend 0.00029900899971835315 time
policy_value spend 0.21708205100003397 time
train_step spend 0.6368231429951265 time
policy_value spend 0.21973355100635672 time
train_step spend 0.6370488140019006 time
policy_value spend 0.21813653699791757 time
train_step spend 0.63724026500131 time
policy_value spend 0.21786443000019062 time
train_step spend 0.6394760660041356 time
policy_value spend 0.21966579899890348 time
train_step spend 0.6447048469999572 time
policy_value spend 0.21831643099721987 time
kl:0.00165,lr_multiplier:11.391,loss:5.67219877243042,entropy:6.253143310546875,explained_var_old:0.979408562,explained_var_new:0.994246304
output spend 0.0001621589981368743 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00806896200083429 time
recovery_state_mcts_prob spend 0.27774436700565275 time
state_batch spend 0.001936661996296607 time
mcts_probs_batch spend 0.0074430419990676455 time
winner_batch spend 0.0003045920020667836 time
policy_value spend 0.21946981999644777 time
train_step spend 0.6391566750025959 time
policy_value spend 0.21878385199670447 time
train_step spend 0.640005838999059 time
policy_value spend 0.21924672099703457 time
train_step spend 0.6410256599992863 time
policy_value spend 0.21857673300110037 time
train_step spend 0.6406927749994793 time
policy_value spend 0.2191516140010208 time
train_step spend 0.6397929439990548 time
policy_value spend 0.21893103500042344 time
kl:0.00516,lr_multiplier:11.391,loss:5.661376953125,entropy:6.253354549407959,explained_var_old:0.981362939,explained_var_new:0.992133081
output spend 0.00016116299957502633 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070856899983482435 time
recovery_state_mcts_prob spend 0.2823575410002377 time
state_batch spend 0.0018084559997078031 time
mcts_probs_batch spend 0.00727480799832847 time
winner_batch spend 0.0002886400034185499 time
policy_value spend 0.2224586750016897 time
train_step spend 0.6396664249987225 time
policy_value spend 0.21755372700135922 time
train_step spend 0.6387658219973673 time
policy_value spend 0.2184187400052906 time
train_step spend 0.6386571259936318 time
policy_value spend 0.2184607350063743 time
train_step spend 0.6378584419944673 time
policy_value spend 0.2187570610039984 time
train_step spend 0.6377990209948621 time
policy_value spend 0.21846963700227207 time
kl:0.00398,lr_multiplier:11.391,loss:5.676074028015137,entropy:6.254036903381348,explained_var_old:0.971123815,explained_var_new:0.981633365
output spend 0.00015320300008170307 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011446710996096954 time
recovery_state_mcts_prob spend 0.2782309410031303 time
state_batch spend 0.0017816129984566942 time
mcts_probs_batch spend 0.0065227730010519736 time
winner_batch spend 0.0002844720002030954 time
policy_value spend 0.21913451599539258 time
train_step spend 0.6388207529962528 time
policy_value spend 0.217708191004931 time
train_step spend 0.6381234229993424 time
policy_value spend 0.218422896003176 time
train_step spend 0.6378580169985071 time
policy_value spend 0.2179437049999251 time
train_step spend 0.6347938549952232 time
policy_value spend 0.2165003410045756 time
train_step spend 0.6338063380026142 time
policy_value spend 0.2165500909977709 time
kl:0.00715,lr_multiplier:11.391,loss:5.620971202850342,entropy:6.220161437988281,explained_var_old:0.972798586,explained_var_new:0.987927198
output spend 0.00015232599980663508 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007437683001626283 time
recovery_state_mcts_prob spend 0.2793355760004488 time
state_batch spend 0.0017869090006570332 time
mcts_probs_batch spend 0.006772979999368545 time
winner_batch spend 0.00030256299942266196 time
policy_value spend 0.2172772600024473 time
train_step spend 0.6354924199986272 time
policy_value spend 0.21675471399794333 time
train_step spend 0.6349133539988543 time
policy_value spend 0.21702720900066197 time
train_step spend 0.6354581020059413 time
policy_value spend 0.21688768599415198 time
train_step spend 0.6373482619965216 time
policy_value spend 0.21806080600072164 time
train_step spend 0.6347182840036112 time
policy_value spend 0.21665657899575308 time
kl:0.00221,lr_multiplier:11.391,loss:5.640747547149658,entropy:6.23687744140625,explained_var_old:0.973914683,explained_var_new:0.981866360
output spend 0.0001514999967184849 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007535026998084504 time
recovery_state_mcts_prob spend 0.2706654850044288 time
state_batch spend 0.0017613550007808954 time
mcts_probs_batch spend 0.0066298179954173975 time
winner_batch spend 0.0003021730008185841 time
policy_value spend 0.21707244100252865 time
train_step spend 0.6381344170004013 time
policy_value spend 0.21709960600128397 time
train_step spend 0.636623457998212 time
policy_value spend 0.21745355400344124 time
train_step spend 0.6370898769964697 time
policy_value spend 0.21760778500174638 time
train_step spend 0.6361450240001432 time
policy_value spend 0.21860415000264766 time
train_step spend 0.6363574329952826 time
policy_value spend 0.2179458290047478 time
kl:0.00196,lr_multiplier:11.391,loss:5.6388630867004395,entropy:6.230260848999023,explained_var_old:0.985569477,explained_var_new:0.992168069
output spend 0.00027314100589137524 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010442658996907994 time
recovery_state_mcts_prob spend 0.2943919530007406 time
state_batch spend 0.0018794479983625934 time
mcts_probs_batch spend 0.005841366000822745 time
winner_batch spend 0.000325965003867168 time
policy_value spend 0.23069253799621947 time
train_step spend 0.6563538249974954 time
policy_value spend 0.21872862100281054 time
train_step spend 0.6376921520059113 time
policy_value spend 0.21786521199828712 time
train_step spend 0.6360851509962231 time
policy_value spend 0.21779240500472952 time
train_step spend 0.6417405850006617 time
policy_value spend 0.21892152100190287 time
train_step spend 0.6401025439990917 time
policy_value spend 0.21950542999547906 time
kl:0.00157,lr_multiplier:11.391,loss:5.651475429534912,entropy:6.232076644897461,explained_var_old:0.968239784,explained_var_new:0.982164979
output spend 0.00015380900003947318 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009658103001129348 time
recovery_state_mcts_prob spend 0.27774258199497126 time
state_batch spend 0.0022204640044947155 time
mcts_probs_batch spend 0.012779174001479987 time
winner_batch spend 0.0003653979947557673 time
policy_value spend 0.22228373899997678 time
train_step spend 0.639137074998871 time
policy_value spend 0.2229909269954078 time
train_step spend 0.6404132479947293 time
policy_value spend 0.21871169500082033 time
train_step spend 0.6397278720032773 time
policy_value spend 0.2184235059976345 time
train_step spend 0.6410248799948022 time
policy_value spend 0.21979001600266201 time
train_step spend 0.6408363779992214 time
policy_value spend 0.22116937099781353 time
kl:0.00380,lr_multiplier:11.391,loss:5.6506147384643555,entropy:6.226810455322266,explained_var_old:0.973954141,explained_var_new:0.987923205
output spend 0.00016632100596325472 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007785919005982578 time
recovery_state_mcts_prob spend 0.2693525989961927 time
state_batch spend 0.0017988359977607615 time
mcts_probs_batch spend 0.006878038999275304 time
winner_batch spend 0.00028978800401091576 time
policy_value spend 0.21534291499847313 time
train_step spend 0.6308715129998745 time
policy_value spend 0.21460432500316529 time
train_step spend 0.6286738889975823 time
policy_value spend 0.21506160600256408 time
train_step spend 0.6294214429944986 time
policy_value spend 0.21464609100075904 time
train_step spend 0.6286961910009268 time
policy_value spend 0.2155084190017078 time
train_step spend 0.6281774829985807 time
policy_value spend 0.2155292620009277 time
kl:0.00942,lr_multiplier:11.391,loss:5.593174457550049,entropy:6.20591926574707,explained_var_old:0.972493827,explained_var_new:0.987553358
output spend 0.0001549279986647889 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00893131200427888 time
recovery_state_mcts_prob spend 0.2729268429975491 time
state_batch spend 0.001860574004240334 time
mcts_probs_batch spend 0.006510535997222178 time
winner_batch spend 0.0003275069975643419 time
policy_value spend 0.21477518900064752 time
train_step spend 0.6297542920001433 time
policy_value spend 0.21496912200382212 time
train_step spend 0.6299402889999328 time
policy_value spend 0.21472727899526944 time
train_step spend 0.629285479997634 time
policy_value spend 0.21559788600279717 time
train_step spend 0.6325402139991638 time
policy_value spend 0.21833134999906179 time
train_step spend 0.6338082860020222 time
policy_value spend 0.21605654299492016 time
kl:0.00235,lr_multiplier:11.391,loss:5.615897178649902,entropy:6.210389137268066,explained_var_old:0.983505487,explained_var_new:0.989392400
output spend 0.00014839199866401032 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006951321003725752 time
recovery_state_mcts_prob spend 0.2884325060003903 time
state_batch spend 0.0021735059999627993 time
mcts_probs_batch spend 0.004916626996418927 time
winner_batch spend 0.00029494299815269187 time
policy_value spend 0.21597536300396314 time
train_step spend 0.6333453580009518 time
policy_value spend 0.21646106399566634 time
train_step spend 0.6332619309978327 time
policy_value spend 0.21620845100551378 time
train_step spend 0.6343192749991431 time
policy_value spend 0.21660484799940605 time
train_step spend 0.633748348998779 time
policy_value spend 0.21691032500530127 time
train_step spend 0.6333792439982062 time
policy_value spend 0.21699018599611009 time
kl:0.00926,lr_multiplier:11.391,loss:5.555790901184082,entropy:6.175956726074219,explained_var_old:0.979587734,explained_var_new:0.988995254
output spend 0.0001464099987060763 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007610182001371868 time
recovery_state_mcts_prob spend 0.27288238199980697 time
state_batch spend 0.0019907899986719713 time
mcts_probs_batch spend 0.004779804999998305 time
winner_batch spend 0.00029003099916735664 time
policy_value spend 0.21780746600416023 time
train_step spend 0.638251707998279 time
policy_value spend 0.21811906099901535 time
train_step spend 0.6380856269970536 time
policy_value spend 0.21859455200319644 time
train_step spend 0.6378362019968336 time
policy_value spend 0.21837169300124515 time
train_step spend 0.6381540120055433 time
policy_value spend 0.21882168999582063 time
train_step spend 0.6390393249967019 time
policy_value spend 0.2178080440062331 time
kl:0.00491,lr_multiplier:11.391,loss:5.640908718109131,entropy:6.217992782592773,explained_var_old:0.965342820,explained_var_new:0.980965495
output spend 0.00015100799646461383 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006920706000528298 time
recovery_state_mcts_prob spend 0.28102634099923307 time
state_batch spend 0.0018604420038172975 time
mcts_probs_batch spend 0.007245572000101674 time
winner_batch spend 0.00037522200000239536 time
policy_value spend 0.21833168499870226 time
train_step spend 0.6388283519991091 time
policy_value spend 0.22000812199985376 time
train_step spend 0.6383316909996211 time
policy_value spend 0.21844099499867298 time
train_step spend 0.6387612779944902 time
policy_value spend 0.21870605100411922 time
train_step spend 0.6428474289932637 time
policy_value spend 0.21897442800400313 time
train_step spend 0.6428063459970872 time
policy_value spend 0.2196536589981406 time
kl:0.00297,lr_multiplier:11.391,loss:5.643899440765381,entropy:6.217328071594238,explained_var_old:0.971154273,explained_var_new:0.984949529
output spend 0.00019880200125044212 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007476341997971758 time
recovery_state_mcts_prob spend 0.2781097890037927 time
state_batch spend 0.0018704100002651103 time
mcts_probs_batch spend 0.00717043099575676 time
winner_batch spend 0.00032907000422710553 time
policy_value spend 0.22008236900001066 time
train_step spend 0.6430960490033613 time
policy_value spend 0.22044496799935587 time
train_step spend 0.643225050996989 time
policy_value spend 0.21959221500583226 time
train_step spend 0.64331072299683 time
policy_value spend 0.21936476699920604 time
train_step spend 0.6427476910030236 time
policy_value spend 0.22021457299706526 time
train_step spend 0.6434100839978782 time
policy_value spend 0.21988104699994437 time
kl:0.00299,lr_multiplier:11.391,loss:5.631772041320801,entropy:6.227724075317383,explained_var_old:0.987265229,explained_var_new:0.990830243
output spend 0.00016211500042118132 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008287832002679352 time
recovery_state_mcts_prob spend 0.2804254970033071 time
state_batch spend 0.0018283129975316115 time
mcts_probs_batch spend 0.006887315998028498 time
winner_batch spend 0.000291919001028873 time
policy_value spend 0.21904179400007706 time
train_step spend 0.6418114810003317 time
policy_value spend 0.219839471996238 time
train_step spend 0.6413289270058158 time
policy_value spend 0.21892045199638233 time
train_step spend 0.6572743590004393 time
policy_value spend 0.23155836300429655 time
train_step spend 0.6685717689979356 time
policy_value spend 0.2205682620042353 time
train_step spend 0.6433122510061366 time
policy_value spend 0.21906574799504597 time
kl:0.00526,lr_multiplier:11.391,loss:5.615482330322266,entropy:6.211185932159424,explained_var_old:0.986960530,explained_var_new:0.991479397
output spend 0.00021027700131526217 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00901268999587046 time
recovery_state_mcts_prob spend 0.2807752730004722 time
state_batch spend 0.0017898270016303286 time
mcts_probs_batch spend 0.007050168002024293 time
winner_batch spend 0.00035684099566424266 time
policy_value spend 0.21970388900081161 time
train_step spend 0.6417007089985418 time
policy_value spend 0.22104457899695262 time
train_step spend 0.6442234569985885 time
policy_value spend 0.21887779200187651 time
train_step spend 0.6341794750042027 time
policy_value spend 0.2113934369990602 time
train_step spend 0.6191206330040586 time
policy_value spend 0.21061064199602697 time
train_step spend 0.618829758001084 time
policy_value spend 0.21063497199793346 time
kl:0.00602,lr_multiplier:11.391,loss:5.5948944091796875,entropy:6.222084999084473,explained_var_old:0.979535520,explained_var_new:0.991894066
output spend 0.000160905001393985 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007158154003263917 time
recovery_state_mcts_prob spend 0.27267326999572106 time
state_batch spend 0.0018492450035410002 time
mcts_probs_batch spend 0.006994824994762894 time
winner_batch spend 0.00031685300200479105 time
policy_value spend 0.2123407050021342 time
train_step spend 0.6181801310012816 time
policy_value spend 0.21120251699903747 time
train_step spend 0.6191984719989705 time
policy_value spend 0.21196895100001711 time
train_step spend 0.6188732019945746 time
policy_value spend 0.2113605480044498 time
train_step spend 0.6188132110037259 time
policy_value spend 0.21123496899963357 time
train_step spend 0.6179244060040219 time
policy_value spend 0.21187152699712897 time
kl:0.00300,lr_multiplier:11.391,loss:5.601110458374023,entropy:6.190991401672363,explained_var_old:0.970262647,explained_var_new:0.975976646
output spend 0.0001454130033380352 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012260865005373489 time
recovery_state_mcts_prob spend 0.2727674559937441 time
state_batch spend 0.00202804400032619 time
mcts_probs_batch spend 0.005756758000643458 time
winner_batch spend 0.0003051790044992231 time
policy_value spend 0.21782160599832423 time
train_step spend 0.6402039259992307 time
policy_value spend 0.21880101900023874 time
train_step spend 0.6400152809947031 time
policy_value spend 0.21843218700087164 time
train_step spend 0.6403699850052362 time
policy_value spend 0.21833363799669314 time
train_step spend 0.6402693549971445 time
policy_value spend 0.21885817300062627 time
train_step spend 0.6403071060049115 time
policy_value spend 0.2190914730017539 time
kl:0.00732,lr_multiplier:11.391,loss:5.619522571563721,entropy:6.204348564147949,explained_var_old:0.977097511,explained_var_new:0.986598909
output spend 0.00015344200073741376 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008830924998619594 time
recovery_state_mcts_prob spend 0.275722518999828 time
state_batch spend 0.001782804996764753 time
mcts_probs_batch spend 0.0061027660049148835 time
winner_batch spend 0.0002947799948742613 time
policy_value spend 0.21925342300528428 time
train_step spend 0.6414693579936284 time
policy_value spend 0.21789501100283815 time
train_step spend 0.6393598889990244 time
policy_value spend 0.21822647199587664 time
train_step spend 0.6374364660005085 time
policy_value spend 0.21428827400086448 time
train_step spend 0.6263429640021059 time
policy_value spend 0.21353381999506382 time
train_step spend 0.6266157430000021 time
policy_value spend 0.21343467899714597 time
kl:0.00262,lr_multiplier:11.391,loss:5.5938262939453125,entropy:6.199644088745117,explained_var_old:0.960561216,explained_var_new:0.973414123
output spend 0.00014382100198417902 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007218596001621336 time
recovery_state_mcts_prob spend 0.2644822279980872 time
state_batch spend 0.0017380429999320768 time
mcts_probs_batch spend 0.004676278003898915 time
winner_batch spend 0.00029299599555088207 time
policy_value spend 0.21249392800382338 time
train_step spend 0.625814293998701 time
policy_value spend 0.21354681100638118 time
train_step spend 0.6262859650014434 time
policy_value spend 0.21386263499880442 time
train_step spend 0.6249161539963097 time
policy_value spend 0.2147046460013371 time
train_step spend 0.6256723080005031 time
policy_value spend 0.2141662450012518 time
train_step spend 0.6258589209974161 time
policy_value spend 0.2145895659996313 time
kl:0.00171,lr_multiplier:11.391,loss:5.591660499572754,entropy:6.204360485076904,explained_var_old:0.978608012,explained_var_new:0.988738716
output spend 0.00015613700088579208 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007158808002714068 time
recovery_state_mcts_prob spend 0.2729207949960255 time
state_batch spend 0.0018288650026079267 time
mcts_probs_batch spend 0.005215853998379316 time
winner_batch spend 0.0003284900012658909 time
policy_value spend 0.21599831600178732 time
train_step spend 0.6352688609986217 time
policy_value spend 0.21648979500605492 time
train_step spend 0.6348202310036868 time
policy_value spend 0.21729382199555403 time
train_step spend 0.6350711970007978 time
policy_value spend 0.21774439499859 time
train_step spend 0.6357962049951311 time
policy_value spend 0.21707765300379833 time
train_step spend 0.6355783239996526 time
policy_value spend 0.21724424899730366 time
kl:0.00484,lr_multiplier:11.391,loss:5.608255863189697,entropy:6.209163665771484,explained_var_old:0.970204234,explained_var_new:0.984855890
output spend 0.00018496000120649114 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008759090000239667 time
recovery_state_mcts_prob spend 0.27346564600156853 time
state_batch spend 0.0018107319992850535 time
mcts_probs_batch spend 0.0045741549984086305 time
winner_batch spend 0.0003044830009457655 time
policy_value spend 0.21840331199928187 time
train_step spend 0.6346351519969176 time
policy_value spend 0.2169110440008808 time
train_step spend 0.6355652590063983 time
policy_value spend 0.21728588800033322 time
train_step spend 0.6360096150019672 time
policy_value spend 0.2172685659970739 time
train_step spend 0.6358355330012273 time
policy_value spend 0.21723308600485325 time
train_step spend 0.6360495100016124 time
policy_value spend 0.21682197700283723 time
kl:0.00462,lr_multiplier:11.391,loss:5.593535423278809,entropy:6.204751014709473,explained_var_old:0.979917467,explained_var_new:0.989158094
output spend 0.00014718699821969494 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0071778830024413764 time
recovery_state_mcts_prob spend 0.27375395499984734 time
state_batch spend 0.0017982259960263036 time
mcts_probs_batch spend 0.0054806720072519965 time
winner_batch spend 0.00028847899375250563 time
policy_value spend 0.21983777599962195 time
train_step spend 0.6359475110002677 time
policy_value spend 0.21775727000203915 time
train_step spend 0.6351513879999402 time
policy_value spend 0.21695450100378366 time
train_step spend 0.6352071700021042 time
policy_value spend 0.21660762400279054 time
train_step spend 0.6351840410061413 time
policy_value spend 0.21693477199733024 time
train_step spend 0.6355451999988873 time
policy_value spend 0.21684327299590223 time
kl:0.00176,lr_multiplier:11.391,loss:5.559482097625732,entropy:6.207724571228027,explained_var_old:0.975625277,explained_var_new:0.986481547
output spend 0.0001873580040410161 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00881537399982335 time
recovery_state_mcts_prob spend 0.27642106900020735 time
state_batch spend 0.001775428005203139 time
mcts_probs_batch spend 0.005429425997135695 time
winner_batch spend 0.0004561789974104613 time
policy_value spend 0.22053351000067778 time
train_step spend 0.6711269290026394 time
policy_value spend 0.23001274000125704 time
train_step spend 0.6397648550046142 time
policy_value spend 0.21860437800205545 time
train_step spend 0.635436757998832 time
policy_value spend 0.21793995799816912 time
train_step spend 0.6363757779981825 time
policy_value spend 0.21752595400175778 time
train_step spend 0.6357095580024179 time
policy_value spend 0.2166158319960232 time
kl:0.00916,lr_multiplier:11.391,loss:5.557236194610596,entropy:6.196102142333984,explained_var_old:0.972436070,explained_var_new:0.992021978
output spend 0.00023283900372916833 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0073134819976985455 time
recovery_state_mcts_prob spend 0.2730712760021561 time
state_batch spend 0.0018164079956477508 time
mcts_probs_batch spend 0.008804302000498865 time
winner_batch spend 0.0002984239981742576 time
policy_value spend 0.22021456000220496 time
train_step spend 0.6377274050028063 time
policy_value spend 0.2173220879994915 time
train_step spend 0.6356282720007584 time
policy_value spend 0.21718747400154825 time
train_step spend 0.6348133180072182 time
policy_value spend 0.21722273799969116 time
train_step spend 0.6357198480036459 time
policy_value spend 0.2174871780007379 time
train_step spend 0.6350367679988267 time
policy_value spend 0.2173913949955022 time
kl:0.00390,lr_multiplier:11.391,loss:5.573805809020996,entropy:6.171767234802246,explained_var_old:0.978652239,explained_var_new:0.986398578
output spend 0.000153290995513089 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00984601700474741 time
recovery_state_mcts_prob spend 0.26832884499890497 time
state_batch spend 0.001800574995286297 time
mcts_probs_batch spend 0.005829711000842508 time
winner_batch spend 0.000296614998660516 time
policy_value spend 0.21731837400147924 time
train_step spend 0.637029152996547 time
policy_value spend 0.21691546899819514 time
train_step spend 0.6347681490005925 time
policy_value spend 0.21736031400359934 time
train_step spend 0.6359775300006731 time
policy_value spend 0.21672889000183204 time
train_step spend 0.6356626130000222 time
policy_value spend 0.21818107799481368 time
train_step spend 0.6357954720006092 time
policy_value spend 0.21778827699745307 time
kl:0.01476,lr_multiplier:11.391,loss:5.558533191680908,entropy:6.192951679229736,explained_var_old:0.970417261,explained_var_new:0.982601523
output spend 0.0001511250011390075 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007015618000878021 time
recovery_state_mcts_prob spend 0.27669290600169916 time
state_batch spend 0.0018771399991237558 time
mcts_probs_batch spend 0.0049942339974222705 time
winner_batch spend 0.0003119989996775985 time
policy_value spend 0.21602828900358872 time
train_step spend 0.6343673610026599 time
policy_value spend 0.21769796699663857 time
train_step spend 0.6344583460013382 time
policy_value spend 0.21705428699351614 time
train_step spend 0.6341378210054245 time
policy_value spend 0.21708125800068956 time
train_step spend 0.6340664259987534 time
policy_value spend 0.21712576900608838 time
train_step spend 0.6346856989985099 time
policy_value spend 0.21737454699905356 time
kl:0.00270,lr_multiplier:11.391,loss:5.590173721313477,entropy:6.185791969299316,explained_var_old:0.978438318,explained_var_new:0.985910296
output spend 0.00014945799921406433 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007567815999209415 time
recovery_state_mcts_prob spend 0.27984833999653347 time
state_batch spend 0.001751529001921881 time
mcts_probs_batch spend 0.005573329995968379 time
winner_batch spend 0.00031285300065064803 time
policy_value spend 0.21594167000148445 time
train_step spend 0.6359145579990582 time
policy_value spend 0.21729578699887497 time
train_step spend 0.6348264350017416 time
policy_value spend 0.21738392799306894 time
train_step spend 0.635377493003034 time
policy_value spend 0.2166807589965174 time
train_step spend 0.6355379570013611 time
policy_value spend 0.2166938869995647 time
train_step spend 0.6362448200015933 time
policy_value spend 0.21708227899944177 time
kl:0.00699,lr_multiplier:11.391,loss:5.537680149078369,entropy:6.1711883544921875,explained_var_old:0.986506939,explained_var_new:0.993691564
output spend 0.00014900100359227508 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009038856995175593 time
recovery_state_mcts_prob spend 0.2725288970032125 time
state_batch spend 0.001807581000321079 time
mcts_probs_batch spend 0.0075577429961413145 time
winner_batch spend 0.0002906440058723092 time
policy_value spend 0.21744415299326647 time
train_step spend 0.6343520990049001 time
policy_value spend 0.2201385529988329 time
train_step spend 0.6351377779938048 time
policy_value spend 0.21662439899955643 time
train_step spend 0.6353799549979158 time
policy_value spend 0.21710593399620848 time
train_step spend 0.6355538470015745 time
policy_value spend 0.21724138699937612 time
train_step spend 0.6355362559988862 time
policy_value spend 0.21827018100157147 time
kl:0.00496,lr_multiplier:11.391,loss:5.588076114654541,entropy:6.181056022644043,explained_var_old:0.979467213,explained_var_new:0.984714210
output spend 0.00023693600087426603 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009227742004441097 time
recovery_state_mcts_prob spend 0.2749535639959504 time
state_batch spend 0.0023336020021815784 time
mcts_probs_batch spend 0.006821852002758533 time
winner_batch spend 0.0002888099988922477 time
policy_value spend 0.2178499279980315 time
train_step spend 0.6345863590031513 time
policy_value spend 0.2170058580013574 time
train_step spend 0.6356505139992805 time
policy_value spend 0.2170716890032054 time
train_step spend 0.6353463570048916 time
policy_value spend 0.2174995189998299 time
train_step spend 0.6365538459940581 time
policy_value spend 0.2175444590029656 time
train_step spend 0.6350561319995904 time
policy_value spend 0.21693863199470798 time
kl:0.00297,lr_multiplier:11.391,loss:5.585574626922607,entropy:6.196355819702148,explained_var_old:0.974881530,explained_var_new:0.985200107
output spend 0.0001488979978603311 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007722717993601691 time
recovery_state_mcts_prob spend 0.2657049330009613 time
state_batch spend 0.001815394003642723 time
mcts_probs_batch spend 0.00633214799745474 time
winner_batch spend 0.0002854060003301129 time
policy_value spend 0.21730614399712067 time
train_step spend 0.6349393700002111 time
policy_value spend 0.2179833949994645 time
train_step spend 0.63571060099639 time
policy_value spend 0.21751395100000082 time
train_step spend 0.6359945880030864 time
policy_value spend 0.2168912380002439 time
train_step spend 0.6357114980055485 time
policy_value spend 0.21689814499404747 time
train_step spend 0.6354999459945248 time
policy_value spend 0.2173985640038154 time
kl:0.00336,lr_multiplier:11.391,loss:5.5742621421813965,entropy:6.189380645751953,explained_var_old:0.985328794,explained_var_new:0.996056020
output spend 0.0001477109981351532 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007561313999758568 time
recovery_state_mcts_prob spend 0.2741918789979536 time
state_batch spend 0.0019908360045519657 time
mcts_probs_batch spend 0.0072414929963997565 time
winner_batch spend 0.00042108900379389524 time
policy_value spend 0.21652448899840238 time
train_step spend 0.636501151995617 time
policy_value spend 0.21714613599760924 time
train_step spend 0.6353351069992641 time
policy_value spend 0.2165303860019776 time
train_step spend 0.6354714530025376 time
policy_value spend 0.21669631399709033 time
train_step spend 0.634794782003155 time
policy_value spend 0.21686520299408585 time
train_step spend 0.651259996004228 time
policy_value spend 0.23002631899726111 time
kl:0.00436,lr_multiplier:11.391,loss:5.5912699699401855,entropy:6.186249732971191,explained_var_old:0.979789555,explained_var_new:0.987458706
output spend 0.00019337500270921737 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009072608001588378 time
recovery_state_mcts_prob spend 0.27913512499799253 time
state_batch spend 0.0019492549981805496 time
mcts_probs_batch spend 0.004796012006409001 time
winner_batch spend 0.00036171799729345366 time
policy_value spend 0.21757268499641214 time
train_step spend 0.6349789179948857 time
policy_value spend 0.2181720230000792 time
train_step spend 0.6349723189996439 time
policy_value spend 0.21713946700037923 time
train_step spend 0.6351679459985462 time
policy_value spend 0.21635384800174506 time
train_step spend 0.6370321069989586 time
policy_value spend 0.216595801000949 time
train_step spend 0.634521569001663 time
policy_value spend 0.21644658199511468 time
kl:0.00507,lr_multiplier:11.391,loss:5.566936492919922,entropy:6.187014579772949,explained_var_old:0.982521653,explained_var_new:0.991944849
output spend 0.00015729099686723202 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013379267998971045 time
recovery_state_mcts_prob spend 0.27697245300078066 time
state_batch spend 0.0020589920022757724 time
mcts_probs_batch spend 0.005599289994279388 time
winner_batch spend 0.0002840029992512427 time
policy_value spend 0.21615055500296876 time
train_step spend 0.635099615996296 time
policy_value spend 0.220041910004511 time
train_step spend 0.635151208996831 time
policy_value spend 0.21704509099799907 time
train_step spend 0.6339164780001738 time
policy_value spend 0.2170706050019362 time
train_step spend 0.6351736659999005 time
policy_value spend 0.21754412199516082 time
train_step spend 0.6339561740023782 time
policy_value spend 0.21743779599637492 time
kl:0.00250,lr_multiplier:11.391,loss:5.566305160522461,entropy:6.199157238006592,explained_var_old:0.979889929,explained_var_new:0.991867542
output spend 0.0001475990065955557 time
已保存最新模型
current self-play batch: 200
load data begin
已加载数据
step i 372: 
random.sample spend 0.007956569999805652 time
recovery_state_mcts_prob spend 0.28360830799647374 time
state_batch spend 0.0018606720041134395 time
mcts_probs_batch spend 0.006948141999600921 time
winner_batch spend 0.0002963199949590489 time
policy_value spend 0.21684140000434127 time
train_step spend 0.6737102499973844 time
policy_value spend 0.22253027099941391 time
train_step spend 0.6387256439993507 time
policy_value spend 0.2176432999985991 time
train_step spend 0.6355328720019315 time
policy_value spend 0.217363187999581 time
train_step spend 0.6354909789952217 time
policy_value spend 0.21692155500204535 time
train_step spend 0.6350014830022701 time
policy_value spend 0.2169532400002936 time
kl:0.00383,lr_multiplier:11.391,loss:5.546550273895264,entropy:6.197951316833496,explained_var_old:0.975174963,explained_var_new:0.984787822
output spend 0.00015690700092818588 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006892725999932736 time
recovery_state_mcts_prob spend 0.2709928919939557 time
state_batch spend 0.0018143950001103804 time
mcts_probs_batch spend 0.006087166002544109 time
winner_batch spend 0.0002956949974759482 time
policy_value spend 0.2164526240012492 time
train_step spend 0.6348731390025932 time
policy_value spend 0.21643546199629782 time
train_step spend 0.6343832109996583 time
policy_value spend 0.21693319699988933 time
train_step spend 0.6347675240031094 time
policy_value spend 0.2174121420030133 time
train_step spend 0.6361217550002038 time
policy_value spend 0.21644072099297773 time
train_step spend 0.6354362929996569 time
policy_value spend 0.21729985400452279 time
kl:0.00393,lr_multiplier:11.391,loss:5.521881103515625,entropy:6.18878173828125,explained_var_old:0.985059798,explained_var_new:0.993108451
output spend 0.0001542169993626885 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011638533003861085 time
recovery_state_mcts_prob spend 0.2749518970013014 time
state_batch spend 0.0018580999967525713 time
mcts_probs_batch spend 0.00560187800147105 time
winner_batch spend 0.00028785099857486784 time
policy_value spend 0.21664827399945352 time
train_step spend 0.636142146999191 time
policy_value spend 0.2170959809955093 time
train_step spend 0.636670726002194 time
policy_value spend 0.21736281100311317 time
train_step spend 0.6431117450047168 time
policy_value spend 0.22001748000184307 time
train_step spend 0.6391378449989134 time
policy_value spend 0.2195191220016568 time
train_step spend 0.6406017030021758 time
policy_value spend 0.2179671359990607 time
kl:0.00221,lr_multiplier:11.391,loss:5.545701026916504,entropy:6.1782989501953125,explained_var_old:0.984683454,explained_var_new:0.989369571
output spend 0.0001906260004034266 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007410525999148376 time
recovery_state_mcts_prob spend 0.2850172489997931 time
state_batch spend 0.0019649660025606863 time
mcts_probs_batch spend 0.00442184600251494 time
winner_batch spend 0.0002910409966716543 time
policy_value spend 0.21770139900036156 time
train_step spend 0.6400351269985549 time
policy_value spend 0.2186196850016131 time
train_step spend 0.6389700050058309 time
policy_value spend 0.21870910700090462 time
train_step spend 0.6395642110001063 time
policy_value spend 0.2184108740038937 time
train_step spend 0.6396118499978911 time
policy_value spend 0.2185120919966721 time
train_step spend 0.639486748004856 time
policy_value spend 0.21886174899555044 time
kl:0.00686,lr_multiplier:11.391,loss:5.514040470123291,entropy:6.1631317138671875,explained_var_old:0.987516999,explained_var_new:0.990139484
output spend 0.00015108100342331454 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009427545999642462 time
recovery_state_mcts_prob spend 0.27130858400050784 time
state_batch spend 0.0019503160001477227 time
mcts_probs_batch spend 0.006826413999078795 time
winner_batch spend 0.0002915600052801892 time
policy_value spend 0.2173212909983704 time
train_step spend 0.6339415809998172 time
policy_value spend 0.2177159290004056 time
train_step spend 0.6359907919977559 time
policy_value spend 0.21673397599806776 time
train_step spend 0.6358841469991603 time
policy_value spend 0.21729285900073592 time
train_step spend 0.6372128770017298 time
policy_value spend 0.21734366299642716 time
train_step spend 0.6364236560038989 time
policy_value spend 0.21696995900128968 time
kl:0.00309,lr_multiplier:11.391,loss:5.503473281860352,entropy:6.152263641357422,explained_var_old:0.962098241,explained_var_new:0.984228313
output spend 0.0001475730023230426 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007883767997554969 time
recovery_state_mcts_prob spend 0.27297068800544366 time
state_batch spend 0.0018716259946813807 time
mcts_probs_batch spend 0.016352662998542655 time
winner_batch spend 0.00030840600084047765 time
policy_value spend 0.2205439870012924 time
train_step spend 0.6352565120032523 time
policy_value spend 0.22093655400385614 time
train_step spend 0.6346222369975294 time
policy_value spend 0.21625449400016805 time
train_step spend 0.6348169900011271 time
policy_value spend 0.21749697199993534 time
train_step spend 0.6355243279977003 time
policy_value spend 0.21724869000172475 time
train_step spend 0.63498361800157 time
policy_value spend 0.21717305600031978 time
kl:0.00921,lr_multiplier:11.391,loss:5.526253700256348,entropy:6.150090217590332,explained_var_old:0.980828881,explained_var_new:0.986984730
output spend 0.000190910002856981 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011971984000410885 time
recovery_state_mcts_prob spend 0.27326200799871003 time
state_batch spend 0.0020083480048924685 time
mcts_probs_batch spend 0.006849533994682133 time
winner_batch spend 0.00043643500248435885 time
policy_value spend 0.22640286100067897 time
train_step spend 0.6546863589974237 time
policy_value spend 0.23121973399975104 time
train_step spend 0.6509642269957112 time
policy_value spend 0.21917499900155235 time
train_step spend 0.636482039000839 time
policy_value spend 0.21840179600258125 time
train_step spend 0.635879287001444 time
policy_value spend 0.2178954179980792 time
train_step spend 0.6356953279973823 time
policy_value spend 0.21772447000694228 time
kl:0.00411,lr_multiplier:11.391,loss:5.540390491485596,entropy:6.164419651031494,explained_var_old:0.973773420,explained_var_new:0.984878421
output spend 0.00019692299974849448 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010741048005002085 time
recovery_state_mcts_prob spend 0.271818823996 time
state_batch spend 0.0017576309983269311 time
mcts_probs_batch spend 0.005430661003629211 time
winner_batch spend 0.0003013719979207963 time
policy_value spend 0.2171964349981863 time
train_step spend 0.6357764999993378 time
policy_value spend 0.21890086200437509 time
train_step spend 0.6360488339996664 time
policy_value spend 0.21739466200233437 time
train_step spend 0.6360369539979729 time
policy_value spend 0.21783625200623646 time
train_step spend 0.6366901319997851 time
policy_value spend 0.2175392449935316 time
train_step spend 0.6351370850024978 time
policy_value spend 0.21780332499474753 time
kl:0.00686,lr_multiplier:11.391,loss:5.582586288452148,entropy:6.181048393249512,explained_var_old:0.981472135,explained_var_new:0.992687881
output spend 0.0001534490002086386 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009557533005136065 time
recovery_state_mcts_prob spend 0.27152737000142224 time
state_batch spend 0.0018181299965362996 time
mcts_probs_batch spend 0.006733169997460209 time
winner_batch spend 0.0003996760060545057 time
policy_value spend 0.21722636399499606 time
train_step spend 0.6357818760006921 time
policy_value spend 0.21853013999498216 time
train_step spend 0.6360615239973413 time
policy_value spend 0.21673841799929505 time
train_step spend 0.6356362420046935 time
policy_value spend 0.2171059129977948 time
train_step spend 0.6353798140044091 time
policy_value spend 0.2178506060008658 time
train_step spend 0.6357231209985912 time
policy_value spend 0.21685050100495573 time
kl:0.00999,lr_multiplier:11.391,loss:5.521295547485352,entropy:6.173005104064941,explained_var_old:0.980540097,explained_var_new:0.989192128
output spend 0.00014887300494592637 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007980125999893062 time
recovery_state_mcts_prob spend 0.28324425099708606 time
state_batch spend 0.0018273230016347952 time
mcts_probs_batch spend 0.006847946999187116 time
winner_batch spend 0.00029845799872418866 time
policy_value spend 0.21739483599958476 time
train_step spend 0.6359459960003733 time
policy_value spend 0.21724182600155473 time
train_step spend 0.637979548999283 time
policy_value spend 0.21690908400341868 time
train_step spend 0.6345507820005878 time
policy_value spend 0.2177638430002844 time
train_step spend 0.6362009109943756 time
policy_value spend 0.21653208100178745 time
train_step spend 0.6349447600005078 time
policy_value spend 0.2169187539984705 time
kl:0.00249,lr_multiplier:11.391,loss:5.529596328735352,entropy:6.172372817993164,explained_var_old:0.972587705,explained_var_new:0.990148067
output spend 0.00015287799760699272 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007526453999162186 time
recovery_state_mcts_prob spend 0.2726619850000134 time
state_batch spend 0.001857464994827751 time
mcts_probs_batch spend 0.006741463002981618 time
winner_batch spend 0.000294242003292311 time
policy_value spend 0.21766702299646568 time
train_step spend 0.6357429999989108 time
policy_value spend 0.21676925700012362 time
train_step spend 0.6363160639957641 time
policy_value spend 0.2177390330034541 time
train_step spend 0.6350507340030163 time
policy_value spend 0.217286957995384 time
train_step spend 0.6363575509967632 time
policy_value spend 0.21685662100207992 time
train_step spend 0.6347387979985797 time
policy_value spend 0.21712686699902406 time
kl:0.00631,lr_multiplier:11.391,loss:5.531631946563721,entropy:6.175968170166016,explained_var_old:0.975288033,explained_var_new:0.983507156
output spend 0.00014975899830460548 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007643575001566205 time
recovery_state_mcts_prob spend 0.2723270139977103 time
state_batch spend 0.0017759960028342903 time
mcts_probs_batch spend 0.004525732998445164 time
winner_batch spend 0.0003176589962095022 time
policy_value spend 0.2168288860048051 time
train_step spend 0.635436655000376 time
policy_value spend 0.21688500099844532 time
train_step spend 0.6349485120008467 time
policy_value spend 0.2169713210023474 time
train_step spend 0.637882417999208 time
policy_value spend 0.21749626800010446 time
train_step spend 0.6386088529980043 time
policy_value spend 0.21807070700015174 time
train_step spend 0.6387728699992294 time
policy_value spend 0.21791488200688036 time
kl:0.00213,lr_multiplier:11.391,loss:5.541609287261963,entropy:6.181248188018799,explained_var_old:0.987190545,explained_var_new:0.993492842
output spend 0.00015979799354681745 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008459944998321589 time
recovery_state_mcts_prob spend 0.28006489599647466 time
state_batch spend 0.0020392090009409003 time
mcts_probs_batch spend 0.004575017002935056 time
winner_batch spend 0.00028993199521210045 time
policy_value spend 0.21674292600073386 time
train_step spend 0.638718133996008 time
policy_value spend 0.2180750320039806 time
train_step spend 0.6386159489993588 time
policy_value spend 0.21782363500096835 time
train_step spend 0.6382202950044302 time
policy_value spend 0.21859690299606882 time
train_step spend 0.6379616799968062 time
policy_value spend 0.2180443280012696 time
train_step spend 0.6388718420057558 time
policy_value spend 0.21796610199817223 time
kl:0.00668,lr_multiplier:11.391,loss:5.4955363273620605,entropy:6.157909393310547,explained_var_old:0.985372603,explained_var_new:0.993876278
output spend 0.00014753800496691838 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00731353199807927 time
recovery_state_mcts_prob spend 0.27550564800185384 time
state_batch spend 0.0018137520019081421 time
mcts_probs_batch spend 0.004920307001157198 time
winner_batch spend 0.00032996400113916025 time
policy_value spend 0.21726643199508544 time
train_step spend 0.6391380010027206 time
policy_value spend 0.21725677599897608 time
train_step spend 0.6340277609997429 time
policy_value spend 0.21723750000091968 time
train_step spend 0.6341584449983202 time
policy_value spend 0.21748697799921501 time
train_step spend 0.6339609380011098 time
policy_value spend 0.21763818599720253 time
train_step spend 0.6353000960007193 time
policy_value spend 0.21662630700302543 time
kl:0.00260,lr_multiplier:11.391,loss:5.513098239898682,entropy:6.165018558502197,explained_var_old:0.975023925,explained_var_new:0.979862094
output spend 0.0001472429939894937 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008546776000002865 time
recovery_state_mcts_prob spend 0.2793603459940641 time
state_batch spend 0.0019418880037846975 time
mcts_probs_batch spend 0.004584124995744787 time
winner_batch spend 0.0002932880015578121 time
policy_value spend 0.2163930720053031 time
train_step spend 0.6356638249999378 time
policy_value spend 0.21801885300374124 time
train_step spend 0.6362626129994169 time
policy_value spend 0.21615554299933137 time
train_step spend 0.6314633030051482 time
policy_value spend 0.21612717799871461 time
train_step spend 0.6314073299945449 time
policy_value spend 0.21586617700086208 time
train_step spend 0.6327124200033722 time
policy_value spend 0.2156560469957185 time
kl:0.00747,lr_multiplier:11.391,loss:5.486372947692871,entropy:6.152488708496094,explained_var_old:0.983087838,explained_var_new:0.993648112
output spend 0.0002755509995040484 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009574253999744542 time
recovery_state_mcts_prob spend 0.29356402599660214 time
state_batch spend 0.0021342539985198528 time
mcts_probs_batch spend 0.006755982001777738 time
winner_batch spend 0.0003197620026185177 time
policy_value spend 0.22834069199598162 time
train_step spend 0.6475766770017799 time
policy_value spend 0.2169074109988287 time
train_step spend 0.6327772740041837 time
policy_value spend 0.21659842199733248 time
train_step spend 0.6300597270019352 time
policy_value spend 0.2156390599993756 time
train_step spend 0.6322184080054285 time
policy_value spend 0.21620863199495943 time
train_step spend 0.6307475970024825 time
policy_value spend 0.2160695200000191 time
kl:0.00319,lr_multiplier:11.391,loss:5.44333028793335,entropy:6.1175217628479,explained_var_old:0.979581118,explained_var_new:0.993494928
output spend 0.00014721100160386413 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010810134001076221 time
recovery_state_mcts_prob spend 0.2799342379948939 time
state_batch spend 0.0021393310016719624 time
mcts_probs_batch spend 0.006723304002662189 time
winner_batch spend 0.00028753899823641405 time
policy_value spend 0.215870524996717 time
train_step spend 0.6326476739995996 time
policy_value spend 0.21706098900176585 time
train_step spend 0.6324831149977399 time
policy_value spend 0.21630929999810178 time
train_step spend 0.6333076749942848 time
policy_value spend 0.21601159200508846 time
train_step spend 0.6323384720017202 time
policy_value spend 0.2161591240001144 time
train_step spend 0.6322218419954879 time
policy_value spend 0.2166165680027916 time
kl:0.00454,lr_multiplier:11.391,loss:5.511590480804443,entropy:6.133188247680664,explained_var_old:0.976498187,explained_var_new:0.986514688
output spend 0.0001643290015636012 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012661831002333201 time
recovery_state_mcts_prob spend 0.2710617729972 time
state_batch spend 0.0022254389987210743 time
mcts_probs_batch spend 0.004941259998304304 time
winner_batch spend 0.0003084540003328584 time
policy_value spend 0.2149944230041001 time
train_step spend 0.6323823619968607 time
policy_value spend 0.21670950500265462 time
train_step spend 0.6329858739991323 time
policy_value spend 0.21838389099866617 time
train_step spend 0.639435418001085 time
policy_value spend 0.21868506499595242 time
train_step spend 0.6400294099948951 time
policy_value spend 0.21811842600436648 time
train_step spend 0.6397354290020303 time
policy_value spend 0.2183876089984551 time
kl:0.00248,lr_multiplier:11.391,loss:5.540104866027832,entropy:6.168756008148193,explained_var_old:0.985469818,explained_var_new:0.992477357
output spend 0.000148899998748675 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011420080001698807 time
recovery_state_mcts_prob spend 0.26876507999986643 time
state_batch spend 0.0019073419971391559 time
mcts_probs_batch spend 0.0069180260034045205 time
winner_batch spend 0.00030777000210946426 time
policy_value spend 0.21917844099516515 time
train_step spend 0.6397011160006514 time
policy_value spend 0.21987647700007074 time
train_step spend 0.6400603040019632 time
policy_value spend 0.21854013799747918 time
train_step spend 0.6401407860030304 time
policy_value spend 0.21853301499504596 time
train_step spend 0.6402446130014141 time
policy_value spend 0.2191600629957975 time
train_step spend 0.6392920610014698 time
policy_value spend 0.21713633200124605 time
kl:0.00528,lr_multiplier:11.391,loss:5.510303974151611,entropy:6.163213729858398,explained_var_old:0.987875700,explained_var_new:0.993286908
output spend 0.00015974899724824354 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007179555999755394 time
recovery_state_mcts_prob spend 0.2731529730008333 time
state_batch spend 0.001812422000512015 time
mcts_probs_batch spend 0.007140378002077341 time
winner_batch spend 0.00033835600333986804 time
policy_value spend 0.21804870499909157 time
train_step spend 0.6357325520002632 time
policy_value spend 0.21877450600004522 time
train_step spend 0.635395466000773 time
policy_value spend 0.21740078100265237 time
train_step spend 0.6363926119956886 time
policy_value spend 0.21718051500647562 time
train_step spend 0.6359900559982634 time
policy_value spend 0.2175796139999875 time
train_step spend 0.6353547910039197 time
policy_value spend 0.21797520099789836 time
kl:0.00264,lr_multiplier:11.391,loss:5.477092742919922,entropy:6.174464225769043,explained_var_old:0.990311027,explained_var_new:0.993810058
output spend 0.0001656159947742708 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009026441999594681 time
recovery_state_mcts_prob spend 0.26481936699565267 time
state_batch spend 0.002755112000158988 time
mcts_probs_batch spend 0.005220423001446761 time
winner_batch spend 0.000330881004629191 time
policy_value spend 0.21669943999586394 time
train_step spend 0.634746711999469 time
policy_value spend 0.21743485200568102 time
train_step spend 0.6348322799967718 time
policy_value spend 0.21802296100213425 time
train_step spend 0.6343113940019975 time
policy_value spend 0.21815828800026793 time
train_step spend 0.6351698180005769 time
policy_value spend 0.21733424599369755 time
train_step spend 0.6347266060038237 time
policy_value spend 0.21747966000111774 time
kl:0.00430,lr_multiplier:11.391,loss:5.5087890625,entropy:6.140506267547607,explained_var_old:0.984673202,explained_var_new:0.990381420
output spend 0.00016930299898376688 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008203363002394326 time
recovery_state_mcts_prob spend 0.26824961799866287 time
state_batch spend 0.0020645619952119887 time
mcts_probs_batch spend 0.006957735000469256 time
winner_batch spend 0.0002858480002032593 time
policy_value spend 0.21685077000438469 time
train_step spend 0.6346897839976009 time
policy_value spend 0.21786364800209412 time
train_step spend 0.6349491580040194 time
policy_value spend 0.2164883439982077 time
train_step spend 0.6346999220040743 time
policy_value spend 0.21682399299606914 time
train_step spend 0.6349662920038099 time
policy_value spend 0.2172109070015722 time
train_step spend 0.6356379130011192 time
policy_value spend 0.21694227300031343 time
kl:0.00582,lr_multiplier:11.391,loss:5.519260883331299,entropy:6.152932167053223,explained_var_old:0.985285163,explained_var_new:0.993233800
output spend 0.00015697300113970414 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009824159998970572 time
recovery_state_mcts_prob spend 0.26830112100287806 time
state_batch spend 0.0018646090029506013 time
mcts_probs_batch spend 0.005581190998782404 time
winner_batch spend 0.0002771619983832352 time
policy_value spend 0.22009598000295227 time
train_step spend 0.635123386993655 time
policy_value spend 0.22067026700096903 time
train_step spend 0.6344765910034766 time
policy_value spend 0.21761390099709388 time
train_step spend 0.6342321269985405 time
policy_value spend 0.21707274300570134 time
train_step spend 0.6351016569969943 time
policy_value spend 0.21669132100214483 time
train_step spend 0.6343893070006743 time
policy_value spend 0.21674054199684178 time
kl:0.00724,lr_multiplier:11.391,loss:5.4672746658325195,entropy:6.127213954925537,explained_var_old:0.980915368,explained_var_new:0.989533663
output spend 0.00016788999346317723 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0077066429948899895 time
recovery_state_mcts_prob spend 0.2723882930004038 time
state_batch spend 0.0020593640001607127 time
mcts_probs_batch spend 0.00681018899922492 time
winner_batch spend 0.00031858900183578953 time
policy_value spend 0.21795720999944024 time
train_step spend 0.6341654149946407 time
policy_value spend 0.2175981340042199 time
train_step spend 0.634694706001028 time
policy_value spend 0.2167174319984042 time
train_step spend 0.6517243979978957 time
policy_value spend 0.22961749900423456 time
train_step spend 0.6642854870005976 time
policy_value spend 0.2192225720064016 time
train_step spend 0.6397367179961293 time
policy_value spend 0.21710296300443588 time
kl:0.00318,lr_multiplier:11.391,loss:5.507711410522461,entropy:6.153188228607178,explained_var_old:0.985510051,explained_var_new:0.991977274
output spend 0.0001485820030211471 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006925983005203307 time
recovery_state_mcts_prob spend 0.28016044499963755 time
state_batch spend 0.001861510994785931 time
mcts_probs_batch spend 0.01612723099970026 time
winner_batch spend 0.00029858100606361404 time
policy_value spend 0.22119847299472895 time
train_step spend 0.6355955309991259 time
policy_value spend 0.22126104299968574 time
train_step spend 0.6359109969998826 time
policy_value spend 0.22191537000617245 time
train_step spend 0.6357504020052147 time
policy_value spend 0.21697291899909033 time
train_step spend 0.6347521099960431 time
policy_value spend 0.21713615600310732 time
train_step spend 0.6357611939965864 time
policy_value spend 0.2176855810030247 time
kl:0.00797,lr_multiplier:11.391,loss:5.438016414642334,entropy:6.130579948425293,explained_var_old:0.978397012,explained_var_new:0.985849202
output spend 0.00014763899525860325 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0081018370037782 time
recovery_state_mcts_prob spend 0.27933468599803746 time
state_batch spend 0.0017836560000432655 time
mcts_probs_batch spend 0.007113888997992035 time
winner_batch spend 0.0003710180026246235 time
policy_value spend 0.21755650100385537 time
train_step spend 0.6363742670000647 time
policy_value spend 0.21677239999553422 time
train_step spend 0.6348477299980004 time
policy_value spend 0.2172121700059506 time
train_step spend 0.6345291770048789 time
policy_value spend 0.21712894200027222 time
train_step spend 0.6360588429961354 time
policy_value spend 0.2169379150000168 time
train_step spend 0.6353291769992211 time
policy_value spend 0.2164278150012251 time
kl:0.00219,lr_multiplier:11.391,loss:5.493061065673828,entropy:6.1432695388793945,explained_var_old:0.973761201,explained_var_new:0.988032401
output spend 0.00014948299940442666 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006804082004236989 time
recovery_state_mcts_prob spend 0.26933689099678304 time
state_batch spend 0.0022736090031685308 time
mcts_probs_batch spend 0.004532802995527163 time
winner_batch spend 0.00032235600519925356 time
policy_value spend 0.21649831700051436 time
train_step spend 0.6359414649996324 time
policy_value spend 0.2167259859998012 time
train_step spend 0.6354314529962721 time
policy_value spend 0.2169171350033139 time
train_step spend 0.6349280220019864 time
policy_value spend 0.2169832720028353 time
train_step spend 0.6335471300044446 time
policy_value spend 0.21662210999784293 time
train_step spend 0.6347794969988172 time
policy_value spend 0.21716097299940884 time
kl:0.00445,lr_multiplier:11.391,loss:5.457331657409668,entropy:6.143040657043457,explained_var_old:0.975429356,explained_var_new:0.982309461
output spend 0.00014637399726780131 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010137559998838697 time
recovery_state_mcts_prob spend 0.26851232000626624 time
state_batch spend 0.001862110999354627 time
mcts_probs_batch spend 0.004503397998632863 time
winner_batch spend 0.00028746599855367094 time
policy_value spend 0.21612639100203523 time
train_step spend 0.6346191690026899 time
policy_value spend 0.21641099699627375 time
train_step spend 0.6345032129975152 time
policy_value spend 0.21681822100072168 time
train_step spend 0.6347355559992138 time
policy_value spend 0.21621735500229988 time
train_step spend 0.6349338319996605 time
policy_value spend 0.21679436800332041 time
train_step spend 0.6354905259941006 time
policy_value spend 0.21679512099944986 time
kl:0.01203,lr_multiplier:11.391,loss:5.459073543548584,entropy:6.119750022888184,explained_var_old:0.984232008,explained_var_new:0.993816137
output spend 0.00014750300033483654 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006736811999871861 time
recovery_state_mcts_prob spend 0.2723306150001008 time
state_batch spend 0.0017932509945239872 time
mcts_probs_batch spend 0.005169893003767356 time
winner_batch spend 0.00037765299930470064 time
policy_value spend 0.2162999790016329 time
train_step spend 0.6346082790041692 time
policy_value spend 0.21812055899499683 time
train_step spend 0.6339584439992905 time
policy_value spend 0.2165637739963131 time
train_step spend 0.6340955650011892 time
policy_value spend 0.21789854999951785 time
train_step spend 0.6358689379994757 time
policy_value spend 0.21698320099676494 time
train_step spend 0.6348950969986618 time
policy_value spend 0.21687886799918488 time
kl:0.00380,lr_multiplier:11.391,loss:5.472534656524658,entropy:6.118203163146973,explained_var_old:0.975234866,explained_var_new:0.982239246
output spend 0.00015010600327514112 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008048003001022153 time
recovery_state_mcts_prob spend 0.26840286700462457 time
state_batch spend 0.0019427009974606335 time
mcts_probs_batch spend 0.004449988002306782 time
winner_batch spend 0.0002900099934777245 time
policy_value spend 0.21616493000328774 time
train_step spend 0.6333606530024554 time
policy_value spend 0.21665676499833353 time
train_step spend 0.6344992570011527 time
policy_value spend 0.21641450099559734 time
train_step spend 0.6343832009952166 time
policy_value spend 0.226129012000456 time
train_step spend 0.6383446979962173 time
policy_value spend 0.21680397300224286 time
train_step spend 0.6361103329982143 time
policy_value spend 0.2167233580039465 time
kl:0.00777,lr_multiplier:11.391,loss:5.49407434463501,entropy:6.145644664764404,explained_var_old:0.988615811,explained_var_new:0.994040251
output spend 0.00014882000687066466 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007114707004802767 time
recovery_state_mcts_prob spend 0.27659337499790126 time
state_batch spend 0.0020809240013477392 time
mcts_probs_batch spend 0.004768858001625631 time
winner_batch spend 0.00031233699701260775 time
policy_value spend 0.21659524000278907 time
train_step spend 0.6347917730017798 time
policy_value spend 0.21688290999736637 time
train_step spend 0.6349377750011627 time
policy_value spend 0.2167409939938807 time
train_step spend 0.6355203159982921 time
policy_value spend 0.21725777100073174 time
train_step spend 0.6348350229964126 time
policy_value spend 0.21702654100226937 time
train_step spend 0.6347406049972051 time
policy_value spend 0.21711904000403592 time
kl:0.00346,lr_multiplier:11.391,loss:5.46284294128418,entropy:6.121792793273926,explained_var_old:0.983174741,explained_var_new:0.989708304
output spend 0.00015412500215461478 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00733265600138111 time
recovery_state_mcts_prob spend 0.2677095230028499 time
state_batch spend 0.0017590339994058013 time
mcts_probs_batch spend 0.004505710996454582 time
winner_batch spend 0.0002924190048361197 time
policy_value spend 0.21673583499796223 time
train_step spend 0.6361011850021896 time
policy_value spend 0.21703446400351822 time
train_step spend 0.636665008001728 time
policy_value spend 0.21639186600077664 time
train_step spend 0.6357085880008526 time
policy_value spend 0.21675015000073472 time
train_step spend 0.6356637439967017 time
policy_value spend 0.21639351000339957 time
train_step spend 0.6354809149997891 time
policy_value spend 0.21682795299420832 time
kl:0.00298,lr_multiplier:11.391,loss:5.455782890319824,entropy:6.118717193603516,explained_var_old:0.984350681,explained_var_new:0.988265276
output spend 0.0001512059970991686 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0101300899987109 time
recovery_state_mcts_prob spend 0.29771330900257453 time
state_batch spend 0.0017871479940367863 time
mcts_probs_batch spend 0.004489014005230274 time
winner_batch spend 0.0002897099984693341 time
policy_value spend 0.21812342300108867 time
train_step spend 0.6692758439967292 time
policy_value spend 0.22955389299750095 time
train_step spend 0.634744173999934 time
policy_value spend 0.21538058599981014 time
train_step spend 0.6273896510028862 time
policy_value spend 0.21497377999912715 time
train_step spend 0.628322060998471 time
policy_value spend 0.21496137900248868 time
train_step spend 0.628122550995613 time
policy_value spend 0.21535115400183713 time
kl:0.00298,lr_multiplier:11.391,loss:5.45618200302124,entropy:6.124827861785889,explained_var_old:0.982128322,explained_var_new:0.986560225
output spend 0.00014595799439121038 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01109865400212584 time
recovery_state_mcts_prob spend 0.27235316999576753 time
state_batch spend 0.0017456569985370152 time
mcts_probs_batch spend 0.006686066000838764 time
winner_batch spend 0.00034724100260064006 time
policy_value spend 0.214601321000373 time
train_step spend 0.6269037410020246 time
policy_value spend 0.21546619199943962 time
train_step spend 0.6288153729983605 time
policy_value spend 0.2147862650017487 time
train_step spend 0.627453549997881 time
policy_value spend 0.21508014600112801 time
train_step spend 0.6283939790009754 time
policy_value spend 0.21539181299885968 time
train_step spend 0.6294807950034738 time
policy_value spend 0.21744170199963264 time
kl:0.00821,lr_multiplier:11.391,loss:5.409150123596191,entropy:6.118673324584961,explained_var_old:0.984975040,explained_var_new:0.993420660
output spend 0.0001767170033417642 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012210231994686183 time
recovery_state_mcts_prob spend 0.26618511900596786 time
state_batch spend 0.0018171299961977638 time
mcts_probs_batch spend 0.006608620002225507 time
winner_batch spend 0.0002845310009433888 time
policy_value spend 0.2176996349953697 time
train_step spend 0.6337574839999434 time
policy_value spend 0.21836617599910824 time
train_step spend 0.6371199229979538 time
policy_value spend 0.21981572700315155 time
train_step spend 0.6353105170055642 time
policy_value spend 0.21765320899430662 time
train_step spend 0.6343849359982414 time
policy_value spend 0.21653700900060358 time
train_step spend 0.636378440001863 time
policy_value spend 0.21750855400023283 time
kl:0.00255,lr_multiplier:11.391,loss:5.472782135009766,entropy:6.1412248611450195,explained_var_old:0.989379823,explained_var_new:0.993770421
output spend 0.0001587819933774881 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007733112004643772 time
recovery_state_mcts_prob spend 0.2739542839990463 time
state_batch spend 0.002153625995561015 time
mcts_probs_batch spend 0.004489555001782719 time
winner_batch spend 0.0002928910034825094 time
policy_value spend 0.2163812609942397 time
train_step spend 0.6350646909995703 time
policy_value spend 0.2186132679998991 time
train_step spend 0.6347634039993864 time
policy_value spend 0.21764353300386574 time
train_step spend 0.634493718003796 time
policy_value spend 0.2174474179992103 time
train_step spend 0.6354135049987235 time
policy_value spend 0.21707559099741047 time
train_step spend 0.6354644390012254 time
policy_value spend 0.21739292400161503 time
kl:0.01041,lr_multiplier:11.391,loss:5.451470375061035,entropy:6.140852451324463,explained_var_old:0.989604950,explained_var_new:0.993569851
output spend 0.0001449150004191324 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0068810849988949485 time
recovery_state_mcts_prob spend 0.28217710899480153 time
state_batch spend 0.0018740850064205006 time
mcts_probs_batch spend 0.007005214996752329 time
winner_batch spend 0.0003826199972536415 time
policy_value spend 0.217160659005458 time
train_step spend 0.637513150999439 time
policy_value spend 0.2179191380055272 time
train_step spend 0.63620193299721 time
policy_value spend 0.21680280700093135 time
train_step spend 0.6358149590014364 time
policy_value spend 0.2172730460006278 time
train_step spend 0.635354580997955 time
policy_value spend 0.2168382269956055 time
train_step spend 0.6350420740054687 time
policy_value spend 0.21733153899549507 time
kl:0.00817,lr_multiplier:11.391,loss:5.412646293640137,entropy:6.1154465675354,explained_var_old:0.983468294,explained_var_new:0.990191877
output spend 0.0001853540015872568 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007437715998094063 time
recovery_state_mcts_prob spend 0.26959673600504175 time
state_batch spend 0.0019560419968911447 time
mcts_probs_batch spend 0.005384670999774244 time
winner_batch spend 0.00028458100132411346 time
policy_value spend 0.21695367099891882 time
train_step spend 0.6371885810003732 time
policy_value spend 0.21720993000053568 time
train_step spend 0.6353504920043633 time
policy_value spend 0.21678019299724838 time
train_step spend 0.6358293439989211 time
policy_value spend 0.21759718900284497 time
train_step spend 0.6365092369960621 time
policy_value spend 0.218205516001035 time
train_step spend 0.635945811001875 time
policy_value spend 0.21676553100405727 time
kl:0.00340,lr_multiplier:11.391,loss:5.397044658660889,entropy:6.108379364013672,explained_var_old:0.986779630,explained_var_new:0.993236125
output spend 0.00014824300160398707 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012251282998477109 time
recovery_state_mcts_prob spend 0.2689811070013093 time
state_batch spend 0.001839224001741968 time
mcts_probs_batch spend 0.004567588999634609 time
winner_batch spend 0.0003272829999332316 time
policy_value spend 0.21645883499877527 time
train_step spend 0.635312514998077 time
policy_value spend 0.21743724700354505 time
train_step spend 0.6349877139946329 time
policy_value spend 0.21721568800421664 time
train_step spend 0.6355776939963107 time
policy_value spend 0.21888209000462666 time
train_step spend 0.6348149650002597 time
policy_value spend 0.21624438000435475 time
train_step spend 0.6346774990015547 time
policy_value spend 0.21663686899410095 time
kl:0.00569,lr_multiplier:11.391,loss:5.378779888153076,entropy:6.073779106140137,explained_var_old:0.970995367,explained_var_new:0.979768693
output spend 0.0002731589993345551 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007543653002358042 time
recovery_state_mcts_prob spend 0.2759816370016779 time
state_batch spend 0.0019308499977341853 time
mcts_probs_batch spend 0.004835719999391586 time
winner_batch spend 0.0003092820043093525 time
policy_value spend 0.2155271459996584 time
train_step spend 0.6364434589995653 time
policy_value spend 0.21717374400031986 time
train_step spend 0.6348319739990984 time
policy_value spend 0.21771971900307108 time
train_step spend 0.6351245900004869 time
policy_value spend 0.2174137889960548 time
train_step spend 0.6347409929949208 time
policy_value spend 0.2171446130014374 time
train_step spend 0.6343493669992313 time
policy_value spend 0.21746297700155992 time
kl:0.00414,lr_multiplier:11.391,loss:5.4639668464660645,entropy:6.090017318725586,explained_var_old:0.986693799,explained_var_new:0.992002070
output spend 0.00015792200429132208 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0083934189970023 time
recovery_state_mcts_prob spend 0.27034714900219114 time
state_batch spend 0.0022204839988262393 time
mcts_probs_batch spend 0.004484098004468251 time
winner_batch spend 0.0003715499988174997 time
policy_value spend 0.21532621799997287 time
train_step spend 0.634755570004927 time
policy_value spend 0.2172298139994382 time
train_step spend 0.6341348069981905 time
policy_value spend 0.2163559750042623 time
train_step spend 0.6338348040007986 time
policy_value spend 0.21744934700109297 time
train_step spend 0.6337394309957745 time
policy_value spend 0.21806361700146226 time
train_step spend 0.6538399620039854 time
policy_value spend 0.22940988600021228 time
kl:0.00577,lr_multiplier:11.391,loss:5.427678108215332,entropy:6.115676403045654,explained_var_old:0.986995697,explained_var_new:0.990742803
output spend 0.0001576650029164739 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008126799002639018 time
recovery_state_mcts_prob spend 0.29217963900009636 time
state_batch spend 0.0017500600006314926 time
mcts_probs_batch spend 0.005108248995384201 time
winner_batch spend 0.000345220003509894 time
policy_value spend 0.21715083399612922 time
train_step spend 0.6391750260008848 time
policy_value spend 0.21667401299782796 time
train_step spend 0.6352246559981722 time
policy_value spend 0.21754462600074476 time
train_step spend 0.6356670390014187 time
policy_value spend 0.2171314090010128 time
train_step spend 0.6362299830070697 time
policy_value spend 0.21688926199567504 time
train_step spend 0.6351935120037524 time
policy_value spend 0.21684581999579677 time
kl:0.01002,lr_multiplier:11.391,loss:5.389895915985107,entropy:6.1201677322387695,explained_var_old:0.991231441,explained_var_new:0.994524181
output spend 0.0001482599982409738 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007822203006071504 time
recovery_state_mcts_prob spend 0.2741537830006564 time
state_batch spend 0.002012985998590011 time
mcts_probs_batch spend 0.006920085994352121 time
winner_batch spend 0.0004044920060550794 time
policy_value spend 0.21782680099568097 time
train_step spend 0.6349025910021737 time
policy_value spend 0.21753796099801548 time
train_step spend 0.636033643000701 time
policy_value spend 0.21680804900097428 time
train_step spend 0.635446709995449 time
policy_value spend 0.21729435300221667 time
train_step spend 0.6360128029991756 time
policy_value spend 0.21694578699680278 time
train_step spend 0.6359009509978932 time
policy_value spend 0.21743889600475086 time
kl:0.01717,lr_multiplier:11.391,loss:5.356106281280518,entropy:6.083871841430664,explained_var_old:0.984968483,explained_var_new:0.993683696
output spend 0.00014448600268224254 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00837370500084944 time
recovery_state_mcts_prob spend 0.2757435129969963 time
state_batch spend 0.0018350140016991645 time
mcts_probs_batch spend 0.012331600999459624 time
winner_batch spend 0.00029513300250982866 time
policy_value spend 0.22084960700158263 time
train_step spend 0.6346616860028007 time
policy_value spend 0.21969029500178294 time
train_step spend 0.635240875002637 time
policy_value spend 0.21714206199976616 time
train_step spend 0.6355724300010479 time
policy_value spend 0.21836048900149763 time
train_step spend 0.6356603360036388 time
policy_value spend 0.21694772499904502 time
train_step spend 0.6350982820003992 time
policy_value spend 0.21660650000558235 time
kl:0.00337,lr_multiplier:11.391,loss:5.41575813293457,entropy:6.089862823486328,explained_var_old:0.975094497,explained_var_new:0.982179761
output spend 0.00015319399972213432 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00747776500065811 time
recovery_state_mcts_prob spend 0.2826330469979439 time
state_batch spend 0.0017932600021595135 time
mcts_probs_batch spend 0.006795251996663865 time
winner_batch spend 0.0002814430044963956 time
policy_value spend 0.21757707199867582 time
train_step spend 0.6365692100007436 time
policy_value spend 0.22315043099661125 time
train_step spend 0.6342259379962343 time
policy_value spend 0.2166532300034305 time
train_step spend 0.6349065079994034 time
policy_value spend 0.2167574720006087 time
train_step spend 0.6337778890010668 time
policy_value spend 0.21662597300019115 time
train_step spend 0.6364908090035897 time
policy_value spend 0.21885203800047748 time
kl:0.01123,lr_multiplier:11.391,loss:5.3579301834106445,entropy:6.071004390716553,explained_var_old:0.980957747,explained_var_new:0.987016976
output spend 0.00016038300236687064 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009502312997938134 time
recovery_state_mcts_prob spend 0.27665283600072144 time
state_batch spend 0.0017792610015021637 time
mcts_probs_batch spend 0.012013409002975095 time
winner_batch spend 0.0002936289965873584 time
policy_value spend 0.21628082299866946 time
train_step spend 0.6356125389938825 time
policy_value spend 0.2161266010007239 time
train_step spend 0.6340746119967662 time
policy_value spend 0.21711236699775327 time
train_step spend 0.634979950998968 time
policy_value spend 0.2165524110023398 time
train_step spend 0.6350076280068606 time
policy_value spend 0.21675181199680082 time
train_step spend 0.636307710003166 time
policy_value spend 0.2170464750015526 time
kl:0.00919,lr_multiplier:11.391,loss:5.423893451690674,entropy:6.109678268432617,explained_var_old:0.984200060,explained_var_new:0.989395618
output spend 0.00017700000171316788 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007137988002796192 time
recovery_state_mcts_prob spend 0.2714062939994619 time
state_batch spend 0.0022067440004320815 time
mcts_probs_batch spend 0.005910960993787739 time
winner_batch spend 0.0003143370049656369 time
policy_value spend 0.21543388199643232 time
train_step spend 0.6350087890023133 time
policy_value spend 0.21604992599895922 time
train_step spend 0.6342323050048435 time
policy_value spend 0.21685043400066206 time
train_step spend 0.6340546060018823 time
policy_value spend 0.21622229899367085 time
train_step spend 0.6338901120034279 time
policy_value spend 0.2171919939937652 time
train_step spend 0.6342507129957085 time
policy_value spend 0.2164021819990012 time
kl:0.00915,lr_multiplier:11.391,loss:5.405051231384277,entropy:6.083790302276611,explained_var_old:0.977742910,explained_var_new:0.983605981
output spend 0.00014869699953123927 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007889606000389904 time
recovery_state_mcts_prob spend 0.2713123749999795 time
state_batch spend 0.002126886996848043 time
mcts_probs_batch spend 0.009222482003679033 time
winner_batch spend 0.0003347329984535463 time
policy_value spend 0.2203612660014187 time
train_step spend 0.6339484429990989 time
policy_value spend 0.2199738109993632 time
train_step spend 0.6346440670022275 time
policy_value spend 0.21701619400118943 time
train_step spend 0.6351023099996382 time
policy_value spend 0.2172094659981667 time
train_step spend 0.6357884909957647 time
policy_value spend 0.21743482400052017 time
train_step spend 0.6354265859990846 time
policy_value spend 0.21699381699727383 time
kl:0.02092,lr_multiplier:11.391,loss:5.4341325759887695,entropy:6.095013618469238,explained_var_old:0.979092062,explained_var_new:0.989852965
output spend 0.00014870100130792707 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006923048000317067 time
recovery_state_mcts_prob spend 0.2730983779983944 time
state_batch spend 0.0020726439979625866 time
mcts_probs_batch spend 0.007194520003395155 time
winner_batch spend 0.0002799220019369386 time
policy_value spend 0.2173100889995112 time
train_step spend 0.6371480010056985 time
policy_value spend 0.21755238499463303 time
train_step spend 0.6352597209988744 time
policy_value spend 0.21773922300053528 time
train_step spend 0.635291172999132 time
policy_value spend 0.21663559100124985 time
train_step spend 0.635554582993791 time
policy_value spend 0.21770327600097517 time
train_step spend 0.6361008099993342 time
policy_value spend 0.21770383799594129 time
kl:0.00344,lr_multiplier:11.391,loss:5.349796772003174,entropy:6.0938897132873535,explained_var_old:0.987286150,explained_var_new:0.995131254
output spend 0.00014971999917179346 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007235771001433022 time
recovery_state_mcts_prob spend 0.2735063479995006 time
state_batch spend 0.0017989510015468113 time
mcts_probs_batch spend 0.006641776999458671 time
winner_batch spend 0.0002912639974965714 time
policy_value spend 0.2253497889978462 time
train_step spend 0.6570460579969222 time
policy_value spend 0.23083109900471754 time
train_step spend 0.6514453950003372 time
policy_value spend 0.21869012900424423 time
train_step spend 0.6363689639983932 time
policy_value spend 0.21737968700472265 time
train_step spend 0.6357071310048923 time
policy_value spend 0.21753880100004608 time
train_step spend 0.6358277599938447 time
policy_value spend 0.21766722500615288 time
kl:0.01598,lr_multiplier:11.391,loss:5.367781162261963,entropy:6.097142219543457,explained_var_old:0.982486367,explained_var_new:0.993896902
output spend 0.00014881700190017 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0072406850013067015 time
recovery_state_mcts_prob spend 0.2810409800003981 time
state_batch spend 0.0018278989955433644 time
mcts_probs_batch spend 0.006456644005083945 time
winner_batch spend 0.0002988319974974729 time
policy_value spend 0.21731600099883508 time
train_step spend 0.6353862549949554 time
policy_value spend 0.21830619200045476 time
train_step spend 0.6336550869964412 time
policy_value spend 0.2165308379990165 time
train_step spend 0.633615324004495 time
policy_value spend 0.21656439200160094 time
train_step spend 0.6339484620039002 time
policy_value spend 0.2171531009953469 time
train_step spend 0.633849312995153 time
policy_value spend 0.21616725299827522 time
kl:0.00255,lr_multiplier:11.391,loss:5.360459327697754,entropy:6.085129737854004,explained_var_old:0.979910672,explained_var_new:0.987078071
output spend 0.0001502519953646697 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010742990001745056 time
recovery_state_mcts_prob spend 0.27102171599835856 time
state_batch spend 0.001988157004234381 time
mcts_probs_batch spend 0.007049340994853992 time
winner_batch spend 0.0002876920043490827 time
policy_value spend 0.21951515999535332 time
train_step spend 0.635277761000907 time
policy_value spend 0.2166372979991138 time
train_step spend 0.633465166996757 time
policy_value spend 0.21630382200237364 time
train_step spend 0.6336002449970692 time
policy_value spend 0.21624665400304366 time
train_step spend 0.6343467280021287 time
policy_value spend 0.2172573409989127 time
train_step spend 0.6362222399984603 time
policy_value spend 0.2163167640028405 time
kl:0.00287,lr_multiplier:11.391,loss:5.3843512535095215,entropy:6.063357830047607,explained_var_old:0.984363079,explained_var_new:0.986870706
output spend 0.00016139400395331904 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011839942002552561 time
recovery_state_mcts_prob spend 0.2794431110014557 time
state_batch spend 0.001847283994720783 time
mcts_probs_batch spend 0.005243463005172089 time
winner_batch spend 0.00039698899490758777 time
policy_value spend 0.21638511600031052 time
train_step spend 0.634086166995985 time
policy_value spend 0.216447769998922 time
train_step spend 0.6341536440013442 time
policy_value spend 0.21603706500172848 time
train_step spend 0.6332971550000366 time
policy_value spend 0.21664577200135682 time
train_step spend 0.6332768880020012 time
policy_value spend 0.21582798499730416 time
train_step spend 0.6331207230032305 time
policy_value spend 0.21644570399803342 time
kl:0.00415,lr_multiplier:11.391,loss:5.428779125213623,entropy:6.082185745239258,explained_var_old:0.985994220,explained_var_new:0.987409353
output spend 0.0001460959974792786 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011048778003896587 time
recovery_state_mcts_prob spend 0.2700365900018369 time
state_batch spend 0.0018408969990559854 time
mcts_probs_batch spend 0.004729752996354364 time
winner_batch spend 0.00033654300204943866 time
policy_value spend 0.2154757550015347 time
train_step spend 0.6334784350037808 time
policy_value spend 0.2168025899954955 time
train_step spend 0.6353564989985898 time
policy_value spend 0.2175900969959912 time
train_step spend 0.6346989119992941 time
policy_value spend 0.21729370699904393 time
train_step spend 0.63537250799709 time
policy_value spend 0.2171435889977147 time
train_step spend 0.6360166289960034 time
policy_value spend 0.21703688400157262 time
kl:0.00784,lr_multiplier:11.391,loss:5.3368916511535645,entropy:6.098470211029053,explained_var_old:0.993593097,explained_var_new:0.998271704
output spend 0.00016955599858192727 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00718503599637188 time
recovery_state_mcts_prob spend 0.2747182960010832 time
state_batch spend 0.0018996639992110431 time
mcts_probs_batch spend 0.004465110003366135 time
winner_batch spend 0.0003474589975667186 time
policy_value spend 0.21613291100220522 time
train_step spend 0.6345972820054158 time
policy_value spend 0.21697958699951414 time
train_step spend 0.6347452720001456 time
policy_value spend 0.2173702139989473 time
train_step spend 0.6351124909997452 time
policy_value spend 0.2170611719993758 time
train_step spend 0.6349854220025009 time
policy_value spend 0.2172963049961254 time
train_step spend 0.6368617170010111 time
policy_value spend 0.21796324299793923 time
kl:0.00400,lr_multiplier:11.391,loss:5.454581260681152,entropy:6.116785049438477,explained_var_old:0.979657650,explained_var_new:0.986275554
output spend 0.00015040599828353152 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009933717003150377 time
recovery_state_mcts_prob spend 0.2689142039962462 time
state_batch spend 0.0019537090047379024 time
mcts_probs_batch spend 0.004789847000211012 time
winner_batch spend 0.0002911179981310852 time
policy_value spend 0.21702019599615596 time
train_step spend 0.6366472139998223 time
policy_value spend 0.21761953300301684 time
train_step spend 0.6370937640022021 time
policy_value spend 0.21756379699945683 time
train_step spend 0.6367092610016698 time
policy_value spend 0.21896930799994152 time
train_step spend 0.64696243799699 time
policy_value spend 0.21805773000232875 time
train_step spend 0.6380835770032718 time
policy_value spend 0.21751377799955662 time
kl:0.00416,lr_multiplier:11.391,loss:5.430735111236572,entropy:6.091926574707031,explained_var_old:0.990086615,explained_var_new:0.994178414
output spend 0.00014838599599897861 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007567557004222181 time
recovery_state_mcts_prob spend 0.2724581919974298 time
state_batch spend 0.0017763720024959184 time
mcts_probs_batch spend 0.0045204630005173385 time
winner_batch spend 0.00028699999529635534 time
policy_value spend 0.21730435400240822 time
train_step spend 0.6372696620019269 time
policy_value spend 0.2167277889966499 time
train_step spend 0.6290593369994895 time
policy_value spend 0.2149403439980233 time
train_step spend 0.6286171870015096 time
policy_value spend 0.21477424500335474 time
train_step spend 0.6293104180003866 time
policy_value spend 0.215580502001103 time
train_step spend 0.6295085249948897 time
policy_value spend 0.2153139460060629 time
kl:0.00387,lr_multiplier:11.391,loss:5.384730339050293,entropy:6.056026458740234,explained_var_old:0.984390914,explained_var_new:0.987353027
output spend 0.00025179600197589025 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010145430998818483 time
recovery_state_mcts_prob spend 0.2719833190058125 time
state_batch spend 0.0018843180005205795 time
mcts_probs_batch spend 0.004517969995504245 time
winner_batch spend 0.00028813900280511007 time
policy_value spend 0.21366845699958503 time
train_step spend 0.6285152480049874 time
policy_value spend 0.21528251999552594 time
train_step spend 0.6291440959976171 time
policy_value spend 0.2149443180023809 time
train_step spend 0.6285727010035771 time
policy_value spend 0.2158040729991626 time
train_step spend 0.6287345349992393 time
policy_value spend 0.21507926200138172 time
train_step spend 0.6316937239971594 time
policy_value spend 0.21575334500084864 time
kl:0.00324,lr_multiplier:11.391,loss:5.316030502319336,entropy:6.055619239807129,explained_var_old:0.988699555,explained_var_new:0.993907094
output spend 0.00027809300081571564 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008133115006785374 time
recovery_state_mcts_prob spend 0.2959927189949667 time
state_batch spend 0.0019159369985572994 time
mcts_probs_batch spend 0.004690267000114545 time
winner_batch spend 0.00037367800541687757 time
policy_value spend 0.23022405699884985 time
train_step spend 0.650481339005637 time
policy_value spend 0.2165694099967368 time
train_step spend 0.6330615730039426 time
policy_value spend 0.2173525409962167 time
train_step spend 0.632136560001527 time
policy_value spend 0.21603886900265934 time
train_step spend 0.6316903039987665 time
policy_value spend 0.21613828600675333 time
train_step spend 0.6320749209990026 time
policy_value spend 0.2163116119991173 time
kl:0.00600,lr_multiplier:11.391,loss:5.346189498901367,entropy:6.047435283660889,explained_var_old:0.990394294,explained_var_new:0.994293809
output spend 0.00015175600128713995 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011776561994338408 time
recovery_state_mcts_prob spend 0.2764276600064477 time
state_batch spend 0.0017636519987718202 time
mcts_probs_batch spend 0.00473875899479026 time
winner_batch spend 0.0002928360045189038 time
policy_value spend 0.21514519499760354 time
train_step spend 0.6313506309961667 time
policy_value spend 0.21634784000343643 time
train_step spend 0.6347514459994272 time
policy_value spend 0.2176873499993235 time
train_step spend 0.6352186829972197 time
policy_value spend 0.2171841180024785 time
train_step spend 0.6356552030047169 time
policy_value spend 0.21733330300048692 time
train_step spend 0.6360654820018681 time
policy_value spend 0.21747361799498321 time
kl:0.01007,lr_multiplier:11.391,loss:5.312705993652344,entropy:6.051303386688232,explained_var_old:0.974096835,explained_var_new:0.992783606
output spend 0.00020199400023557246 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007255440003063995 time
recovery_state_mcts_prob spend 0.2693309140013298 time
state_batch spend 0.0019133429959765635 time
mcts_probs_batch spend 0.016058159999374766 time
winner_batch spend 0.0002896330042858608 time
policy_value spend 0.22057864099770086 time
train_step spend 0.636708586003806 time
policy_value spend 0.217041778996645 time
train_step spend 0.6354330989997834 time
policy_value spend 0.21731911399547243 time
train_step spend 0.6356114399968646 time
policy_value spend 0.2172689610015368 time
train_step spend 0.6352250749987434 time
policy_value spend 0.21744707700418076 time
train_step spend 0.6464804319984978 time
policy_value spend 0.22038067300309194 time
kl:0.00518,lr_multiplier:11.391,loss:5.28966760635376,entropy:6.021694183349609,explained_var_old:0.985737085,explained_var_new:0.992728591
output spend 0.00015758299559820443 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008006635995116085 time
recovery_state_mcts_prob spend 0.27184647700050846 time
state_batch spend 0.001825806000852026 time
mcts_probs_batch spend 0.006738167998264544 time
winner_batch spend 0.00033413200435461476 time
policy_value spend 0.2219871540000895 time
train_step spend 0.6474814039975172 time
policy_value spend 0.22118178000528133 time
train_step spend 0.6474800729993149 time
policy_value spend 0.22108857299463125 time
train_step spend 0.6465624170014053 time
policy_value spend 0.2211033409985248 time
train_step spend 0.6474640059968806 time
policy_value spend 0.2215514470008202 time
train_step spend 0.646074600997963 time
policy_value spend 0.22167429600085597 time
kl:0.01715,lr_multiplier:11.391,loss:5.403979301452637,entropy:6.097268104553223,explained_var_old:0.970841050,explained_var_new:0.982158363
output spend 0.00015009700291557238 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009893201000522822 time
recovery_state_mcts_prob spend 0.2707364149973728 time
state_batch spend 0.0017850970034487545 time
mcts_probs_batch spend 0.006783751996408682 time
winner_batch spend 0.0003421010042075068 time
policy_value spend 0.22112725999613758 time
train_step spend 0.6462993000022834 time
policy_value spend 0.20884587600448867 time
train_step spend 0.6089858430059394 time
policy_value spend 0.21164491499803262 time
train_step spend 0.6089259180007502 time
policy_value spend 0.20788986700063106 time
train_step spend 0.6092696139967302 time
policy_value spend 0.20795812900178134 time
train_step spend 0.6090801339960308 time
policy_value spend 0.20819363000191515 time
kl:0.02499,lr_multiplier:11.391,loss:5.343759536743164,entropy:6.037168979644775,explained_var_old:0.973883569,explained_var_new:0.982184172
output spend 0.00014078000094741583 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009117034998780582 time
recovery_state_mcts_prob spend 0.27038360600272426 time
state_batch spend 0.0019686300001922064 time
mcts_probs_batch spend 0.006743909994838759 time
winner_batch spend 0.00027141500322613865 time
policy_value spend 0.20836678699561162 time
train_step spend 0.611272371999803 time
policy_value spend 0.21702026300044963 time
train_step spend 0.6355773499963107 time
policy_value spend 0.21818697600247106 time
train_step spend 0.6354938709991984 time
policy_value spend 0.2173750329966424 time
train_step spend 0.636003127998265 time
policy_value spend 0.21807475300010992 time
train_step spend 0.6351528520026477 time
policy_value spend 0.21748426200065296 time
kl:0.01284,lr_multiplier:11.391,loss:5.363014221191406,entropy:6.052342891693115,explained_var_old:0.974782288,explained_var_new:0.979032993
output spend 0.0001457840044167824 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007269214002008084 time
recovery_state_mcts_prob spend 0.2687313809947227 time
state_batch spend 0.0017713180059217848 time
mcts_probs_batch spend 0.006262113995035179 time
winner_batch spend 0.0002815280022332445 time
policy_value spend 0.21704353699897183 time
train_step spend 0.6362760859992704 time
policy_value spend 0.21654815899819368 time
train_step spend 0.6348113519998151 time
policy_value spend 0.21682264399714768 time
train_step spend 0.6352308339992305 time
policy_value spend 0.21703366900328547 time
train_step spend 0.6363220519997412 time
policy_value spend 0.21713795400137315 time
train_step spend 0.6357467690031626 time
policy_value spend 0.21704156100167893 time
kl:0.00467,lr_multiplier:11.391,loss:5.341452598571777,entropy:6.026699066162109,explained_var_old:0.986370683,explained_var_new:0.990638256
output spend 0.00014807399566052482 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007399893998808693 time
recovery_state_mcts_prob spend 0.27028777700616047 time
state_batch spend 0.002120621000358369 time
mcts_probs_batch spend 0.004552787999273278 time
winner_batch spend 0.0002891999974963255 time
policy_value spend 0.2158966139977565 time
train_step spend 0.6360613900033059 time
policy_value spend 0.21713347499462543 time
train_step spend 0.6369636899980833 time
policy_value spend 0.2175161460036179 time
train_step spend 0.6363772260010592 time
policy_value spend 0.21787520200450672 time
train_step spend 0.6369901790021686 time
policy_value spend 0.21761911700014025 time
train_step spend 0.636529192001035 time
policy_value spend 0.21855367000534898 time
kl:0.00966,lr_multiplier:11.391,loss:5.323531150817871,entropy:6.047849655151367,explained_var_old:0.988119721,explained_var_new:0.993949294
output spend 0.00015824000001884997 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007564993000414688 time
recovery_state_mcts_prob spend 0.2743129169975873 time
state_batch spend 0.0018597059970488772 time
mcts_probs_batch spend 0.004604293004376814 time
winner_batch spend 0.0003218709971406497 time
policy_value spend 0.21781521599768894 time
train_step spend 0.6363971729952027 time
policy_value spend 0.21869650600274326 time
train_step spend 0.6400028579955688 time
policy_value spend 0.21742739800538402 time
train_step spend 0.6525861080008326 time
policy_value spend 0.23171418799756793 time
train_step spend 0.66473431999475 time
policy_value spend 0.22068512700207066 time
train_step spend 0.6555804510062444 time
policy_value spend 0.22301582899672212 time
kl:0.00322,lr_multiplier:11.391,loss:5.358656883239746,entropy:6.078794479370117,explained_var_old:0.984351635,explained_var_new:0.993743658
output spend 0.00016496200260007754 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008450663000985514 time
recovery_state_mcts_prob spend 0.27674597399891354 time
state_batch spend 0.001903705000586342 time
mcts_probs_batch spend 0.004917785001453012 time
winner_batch spend 0.0003215589968021959 time
policy_value spend 0.22166544599895133 time
train_step spend 0.6526078779934323 time
policy_value spend 0.22464058000332443 time
train_step spend 0.6531116189944441 time
policy_value spend 0.22194808500353247 time
train_step spend 0.6519087939959718 time
policy_value spend 0.22184732100140536 time
train_step spend 0.6518739249950158 time
policy_value spend 0.22204355800204212 time
train_step spend 0.6520064069991349 time
policy_value spend 0.2225686490055523 time
kl:0.00753,lr_multiplier:11.391,loss:5.400615215301514,entropy:6.103799819946289,explained_var_old:0.979220450,explained_var_new:0.988501251
output spend 0.00015294500190066174 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0067319570007384755 time
recovery_state_mcts_prob spend 0.29691831699892646 time
state_batch spend 0.0018587820013635792 time
mcts_probs_batch spend 0.012397972001053859 time
winner_batch spend 0.00033831399923656136 time
policy_value spend 0.21690257199952612 time
train_step spend 0.6374960940011078 time
policy_value spend 0.21715449099428952 time
train_step spend 0.634428602999833 time
policy_value spend 0.21655373200337635 time
train_step spend 0.634640602998843 time
policy_value spend 0.2163177149996045 time
train_step spend 0.6361448460011161 time
policy_value spend 0.2166178499974194 time
train_step spend 0.6348743740018108 time
policy_value spend 0.21662178599945037 time
kl:0.00460,lr_multiplier:11.391,loss:5.312802791595459,entropy:6.063525199890137,explained_var_old:0.992163122,explained_var_new:0.996947169
output spend 0.00014949699834687635 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007396188004349824 time
recovery_state_mcts_prob spend 0.2778642819976085 time
state_batch spend 0.0019249839970143512 time
mcts_probs_batch spend 0.004901621003227774 time
winner_batch spend 0.0003158210020046681 time
policy_value spend 0.2158024039963493 time
train_step spend 0.6349628280004254 time
policy_value spend 0.21575850999943214 time
train_step spend 0.6344664089992875 time
policy_value spend 0.21603136300109327 time
train_step spend 0.6340332969994051 time
policy_value spend 0.21654098599537974 time
train_step spend 0.6324320400017314 time
policy_value spend 0.2103427490001195 time
train_step spend 0.6146948030000203 time
policy_value spend 0.21044398300000466 time
kl:0.00380,lr_multiplier:11.391,loss:5.333083152770996,entropy:6.053379058837891,explained_var_old:0.973444700,explained_var_new:0.982275665
output spend 0.00014498800010187551 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011612474001594819 time
recovery_state_mcts_prob spend 0.2646038250022684 time
state_batch spend 0.0017398309937561862 time
mcts_probs_batch spend 0.004454651003470644 time
winner_batch spend 0.0002813440005411394 time
policy_value spend 0.2103627010001219 time
train_step spend 0.6149829369969666 time
policy_value spend 0.2097988820023602 time
train_step spend 0.6152528729944606 time
policy_value spend 0.21011760500550736 time
train_step spend 0.6145677519962192 time
policy_value spend 0.21129591300268658 time
train_step spend 0.6222774510024465 time
policy_value spend 0.21845095499884337 time
train_step spend 0.6351304049967439 time
policy_value spend 0.21784373599803075 time
kl:0.02122,lr_multiplier:11.391,loss:5.321657180786133,entropy:6.0767364501953125,explained_var_old:0.990899265,explained_var_new:0.997953415
output spend 0.00015107799845281988 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0072374539959128015 time
recovery_state_mcts_prob spend 0.2753929350001272 time
state_batch spend 0.0017753799984348007 time
mcts_probs_batch spend 0.0061876480031060055 time
winner_batch spend 0.00034694699570536613 time
policy_value spend 0.2166105080032139 time
train_step spend 0.6344529730049544 time
policy_value spend 0.2166726790019311 time
train_step spend 0.6356301510022604 time
policy_value spend 0.21711560300173005 time
train_step spend 0.6350895929936087 time
policy_value spend 0.21856261500215624 time
train_step spend 0.6356167030025972 time
policy_value spend 0.21716715399816167 time
train_step spend 0.6353461839971715 time
policy_value spend 0.21740238900383702 time
kl:0.00760,lr_multiplier:11.391,loss:5.35438346862793,entropy:6.076970100402832,explained_var_old:0.977954686,explained_var_new:0.981541693
output spend 0.0001694310049060732 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009811183001147583 time
recovery_state_mcts_prob spend 0.2968697179967421 time
state_batch spend 0.002013833000091836 time
mcts_probs_batch spend 0.005042359000071883 time
winner_batch spend 0.0003053410036955029 time
policy_value spend 0.21646582299581496 time
train_step spend 0.6359454279954662 time
policy_value spend 0.21826947200315772 time
train_step spend 0.6363306030034437 time
policy_value spend 0.21795775999635225 time
train_step spend 0.6354063569960999 time
policy_value spend 0.2176605839995318 time
train_step spend 0.6367407200013986 time
policy_value spend 0.22349190100067062 time
train_step spend 0.6516449810005724 time
policy_value spend 0.22255320299882442 time
kl:0.00507,lr_multiplier:11.391,loss:5.333988666534424,entropy:6.082269668579102,explained_var_old:0.987332225,explained_var_new:0.991141498
output spend 0.00019615099881775677 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009316555006080307 time
recovery_state_mcts_prob spend 0.2795455919986125 time
state_batch spend 0.0018151990007027052 time
mcts_probs_batch spend 0.006895820995850954 time
winner_batch spend 0.00029782400088151917 time
policy_value spend 0.22214068400353426 time
train_step spend 0.6526419099973282 time
policy_value spend 0.22391506600251887 time
train_step spend 0.6523880630047643 time
policy_value spend 0.22367958100221585 time
train_step spend 0.6517653910050285 time
policy_value spend 0.22244528000010177 time
train_step spend 0.6520572009976604 time
policy_value spend 0.22336033399915323 time
train_step spend 0.6478685879992554 time
policy_value spend 0.21716868499788688 time
kl:0.00765,lr_multiplier:11.391,loss:5.319531440734863,entropy:6.042337417602539,explained_var_old:0.974304140,explained_var_new:0.981056452
output spend 0.00015163900388870388 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009500419997493736 time
recovery_state_mcts_prob spend 0.27239049399940995 time
state_batch spend 0.0026814880038728006 time
mcts_probs_batch spend 0.009266178996767849 time
winner_batch spend 0.000419957003032323 time
policy_value spend 0.21722303400019882 time
train_step spend 0.6344089379999787 time
policy_value spend 0.2158023480005795 time
train_step spend 0.6310120499983896 time
policy_value spend 0.21582216500246432 time
train_step spend 0.6306211670016637 time
policy_value spend 0.2157769389959867 time
train_step spend 0.6312868719978724 time
policy_value spend 0.2158905140022398 time
train_step spend 0.6305188990008901 time
policy_value spend 0.21574368399888044 time
kl:0.00375,lr_multiplier:11.391,loss:5.315584182739258,entropy:6.064108848571777,explained_var_old:0.988808155,explained_var_new:0.990519047
output spend 0.0001488030029577203 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009834615004365332 time
recovery_state_mcts_prob spend 0.275919312996848 time
state_batch spend 0.0019230649995733984 time
mcts_probs_batch spend 0.006969791000301484 time
winner_batch spend 0.0003227220004191622 time
policy_value spend 0.2172528200026136 time
train_step spend 0.6640664459991967 time
policy_value spend 0.23007723100454314 time
train_step spend 0.6344363459938904 time
policy_value spend 0.21725880600570235 time
train_step spend 0.6308861959987553 time
policy_value spend 0.21540224899945315 time
train_step spend 0.6249214679992292 time
policy_value spend 0.21095254200190539 time
train_step spend 0.6154528019978898 time
policy_value spend 0.2107810219968087 time
kl:0.00472,lr_multiplier:11.391,loss:5.364962577819824,entropy:6.072247505187988,explained_var_old:0.978633225,explained_var_new:0.983389974
output spend 0.0001455570018151775 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006626524998864625 time
recovery_state_mcts_prob spend 0.2582898630062118 time
state_batch spend 0.0017118979958468117 time
mcts_probs_batch spend 0.005838279997988138 time
winner_batch spend 0.00038999200478428975 time
policy_value spend 0.21231118199648336 time
train_step spend 0.6146232370010694 time
policy_value spend 0.2104791940000723 time
train_step spend 0.6150411849957891 time
policy_value spend 0.2099793840025086 time
train_step spend 0.615172548998089 time
policy_value spend 0.20978962200024398 time
train_step spend 0.6303578660008498 time
policy_value spend 0.21756431199901272 time
train_step spend 0.6381892790013808 time
policy_value spend 0.22006025900191162 time
kl:0.00958,lr_multiplier:11.391,loss:5.260772228240967,entropy:6.028933525085449,explained_var_old:0.992417157,explained_var_new:0.996121287
output spend 0.00016084300295915455 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010060815999167971 time
recovery_state_mcts_prob spend 0.2673492790054297 time
state_batch spend 0.0017788219993235543 time
mcts_probs_batch spend 0.004787490994203836 time
winner_batch spend 0.0003130610057269223 time
policy_value spend 0.21721475199592533 time
train_step spend 0.6351085859932937 time
policy_value spend 0.21717255000112345 time
train_step spend 0.6358210730031715 time
policy_value spend 0.21773138800199376 time
train_step spend 0.6354202680013259 time
policy_value spend 0.21751543999562273 time
train_step spend 0.6364322810040903 time
policy_value spend 0.21729426299862098 time
train_step spend 0.6367499769985443 time
policy_value spend 0.21764076199906413 time
kl:0.00367,lr_multiplier:11.391,loss:5.339426040649414,entropy:6.060147285461426,explained_var_old:0.985115886,explained_var_new:0.992989779
output spend 0.00018251499568577856 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007258999001351185 time
recovery_state_mcts_prob spend 0.2721852079994278 time
state_batch spend 0.0019065450032940134 time
mcts_probs_batch spend 0.00488791499810759 time
winner_batch spend 0.00029580199770862237 time
policy_value spend 0.2168561110011069 time
train_step spend 0.6365546129964059 time
policy_value spend 0.21744056600437034 time
train_step spend 0.6355934390012408 time
policy_value spend 0.21760939399973722 time
train_step spend 0.6360830889971112 time
policy_value spend 0.21777821699652122 time
train_step spend 0.6403971549952985 time
policy_value spend 0.2246820750006009 time
train_step spend 0.6581439309957204 time
policy_value spend 0.224322377005592 time
kl:0.00905,lr_multiplier:11.391,loss:5.259045600891113,entropy:6.041098594665527,explained_var_old:0.988504350,explained_var_new:0.994827390
output spend 0.0001600150062586181 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012185175997728948 time
recovery_state_mcts_prob spend 0.29124773000512505 time
state_batch spend 0.002236814994830638 time
mcts_probs_batch spend 0.004908588001853786 time
winner_batch spend 0.0003386190001037903 time
policy_value spend 0.2241047110001091 time
train_step spend 0.6577257550015929 time
policy_value spend 0.22475344199483516 time
train_step spend 0.657161849005206 time
policy_value spend 0.22433067499514436 time
train_step spend 0.6571782820028602 time
policy_value spend 0.22468542199931107 time
train_step spend 0.6453622890039696 time
policy_value spend 0.21662939799716696 time
train_step spend 0.6379179299983662 time
policy_value spend 0.21768007799983025 time
kl:0.00781,lr_multiplier:11.391,loss:5.322990417480469,entropy:6.0563459396362305,explained_var_old:0.988476992,explained_var_new:0.989231765
output spend 0.00014970899792388082 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007221378000394907 time
recovery_state_mcts_prob spend 0.2659495519983466 time
state_batch spend 0.001777653000317514 time
mcts_probs_batch spend 0.0047425660013686866 time
winner_batch spend 0.0003008920029969886 time
policy_value spend 0.21618223899713485 time
train_step spend 0.6304660759997205 time
policy_value spend 0.21483613199961837 time
train_step spend 0.6286363749968586 time
policy_value spend 0.2150651440024376 time
train_step spend 0.6282816099992488 time
policy_value spend 0.2151840459991945 time
train_step spend 0.6274284499959322 time
policy_value spend 0.21521051799936686 time
train_step spend 0.627476622001268 time
policy_value spend 0.21491532700019889 time
kl:0.00974,lr_multiplier:11.391,loss:5.225615501403809,entropy:6.014134883880615,explained_var_old:0.986273766,explained_var_new:0.993032813
output spend 0.00015916199481580406 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011370114996680059 time
recovery_state_mcts_prob spend 0.26926511299825506 time
state_batch spend 0.0017539910040795803 time
mcts_probs_batch spend 0.006912851000379305 time
winner_batch spend 0.00029458799690473825 time
policy_value spend 0.21473849799804157 time
train_step spend 0.6282776169973658 time
policy_value spend 0.21385500900214538 time
train_step spend 0.6270072199986316 time
policy_value spend 0.21394556899758754 time
train_step spend 0.6274958279973362 time
policy_value spend 0.21421953800017945 time
train_step spend 0.622974839003291 time
policy_value spend 0.20860077599354554 time
train_step spend 0.6111211560055381 time
policy_value spend 0.2091062819963554 time
kl:0.02113,lr_multiplier:11.391,loss:5.206599235534668,entropy:6.003324031829834,explained_var_old:0.982418120,explained_var_new:0.987283528
output spend 0.00014371900033438578 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008079170998826157 time
recovery_state_mcts_prob spend 0.26134375899709994 time
state_batch spend 0.0018004230005317368 time
mcts_probs_batch spend 0.004452412002137862 time
winner_batch spend 0.0002796539993141778 time
policy_value spend 0.2084280119961477 time
train_step spend 0.6117140279966407 time
policy_value spend 0.21105591300147353 time
train_step spend 0.6104384709979058 time
policy_value spend 0.2089704370009713 time
train_step spend 0.6113940959985484 time
policy_value spend 0.20913712000037776 time
train_step spend 0.6103326739976183 time
policy_value spend 0.20889190000161761 time
train_step spend 0.6121206729949336 time
policy_value spend 0.2092014290028601 time
kl:0.00514,lr_multiplier:11.391,loss:5.302394390106201,entropy:6.009499549865723,explained_var_old:0.987452507,explained_var_new:0.991429746
output spend 0.00017325999942841008 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01361618899682071 time
recovery_state_mcts_prob spend 0.2732739240018418 time
state_batch spend 0.0018346799988648854 time
mcts_probs_batch spend 0.005719392000173684 time
winner_batch spend 0.0002911650008172728 time
policy_value spend 0.21625119099917356 time
train_step spend 0.6351812869979767 time
policy_value spend 0.22068914199917344 time
train_step spend 0.6351532699991367 time
policy_value spend 0.2173074859965709 time
train_step spend 0.6351750300018466 time
policy_value spend 0.21730178500001784 time
train_step spend 0.635980668994307 time
policy_value spend 0.2170696540051722 time
train_step spend 0.652535531000467 time
policy_value spend 0.23010669199720724 time
kl:0.01966,lr_multiplier:11.391,loss:5.284049034118652,entropy:6.040205955505371,explained_var_old:0.983960450,explained_var_new:0.989696324
output spend 0.0001996200007852167 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00809267899603583 time
recovery_state_mcts_prob spend 0.27947650400165003 time
state_batch spend 0.001799735997337848 time
mcts_probs_batch spend 0.006652098003542051 time
winner_batch spend 0.00040170099964598194 time
policy_value spend 0.21916943899850594 time
train_step spend 0.6371176940010628 time
policy_value spend 0.2166052350003156 time
train_step spend 0.6346567630025675 time
policy_value spend 0.21726630599732744 time
train_step spend 0.6358391499961726 time
policy_value spend 0.216781423005159 time
train_step spend 0.6390647269945475 time
policy_value spend 0.22889132700220216 time
train_step spend 0.6678231969999615 time
policy_value spend 0.22891448400332592 time
kl:0.01368,lr_multiplier:11.391,loss:5.246424198150635,entropy:6.013139724731445,explained_var_old:0.986688375,explained_var_new:0.990110159
output spend 0.00016203899576794356 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007838639998226427 time
recovery_state_mcts_prob spend 0.28077233400108526 time
state_batch spend 0.0019155440022586845 time
mcts_probs_batch spend 0.01318638600059785 time
winner_batch spend 0.0003274889968452044 time
policy_value spend 0.23264138000376988 time
train_step spend 0.6708681820018683 time
policy_value spend 0.2287824009981705 time
train_step spend 0.6680313559991191 time
policy_value spend 0.2287134150028578 time
train_step spend 0.6688153869981761 time
policy_value spend 0.22850685400044313 time
train_step spend 0.6693365739993169 time
policy_value spend 0.22953287600103067 time
train_step spend 0.6685086599973147 time
policy_value spend 0.22902729400084354 time
kl:0.00485,lr_multiplier:11.391,loss:5.303936958312988,entropy:6.029976844787598,explained_var_old:0.987062752,explained_var_new:0.992843628
output spend 0.00017201100126840174 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00807947800058173 time
recovery_state_mcts_prob spend 0.26840856499620713 time
state_batch spend 0.002072212999337353 time
mcts_probs_batch spend 0.005665672004397493 time
winner_batch spend 0.000294102996122092 time
policy_value spend 0.21797344800143037 time
train_step spend 0.6347242420015391 time
policy_value spend 0.21845050700358115 time
train_step spend 0.6356334800002514 time
policy_value spend 0.21715851399494568 time
train_step spend 0.6358980090008117 time
policy_value spend 0.21687710900005186 time
train_step spend 0.6362140439960058 time
policy_value spend 0.21671488900028635 time
train_step spend 0.6351862609953969 time
policy_value spend 0.21720447500410955 time
kl:0.00349,lr_multiplier:11.391,loss:5.292447566986084,entropy:6.042325019836426,explained_var_old:0.991879165,explained_var_new:0.997531176
output spend 0.0001713919991743751 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007027478000964038 time
recovery_state_mcts_prob spend 0.26979528200172354 time
state_batch spend 0.0018084570037899539 time
mcts_probs_batch spend 0.005676656997820828 time
winner_batch spend 0.0004343190012150444 time
policy_value spend 0.21784047500113957 time
train_step spend 0.6364976819968433 time
policy_value spend 0.21743399700062582 time
train_step spend 0.6357545199934975 time
policy_value spend 0.2171236710055382 time
train_step spend 0.6395313530010753 time
policy_value spend 0.21699761500349268 time
train_step spend 0.6115411299979314 time
policy_value spend 0.20628674100589706 time
train_step spend 0.6029123009939212 time
policy_value spend 0.2062552150018746 time
kl:0.00665,lr_multiplier:11.391,loss:5.346449375152588,entropy:6.069187164306641,explained_var_old:0.986087680,explained_var_new:0.994070411
output spend 0.00015049100329633802 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0071260620024986565 time
recovery_state_mcts_prob spend 0.2601903129980201 time
state_batch spend 0.0016935489984462038 time
mcts_probs_batch spend 0.005483295004523825 time
winner_batch spend 0.0002803509996738285 time
policy_value spend 0.20615430899488274 time
train_step spend 0.6033654159982689 time
policy_value spend 0.20574625200242735 time
train_step spend 0.6021593080004095 time
policy_value spend 0.20583845799410483 time
train_step spend 0.6023520490052761 time
policy_value spend 0.2060613369976636 time
train_step spend 0.602747211996757 time
policy_value spend 0.2062485269998433 time
train_step spend 0.6015522569941822 time
policy_value spend 0.2055920570055605 time
kl:0.00438,lr_multiplier:11.391,loss:5.322565078735352,entropy:6.051108360290527,explained_var_old:0.991675675,explained_var_new:0.994709492
output spend 0.0001388770033372566 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011871328999404795 time
recovery_state_mcts_prob spend 0.26063011799851665 time
state_batch spend 0.0018935429980047047 time
mcts_probs_batch spend 0.005668165998940822 time
winner_batch spend 0.00026900800003204495 time
policy_value spend 0.20775691600283608 time
train_step spend 0.6324210740058334 time
policy_value spend 0.2218423559970688 time
train_step spend 0.6360420550045092 time
policy_value spend 0.21748456699424423 time
train_step spend 0.6360887780028861 time
policy_value spend 0.21719619799841894 time
train_step spend 0.6363196809979854 time
policy_value spend 0.21707592599705094 time
train_step spend 0.635714165000536 time
policy_value spend 0.21749500399891986 time
kl:0.01032,lr_multiplier:11.391,loss:5.226201057434082,entropy:6.010058403015137,explained_var_old:0.987343073,explained_var_new:0.994333804
output spend 0.000159420000272803 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008554900996387005 time
recovery_state_mcts_prob spend 0.28018982900539413 time
state_batch spend 0.00191161399561679 time
mcts_probs_batch spend 0.006390410999301821 time
winner_batch spend 0.0003314480054541491 time
policy_value spend 0.21749168499809457 time
train_step spend 0.636671808999381 time
policy_value spend 0.21782947100291494 time
train_step spend 0.6364194490015507 time
policy_value spend 0.2177963939975598 time
train_step spend 0.6359619249997195 time
policy_value spend 0.21793720499408664 time
train_step spend 0.6411602560037863 time
policy_value spend 0.22522732399374945 time
train_step spend 0.6580948530026944 time
policy_value spend 0.22527298399654683 time
kl:0.00323,lr_multiplier:11.391,loss:5.203060150146484,entropy:5.999581336975098,explained_var_old:0.980825603,explained_var_new:0.986872852
output spend 0.0001655060041230172 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010139081998204347 time
recovery_state_mcts_prob spend 0.2888574519965914 time
state_batch spend 0.0018454750024829991 time
mcts_probs_batch spend 0.005908305000048131 time
winner_batch spend 0.00030038099794182926 time
policy_value spend 0.22497121700143907 time
train_step spend 0.6583195369967143 time
policy_value spend 0.22463823500584112 time
train_step spend 0.6567831120046321 time
policy_value spend 0.22480307299701963 time
train_step spend 0.6590057400026126 time
policy_value spend 0.22524305200204253 time
train_step spend 0.657790514997032 time
policy_value spend 0.22546057600266067 time
train_step spend 0.6573682630041731 time
policy_value spend 0.22521053200034657 time
kl:0.01583,lr_multiplier:11.391,loss:5.298009395599365,entropy:6.0371856689453125,explained_var_old:0.993934214,explained_var_new:0.998778880
output spend 0.00023074400087352842 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009997287001169752 time
recovery_state_mcts_prob spend 0.27515412300272146 time
state_batch spend 0.001977533996978309 time
mcts_probs_batch spend 0.0055445999969379045 time
winner_batch spend 0.0003300990065326914 time
policy_value spend 0.22855165199871408 time
train_step spend 0.6285191749993828 time
policy_value spend 0.22039090399630368 time
train_step spend 0.6180782619994716 time
policy_value spend 0.207313503997284 time
train_step spend 0.6026618129981216 time
policy_value spend 0.20647882600314915 time
train_step spend 0.6037115029976121 time
policy_value spend 0.20666959100344684 time
train_step spend 0.6031039180015796 time
policy_value spend 0.2062352699940675 time
kl:0.00859,lr_multiplier:11.391,loss:5.249241828918457,entropy:6.05033016204834,explained_var_old:0.993124664,explained_var_new:0.997548938
output spend 0.00013961600052425638 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008033245001570322 time
recovery_state_mcts_prob spend 0.2534282339984202 time
state_batch spend 0.0016696550010237843 time
mcts_probs_batch spend 0.005801579995022621 time
winner_batch spend 0.00029502100369427353 time
policy_value spend 0.20641818599688122 time
train_step spend 0.6021539970024605 time
policy_value spend 0.20608596899546683 time
train_step spend 0.6024304589955136 time
policy_value spend 0.2059505569995963 time
train_step spend 0.6028860619990155 time
policy_value spend 0.20650804099568632 time
train_step spend 0.6036433929984923 time
policy_value spend 0.21240465300070355 time
train_step spend 0.6190977610021946 time
policy_value spend 0.2120396910031559 time
kl:0.00377,lr_multiplier:11.391,loss:5.239238739013672,entropy:6.033618927001953,explained_var_old:0.988765299,explained_var_new:0.994048238
output spend 0.00015046500629978254 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007395364998956211 time
recovery_state_mcts_prob spend 0.2608729339990532 time
state_batch spend 0.0018308030048501678 time
mcts_probs_batch spend 0.005811064998852089 time
winner_batch spend 0.0002831109959515743 time
policy_value spend 0.21123464200354647 time
train_step spend 0.6198177010010113 time
policy_value spend 0.21298035499785328 time
train_step spend 0.6173332899998059 time
policy_value spend 0.2110467439997592 time
train_step spend 0.6186017290019663 time
policy_value spend 0.2116725019950536 time
train_step spend 0.618864547002886 time
policy_value spend 0.21129293999547372 time
train_step spend 0.6185546310007339 time
policy_value spend 0.21146884699555812 time
kl:0.00283,lr_multiplier:11.391,loss:5.232145309448242,entropy:6.005343437194824,explained_var_old:0.989220202,explained_var_new:0.997731924
output spend 0.00014401599764823914 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007258969999384135 time
recovery_state_mcts_prob spend 0.2745085950009525 time
state_batch spend 0.0018489450012566522 time
mcts_probs_batch spend 0.004602768000040669 time
winner_batch spend 0.00029068799631204456 time
policy_value spend 0.2103478319986607 time
train_step spend 0.6190129480019095 time
policy_value spend 0.21771935199649306 time
train_step spend 0.6450665239972295 time
policy_value spend 0.22028454600513214 time
train_step spend 0.6441082090022974 time
policy_value spend 0.22090773400122998 time
train_step spend 0.6452820080012316 time
policy_value spend 0.2203928589951829 time
train_step spend 0.6456622699988657 time
policy_value spend 0.2199007880044519 time
kl:0.00506,lr_multiplier:11.391,loss:5.295198917388916,entropy:5.99809455871582,explained_var_old:0.974051356,explained_var_new:0.978205860
output spend 0.00015208800323307514 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007378603004326578 time
recovery_state_mcts_prob spend 0.2684962470011669 time
state_batch spend 0.0017971599954762496 time
mcts_probs_batch spend 0.005612838998786174 time
winner_batch spend 0.000292030003038235 time
policy_value spend 0.22053807000338566 time
train_step spend 0.646156164999411 time
policy_value spend 0.22045277799770702 time
train_step spend 0.6448679989989614 time
policy_value spend 0.22049321899976349 time
train_step spend 0.6442422420004732 time
policy_value spend 0.22001408499636455 time
train_step spend 0.6451813480016426 time
policy_value spend 0.2329765579997911 time
train_step spend 0.680492226005299 time
policy_value spend 0.2323249209948699 time
kl:0.01389,lr_multiplier:11.391,loss:5.296950340270996,entropy:6.040266036987305,explained_var_old:0.981833696,explained_var_new:0.985993743
output spend 0.000168219004990533 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007716888998402283 time
recovery_state_mcts_prob spend 0.2849921449960675 time
state_batch spend 0.0019889430041075684 time
mcts_probs_batch spend 0.006233007996343076 time
winner_batch spend 0.0003151800046907738 time
policy_value spend 0.23263318699900992 time
train_step spend 0.6815999239988741 time
policy_value spend 0.23211312900093617 time
train_step spend 0.680318560996966 time
policy_value spend 0.23313435300224228 time
train_step spend 0.680817542001023 time
policy_value spend 0.2191504590009572 time
train_step spend 0.6367488210016745 time
policy_value spend 0.21750874900317285 time
train_step spend 0.6356647190041258 time
policy_value spend 0.2167542829993181 time
kl:0.00739,lr_multiplier:11.391,loss:5.1948418617248535,entropy:6.023517608642578,explained_var_old:0.983669221,explained_var_new:0.991031528
output spend 0.00014835000183666125 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007155812003475148 time
recovery_state_mcts_prob spend 0.27057825199881336 time
state_batch spend 0.001939018999109976 time
mcts_probs_batch spend 0.006055974001355935 time
winner_batch spend 0.00035107399889966473 time
policy_value spend 0.21853226800158154 time
train_step spend 0.6278572139999596 time
policy_value spend 0.2125447259968496 time
train_step spend 0.6188172990005114 time
policy_value spend 0.21165664000000106 time
train_step spend 0.619389080995461 time
policy_value spend 0.21129245799966156 time
train_step spend 0.6183431610043044 time
policy_value spend 0.21110855499864556 time
train_step spend 0.6190350969991414 time
policy_value spend 0.21103157899779035 time
kl:0.00497,lr_multiplier:11.391,loss:5.1812744140625,entropy:5.968990325927734,explained_var_old:0.984654427,explained_var_new:0.990524054
output spend 0.000141885997436475 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007132257997000124 time
recovery_state_mcts_prob spend 0.26255220400344115 time
state_batch spend 0.0018090629964717664 time
mcts_probs_batch spend 0.0046331789999385364 time
winner_batch spend 0.00029663799796253443 time
policy_value spend 0.21125517200562172 time
train_step spend 0.6189990389975719 time
policy_value spend 0.21155265299603343 time
train_step spend 0.619564068998443 time
policy_value spend 0.21231026200257475 time
train_step spend 0.6194040019981912 time
policy_value spend 0.21218022199900588 time
train_step spend 0.61566039200261 time
policy_value spend 0.20606895499804523 time
train_step spend 0.6038953499955824 time
policy_value spend 0.2061590170051204 time
kl:0.00357,lr_multiplier:11.391,loss:5.228301048278809,entropy:6.001549243927002,explained_var_old:0.979826868,explained_var_new:0.990820348
output spend 0.00014134799857856706 time
已保存最新模型
current self-play batch: 300
load data begin
已加载数据
step i 372: 
random.sample spend 0.010171522000746336 time
recovery_state_mcts_prob spend 0.27372075599851087 time
state_batch spend 0.0020244300030753948 time
mcts_probs_batch spend 0.005217585996433627 time
winner_batch spend 0.00030789800075581297 time
policy_value spend 0.20712003000517143 time
train_step spend 0.6379032350014313 time
policy_value spend 0.21027343099558493 time
train_step spend 0.6063392119976925 time
policy_value spend 0.20663461500225822 time
train_step spend 0.6025755769951502 time
policy_value spend 0.2062196810002206 time
train_step spend 0.6025854679974145 time
policy_value spend 0.20566777999920305 time
train_step spend 0.6027051120036049 time
policy_value spend 0.2060229439957766 time
kl:0.00345,lr_multiplier:11.391,loss:5.212087154388428,entropy:6.002042293548584,explained_var_old:0.988760471,explained_var_new:0.994265258
output spend 0.0002735070011112839 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011321284000587184 time
recovery_state_mcts_prob spend 0.30150234999746317 time
state_batch spend 0.001700284999969881 time
mcts_probs_batch spend 0.006424760002119001 time
winner_batch spend 0.00038479299837490544 time
policy_value spend 0.22616377499798546 time
train_step spend 0.6553289360017516 time
policy_value spend 0.22304691300087143 time
train_step spend 0.6426761530019576 time
policy_value spend 0.21937374699336942 time
train_step spend 0.6402567980039748 time
policy_value spend 0.21988161299668718 time
train_step spend 0.6422657750008511 time
policy_value spend 0.2188225850040908 time
train_step spend 0.6426534910060582 time
policy_value spend 0.21846172899677185 time
kl:0.00281,lr_multiplier:11.391,loss:5.170478820800781,entropy:5.961732387542725,explained_var_old:0.995714307,explained_var_new:0.998232603
output spend 0.00014948200259823352 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010326130002795253 time
recovery_state_mcts_prob spend 0.269922173996747 time
state_batch spend 0.001922160001413431 time
mcts_probs_batch spend 0.006889115000376478 time
winner_batch spend 0.00030085499747656286 time
policy_value spend 0.2199693889997434 time
train_step spend 0.6421377489969018 time
policy_value spend 0.21879017200262751 time
train_step spend 0.6413935710006626 time
policy_value spend 0.21900355099933222 time
train_step spend 0.6412127279982087 time
policy_value spend 0.21897186700516613 time
train_step spend 0.6470611709955847 time
policy_value spend 0.23263194500032114 time
train_step spend 0.6820402439989266 time
policy_value spend 0.2323475960001815 time
kl:0.00461,lr_multiplier:11.391,loss:5.172235488891602,entropy:5.972723960876465,explained_var_old:0.994305372,explained_var_new:0.997971892
output spend 0.00015941899619065225 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007737010004348122 time
recovery_state_mcts_prob spend 0.29775838899513474 time
state_batch spend 0.001995147998968605 time
mcts_probs_batch spend 0.004814495005120989 time
winner_batch spend 0.0003083580013480969 time
policy_value spend 0.23126143199624494 time
train_step spend 0.6810440670014941 time
policy_value spend 0.23492139999871142 time
train_step spend 0.6728754689975176 time
policy_value spend 0.21740225100074895 time
train_step spend 0.6349158069933765 time
policy_value spend 0.21732239900302375 time
train_step spend 0.6348531769981491 time
policy_value spend 0.21686849700199673 time
train_step spend 0.6366633099969476 time
policy_value spend 0.21776669500104617 time
kl:0.01008,lr_multiplier:11.391,loss:5.274129390716553,entropy:5.9996538162231445,explained_var_old:0.984389544,explained_var_new:0.987227798
output spend 0.0002020009997067973 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010820465002325363 time
recovery_state_mcts_prob spend 0.276832766001462 time
state_batch spend 0.0020834399983868934 time
mcts_probs_batch spend 0.007134751002013218 time
winner_batch spend 0.0003325239958940074 time
policy_value spend 0.21696358500048518 time
train_step spend 0.6220760709984461 time
policy_value spend 0.20948830700217513 time
train_step spend 0.6130348229999072 time
policy_value spend 0.2099446399952285 time
train_step spend 0.6131863619957585 time
policy_value spend 0.21050103600282455 time
train_step spend 0.6127493890016922 time
policy_value spend 0.20930228599900147 time
train_step spend 0.6160098429973004 time
policy_value spend 0.20938069999829168 time
kl:0.00920,lr_multiplier:11.391,loss:5.218169689178467,entropy:6.002352237701416,explained_var_old:0.984260023,explained_var_new:0.989558697
output spend 0.0001444870067643933 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010698890997446142 time
recovery_state_mcts_prob spend 0.26995619800436543 time
state_batch spend 0.0017327460009255446 time
mcts_probs_batch spend 0.012463292994652875 time
winner_batch spend 0.0002806109987432137 time
policy_value spend 0.21192147800320527 time
train_step spend 0.612675907999801 time
policy_value spend 0.2128163909947034 time
train_step spend 0.6127825489966199 time
policy_value spend 0.20938737699907506 time
train_step spend 0.6126185769971926 time
policy_value spend 0.20874866499798372 time
train_step spend 0.6142069679990527 time
policy_value spend 0.21018003700010013 time
train_step spend 0.6156489490022068 time
policy_value spend 0.21056831900204998 time
kl:0.00409,lr_multiplier:11.391,loss:5.254532814025879,entropy:6.003515243530273,explained_var_old:0.984990060,explained_var_new:0.990184426
output spend 0.0001725410038488917 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011484849004773423 time
recovery_state_mcts_prob spend 0.2603185650004889 time
state_batch spend 0.002186300996982027 time
mcts_probs_batch spend 0.005844380997586995 time
winner_batch spend 0.0003173500008415431 time
policy_value spend 0.21026568000525003 time
train_step spend 0.6164265499974135 time
policy_value spend 0.21026333099871408 time
train_step spend 0.6157157889974769 time
policy_value spend 0.2123112420013058 time
train_step spend 0.6159775089981849 time
policy_value spend 0.21022544000152266 time
train_step spend 0.6164615410016268 time
policy_value spend 0.21337663200392853 time
train_step spend 0.6166560719939298 time
policy_value spend 0.2101624790011556 time
kl:0.00674,lr_multiplier:11.391,loss:5.247550010681152,entropy:6.009756088256836,explained_var_old:0.988986075,explained_var_new:0.994201124
output spend 0.00015636400348739699 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009306048006692436 time
recovery_state_mcts_prob spend 0.271010608994402 time
state_batch spend 0.0017803470036596991 time
mcts_probs_batch spend 0.014695434998429846 time
winner_batch spend 0.0003993319987785071 time
policy_value spend 0.21411905300192302 time
train_step spend 0.6184426489999169 time
policy_value spend 0.21932794299937086 time
train_step spend 0.6424296980039799 time
policy_value spend 0.21966073099611094 time
train_step spend 0.641709780000383 time
policy_value spend 0.2191889669993543 time
train_step spend 0.6413758999988204 time
policy_value spend 0.21912908200465608 time
train_step spend 0.6423641859946656 time
policy_value spend 0.21908076500403695 time
kl:0.00424,lr_multiplier:11.391,loss:5.148515701293945,entropy:5.963006019592285,explained_var_old:0.989180386,explained_var_new:0.997623146
output spend 0.0001528409993625246 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006988842003920581 time
recovery_state_mcts_prob spend 0.26848248099850025 time
state_batch spend 0.0017929539972101338 time
mcts_probs_batch spend 0.006628355004067998 time
winner_batch spend 0.00028900399775011465 time
policy_value spend 0.21911095199902775 time
train_step spend 0.6424036829994293 time
policy_value spend 0.21994213200378 time
train_step spend 0.6418862709979294 time
policy_value spend 0.21950991700578015 time
train_step spend 0.6413802999959444 time
policy_value spend 0.21919687499757856 time
train_step spend 0.6453744480022579 time
policy_value spend 0.23340783700405154 time
train_step spend 0.6806599209958222 time
policy_value spend 0.2328735660048551 time
kl:0.00889,lr_multiplier:11.391,loss:5.178106307983398,entropy:5.976827621459961,explained_var_old:0.977633476,explained_var_new:0.986416936
output spend 0.0002016649959841743 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01127552999969339 time
recovery_state_mcts_prob spend 0.28769831899990095 time
state_batch spend 0.001931197002704721 time
mcts_probs_batch spend 0.013220885994087439 time
winner_batch spend 0.00033252299908781424 time
policy_value spend 0.23585013900446938 time
train_step spend 0.6810354439949151 time
policy_value spend 0.23246477600332582 time
train_step spend 0.6444895349995932 time
policy_value spend 0.21732429900293937 time
train_step spend 0.6533812550042057 time
policy_value spend 0.23096795699530048 time
train_step spend 0.6615930319967447 time
policy_value spend 0.21839923600055045 time
train_step spend 0.6371287690053578 time
policy_value spend 0.21757875500043156 time
kl:0.00310,lr_multiplier:11.391,loss:5.202510833740234,entropy:5.994977951049805,explained_var_old:0.993678033,explained_var_new:0.994893551
output spend 0.00016054799925768748 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008390077004150953 time
recovery_state_mcts_prob spend 0.2689005729989731 time
state_batch spend 0.0017721859985613264 time
mcts_probs_batch spend 0.01595659500162583 time
winner_batch spend 0.00029590899794129655 time
policy_value spend 0.2201562650006963 time
train_step spend 0.6174283740037936 time
policy_value spend 0.21070345699990867 time
train_step spend 0.6058385619980982 time
policy_value spend 0.20686272899911273 time
train_step spend 0.6059344269961002 time
policy_value spend 0.2065682399988873 time
train_step spend 0.6062133439991158 time
policy_value spend 0.20657842500077095 time
train_step spend 0.6055313079996267 time
policy_value spend 0.20694421900407178 time
kl:0.00496,lr_multiplier:11.391,loss:5.156768321990967,entropy:5.964302062988281,explained_var_old:0.991568923,explained_var_new:0.997174978
output spend 0.00018507200002204627 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006884366994199809 time
recovery_state_mcts_prob spend 0.2648236690001795 time
state_batch spend 0.0017928880042745732 time
mcts_probs_batch spend 0.0054882789991097525 time
winner_batch spend 0.0003020149961230345 time
policy_value spend 0.20768285600206582 time
train_step spend 0.6055356340002618 time
policy_value spend 0.209222381003201 time
train_step spend 0.6049226510003791 time
policy_value spend 0.20783682899491396 time
train_step spend 0.6057724570055143 time
policy_value spend 0.21022058299422497 time
train_step spend 0.6349190050023026 time
policy_value spend 0.21357770799659193 time
train_step spend 0.6247175070020603 time
policy_value spend 0.21329968200006988 time
kl:0.00355,lr_multiplier:11.391,loss:5.205264091491699,entropy:5.990910530090332,explained_var_old:0.982940555,explained_var_new:0.993610442
output spend 0.00015958500443957746 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00676662699697772 time
recovery_state_mcts_prob spend 0.2814799990010215 time
state_batch spend 0.0021985850034980103 time
mcts_probs_batch spend 0.00649126099597197 time
winner_batch spend 0.0002909969989559613 time
policy_value spend 0.21759311699861428 time
train_step spend 0.6254634889992303 time
policy_value spend 0.21727221599576296 time
train_step spend 0.6249381379966508 time
policy_value spend 0.21338782400562195 time
train_step spend 0.6252676590011106 time
policy_value spend 0.21358160299860174 time
train_step spend 0.6254822659975616 time
policy_value spend 0.2147708970005624 time
train_step spend 0.6253305399950477 time
policy_value spend 0.21421327400457812 time
kl:0.00369,lr_multiplier:11.391,loss:5.15509033203125,entropy:5.9581708908081055,explained_var_old:0.992937505,explained_var_new:0.997475684
output spend 0.00014553599612554535 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010394345998065546 time
recovery_state_mcts_prob spend 0.2698344329983229 time
state_batch spend 0.002036705998762045 time
mcts_probs_batch spend 0.00671621900255559 time
winner_batch spend 0.0003168559996993281 time
policy_value spend 0.21637195000221254 time
train_step spend 0.6261779420019593 time
policy_value spend 0.22050919399771374 time
train_step spend 0.6392100750017562 time
policy_value spend 0.21961433199612657 time
train_step spend 0.6395935580003425 time
policy_value spend 0.21923109699855559 time
train_step spend 0.6400233969980036 time
policy_value spend 0.21892623000167077 time
train_step spend 0.6393507339962525 time
policy_value spend 0.21860872100660345 time
kl:0.00575,lr_multiplier:11.391,loss:5.237191677093506,entropy:5.979510307312012,explained_var_old:0.983282626,explained_var_new:0.989175618
output spend 0.0001503710009274073 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006965542001125868 time
recovery_state_mcts_prob spend 0.2759980970004108 time
state_batch spend 0.0018005079982685857 time
mcts_probs_batch spend 0.016449021000880748 time
winner_batch spend 0.0003137090025120415 time
policy_value spend 0.22130309000203852 time
train_step spend 0.6395261970028514 time
policy_value spend 0.21844448299816577 time
train_step spend 0.638423280994175 time
policy_value spend 0.21839439600444166 time
train_step spend 0.6391812700021546 time
policy_value spend 0.21820792699872982 time
train_step spend 0.6397547960004886 time
policy_value spend 0.23144607399444794 time
train_step spend 0.6775950150040444 time
policy_value spend 0.23135707800247474 time
kl:0.00429,lr_multiplier:11.391,loss:5.179847717285156,entropy:5.979043006896973,explained_var_old:0.979653597,explained_var_new:0.989896178
output spend 0.000160297000547871 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007690607002587058 time
recovery_state_mcts_prob spend 0.2941135450018919 time
state_batch spend 0.001967386997421272 time
mcts_probs_batch spend 0.0073752079988480546 time
winner_batch spend 0.00033128500217571855 time
policy_value spend 0.23324488200159976 time
train_step spend 0.6766403300061938 time
policy_value spend 0.23547860399412457 time
train_step spend 0.6769974349954282 time
policy_value spend 0.21890520799934166 time
train_step spend 0.634370036998007 time
policy_value spend 0.21816204600327183 time
train_step spend 0.6366929600044386 time
policy_value spend 0.21724794199690223 time
train_step spend 0.6347883560010814 time
policy_value spend 0.21754044100089232 time
kl:0.00342,lr_multiplier:11.391,loss:5.170351028442383,entropy:5.951241493225098,explained_var_old:0.985013843,explained_var_new:0.989367366
output spend 0.00014649499644292518 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009152816004643682 time
recovery_state_mcts_prob spend 0.26770544199825963 time
state_batch spend 0.001786875000107102 time
mcts_probs_batch spend 0.0071767479967093095 time
winner_batch spend 0.00032545000431127846 time
policy_value spend 0.21730624599877046 time
train_step spend 0.6247465569977066 time
policy_value spend 0.2102018580044387 time
train_step spend 0.6148283530055778 time
policy_value spend 0.209509653999703 time
train_step spend 0.6144071410017204 time
policy_value spend 0.20963028999540256 time
train_step spend 0.6146940670005279 time
policy_value spend 0.21015100599470316 time
train_step spend 0.6134044480058947 time
policy_value spend 0.20987869599775877 time
kl:0.00604,lr_multiplier:11.391,loss:5.19377326965332,entropy:5.972806930541992,explained_var_old:0.990457714,explained_var_new:0.994614661
output spend 0.00014374899910762906 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00823575200047344 time
recovery_state_mcts_prob spend 0.2759479639935307 time
state_batch spend 0.0021677630065823905 time
mcts_probs_batch spend 0.006701853999402374 time
winner_batch spend 0.00029538999660871923 time
policy_value spend 0.21051359699777095 time
train_step spend 0.6156520599979558 time
policy_value spend 0.2094884969992563 time
train_step spend 0.6139606040014769 time
policy_value spend 0.2094633039960172 time
train_step spend 0.6145844759957981 time
policy_value spend 0.21020153700374067 time
train_step spend 0.6146393480012193 time
policy_value spend 0.21140503999777138 time
train_step spend 0.6177784870014875 time
policy_value spend 0.2120561629999429 time
kl:0.01792,lr_multiplier:11.391,loss:5.196022033691406,entropy:5.973840713500977,explained_var_old:0.973844767,explained_var_new:0.984033644
output spend 0.00015070400695549324 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0067468570050550625 time
recovery_state_mcts_prob spend 0.2905957370021497 time
state_batch spend 0.0021312209937605076 time
mcts_probs_batch spend 0.006249722006032243 time
winner_batch spend 0.00027799999952549115 time
policy_value spend 0.21239822999632452 time
train_step spend 0.649557304001064 time
policy_value spend 0.2240073590000975 time
train_step spend 0.6208037739997962 time
policy_value spend 0.2122043429990299 time
train_step spend 0.6174795519982581 time
policy_value spend 0.21065934999933233 time
train_step spend 0.6175053400002071 time
policy_value spend 0.21096645999932662 time
train_step spend 0.6171780639997451 time
policy_value spend 0.21116643999994267 time
kl:0.01860,lr_multiplier:11.391,loss:5.140748023986816,entropy:5.945417404174805,explained_var_old:0.976664603,explained_var_new:0.988608241
output spend 0.00014862399984849617 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007557568998890929 time
recovery_state_mcts_prob spend 0.26836679500411265 time
state_batch spend 0.0017649590008659288 time
mcts_probs_batch spend 0.005341727999621071 time
winner_batch spend 0.0002920279948739335 time
policy_value spend 0.2122790480061667 time
train_step spend 0.6176563379995059 time
policy_value spend 0.21925408799870638 time
train_step spend 0.6447060680002323 time
policy_value spend 0.21999794700241182 time
train_step spend 0.6428820799992536 time
policy_value spend 0.21950140799890505 time
train_step spend 0.6425935759980348 time
policy_value spend 0.22013240100204712 time
train_step spend 0.6422370910004247 time
policy_value spend 0.22027774799789768 time
kl:0.00679,lr_multiplier:11.391,loss:5.151776313781738,entropy:5.968460559844971,explained_var_old:0.988248765,explained_var_new:0.997883201
output spend 0.00014735700096935034 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008811325002170634 time
recovery_state_mcts_prob spend 0.2699205879980582 time
state_batch spend 0.0017996770038735121 time
mcts_probs_batch spend 0.0063105480003287084 time
winner_batch spend 0.0002875319987651892 time
policy_value spend 0.2198355829968932 time
train_step spend 0.6426261840024381 time
policy_value spend 0.22085958300158381 time
train_step spend 0.6429317520014592 time
policy_value spend 0.21950290799577488 time
train_step spend 0.6417872539968812 time
policy_value spend 0.2195811359997606 time
train_step spend 0.6428902340048808 time
policy_value spend 0.23048064999602502 time
train_step spend 0.6791790249990299 time
policy_value spend 0.231543525995221 time
kl:0.01650,lr_multiplier:11.391,loss:5.1923089027404785,entropy:5.98961067199707,explained_var_old:0.987801373,explained_var_new:0.993857026
output spend 0.00017910800670506433 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007637381997483317 time
recovery_state_mcts_prob spend 0.29149301999859745 time
state_batch spend 0.001996516002691351 time
mcts_probs_batch spend 0.007196197999292053 time
winner_batch spend 0.0003206979963579215 time
policy_value spend 0.23181963800016092 time
train_step spend 0.6791793480006163 time
policy_value spend 0.23326869400625583 time
train_step spend 0.67323697500251 time
policy_value spend 0.21730724999360973 time
train_step spend 0.6344028790044831 time
policy_value spend 0.21691394599474734 time
train_step spend 0.6351088549999986 time
policy_value spend 0.2173378599982243 time
train_step spend 0.6348552550043678 time
policy_value spend 0.21706653599540005 time
kl:0.00392,lr_multiplier:11.391,loss:5.144944190979004,entropy:5.942124366760254,explained_var_old:0.971685171,explained_var_new:0.978674591
output spend 0.0001452979995519854 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007597529998747632 time
recovery_state_mcts_prob spend 0.27077370500046527 time
state_batch spend 0.0018317139983992092 time
mcts_probs_batch spend 0.016437534002761822 time
winner_batch spend 0.00029459800134645775 time
policy_value spend 0.22022626100078924 time
train_step spend 0.6249433999983012 time
policy_value spend 0.20960506800474832 time
train_step spend 0.6126202719970024 time
policy_value spend 0.20936547400197014 time
train_step spend 0.6133886460011126 time
policy_value spend 0.20950676999927964 time
train_step spend 0.6136974510009168 time
policy_value spend 0.2097661239968147 time
train_step spend 0.6152165189996595 time
policy_value spend 0.2093194039989612 time
kl:0.01358,lr_multiplier:11.391,loss:5.0826287269592285,entropy:5.949466705322266,explained_var_old:0.988871753,explained_var_new:0.994222820
output spend 0.00016814300033729523 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0073560590026318096 time
recovery_state_mcts_prob spend 0.26487083100073505 time
state_batch spend 0.0019609669980127364 time
mcts_probs_batch spend 0.00434936899546301 time
winner_batch spend 0.0002829830045811832 time
policy_value spend 0.20861820099526085 time
train_step spend 0.6129796910026926 time
policy_value spend 0.20977390299958643 time
train_step spend 0.6140224510018015 time
policy_value spend 0.20909580100124003 time
train_step spend 0.6133601559995441 time
policy_value spend 0.21040911500313086 time
train_step spend 0.6135560320035438 time
policy_value spend 0.21108575399557594 time
train_step spend 0.6181693830003496 time
policy_value spend 0.2114179959971807 time
kl:0.00671,lr_multiplier:11.391,loss:5.151074409484863,entropy:5.988857746124268,explained_var_old:0.987894773,explained_var_new:0.997128487
output spend 0.00014581799769075587 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006759202995453961 time
recovery_state_mcts_prob spend 0.2651256020035362 time
state_batch spend 0.0017908630034071393 time
mcts_probs_batch spend 0.00756488399929367 time
winner_batch spend 0.00029048899887129664 time
policy_value spend 0.2147546220003278 time
train_step spend 0.6195825440008775 time
policy_value spend 0.21155528700182913 time
train_step spend 0.6185361519965227 time
policy_value spend 0.21125893900170922 time
train_step spend 0.61797639499855 time
policy_value spend 0.21131849399534985 time
train_step spend 0.6193438050031546 time
policy_value spend 0.21102736499597086 time
train_step spend 0.6186043289999361 time
policy_value spend 0.21152851600345457 time
kl:0.01329,lr_multiplier:11.391,loss:5.163531303405762,entropy:5.945958614349365,explained_var_old:0.983083665,explained_var_new:0.989366114
output spend 0.000141448006615974 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008166064006218221 time
recovery_state_mcts_prob spend 0.2738951339997584 time
state_batch spend 0.0017601729996385984 time
mcts_probs_batch spend 0.004416531999595463 time
winner_batch spend 0.0002840919987647794 time
policy_value spend 0.2107155830017291 time
train_step spend 0.6187453710008413 time
policy_value spend 0.21523144600359956 time
train_step spend 0.6413059430051362 time
policy_value spend 0.21959297499415698 time
train_step spend 0.6421915429964429 time
policy_value spend 0.2200019770025392 time
train_step spend 0.6425080959961633 time
policy_value spend 0.22040766900317976 time
train_step spend 0.6430793590043322 time
policy_value spend 0.21914652900159126 time
kl:0.02510,lr_multiplier:11.391,loss:5.129404544830322,entropy:5.947082996368408,explained_var_old:0.984522641,explained_var_new:0.990109742
output spend 0.00016525200044270605 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011052370005927514 time
recovery_state_mcts_prob spend 0.27308490599534707 time
state_batch spend 0.002309980998688843 time
mcts_probs_batch spend 0.004490254999836907 time
winner_batch spend 0.00029073800396872684 time
policy_value spend 0.22171315000014147 time
train_step spend 0.6420408060002956 time
policy_value spend 0.219078541995259 time
train_step spend 0.6420200729990029 time
policy_value spend 0.2197358470002655 time
train_step spend 0.6436009089957224 time
policy_value spend 0.2195877339981962 time
train_step spend 0.6424416800000472 time
policy_value spend 0.2280826049973257 time
train_step spend 0.7005337359951227 time
policy_value spend 0.2478728569985833 time
kl:0.00586,lr_multiplier:11.391,loss:5.150776386260986,entropy:5.963207244873047,explained_var_old:0.979188085,explained_var_new:0.987993896
output spend 0.00016519099881406873 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009922826997353695 time
recovery_state_mcts_prob spend 0.29975215200101957 time
state_batch spend 0.002005285998166073 time
mcts_probs_batch spend 0.006729034001182299 time
winner_batch spend 0.00032285499764839187 time
policy_value spend 0.23543517500365851 time
train_step spend 0.6838477889978094 time
policy_value spend 0.2326248589961324 time
train_step spend 0.6345322900015162 time
policy_value spend 0.21682615900499513 time
train_step spend 0.6352307150009437 time
policy_value spend 0.21793928400438745 time
train_step spend 0.6351758889941266 time
policy_value spend 0.217193563003093 time
train_step spend 0.6359104250004748 time
policy_value spend 0.21691003299929434 time
kl:0.02470,lr_multiplier:11.391,loss:5.168474197387695,entropy:5.947596073150635,explained_var_old:0.990090072,explained_var_new:0.994135261
output spend 0.0001475509998272173 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009837498000706546 time
recovery_state_mcts_prob spend 0.2706877300006454 time
state_batch spend 0.0018210080015705898 time
mcts_probs_batch spend 0.006474116999015678 time
winner_batch spend 0.00030049199995119125 time
policy_value spend 0.2173678530016332 time
train_step spend 0.6228201339981752 time
policy_value spend 0.20739645200228551 time
train_step spend 0.6082798240022385 time
policy_value spend 0.2080922249951982 time
train_step spend 0.6085753639999893 time
policy_value spend 0.20827778700186173 time
train_step spend 0.6088930559999426 time
policy_value spend 0.20795428800192894 time
train_step spend 0.6090598369992222 time
policy_value spend 0.20751659700181335 time
kl:0.01199,lr_multiplier:11.391,loss:5.0616536140441895,entropy:5.93826961517334,explained_var_old:0.983192325,explained_var_new:0.988868713
output spend 0.00014916299551259726 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007185611997556407 time
recovery_state_mcts_prob spend 0.2595108580062515 time
state_batch spend 0.0017355569943902083 time
mcts_probs_batch spend 0.004663427003833931 time
winner_batch spend 0.00030611900001531467 time
policy_value spend 0.2072645599982934 time
train_step spend 0.6080095349971089 time
policy_value spend 0.21079745900351554 time
train_step spend 0.6079482839995762 time
policy_value spend 0.20972919999621809 time
train_step spend 0.6086745860011433 time
policy_value spend 0.20745967199763982 time
train_step spend 0.6317926999981864 time
policy_value spend 0.21475835800083587 time
train_step spend 0.6279309279998415 time
policy_value spend 0.2152862049988471 time
kl:0.00446,lr_multiplier:11.391,loss:5.111981391906738,entropy:5.933732032775879,explained_var_old:0.984700203,explained_var_new:0.991308391
output spend 0.00015361599798779935 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006686720000288915 time
recovery_state_mcts_prob spend 0.2639422549982555 time
state_batch spend 0.001738724000460934 time
mcts_probs_batch spend 0.005413767998106778 time
winner_batch spend 0.0002804989999276586 time
policy_value spend 0.2143391010031337 time
train_step spend 0.6248417629976757 time
policy_value spend 0.21548222599813016 time
train_step spend 0.6252674689967535 time
policy_value spend 0.21371309900132474 time
train_step spend 0.624330717997509 time
policy_value spend 0.21387609100202098 time
train_step spend 0.6255469219977385 time
policy_value spend 0.21350721899943892 time
train_step spend 0.6259743209957378 time
policy_value spend 0.21392910400027176 time
kl:0.00418,lr_multiplier:11.391,loss:5.106007099151611,entropy:5.940207004547119,explained_var_old:0.984831274,explained_var_new:0.987557173
output spend 0.00014707000082125887 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009615661001589615 time
recovery_state_mcts_prob spend 0.26464190499973483 time
state_batch spend 0.0017978169998968951 time
mcts_probs_batch spend 0.0054981599969323725 time
winner_batch spend 0.0002858829975593835 time
policy_value spend 0.2141449770060717 time
train_step spend 0.6263157450011931 time
policy_value spend 0.2164391379992594 time
train_step spend 0.6416606140046497 time
policy_value spend 0.21919264399912208 time
train_step spend 0.6415594150021207 time
policy_value spend 0.21845670299808262 time
train_step spend 0.6410336179978913 time
policy_value spend 0.21907951700268313 time
train_step spend 0.6419900760010933 time
policy_value spend 0.21907594599906588 time
kl:0.00322,lr_multiplier:11.391,loss:5.141030311584473,entropy:5.939296245574951,explained_var_old:0.987479746,explained_var_new:0.994617343
output spend 0.0002411070017842576 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007568827997602057 time
recovery_state_mcts_prob spend 0.27154545899975346 time
state_batch spend 0.0018250510038342327 time
mcts_probs_batch spend 0.004738288997032214 time
winner_batch spend 0.0003578239993657917 time
policy_value spend 0.2184313040052075 time
train_step spend 0.6413777959969593 time
policy_value spend 0.2189201020009932 time
train_step spend 0.6417961839979398 time
policy_value spend 0.2191950030028238 time
train_step spend 0.6416669830068713 time
policy_value spend 0.21880081199924462 time
train_step spend 0.6406172030037851 time
policy_value spend 0.22768769200047245 time
train_step spend 0.6792680529979407 time
policy_value spend 0.2322286529961275 time
kl:0.00301,lr_multiplier:11.391,loss:5.132318019866943,entropy:5.925753593444824,explained_var_old:0.984289229,explained_var_new:0.994353056
output spend 0.00017713599663693458 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01085493200662313 time
recovery_state_mcts_prob spend 0.2977143049938604 time
state_batch spend 0.0023635640027350746 time
mcts_probs_batch spend 0.005803897001896985 time
winner_batch spend 0.000315104000037536 time
policy_value spend 0.2315911839978071 time
train_step spend 0.6794341759959934 time
policy_value spend 0.23297059300239198 time
train_step spend 0.670118148002075 time
policy_value spend 0.21764438600075664 time
train_step spend 0.6345955970027717 time
policy_value spend 0.21739383599924622 time
train_step spend 0.635381469001004 time
policy_value spend 0.2170903240039479 time
train_step spend 0.635178807999182 time
policy_value spend 0.2172828630064032 time
kl:0.00491,lr_multiplier:11.391,loss:5.18410062789917,entropy:5.953006744384766,explained_var_old:0.983346343,explained_var_new:0.988653183
output spend 0.0001503649982623756 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008991319002234377 time
recovery_state_mcts_prob spend 0.28895251599897165 time
state_batch spend 0.0018684899987420067 time
mcts_probs_batch spend 0.00520808400324313 time
winner_batch spend 0.00034035799762932584 time
policy_value spend 0.21586206599749858 time
train_step spend 0.6248959290023777 time
policy_value spend 0.20785922600043705 time
train_step spend 0.6082641380053246 time
policy_value spend 0.20718623599532293 time
train_step spend 0.6072969739980181 time
policy_value spend 0.20815233499888564 time
train_step spend 0.6080425069958437 time
policy_value spend 0.20772908499930054 time
train_step spend 0.6069230899956892 time
policy_value spend 0.2080559330061078 time
kl:0.01608,lr_multiplier:11.391,loss:5.060224533081055,entropy:5.906085014343262,explained_var_old:0.988566756,explained_var_new:0.993113935
output spend 0.00014311700215330347 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008201919998100493 time
recovery_state_mcts_prob spend 0.26311830199847464 time
state_batch spend 0.001880556003015954 time
mcts_probs_batch spend 0.004710116001660936 time
winner_batch spend 0.0003188900009263307 time
policy_value spend 0.2147764549954445 time
train_step spend 0.6278938050018041 time
policy_value spend 0.22034403200086672 time
train_step spend 0.6211145060005947 time
policy_value spend 0.20894047999900067 time
train_step spend 0.6088552930013975 time
policy_value spend 0.20736084000236588 time
train_step spend 0.614598110994848 time
policy_value spend 0.2187535859993659 time
train_step spend 0.6293127289973199 time
policy_value spend 0.2134662919997936 time
kl:0.01187,lr_multiplier:11.391,loss:5.0861029624938965,entropy:5.92344856262207,explained_var_old:0.988765895,explained_var_new:0.990938902
output spend 0.00019953699666075408 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010111365998454858 time
recovery_state_mcts_prob spend 0.2718846569987363 time
state_batch spend 0.0019415760034462437 time
mcts_probs_batch spend 0.008967565998318605 time
winner_batch spend 0.00030307099950732663 time
policy_value spend 0.21606947999680415 time
train_step spend 0.6256974679999985 time
policy_value spend 0.21805890499672387 time
train_step spend 0.6258150610010489 time
policy_value spend 0.2138784900016617 time
train_step spend 0.6255770089992438 time
policy_value spend 0.21337279099680018 time
train_step spend 0.6272690199984936 time
policy_value spend 0.21404188399901614 time
train_step spend 0.6266121450025821 time
policy_value spend 0.21319963799760444 time
kl:0.05583,lr_multiplier:7.594,loss:5.148381233215332,entropy:5.945276260375977,explained_var_old:0.990638733,explained_var_new:0.993935704
output spend 0.0001459809936932288 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007502578002458904 time
recovery_state_mcts_prob spend 0.2666396589993383 time
state_batch spend 0.001781694998499006 time
mcts_probs_batch spend 0.00730590800230857 time
winner_batch spend 0.00028505099908215925 time
policy_value spend 0.21706139500020072 time
train_step spend 0.6251038560003508 time
policy_value spend 0.22146473000611877 time
train_step spend 0.6401777419960126 time
policy_value spend 0.21972713300056057 time
train_step spend 0.6409879790007835 time
policy_value spend 0.21881217299960554 time
train_step spend 0.6423907680000411 time
policy_value spend 0.21895362899522297 time
train_step spend 0.6417539780013612 time
policy_value spend 0.2194308979960624 time
kl:0.07678,lr_multiplier:5.062,loss:5.090166091918945,entropy:5.925687789916992,explained_var_old:0.991544902,explained_var_new:0.995196342
output spend 0.0001501320002716966 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009207708993926644 time
recovery_state_mcts_prob spend 0.27932702300313395 time
state_batch spend 0.002095073003147263 time
mcts_probs_batch spend 0.0056750419971649535 time
winner_batch spend 0.0003351170016685501 time
policy_value spend 0.2186886939962278 time
train_step spend 0.6407917160031502 time
policy_value spend 0.21923217899893643 time
train_step spend 0.6406290770028136 time
policy_value spend 0.21948487299960107 time
train_step spend 0.6414678310029558 time
policy_value spend 0.21885141999518964 time
train_step spend 0.6406385370064527 time
policy_value spend 0.23115470799530158 time
train_step spend 0.6851684540015412 time
policy_value spend 0.23391500399884535 time
kl:0.00699,lr_multiplier:7.594,loss:5.100061416625977,entropy:5.933893203735352,explained_var_old:0.989556015,explained_var_new:0.994540334
output spend 0.00016370400408050045 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011045496998121962 time
recovery_state_mcts_prob spend 0.30493302900140407 time
state_batch spend 0.002013183999224566 time
mcts_probs_batch spend 0.005773176999355201 time
winner_batch spend 0.0003082589973928407 time
policy_value spend 0.23306788400077494 time
train_step spend 0.6840095350053161 time
policy_value spend 0.23759127399534918 time
train_step spend 0.6518771530027152 time
policy_value spend 0.21774426299816696 time
train_step spend 0.6354324359999737 time
policy_value spend 0.21707738500117557 time
train_step spend 0.6347900800028583 time
policy_value spend 0.21689327700005379 time
train_step spend 0.6351153170035104 time
policy_value spend 0.21772842700011097 time
kl:0.03459,lr_multiplier:7.594,loss:5.160770893096924,entropy:5.935670852661133,explained_var_old:0.985766470,explained_var_new:0.986409009
output spend 0.0001627629972063005 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009419442001671996 time
recovery_state_mcts_prob spend 0.2729238149986486 time
state_batch spend 0.0018056720000458881 time
mcts_probs_batch spend 0.005690819998562802 time
winner_batch spend 0.0003468330032774247 time
policy_value spend 0.21661558299820172 time
train_step spend 0.6211706000030972 time
policy_value spend 0.20928996300062863 time
train_step spend 0.6022784919987316 time
policy_value spend 0.2056663719995413 time
train_step spend 0.6055970609959331 time
policy_value spend 0.20652397300000302 time
train_step spend 0.6025383009982761 time
policy_value spend 0.2055285160022322 time
train_step spend 0.6021843719936442 time
policy_value spend 0.20605253700341564 time
kl:0.01681,lr_multiplier:7.594,loss:5.119808673858643,entropy:5.928908348083496,explained_var_old:0.984825015,explained_var_new:0.988765121
output spend 0.00013867799862055108 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0077905930011183955 time
recovery_state_mcts_prob spend 0.2663840080058435 time
state_batch spend 0.0019015219950233586 time
mcts_probs_batch spend 0.005231672002992127 time
winner_batch spend 0.0002739849951467477 time
policy_value spend 0.20648991600319277 time
train_step spend 0.6019283760033431 time
policy_value spend 0.20588709600269794 time
train_step spend 0.602473580998776 time
policy_value spend 0.2058968680066755 time
train_step spend 0.602375899994513 time
policy_value spend 0.20592671500344295 time
train_step spend 0.6293287549997331 time
policy_value spend 0.21643691300414503 time
train_step spend 0.6289602940014447 time
policy_value spend 0.21491665599751286 time
kl:0.00621,lr_multiplier:11.391,loss:5.093543529510498,entropy:5.931179046630859,explained_var_old:0.993528843,explained_var_new:0.994450331
output spend 0.00015262499800883234 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010677591999410652 time
recovery_state_mcts_prob spend 0.2666148809948936 time
state_batch spend 0.0023665090047870763 time
mcts_probs_batch spend 0.0064791900003911 time
winner_batch spend 0.00028737499815179035 time
policy_value spend 0.21533734200056642 time
train_step spend 0.6287117839965504 time
policy_value spend 0.21579713800019817 time
train_step spend 0.628801333004958 time
policy_value spend 0.21482865099824267 time
train_step spend 0.6290266329961014 time
policy_value spend 0.2158671700017294 time
train_step spend 0.6295641100005014 time
policy_value spend 0.2155369480024092 time
train_step spend 0.6274995860003401 time
policy_value spend 0.21584972600248875 time
kl:0.00609,lr_multiplier:11.391,loss:5.086594581604004,entropy:5.9202752113342285,explained_var_old:0.986971080,explained_var_new:0.995450675
output spend 0.00015496899868594483 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00896178499533562 time
recovery_state_mcts_prob spend 0.2666043740027817 time
state_batch spend 0.0017726410005707294 time
mcts_probs_batch spend 0.005750101998273749 time
winner_batch spend 0.00028657499933615327 time
policy_value spend 0.21544424300373066 time
train_step spend 0.6301786199983326 time
policy_value spend 0.21658937900065212 time
train_step spend 0.6427062490038224 time
policy_value spend 0.22078565799893113 time
train_step spend 0.6435530359958648 time
policy_value spend 0.21950081700197188 time
train_step spend 0.6434817269982887 time
policy_value spend 0.21955246700235875 time
train_step spend 0.6422818030041526 time
policy_value spend 0.22008636099781143 time
kl:0.00891,lr_multiplier:11.391,loss:5.025031089782715,entropy:5.892889976501465,explained_var_old:0.992078424,explained_var_new:0.993599474
output spend 0.00027984399639535695 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008144670995534398 time
recovery_state_mcts_prob spend 0.2934673650015611 time
state_batch spend 0.002729640997131355 time
mcts_probs_batch spend 0.006641838001087308 time
winner_batch spend 0.0003630190039984882 time
policy_value spend 0.23379470499639865 time
train_step spend 0.6616935479978565 time
policy_value spend 0.22084196600189898 time
train_step spend 0.6437899980010116 time
policy_value spend 0.2198907399942982 time
train_step spend 0.6429127830051584 time
policy_value spend 0.21974132499599364 time
train_step spend 0.6442772930022329 time
policy_value spend 0.23490555400348967 time
train_step spend 0.6865227890011738 time
policy_value spend 0.23698640799557324 time
kl:0.00524,lr_multiplier:11.391,loss:5.040203094482422,entropy:5.891783237457275,explained_var_old:0.993858337,explained_var_new:0.998787045
output spend 0.00016122800298035145 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013866568995581474 time
recovery_state_mcts_prob spend 0.29788966900378 time
state_batch spend 0.0019490740014589392 time
mcts_probs_batch spend 0.006025099995895289 time
winner_batch spend 0.00031762500293552876 time
policy_value spend 0.2349638119994779 time
train_step spend 0.6861626429963508 time
policy_value spend 0.23478913900180487 time
train_step spend 0.686715333002212 time
policy_value spend 0.22346228300011717 time
train_step spend 0.6346775769998203 time
policy_value spend 0.21642808799515478 time
train_step spend 0.6348301459947834 time
policy_value spend 0.2170590580062708 time
train_step spend 0.6427835740032606 time
policy_value spend 0.21658734299853677 time
kl:0.01440,lr_multiplier:11.391,loss:5.059822082519531,entropy:5.903468132019043,explained_var_old:0.984401703,explained_var_new:0.986874938
output spend 0.00015397799870697781 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070779040033812635 time
recovery_state_mcts_prob spend 0.2768845219979994 time
state_batch spend 0.0018003479999606498 time
mcts_probs_batch spend 0.005627908001770265 time
winner_batch spend 0.00028509899857454 time
policy_value spend 0.21738291099609341 time
train_step spend 0.6179328979997081 time
policy_value spend 0.2060097700014012 time
train_step spend 0.6023125380015699 time
policy_value spend 0.205925173999276 time
train_step spend 0.6022730080003385 time
policy_value spend 0.2056416760024149 time
train_step spend 0.6034957250012667 time
policy_value spend 0.2065915280036279 time
train_step spend 0.6026546549983323 time
policy_value spend 0.20580366099602543 time
kl:0.01751,lr_multiplier:11.391,loss:5.103837490081787,entropy:5.908496856689453,explained_var_old:0.993504763,explained_var_new:0.998509824
output spend 0.0001386700023431331 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007293151997146197 time
recovery_state_mcts_prob spend 0.2534991420034203 time
state_batch spend 0.0017165160024887882 time
mcts_probs_batch spend 0.0059154169939574786 time
winner_batch spend 0.00042074300290551037 time
policy_value spend 0.20646329000010155 time
train_step spend 0.6027205939972191 time
policy_value spend 0.20722211800602963 time
train_step spend 0.6017043639949406 time
policy_value spend 0.20513683099852642 time
train_step spend 0.6017144340003142 time
policy_value spend 0.2056794300006004 time
train_step spend 0.6019789150013821 time
policy_value spend 0.21053679000033299 time
train_step spend 0.6269771029983531 time
policy_value spend 0.21462249600153882 time
kl:0.00863,lr_multiplier:11.391,loss:5.080031871795654,entropy:5.917339324951172,explained_var_old:0.980940044,explained_var_new:0.988521814
output spend 0.0002117749972967431 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009169269003905356 time
recovery_state_mcts_prob spend 0.2644756579975365 time
state_batch spend 0.001789437999832444 time
mcts_probs_batch spend 0.006462108998675831 time
winner_batch spend 0.0002885120047722012 time
policy_value spend 0.21461667299445253 time
train_step spend 0.6279721720056841 time
policy_value spend 0.21383422099461313 time
train_step spend 0.6280207780000637 time
policy_value spend 0.21437210799922468 time
train_step spend 0.6277854439977091 time
policy_value spend 0.21464378199743805 time
train_step spend 0.6281636870044167 time
policy_value spend 0.21473726499971235 time
train_step spend 0.6286685869999928 time
policy_value spend 0.2140881890009041 time
kl:0.03190,lr_multiplier:11.391,loss:5.067432880401611,entropy:5.927426338195801,explained_var_old:0.991945267,explained_var_new:0.997535884
output spend 0.00015266700211213902 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01005193599849008 time
recovery_state_mcts_prob spend 0.2648315249971347 time
state_batch spend 0.001754197000991553 time
mcts_probs_batch spend 0.004563585003779735 time
winner_batch spend 0.00029799799813190475 time
policy_value spend 0.21378738500061445 time
train_step spend 0.6276462419991731 time
policy_value spend 0.2174087250023149 time
train_step spend 0.6483694199996535 time
policy_value spend 0.22210110400192207 time
train_step spend 0.6476891730053467 time
policy_value spend 0.22118300199508667 time
train_step spend 0.6491899269967689 time
policy_value spend 0.22069352700054878 time
train_step spend 0.6471840559970587 time
policy_value spend 0.22157455600245157 time
kl:0.03351,lr_multiplier:11.391,loss:5.08476448059082,entropy:5.896204948425293,explained_var_old:0.977952242,explained_var_new:0.987160146
output spend 0.00016178599616978317 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007281687998329289 time
recovery_state_mcts_prob spend 0.2873781330054044 time
state_batch spend 0.0018553080008132383 time
mcts_probs_batch spend 0.004539656998531427 time
winner_batch spend 0.0003049910010304302 time
policy_value spend 0.22056761299609207 time
train_step spend 0.6473518269995111 time
policy_value spend 0.22065757399832364 time
train_step spend 0.6473566589993425 time
policy_value spend 0.2236181830012356 time
train_step spend 0.6492822709988104 time
policy_value spend 0.22121807200164767 time
train_step spend 0.6483134820009582 time
policy_value spend 0.23550484199950006 time
train_step spend 0.6885734219977167 time
policy_value spend 0.23529976900317706 time
kl:0.00650,lr_multiplier:11.391,loss:5.050933361053467,entropy:5.884312152862549,explained_var_old:0.992202044,explained_var_new:0.995139897
output spend 0.00025096099852817133 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010221525997621939 time
recovery_state_mcts_prob spend 0.29356692200235557 time
state_batch spend 0.001993997997487895 time
mcts_probs_batch spend 0.004874179998296313 time
winner_batch spend 0.0003150789998471737 time
policy_value spend 0.2363221620034892 time
train_step spend 0.6913795380023657 time
policy_value spend 0.23498412399931112 time
train_step spend 0.688364998997713 time
policy_value spend 0.23506151800393127 time
train_step spend 0.644131262000883 time
policy_value spend 0.21628424899972742 time
train_step spend 0.6342964130017208 time
policy_value spend 0.21702421700319974 time
train_step spend 0.6331453719976707 time
policy_value spend 0.21674465500109363 time
kl:0.00705,lr_multiplier:11.391,loss:5.015385150909424,entropy:5.883917808532715,explained_var_old:0.987073898,explained_var_new:0.990485251
output spend 0.00015955200069583952 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007767484996293206 time
recovery_state_mcts_prob spend 0.27321855800255435 time
state_batch spend 0.0018506609994801693 time
mcts_probs_batch spend 0.00562639300187584 time
winner_batch spend 0.0002974279996124096 time
policy_value spend 0.2161701169970911 time
train_step spend 0.6155303080013255 time
policy_value spend 0.2054737290018238 time
train_step spend 0.6027388529983 time
policy_value spend 0.20578013700287556 time
train_step spend 0.6188447999957134 time
policy_value spend 0.21787385900097433 time
train_step spend 0.6312923859950388 time
policy_value spend 0.20687627600273117 time
train_step spend 0.6054859229989233 time
policy_value spend 0.20588007799960906 time
kl:0.02405,lr_multiplier:11.391,loss:5.060464859008789,entropy:5.868824005126953,explained_var_old:0.993568480,explained_var_new:0.998122275
output spend 0.00021310399461071938 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010964695997245144 time
recovery_state_mcts_prob spend 0.2622096960039926 time
state_batch spend 0.0017293909986619838 time
mcts_probs_batch spend 0.005914614994253498 time
winner_batch spend 0.0003006670012837276 time
policy_value spend 0.20565159700345248 time
train_step spend 0.6043635960013489 time
policy_value spend 0.20631684699765174 time
train_step spend 0.6022631960004219 time
policy_value spend 0.20599565000156872 time
train_step spend 0.6017335850046948 time
policy_value spend 0.20640245299728122 time
train_step spend 0.6033287969985395 time
policy_value spend 0.21245852800348075 time
train_step spend 0.6271486500045285 time
policy_value spend 0.2139572429950931 time
kl:0.01286,lr_multiplier:11.391,loss:5.072351932525635,entropy:5.9109907150268555,explained_var_old:0.990048647,explained_var_new:0.992576957
output spend 0.00016226500156335533 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00791547900007572 time
recovery_state_mcts_prob spend 0.2719875850016251 time
state_batch spend 0.0018473720047040842 time
mcts_probs_batch spend 0.004799780996108893 time
winner_batch spend 0.0003482920001260936 time
policy_value spend 0.21309642500273185 time
train_step spend 0.6275126979962806 time
policy_value spend 0.21579702400049428 time
train_step spend 0.6265212060025078 time
policy_value spend 0.21492560699698515 time
train_step spend 0.6270760769984918 time
policy_value spend 0.21457638800347922 time
train_step spend 0.6267676480056252 time
policy_value spend 0.21459125600085827 time
train_step spend 0.6268562490004115 time
policy_value spend 0.21454747000097996 time
kl:0.00574,lr_multiplier:11.391,loss:5.099737167358398,entropy:5.926050662994385,explained_var_old:0.982291102,explained_var_new:0.985019863
output spend 0.00017125799786299467 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007593012000143062 time
recovery_state_mcts_prob spend 0.27587699700234225 time
state_batch spend 0.0018016129979514517 time
mcts_probs_batch spend 0.005421763002232183 time
winner_batch spend 0.0002952189970528707 time
policy_value spend 0.2146388359979028 time
train_step spend 0.6273877840067144 time
policy_value spend 0.22326918399630813 time
train_step spend 0.6603182300023036 time
policy_value spend 0.2252463729964802 time
train_step spend 0.6599425499953213 time
policy_value spend 0.2252944230058347 time
train_step spend 0.6601271059989813 time
policy_value spend 0.226010412996402 time
train_step spend 0.6596566110019921 time
policy_value spend 0.2258247619975009 time
kl:0.00387,lr_multiplier:11.391,loss:5.073305606842041,entropy:5.911178112030029,explained_var_old:0.991766036,explained_var_new:0.997195065
output spend 0.00015230300050461665 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007505452995246742 time
recovery_state_mcts_prob spend 0.2892209970013937 time
state_batch spend 0.003253344002587255 time
mcts_probs_batch spend 0.006417689997761045 time
winner_batch spend 0.0004458940020413138 time
policy_value spend 0.22531214699847624 time
train_step spend 0.6601976649981225 time
policy_value spend 0.22631327400449663 time
train_step spend 0.6448508609973942 time
policy_value spend 0.21706084899778944 time
train_step spend 0.635566581004241 time
policy_value spend 0.21765303699794458 time
train_step spend 0.6386304359984933 time
policy_value spend 0.2234272889982094 time
train_step spend 0.6542712220034446 time
policy_value spend 0.22358478500245837 time
kl:0.00876,lr_multiplier:11.391,loss:5.045212268829346,entropy:5.885096549987793,explained_var_old:0.987262249,explained_var_new:0.992024839
output spend 0.00016591000166954473 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007474726997315884 time
recovery_state_mcts_prob spend 0.2813408130023163 time
state_batch spend 0.0018333509942749515 time
mcts_probs_batch spend 0.004909219002001919 time
winner_batch spend 0.00033414000063203275 time
policy_value spend 0.2235421290024533 time
train_step spend 0.6534822230023565 time
policy_value spend 0.22281463899707887 time
train_step spend 0.6543061389966169 time
policy_value spend 0.22346026000013808 time
train_step spend 0.6541489649971481 time
policy_value spend 0.22315543099830393 time
train_step spend 0.6537389170043753 time
policy_value spend 0.22358180299488595 time
train_step spend 0.6413986460029264 time
policy_value spend 0.2172339929966256 time
kl:0.01724,lr_multiplier:11.391,loss:5.050681114196777,entropy:5.894386291503906,explained_var_old:0.991155386,explained_var_new:0.998523295
output spend 0.00017769899568520486 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007375421999313403 time
recovery_state_mcts_prob spend 0.27381474399589933 time
state_batch spend 0.001896804002171848 time
mcts_probs_batch spend 0.007587861000502016 time
winner_batch spend 0.00030549299845006317 time
policy_value spend 0.22009135899861576 time
train_step spend 0.6236259080033051 time
policy_value spend 0.20861535299627576 time
train_step spend 0.6106438330025412 time
policy_value spend 0.20827735499915434 time
train_step spend 0.6112600609994843 time
policy_value spend 0.20822684800077695 time
train_step spend 0.6110727569976007 time
policy_value spend 0.20870604600349907 time
train_step spend 0.610815341999114 time
policy_value spend 0.21009308700013207 time
kl:0.00721,lr_multiplier:11.391,loss:5.092963218688965,entropy:5.909600257873535,explained_var_old:0.989738584,explained_var_new:0.991269290
output spend 0.00016065299860201776 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007503421998990234 time
recovery_state_mcts_prob spend 0.2630861990037374 time
state_batch spend 0.0018054679967463017 time
mcts_probs_batch spend 0.0044259790010983124 time
winner_batch spend 0.00029062900284770876 time
policy_value spend 0.2080064219990163 time
train_step spend 0.6103147989997524 time
policy_value spend 0.21052456500183325 time
train_step spend 0.6121408689941745 time
policy_value spend 0.2083660830030567 time
train_step spend 0.6107428569957847 time
policy_value spend 0.2093076410019421 time
train_step spend 0.610641632003535 time
policy_value spend 0.20586286199977621 time
train_step spend 0.6028346820021397 time
policy_value spend 0.20607055500295246 time
kl:0.01262,lr_multiplier:11.391,loss:5.0508832931518555,entropy:5.904627799987793,explained_var_old:0.977908194,explained_var_new:0.989416480
output spend 0.00020028199651278555 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.014741519000381231 time
recovery_state_mcts_prob spend 0.25633001099777175 time
state_batch spend 0.0016930630008573644 time
mcts_probs_batch spend 0.004245149000780657 time
winner_batch spend 0.00028629299777094275 time
policy_value spend 0.20519933800096624 time
train_step spend 0.6032557790022111 time
policy_value spend 0.20639121899876045 time
train_step spend 0.6027562119998038 time
policy_value spend 0.20588713100005407 time
train_step spend 0.6027422080005636 time
policy_value spend 0.20581895500072278 time
train_step spend 0.6121974780035089 time
policy_value spend 0.2167474339948967 time
train_step spend 0.6358404060010798 time
policy_value spend 0.21712365800340194 time
kl:0.01771,lr_multiplier:11.391,loss:5.010201454162598,entropy:5.874659538269043,explained_var_old:0.986539245,explained_var_new:0.995101154
output spend 0.0001466570029151626 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011184049995790701 time
recovery_state_mcts_prob spend 0.31457408999995096 time
state_batch spend 0.002153342000383418 time
mcts_probs_batch spend 0.004433232003066223 time
winner_batch spend 0.0003548949971445836 time
policy_value spend 0.21708139700058382 time
train_step spend 0.6698721630018554 time
policy_value spend 0.2366197919982369 time
train_step spend 0.6669116920020315 time
policy_value spend 0.22809052500088 time
train_step spend 0.6662455270052305 time
policy_value spend 0.22845474399946397 time
train_step spend 0.6642923149993294 time
policy_value spend 0.22816924499784363 time
train_step spend 0.666274543000327 time
policy_value spend 0.22659732699685264 time
kl:0.00709,lr_multiplier:11.391,loss:5.066191673278809,entropy:5.873979568481445,explained_var_old:0.987626255,explained_var_new:0.991022646
output spend 0.00023963899730006233 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011804986002971418 time
recovery_state_mcts_prob spend 0.2810615999987931 time
state_batch spend 0.0018840429984265938 time
mcts_probs_batch spend 0.005970012003672309 time
winner_batch spend 0.0003315479989396408 time
policy_value spend 0.22752899999613874 time
train_step spend 0.665730952998274 time
policy_value spend 0.22672420000162674 time
train_step spend 0.6463523009952041 time
policy_value spend 0.21694532000401523 time
train_step spend 0.6358664679937647 time
policy_value spend 0.21714208200137364 time
train_step spend 0.6427021109993802 time
policy_value spend 0.22744436300126836 time
train_step spend 0.6635717210010625 time
policy_value spend 0.22720703700179 time
kl:0.00695,lr_multiplier:11.391,loss:5.0377068519592285,entropy:5.9222636222839355,explained_var_old:0.992904723,explained_var_new:0.994664133
output spend 0.0001754890035954304 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010950166004477069 time
recovery_state_mcts_prob spend 0.28668779999861727 time
state_batch spend 0.0021943129977444187 time
mcts_probs_batch spend 0.00581706299999496 time
winner_batch spend 0.0003034210021723993 time
policy_value spend 0.2262941230001161 time
train_step spend 0.6667058000020916 time
policy_value spend 0.22862931800045772 time
train_step spend 0.6637264739983948 time
policy_value spend 0.22672175300249364 time
train_step spend 0.6577966100012418 time
policy_value spend 0.21860213600302814 time
train_step spend 0.6348709910016623 time
policy_value spend 0.21686626500013517 time
train_step spend 0.6350516859965865 time
policy_value spend 0.21705779100011569 time
kl:0.03075,lr_multiplier:11.391,loss:5.0454583168029785,entropy:5.898079872131348,explained_var_old:0.985709131,explained_var_new:0.987384439
output spend 0.0001482619991293177 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0066876329947263 time
recovery_state_mcts_prob spend 0.2653669890059973 time
state_batch spend 0.0019162009994033724 time
mcts_probs_batch spend 0.0046324860013555735 time
winner_batch spend 0.0002944709995063022 time
policy_value spend 0.21597001899499446 time
train_step spend 0.6113310959990486 time
policy_value spend 0.20674630800203886 time
train_step spend 0.6027638659943477 time
policy_value spend 0.20557546600321075 time
train_step spend 0.602444905001903 time
policy_value spend 0.20602083400444826 time
train_step spend 0.6088766180037055 time
policy_value spend 0.20599621599831153 time
train_step spend 0.6024930739949923 time
policy_value spend 0.2064950010026223 time
kl:0.01855,lr_multiplier:11.391,loss:5.04059362411499,entropy:5.8935980796813965,explained_var_old:0.984458745,explained_var_new:0.991149843
output spend 0.00013894100266043097 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010114389995578676 time
recovery_state_mcts_prob spend 0.26654782600235194 time
state_batch spend 0.0021302890017977916 time
mcts_probs_batch spend 0.004235337997670285 time
winner_batch spend 0.00027938599669141695 time
policy_value spend 0.20460571400326444 time
train_step spend 0.6020462099986617 time
policy_value spend 0.2058652819978306 time
train_step spend 0.6028662520038779 time
policy_value spend 0.20552064300136408 time
train_step spend 0.6028824730019551 time
policy_value spend 0.205699302998255 time
train_step spend 0.6026578649980365 time
policy_value spend 0.20865687200421235 time
train_step spend 0.6133222549979109 time
policy_value spend 0.20952273099828744 time
kl:0.00716,lr_multiplier:11.391,loss:5.016036510467529,entropy:5.879378795623779,explained_var_old:0.987342119,explained_var_new:0.993559062
output spend 0.0001841850025812164 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006914498000696767 time
recovery_state_mcts_prob spend 0.26668595500086667 time
state_batch spend 0.0017101810008171014 time
mcts_probs_batch spend 0.0052970489996369 time
winner_batch spend 0.00027686099929269403 time
policy_value spend 0.21037598499970045 time
train_step spend 0.6138554089993704 time
policy_value spend 0.2096692790000816 time
train_step spend 0.6129142299978412 time
policy_value spend 0.20954221000283724 time
train_step spend 0.6129831779981032 time
policy_value spend 0.2101718810008606 time
train_step spend 0.6137509620020865 time
policy_value spend 0.2099701940023806 time
train_step spend 0.6355081450019497 time
policy_value spend 0.21757463899848517 time
kl:0.00458,lr_multiplier:11.391,loss:5.0543742179870605,entropy:5.884790420532227,explained_var_old:0.982157111,explained_var_new:0.989095092
output spend 0.00014864400145597756 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01002702499681618 time
recovery_state_mcts_prob spend 0.2687545529988711 time
state_batch spend 0.0019079560006503016 time
mcts_probs_batch spend 0.0057353360025445 time
winner_batch spend 0.0002815059997374192 time
policy_value spend 0.21704830599628622 time
train_step spend 0.6356148900013068 time
policy_value spend 0.22154238700022688 time
train_step spend 0.6677036780019989 time
policy_value spend 0.22807966599793872 time
train_step spend 0.6679365699965274 time
policy_value spend 0.22784363700338872 time
train_step spend 0.6683592920016963 time
policy_value spend 0.2275447020001593 time
train_step spend 0.6680115510025644 time
policy_value spend 0.2278324569997494 time
kl:0.00997,lr_multiplier:11.391,loss:5.109039306640625,entropy:5.937925338745117,explained_var_old:0.992829621,explained_var_new:0.994691432
output spend 0.00017551299970364198 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00841622200096026 time
recovery_state_mcts_prob spend 0.2795588340013637 time
state_batch spend 0.0018476069963071495 time
mcts_probs_batch spend 0.00771426000574138 time
winner_batch spend 0.0003569309992599301 time
policy_value spend 0.22848064699792303 time
train_step spend 0.6636915970011614 time
policy_value spend 0.21672892299829982 time
train_step spend 0.6354308629961452 time
policy_value spend 0.21691408900369424 time
train_step spend 0.63602141100273 time
policy_value spend 0.21681282299687155 time
train_step spend 0.6401826500004972 time
policy_value spend 0.2352768089986057 time
train_step spend 0.688759119999304 time
policy_value spend 0.23630809399764985 time
kl:0.02416,lr_multiplier:11.391,loss:5.078697204589844,entropy:5.91802453994751,explained_var_old:0.988389909,explained_var_new:0.994518161
output spend 0.0001633080028113909 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013402871998550836 time
recovery_state_mcts_prob spend 0.3095442199992249 time
state_batch spend 0.0019333300006110221 time
mcts_probs_batch spend 0.006751016000634991 time
winner_batch spend 0.00031946699891705066 time
policy_value spend 0.23598117900110083 time
train_step spend 0.6904767399973935 time
policy_value spend 0.23486995900020702 time
train_step spend 0.688497508999717 time
policy_value spend 0.23585089400148718 time
train_step spend 0.6889431509989663 time
policy_value spend 0.23535020899726078 time
train_step spend 0.6729191359991091 time
policy_value spend 0.21760405199893285 time
train_step spend 0.6507130190002499 time
policy_value spend 0.23225267200177768 time
kl:0.02849,lr_multiplier:11.391,loss:5.031816482543945,entropy:5.933511257171631,explained_var_old:0.996486008,explained_var_new:0.998183727
output spend 0.00014988000475568697 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010682963002182078 time
recovery_state_mcts_prob spend 0.27362657799676526 time
state_batch spend 0.0017760180053301156 time
mcts_probs_batch spend 0.006929791998118162 time
winner_batch spend 0.00028812299569835886 time
policy_value spend 0.21767993500543525 time
train_step spend 0.6022341989955748 time
policy_value spend 0.20693909000692656 time
train_step spend 0.6065779839991592 time
policy_value spend 0.20604901199840242 time
train_step spend 0.6032699730058084 time
policy_value spend 0.20577211199997691 time
train_step spend 0.6026901100049145 time
policy_value spend 0.20608646599430358 time
train_step spend 0.6027657320009894 time
policy_value spend 0.20601791299850447 time
kl:0.03115,lr_multiplier:11.391,loss:5.053082466125488,entropy:5.863003730773926,explained_var_old:0.975649893,explained_var_new:0.981395066
output spend 0.0001478669946664013 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00815417699777754 time
recovery_state_mcts_prob spend 0.26598037000076147 time
state_batch spend 0.0017917330042109825 time
mcts_probs_batch spend 0.016151698997418862 time
winner_batch spend 0.0002829750010278076 time
policy_value spend 0.20844533300260082 time
train_step spend 0.604574147000676 time
policy_value spend 0.2056864990008762 time
train_step spend 0.6025584710005205 time
policy_value spend 0.20597583999915514 time
train_step spend 0.6025777050017496 time
policy_value spend 0.20585118400049396 time
train_step spend 0.6027330569995684 time
policy_value spend 0.20611602499411674 time
train_step spend 0.6042724010039819 time
policy_value spend 0.20594020599673968 time
kl:0.01275,lr_multiplier:11.391,loss:5.021076679229736,entropy:5.876492023468018,explained_var_old:0.984384060,explained_var_new:0.994600654
output spend 0.00014305199874797836 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00639251500251703 time
recovery_state_mcts_prob spend 0.2643128979980247 time
state_batch spend 0.0017595880053704605 time
mcts_probs_batch spend 0.006144524995761458 time
winner_batch spend 0.000294363999273628 time
policy_value spend 0.20598926400271012 time
train_step spend 0.6022099800029537 time
policy_value spend 0.21015337300195824 time
train_step spend 0.6061749400032568 time
policy_value spend 0.20624739099730505 time
train_step spend 0.6017007999980706 time
policy_value spend 0.20639794399903622 time
train_step spend 0.6017128750027041 time
policy_value spend 0.20702537999750348 time
train_step spend 0.6138458979985444 time
policy_value spend 0.21677289700164692 time
kl:0.00849,lr_multiplier:11.391,loss:5.034910202026367,entropy:5.854220867156982,explained_var_old:0.981336296,explained_var_new:0.985082805
output spend 0.0001485680040786974 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007095362001564354 time
recovery_state_mcts_prob spend 0.26300773300317815 time
state_batch spend 0.0019200879978598095 time
mcts_probs_batch spend 0.006659411003056448 time
winner_batch spend 0.00028997699700994417 time
policy_value spend 0.21979865000321297 time
train_step spend 0.6367411730025196 time
policy_value spend 0.23347835300228326 time
train_step spend 0.6870544589983183 time
policy_value spend 0.234880673000589 time
train_step spend 0.6886061179975513 time
policy_value spend 0.23580020399822388 time
train_step spend 0.6883190850057872 time
policy_value spend 0.2351745489941095 time
train_step spend 0.69136629300192 time
policy_value spend 0.234563199999684 time
kl:0.02596,lr_multiplier:11.391,loss:5.092216491699219,entropy:5.916869163513184,explained_var_old:0.984804034,explained_var_new:0.993881404
output spend 0.00016777400014689192 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008389802002056967 time
recovery_state_mcts_prob spend 0.2940584619936999 time
state_batch spend 0.0019513490042299964 time
mcts_probs_batch spend 0.0077824769978178665 time
winner_batch spend 0.0003119590037385933 time
policy_value spend 0.23456035900017014 time
train_step spend 0.6722785910023958 time
policy_value spend 0.21895770999981323 time
train_step spend 0.6361480029954691 time
policy_value spend 0.21795038300479064 time
train_step spend 0.6357124530040892 time
policy_value spend 0.21730134599783923 time
train_step spend 0.6640603720006766 time
policy_value spend 0.23518389300443232 time
train_step spend 0.6882058039991534 time
policy_value spend 0.23479057399526937 time
kl:0.02688,lr_multiplier:11.391,loss:4.950924396514893,entropy:5.859009265899658,explained_var_old:0.986729085,explained_var_new:0.988136292
output spend 0.00018156900478061289 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012198404998343904 time
recovery_state_mcts_prob spend 0.29100468000251567 time
state_batch spend 0.002106906998960767 time
mcts_probs_batch spend 0.007605917999171652 time
winner_batch spend 0.00035912200110033154 time
policy_value spend 0.23557514999993145 time
train_step spend 0.6876795120042516 time
policy_value spend 0.23493827899801545 time
train_step spend 0.6883243839984061 time
policy_value spend 0.2357554850023007 time
train_step spend 0.6889711049952894 time
policy_value spend 0.23485630000504898 time
train_step spend 0.6397090919999755 time
policy_value spend 0.21786185599921737 time
train_step spend 0.6358313460004865 time
policy_value spend 0.21702721899782773 time
kl:0.01214,lr_multiplier:11.391,loss:5.027167797088623,entropy:5.8778181076049805,explained_var_old:0.991021514,explained_var_new:0.992155433
output spend 0.0001474029995733872 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007900832002633251 time
recovery_state_mcts_prob spend 0.2748034309988725 time
state_batch spend 0.0017658209981163964 time
mcts_probs_batch spend 0.005578741001954768 time
winner_batch spend 0.0002889120005420409 time
policy_value spend 0.2056373729938059 time
train_step spend 0.6030422180047026 time
policy_value spend 0.20676377299969317 time
train_step spend 0.6026709860016126 time
policy_value spend 0.2053797080006916 time
train_step spend 0.6023576939987834 time
policy_value spend 0.20555597999918973 time
train_step spend 0.6034764659998473 time
policy_value spend 0.20580374500423204 time
train_step spend 0.6020930689992383 time
policy_value spend 0.2063335909988382 time
kl:0.01024,lr_multiplier:11.391,loss:4.97303581237793,entropy:5.850472927093506,explained_var_old:0.990331888,explained_var_new:0.998099744
output spend 0.00013914800365455449 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008879526998498477 time
recovery_state_mcts_prob spend 0.26452269199944567 time
state_batch spend 0.0017864230030681938 time
mcts_probs_batch spend 0.00682057099766098 time
winner_batch spend 0.0003204399981768802 time
policy_value spend 0.20655460299894912 time
train_step spend 0.6035735059995204 time
policy_value spend 0.2060302110039629 time
train_step spend 0.6024298569973325 time
policy_value spend 0.2063424100051634 time
train_step spend 0.6030864159984048 time
policy_value spend 0.20589795100386254 time
train_step spend 0.6029073559984681 time
policy_value spend 0.2061225259967614 time
train_step spend 0.6022439739972469 time
policy_value spend 0.20593713899870636 time
kl:0.01169,lr_multiplier:11.391,loss:4.988223075866699,entropy:5.867588043212891,explained_var_old:0.993448555,explained_var_new:0.998765767
output spend 0.0002451580003253184 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010416689998237416 time
recovery_state_mcts_prob spend 0.2589527800009819 time
state_batch spend 0.0017435740010114387 time
mcts_probs_batch spend 0.006352625998260919 time
winner_batch spend 0.00030879900441505015 time
policy_value spend 0.21596334900095826 time
train_step spend 0.6227550900002825 time
policy_value spend 0.21785356000327738 time
train_step spend 0.617574968993722 time
policy_value spend 0.20765998600109015 time
train_step spend 0.6049629480039584 time
policy_value spend 0.20616108499962138 time
train_step spend 0.6064881479978794 time
policy_value spend 0.21719430899975123 time
train_step spend 0.6355777619974106 time
policy_value spend 0.2168494829966221 time
kl:0.01923,lr_multiplier:11.391,loss:4.982037544250488,entropy:5.8547821044921875,explained_var_old:0.987073660,explained_var_new:0.991286397
output spend 0.0001491759976488538 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008819286005746108 time
recovery_state_mcts_prob spend 0.27375460799521534 time
state_batch spend 0.0020673059989348985 time
mcts_probs_batch spend 0.006619718005822506 time
winner_batch spend 0.0002829119985108264 time
policy_value spend 0.21668473500176333 time
train_step spend 0.6565919409986236 time
policy_value spend 0.23495485100283986 time
train_step spend 0.6885880370027735 time
policy_value spend 0.2363953549938742 time
train_step spend 0.688628272000642 time
policy_value spend 0.23553987400373444 time
train_step spend 0.6889165979955578 time
policy_value spend 0.23536174300534185 time
train_step spend 0.6889754410003661 time
policy_value spend 0.23511930200038478 time
kl:0.00978,lr_multiplier:11.391,loss:4.961734771728516,entropy:5.811833381652832,explained_var_old:0.980769634,explained_var_new:0.984166324
output spend 0.0001606090008863248 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008327985000505578 time
recovery_state_mcts_prob spend 0.3004149309999775 time
state_batch spend 0.002024094996158965 time
mcts_probs_batch spend 0.007896145005361177 time
winner_batch spend 0.0003123799979221076 time
policy_value spend 0.2356107469968265 time
train_step spend 0.6580089440030861 time
policy_value spend 0.22001972499856493 time
train_step spend 0.6347543010051595 time
policy_value spend 0.21723570599715458 time
train_step spend 0.6356609260037658 time
policy_value spend 0.21642978499585297 time
train_step spend 0.6865445200019167 time
policy_value spend 0.23506439199991291 time
train_step spend 0.6889555029993062 time
policy_value spend 0.23470922699925723 time
kl:0.00507,lr_multiplier:11.391,loss:4.9696431159973145,entropy:5.836972236633301,explained_var_old:0.991320252,explained_var_new:0.997518063
output spend 0.00021336500503821298 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00880008599779103 time
recovery_state_mcts_prob spend 0.2879216660003294 time
state_batch spend 0.0019495840024319477 time
mcts_probs_batch spend 0.01738629499595845 time
winner_batch spend 0.00045512799988500774 time
policy_value spend 0.23868382100044983 time
train_step spend 0.6902002740025637 time
policy_value spend 0.23513079500116874 time
train_step spend 0.6941375039968989 time
policy_value spend 0.23581643799843732 time
train_step spend 0.6876742900058161 time
policy_value spend 0.23491392799769528 time
train_step spend 0.6356539320040611 time
policy_value spend 0.21767814299528254 time
train_step spend 0.6350481799963745 time
policy_value spend 0.2166630880019511 time
kl:0.00855,lr_multiplier:11.391,loss:4.946404933929443,entropy:5.814208030700684,explained_var_old:0.995529592,explained_var_new:0.998935878
output spend 0.00014636999549111351 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00868154799536569 time
recovery_state_mcts_prob spend 0.2629576790059218 time
state_batch spend 0.0020389119963510893 time
mcts_probs_batch spend 0.006374885997502133 time
winner_batch spend 0.0002882590051740408 time
policy_value spend 0.20638835199497407 time
train_step spend 0.6039335370005574 time
policy_value spend 0.2056086390002747 time
train_step spend 0.6030538380000507 time
policy_value spend 0.20641899900510907 time
train_step spend 0.6019984369995655 time
policy_value spend 0.20599179100099718 time
train_step spend 0.6024029960026382 time
policy_value spend 0.20577822600171203 time
train_step spend 0.6030062400022871 time
policy_value spend 0.20643986399954883 time
kl:0.01270,lr_multiplier:11.391,loss:4.9681525230407715,entropy:5.850851058959961,explained_var_old:0.974838078,explained_var_new:0.977101088
output spend 0.00014412500604521483 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007150759003707208 time
recovery_state_mcts_prob spend 0.26936288299475564 time
state_batch spend 0.0018275750044267625 time
mcts_probs_batch spend 0.00624984299793141 time
winner_batch spend 0.0002688809981918894 time
policy_value spend 0.2065846400000737 time
train_step spend 0.6025488130035228 time
policy_value spend 0.20574046499677934 time
train_step spend 0.6019416479975916 time
policy_value spend 0.20649861000129022 time
train_step spend 0.6016538680050871 time
policy_value spend 0.20650513599684928 time
train_step spend 0.6018574320041807 time
policy_value spend 0.20638196700019762 time
train_step spend 0.6052170120019582 time
policy_value spend 0.20627037299709627 time
kl:0.01827,lr_multiplier:11.391,loss:4.953507900238037,entropy:5.837366580963135,explained_var_old:0.993451059,explained_var_new:0.998658776
output spend 0.0001375070060021244 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007051888998830691 time
recovery_state_mcts_prob spend 0.25596643499739 time
state_batch spend 0.0018411010023555718 time
mcts_probs_batch spend 0.006241032999241725 time
winner_batch spend 0.0002731650019995868 time
policy_value spend 0.20635762099846033 time
train_step spend 0.603791027002444 time
policy_value spend 0.20571461999497842 time
train_step spend 0.6015551539967419 time
policy_value spend 0.20606306599802338 time
train_step spend 0.6063735729985638 time
policy_value spend 0.20652280000649625 time
train_step spend 0.6092312319960911 time
policy_value spend 0.2173063189984532 time
train_step spend 0.6360288089999813 time
policy_value spend 0.21767128499777755 time
kl:0.02635,lr_multiplier:11.391,loss:5.016485691070557,entropy:5.865261554718018,explained_var_old:0.996601462,explained_var_new:0.998469710
output spend 0.0001564599951962009 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007514480996178463 time
recovery_state_mcts_prob spend 0.27622048900229856 time
state_batch spend 0.001764075001119636 time
mcts_probs_batch spend 0.004543301998637617 time
winner_batch spend 0.00028883600316476077 time
policy_value spend 0.21680439899500925 time
train_step spend 0.6724028110038489 time
policy_value spend 0.23763756299740635 time
train_step spend 0.6879102849998162 time
policy_value spend 0.23583831599535188 time
train_step spend 0.6892235499981325 time
policy_value spend 0.2348905380058568 time
train_step spend 0.6876714660029393 time
policy_value spend 0.23468197100010002 time
train_step spend 0.6884543530031806 time
policy_value spend 0.234961515001487 time
kl:0.02449,lr_multiplier:11.391,loss:4.964460849761963,entropy:5.837441921234131,explained_var_old:0.998001695,explained_var_new:0.998846054
output spend 0.000156664005771745 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008891819998098072 time
recovery_state_mcts_prob spend 0.2990744929993525 time
state_batch spend 0.002070909002213739 time
mcts_probs_batch spend 0.0077729449985781685 time
winner_batch spend 0.0003271809982834384 time
policy_value spend 0.2362472510067164 time
train_step spend 0.6875563520006835 time
policy_value spend 0.2173416419973364 time
train_step spend 0.6351414300006581 time
policy_value spend 0.21679729400057113 time
train_step spend 0.6345477529976051 time
policy_value spend 0.23166034800669877 time
train_step spend 0.6878616769972723 time
policy_value spend 0.23560792700300226 time
train_step spend 0.6879292660014471 time
policy_value spend 0.23470287099917186 time
kl:0.01108,lr_multiplier:11.391,loss:4.958454608917236,entropy:5.833865642547607,explained_var_old:0.994648159,explained_var_new:0.995120525
output spend 0.0002952819995698519 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011806230002548546 time
recovery_state_mcts_prob spend 0.31271011699573137 time
state_batch spend 0.002123035999829881 time
mcts_probs_batch spend 0.007343918005062733 time
winner_batch spend 0.00031985800160327926 time
policy_value spend 0.24999757299519842 time
train_step spend 0.7093968660046812 time
policy_value spend 0.23661437499686144 time
train_step spend 0.6901826949979295 time
policy_value spend 0.23560951000399655 time
train_step spend 0.6888818450024701 time
policy_value spend 0.23607141699903877 time
train_step spend 0.6519801020040177 time
policy_value spend 0.21682611500000348 time
train_step spend 0.6340901040020981 time
policy_value spend 0.21692334100225708 time
kl:0.01191,lr_multiplier:11.391,loss:4.979344367980957,entropy:5.833319187164307,explained_var_old:0.985841632,explained_var_new:0.991079986
output spend 0.00014542700228048488 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007260033999045845 time
recovery_state_mcts_prob spend 0.2757762229957734 time
state_batch spend 0.0017126570019172505 time
mcts_probs_batch spend 0.005948345999058802 time
winner_batch spend 0.0002666460059117526 time
policy_value spend 0.20679726399976062 time
train_step spend 0.6030085009988397 time
policy_value spend 0.20605929800512968 time
train_step spend 0.602424880999024 time
policy_value spend 0.20609747499838704 time
train_step spend 0.6022320989941363 time
policy_value spend 0.20555507000244688 time
train_step spend 0.6025566240059561 time
policy_value spend 0.2057575779981562 time
train_step spend 0.6026645380043192 time
policy_value spend 0.2061668699971051 time
kl:0.00436,lr_multiplier:11.391,loss:4.935885429382324,entropy:5.810952186584473,explained_var_old:0.997394443,explained_var_new:0.998761892
output spend 0.00019584500114433467 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006770482999854721 time
recovery_state_mcts_prob spend 0.25302831099543255 time
state_batch spend 0.0017326640008832328 time
mcts_probs_batch spend 0.0071004089986672625 time
winner_batch spend 0.000282110006082803 time
policy_value spend 0.20883261400012998 time
train_step spend 0.6033269940016908 time
policy_value spend 0.20590618499409175 time
train_step spend 0.6019225070049288 time
policy_value spend 0.20606562899774872 time
train_step spend 0.6031069310047315 time
policy_value spend 0.20540375599375693 time
train_step spend 0.6037424449968967 time
policy_value spend 0.20614344400382834 time
train_step spend 0.6023556930013001 time
policy_value spend 0.20574132099864073 time
kl:0.00558,lr_multiplier:11.391,loss:4.958621501922607,entropy:5.817584037780762,explained_var_old:0.987392843,explained_var_new:0.993514717
output spend 0.00013729000056628138 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010817864997079596 time
recovery_state_mcts_prob spend 0.2567470490030246 time
state_batch spend 0.0017650529989623465 time
mcts_probs_batch spend 0.006044492998626083 time
winner_batch spend 0.000298511004075408 time
policy_value spend 0.2056413159953081 time
train_step spend 0.6034010399962426 time
policy_value spend 0.2075066000033985 time
train_step spend 0.6021274849990732 time
policy_value spend 0.20644539999921108 time
train_step spend 0.6034446549965651 time
policy_value spend 0.20547350400011055 time
train_step spend 0.6024643700002343 time
policy_value spend 0.20545106400095392 time
train_step spend 0.631849574005173 time
policy_value spend 0.2167892059951555 time
kl:0.00660,lr_multiplier:11.391,loss:4.987360954284668,entropy:5.83677339553833,explained_var_old:0.985086679,explained_var_new:0.994791448
output spend 0.00014892900071572512 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007842231003451161 time
recovery_state_mcts_prob spend 0.27365397199901054 time
state_batch spend 0.0017846030023065396 time
mcts_probs_batch spend 0.007611411994730588 time
winner_batch spend 0.0002931520066340454 time
policy_value spend 0.22291782499814872 time
train_step spend 0.6883130130008794 time
policy_value spend 0.23537294100242434 time
train_step spend 0.688099601000431 time
policy_value spend 0.23553893599455478 time
train_step spend 0.6884954710039892 time
policy_value spend 0.23545508399547543 time
train_step spend 0.6882048140032566 time
policy_value spend 0.23472905100061325 time
train_step spend 0.6889304109936347 time
policy_value spend 0.2352647590014385 time
kl:0.01011,lr_multiplier:11.391,loss:4.9173688888549805,entropy:5.807377815246582,explained_var_old:0.995883942,explained_var_new:0.998509586
output spend 0.00016798399883555248 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012980300998606253 time
recovery_state_mcts_prob spend 0.3026525999957812 time
state_batch spend 0.0020908389997202903 time
mcts_probs_batch spend 0.008078116006799974 time
winner_batch spend 0.0003544449937180616 time
policy_value spend 0.2332407450012397 time
train_step spend 0.6348928289953619 time
policy_value spend 0.21815154000069015 time
train_step spend 0.6353227349973167 time
policy_value spend 0.21715596400463255 time
train_step spend 0.6489491510001244 time
policy_value spend 0.23473223600012716 time
train_step spend 0.6891882609997992 time
policy_value spend 0.2354109379957663 time
train_step spend 0.6878309750027256 time
policy_value spend 0.23567438399913954 time
kl:0.01018,lr_multiplier:11.391,loss:4.939852714538574,entropy:5.828360557556152,explained_var_old:0.991064250,explained_var_new:0.995884180
output spend 0.0003711829995154403 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00848929399944609 time
recovery_state_mcts_prob spend 0.2980748650006717 time
state_batch spend 0.0021060729995951988 time
mcts_probs_batch spend 0.007289314999070484 time
winner_batch spend 0.0003206819965271279 time
policy_value spend 0.23503085400443524 time
train_step spend 0.6875973979986156 time
policy_value spend 0.23820159200113267 time
train_step spend 0.6876068130004569 time
policy_value spend 0.23535978799918666 time
train_step spend 0.6897800030055805 time
policy_value spend 0.2366812399995979 time
train_step spend 0.6590031570012798 time
policy_value spend 0.2170135529959225 time
train_step spend 0.6352643549980712 time
policy_value spend 0.2172643509984482 time
kl:0.02395,lr_multiplier:11.391,loss:4.9280314445495605,entropy:5.807512283325195,explained_var_old:0.990166187,explained_var_new:0.994478464
output spend 0.0001461670035496354 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009128789002716076 time
recovery_state_mcts_prob spend 0.2670307299995329 time
state_batch spend 0.001671575999353081 time
mcts_probs_batch spend 0.006273881001106929 time
winner_batch spend 0.0002998369964188896 time
policy_value spend 0.20670089300256222 time
train_step spend 0.6043720340021537 time
policy_value spend 0.20612411099864403 time
train_step spend 0.6026325720013119 time
policy_value spend 0.20568265199835878 time
train_step spend 0.6013074840011541 time
policy_value spend 0.20531227600440616 time
train_step spend 0.6025517930029309 time
policy_value spend 0.20562946800055215 time
train_step spend 0.6022511509945616 time
policy_value spend 0.2059663090039976 time
kl:0.00749,lr_multiplier:11.391,loss:4.955620288848877,entropy:5.805450439453125,explained_var_old:0.989342034,explained_var_new:0.994018435
output spend 0.0001541780002298765 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00879889000498224 time
recovery_state_mcts_prob spend 0.2583510339973145 time
state_batch spend 0.001981790002901107 time
mcts_probs_batch spend 0.006713108996336814 time
winner_batch spend 0.00031595900509273633 time
policy_value spend 0.2082737509990693 time
train_step spend 0.60231342100451 time
policy_value spend 0.20695010900089983 time
train_step spend 0.6020462439992116 time
policy_value spend 0.2059124340012204 time
train_step spend 0.6169930980031495 time
policy_value spend 0.21997300099610584 time
train_step spend 0.6293880860030185 time
policy_value spend 0.20752685299521545 time
train_step spend 0.6046470579967718 time
policy_value spend 0.20603127300273627 time
kl:0.00929,lr_multiplier:11.391,loss:4.978926181793213,entropy:5.856245517730713,explained_var_old:0.986864388,explained_var_new:0.991097689
output spend 0.0001409780015819706 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006848046003142372 time
recovery_state_mcts_prob spend 0.2587946240018937 time
state_batch spend 0.0017496799991931766 time
mcts_probs_batch spend 0.005712492995371576 time
winner_batch spend 0.00029068500589346513 time
policy_value spend 0.20551085799525026 time
train_step spend 0.6041247510001995 time
policy_value spend 0.20575770300638396 time
train_step spend 0.6016243729973212 time
policy_value spend 0.20564449900120962 time
train_step spend 0.6021783399992273 time
policy_value spend 0.20604078799806302 time
train_step spend 0.6132637920018169 time
policy_value spend 0.21751457799837226 time
train_step spend 0.634969575003197 time
policy_value spend 0.2170946769983857 time
kl:0.00597,lr_multiplier:11.391,loss:4.949077606201172,entropy:5.81710147857666,explained_var_old:0.989971817,explained_var_new:0.994755149
output spend 0.00014658999862149358 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007347400998696685 time
recovery_state_mcts_prob spend 0.2823047880010563 time
state_batch spend 0.0020131240016780794 time
mcts_probs_batch spend 0.007001739999395795 time
winner_batch spend 0.0003283139958512038 time
policy_value spend 0.23572315300407354 time
train_step spend 0.6873287490016082 time
policy_value spend 0.23728889699850697 time
train_step spend 0.687809078997816 time
policy_value spend 0.23516381600347813 time
train_step spend 0.6878750869946089 time
policy_value spend 0.2355240530014271 time
train_step spend 0.6878496680001263 time
policy_value spend 0.23464854800113244 time
train_step spend 0.6878278119984316 time
policy_value spend 0.2349074189987732 time
kl:0.01049,lr_multiplier:11.391,loss:4.927840232849121,entropy:5.856557846069336,explained_var_old:0.987751067,explained_var_new:0.993527114
output spend 0.0001585589998285286 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008887524003512226 time
recovery_state_mcts_prob spend 0.2975478730004397 time
state_batch spend 0.0019314050005050376 time
mcts_probs_batch spend 0.007223777000035625 time
winner_batch spend 0.00030581899773096666 time
policy_value spend 0.23946887900092406 time
train_step spend 0.6376508780012955 time
policy_value spend 0.21644252899568528 time
train_step spend 0.6350132090010447 time
policy_value spend 0.21741077899787342 time
train_step spend 0.6763724699994782 time
policy_value spend 0.23530865700013237 time
train_step spend 0.6889274920031312 time
policy_value spend 0.2353214000031585 time
train_step spend 0.6880888450032216 time
policy_value spend 0.23509238899714546 time
kl:0.01264,lr_multiplier:11.391,loss:4.970592498779297,entropy:5.840085029602051,explained_var_old:0.991005957,explained_var_new:0.992284060
output spend 0.0001692609948804602 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.016157261001353618 time
recovery_state_mcts_prob spend 0.3002571449978859 time
state_batch spend 0.002273879996209871 time
mcts_probs_batch spend 0.0071890969993546605 time
winner_batch spend 0.00032106300204759464 time
policy_value spend 0.23588025999924866 time
train_step spend 0.6875160900017363 time
policy_value spend 0.23671355500118807 time
train_step spend 0.688436112999625 time
policy_value spend 0.23505935300636338 time
train_step spend 0.6875584020017413 time
policy_value spend 0.23503967299620854 time
train_step spend 0.6631632339995122 time
policy_value spend 0.21535278700321214 time
train_step spend 0.632029758002318 time
policy_value spend 0.21892198899877258 time
kl:0.01773,lr_multiplier:11.391,loss:4.894529819488525,entropy:5.788659572601318,explained_var_old:0.979522347,explained_var_new:0.987253308
output spend 0.00015689999418100342 time
已保存最新模型
current self-play batch: 400
load data begin
已加载数据
step i 372: 
random.sample spend 0.00800231700122822 time
recovery_state_mcts_prob spend 0.279474825001671 time
state_batch spend 0.0025092789946938865 time
mcts_probs_batch spend 0.008110087001114152 time
winner_batch spend 0.00031248300365405157 time
policy_value spend 0.22002355199947488 time
train_step spend 0.6758198859970435 time
policy_value spend 0.2244019690042478 time
train_step spend 0.6423689100047341 time
policy_value spend 0.2196629799946095 time
train_step spend 0.6377927520006779 time
policy_value spend 0.21824402299534995 time
train_step spend 0.637439831996744 time
policy_value spend 0.2182816440035822 time
train_step spend 0.6382210480005597 time
policy_value spend 0.21789803599676816 time
kl:0.00889,lr_multiplier:11.391,loss:4.892398834228516,entropy:5.767427921295166,explained_var_old:0.995349109,explained_var_new:0.995268583
output spend 0.00015732100291643292 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0087439569979324 time
recovery_state_mcts_prob spend 0.2739699970043148 time
state_batch spend 0.0017568709954502992 time
mcts_probs_batch spend 0.005679289002728183 time
winner_batch spend 0.000316858000587672 time
policy_value spend 0.21838917399873026 time
train_step spend 0.6384621929973946 time
policy_value spend 0.2192220350043499 time
train_step spend 0.6699861430024612 time
policy_value spend 0.23501021399715682 time
train_step spend 0.6880119740017108 time
policy_value spend 0.23480696300248383 time
train_step spend 0.6883503119970555 time
policy_value spend 0.2352813920006156 time
train_step spend 0.688141953003651 time
policy_value spend 0.23479130499617895 time
kl:0.00709,lr_multiplier:11.391,loss:4.964266300201416,entropy:5.842771530151367,explained_var_old:0.989580572,explained_var_new:0.991534054
output spend 0.00019885300571331754 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008490694999636617 time
recovery_state_mcts_prob spend 0.2898318650040892 time
state_batch spend 0.0019212690021959133 time
mcts_probs_batch spend 0.006680243997834623 time
winner_batch spend 0.0003486259956844151 time
policy_value spend 0.2359283200057689 time
train_step spend 0.6886438930014265 time
policy_value spend 0.23499377600091975 time
train_step spend 0.6888321279984666 time
policy_value spend 0.23562713600404095 time
train_step spend 0.6881969559981371 time
policy_value spend 0.23533145100373076 time
train_step spend 0.6884490789962001 time
policy_value spend 0.2356194510066416 time
train_step spend 0.6890566309957649 time
policy_value spend 0.2350750540063018 time
kl:0.00635,lr_multiplier:11.391,loss:4.988585948944092,entropy:5.867434501647949,explained_var_old:0.986720383,explained_var_new:0.996683419
output spend 0.0002655770003912039 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.015497954998863861 time
recovery_state_mcts_prob spend 0.3018429650037433 time
state_batch spend 0.002002886001719162 time
mcts_probs_batch spend 0.007261380997078959 time
winner_batch spend 0.0003668979989015497 time
policy_value spend 0.235286481998628 time
train_step spend 0.6881179320043884 time
policy_value spend 0.24099946599744726 time
train_step spend 0.6882289950008271 time
policy_value spend 0.23516341699723853 time
train_step spend 0.6883158700002241 time
policy_value spend 0.2360638980026124 time
train_step spend 0.6888361320015974 time
policy_value spend 0.2354304249965935 time
train_step spend 0.689762501999212 time
policy_value spend 0.23552938800276024 time
kl:0.00796,lr_multiplier:11.391,loss:4.914079189300537,entropy:5.779384613037109,explained_var_old:0.986267328,explained_var_new:0.991232693
output spend 0.00016058800247265026 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01197171000239905 time
recovery_state_mcts_prob spend 0.29159430800064 time
state_batch spend 0.001774828000634443 time
mcts_probs_batch spend 0.005526668996026274 time
winner_batch spend 0.0003048470025532879 time
policy_value spend 0.2302184389991453 time
train_step spend 0.7291164999987814 time
policy_value spend 0.24947465999866836 time
train_step spend 0.6910271209999337 time
policy_value spend 0.23659444500663085 time
train_step spend 0.6876715589969535 time
policy_value spend 0.23466639600519557 time
train_step spend 0.6884265100015909 time
policy_value spend 0.23550953000085428 time
train_step spend 0.6884001539947349 time
policy_value spend 0.235589110001456 time
kl:0.00728,lr_multiplier:11.391,loss:4.87924337387085,entropy:5.781540393829346,explained_var_old:0.983893216,explained_var_new:0.988351941
output spend 0.00014989000192144886 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00824974200077122 time
recovery_state_mcts_prob spend 0.28930661900085397 time
state_batch spend 0.0019772110026679 time
mcts_probs_batch spend 0.00651931700122077 time
winner_batch spend 0.00029145999724278226 time
policy_value spend 0.2173123660031706 time
train_step spend 0.6348533459968166 time
policy_value spend 0.21761408600286813 time
train_step spend 0.6352193310012808 time
policy_value spend 0.21689157500077272 time
train_step spend 0.6212060220059357 time
policy_value spend 0.20624107699404703 time
train_step spend 0.6059942880019662 time
policy_value spend 0.2065515919966856 time
train_step spend 0.6032171780025237 time
policy_value spend 0.20583827899827156 time
kl:0.01762,lr_multiplier:11.391,loss:4.936347484588623,entropy:5.8202056884765625,explained_var_old:0.987769127,explained_var_new:0.994797230
output spend 0.00015179900219663978 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006543674004205968 time
recovery_state_mcts_prob spend 0.258640148997074 time
state_batch spend 0.0016967600022326224 time
mcts_probs_batch spend 0.005769704999693204 time
winner_batch spend 0.0002733450019150041 time
policy_value spend 0.2058926239988068 time
train_step spend 0.6024565809930209 time
policy_value spend 0.207467259002442 time
train_step spend 0.6027814029948786 time
policy_value spend 0.20710179000161588 time
train_step spend 0.6034436440022546 time
policy_value spend 0.20617900699289748 time
train_step spend 0.6032717760026571 time
policy_value spend 0.20633894599450286 time
train_step spend 0.6026444239978446 time
policy_value spend 0.206019910001487 time
kl:0.01139,lr_multiplier:11.391,loss:4.8924150466918945,entropy:5.7794952392578125,explained_var_old:0.981133521,explained_var_new:0.986749411
output spend 0.00014053599443286657 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0072833140002330765 time
recovery_state_mcts_prob spend 0.2610685339968768 time
state_batch spend 0.0018337250003241934 time
mcts_probs_batch spend 0.0043243350010016 time
winner_batch spend 0.0002825330011546612 time
policy_value spend 0.2058513879965176 time
train_step spend 0.6014408629998798 time
policy_value spend 0.2054553920024773 time
train_step spend 0.6024994460021844 time
policy_value spend 0.2058753949968377 time
train_step spend 0.6033838470029877 time
policy_value spend 0.20629379199817777 time
train_step spend 0.6034796399981133 time
policy_value spend 0.20648681500460953 time
train_step spend 0.6037896370035014 time
policy_value spend 0.20592887999373488 time
kl:0.03162,lr_multiplier:11.391,loss:4.902621269226074,entropy:5.77449893951416,explained_var_old:0.980402946,explained_var_new:0.989927649
output spend 0.0001400499968440272 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0065925269955187105 time
recovery_state_mcts_prob spend 0.26631878000625875 time
state_batch spend 0.0018531739988247864 time
mcts_probs_batch spend 0.006122227001469582 time
winner_batch spend 0.0002794679967337288 time
policy_value spend 0.2058525800021016 time
train_step spend 0.6039781159997801 time
policy_value spend 0.21227783399808686 time
train_step spend 0.6029290020014741 time
policy_value spend 0.20671472200046992 time
train_step spend 0.6032031220020144 time
policy_value spend 0.20585091099928832 time
train_step spend 0.6329800029998296 time
policy_value spend 0.22604031799710356 time
train_step spend 0.658254087997193 time
policy_value spend 0.22477505700226175 time
kl:0.04739,lr_multiplier:7.594,loss:4.9477057456970215,entropy:5.8126325607299805,explained_var_old:0.997343481,explained_var_new:0.998627186
output spend 0.00016233999485848472 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008208042003388982 time
recovery_state_mcts_prob spend 0.28533386700291885 time
state_batch spend 0.001892511994810775 time
mcts_probs_batch spend 0.006890321004902944 time
winner_batch spend 0.0003270619999966584 time
policy_value spend 0.22514446399873123 time
train_step spend 0.658672233003017 time
policy_value spend 0.22459021500253584 time
train_step spend 0.6573979500026326 time
policy_value spend 0.22493528799532214 time
train_step spend 0.6577511969953775 time
policy_value spend 0.22404356000333792 time
train_step spend 0.65820153200184 time
policy_value spend 0.22505680099857273 time
train_step spend 0.6580508699989878 time
policy_value spend 0.22444523800368188 time
kl:0.01658,lr_multiplier:7.594,loss:4.946988105773926,entropy:5.854241847991943,explained_var_old:0.994362772,explained_var_new:0.998607934
output spend 0.0001614339998923242 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012673464007093571 time
recovery_state_mcts_prob spend 0.2783243589947233 time
state_batch spend 0.0018664950039237738 time
mcts_probs_batch spend 0.006525886994495522 time
winner_batch spend 0.0002964750019600615 time
policy_value spend 0.23834373999852687 time
train_step spend 0.7248422229968128 time
policy_value spend 0.2513191200050642 time
train_step spend 0.7247327080040122 time
policy_value spend 0.247749713002122 time
train_step spend 0.7254226910008583 time
policy_value spend 0.24789465199864935 time
train_step spend 0.7262179909957922 time
policy_value spend 0.24843811000027927 time
train_step spend 0.7251177740035928 time
policy_value spend 0.2481223279974074 time
kl:0.03758,lr_multiplier:7.594,loss:4.892940998077393,entropy:5.797386169433594,explained_var_old:0.993483543,explained_var_new:0.994942069
output spend 0.00018796299991663545 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01129607499751728 time
recovery_state_mcts_prob spend 0.3081891129986616 time
state_batch spend 0.0026004640021710657 time
mcts_probs_batch spend 0.009752163001394365 time
winner_batch spend 0.0004143900005146861 time
policy_value spend 0.24867783499939833 time
train_step spend 0.7247638810003991 time
policy_value spend 0.2518539309967309 time
train_step spend 0.7246164359967224 time
policy_value spend 0.24811582500115037 time
train_step spend 0.7249383119997219 time
policy_value spend 0.24735769299877575 time
train_step spend 0.7253433459991356 time
policy_value spend 0.24884759799897438 time
train_step spend 0.7256497749986011 time
policy_value spend 0.24804420600412413 time
kl:0.03501,lr_multiplier:7.594,loss:4.9281158447265625,entropy:5.808314323425293,explained_var_old:0.993185222,explained_var_new:0.995170414
output spend 0.0001704559981590137 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00890839500061702 time
recovery_state_mcts_prob spend 0.2809240279966616 time
state_batch spend 0.001867756000137888 time
mcts_probs_batch spend 0.006357500002195593 time
winner_batch spend 0.0003552839989424683 time
policy_value spend 0.22899806500208797 time
train_step spend 0.6687803259992506 time
policy_value spend 0.23245702100393828 time
train_step spend 0.6699583060035366 time
policy_value spend 0.22824847999436315 time
train_step spend 0.6686706640030025 time
policy_value spend 0.2284239169966895 time
train_step spend 0.6708652710003662 time
policy_value spend 0.22789480900246417 time
train_step spend 0.6885718630001065 time
policy_value spend 0.2416130260025966 time
kl:0.02118,lr_multiplier:7.594,loss:4.905673027038574,entropy:5.79683780670166,explained_var_old:0.987462699,explained_var_new:0.990700066
output spend 0.00019881099433405325 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00853399599873228 time
recovery_state_mcts_prob spend 0.29340813899761997 time
state_batch spend 0.002438060000713449 time
mcts_probs_batch spend 0.006589258002350107 time
winner_batch spend 0.0003134750004392117 time
policy_value spend 0.23096026499842992 time
train_step spend 0.6714431869986583 time
policy_value spend 0.2273507290010457 time
train_step spend 0.6701176510032383 time
policy_value spend 0.2292088869944564 time
kl:0.10341,lr_multiplier:5.062,loss:4.919105529785156,entropy:5.775495529174805,explained_var_old:0.984720528,explained_var_new:0.990175188
output spend 0.00015828499454073608 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008427868997387122 time
recovery_state_mcts_prob spend 0.2890608660018188 time
state_batch spend 0.0020564680016832426 time
mcts_probs_batch spend 0.006751460001396481 time
winner_batch spend 0.00032579799881204963 time
policy_value spend 0.22862704099679831 time
train_step spend 0.6688691329982248 time
policy_value spend 0.2328432030044496 time
train_step spend 0.6689128309953958 time
policy_value spend 0.22806766000576317 time
train_step spend 0.6689193120037089 time
policy_value spend 0.22830574399995385 time
train_step spend 0.6695106339975609 time
policy_value spend 0.22780277200217824 time
train_step spend 0.6694495490010013 time
policy_value spend 0.22774428100092337 time
kl:0.00583,lr_multiplier:7.594,loss:4.924551010131836,entropy:5.784609794616699,explained_var_old:0.991690218,explained_var_new:0.993010461
output spend 0.00015674300084356219 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00948726299975533 time
recovery_state_mcts_prob spend 0.29915834099665517 time
state_batch spend 0.0019428550003794953 time
mcts_probs_batch spend 0.017836102000728715 time
winner_batch spend 0.00031042999762576073 time
policy_value spend 0.23249665000184905 time
train_step spend 0.671866015996784 time
policy_value spend 0.2295081550037139 time
train_step spend 0.6711980309992214 time
policy_value spend 0.22907972400571452 time
train_step spend 0.6707693489952362 time
policy_value spend 0.22932735700305784 time
train_step spend 0.6697284889960429 time
policy_value spend 0.22893513300368795 time
train_step spend 0.6695105510007124 time
policy_value spend 0.22851416900084587 time
kl:0.01323,lr_multiplier:7.594,loss:4.911391735076904,entropy:5.819247245788574,explained_var_old:0.991582513,explained_var_new:0.996493101
output spend 0.00016414700075984 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008455789000436198 time
recovery_state_mcts_prob spend 0.2842065620061476 time
state_batch spend 0.0018595999936223961 time
mcts_probs_batch spend 0.006968734000110999 time
winner_batch spend 0.0003191150026395917 time
policy_value spend 0.22828447999927448 time
train_step spend 0.6710384679972776 time
policy_value spend 0.22779204700054834 time
train_step spend 0.6681056859961245 time
policy_value spend 0.22839154500252334 time
train_step spend 0.6692131430027075 time
policy_value spend 0.2277260029950412 time
train_step spend 0.6692918699991424 time
policy_value spend 0.22803618199395714 time
train_step spend 0.6746795939980075 time
policy_value spend 0.2289956910026376 time
kl:0.00524,lr_multiplier:11.391,loss:4.909682750701904,entropy:5.77397346496582,explained_var_old:0.988595545,explained_var_new:0.991304576
output spend 0.00015495899424422532 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008157281001331285 time
recovery_state_mcts_prob spend 0.2895085529962671 time
state_batch spend 0.001868396000645589 time
mcts_probs_batch spend 0.006885688002512325 time
winner_batch spend 0.0003059109949390404 time
policy_value spend 0.2297777909989236 time
train_step spend 0.6696102740024799 time
policy_value spend 0.2352817619976122 time
train_step spend 0.6695691679997253 time
policy_value spend 0.22820527700241655 time
train_step spend 0.6700754170014989 time
policy_value spend 0.22905900800105883 time
train_step spend 0.670114865002688 time
policy_value spend 0.2290748489976977 time
train_step spend 0.6706209490002948 time
policy_value spend 0.22918368999671657 time
kl:0.00569,lr_multiplier:11.391,loss:4.91229248046875,entropy:5.810214996337891,explained_var_old:0.981780589,explained_var_new:0.991510630
output spend 0.0001671919962973334 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010573922001640312 time
recovery_state_mcts_prob spend 0.28398251500038896 time
state_batch spend 0.002331680996576324 time
mcts_probs_batch spend 0.006403118997695856 time
winner_batch spend 0.00029751500551356 time
policy_value spend 0.2289475619982113 time
train_step spend 0.6685173040023074 time
policy_value spend 0.23307969299639808 time
train_step spend 0.6698247770036687 time
policy_value spend 0.22879685699444963 time
train_step spend 0.6694769539972185 time
policy_value spend 0.22894759200426051 time
train_step spend 0.6693878450023476 time
policy_value spend 0.22833669599640416 time
train_step spend 0.669765370003006 time
policy_value spend 0.2284936479991302 time
kl:0.00502,lr_multiplier:11.391,loss:4.858695030212402,entropy:5.755331039428711,explained_var_old:0.994044363,explained_var_new:0.996878147
output spend 0.00015783499839017168 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010559621005086228 time
recovery_state_mcts_prob spend 0.25797665899881395 time
state_batch spend 0.0017577429971424863 time
mcts_probs_batch spend 0.00684925200039288 time
winner_batch spend 0.00042817700159503147 time
policy_value spend 0.20997657399857417 time
train_step spend 0.6142014130018651 time
policy_value spend 0.20969504900131142 time
train_step spend 0.613890521999565 time
policy_value spend 0.20964649700181326 time
train_step spend 0.6131417400029022 time
policy_value spend 0.20979562499996973 time
train_step spend 0.6129897270002402 time
policy_value spend 0.20974194099835586 time
train_step spend 0.6141367620002711 time
policy_value spend 0.20987987599801272 time
kl:0.00915,lr_multiplier:11.391,loss:4.8612260818481445,entropy:5.772177219390869,explained_var_old:0.998666704,explained_var_new:0.999190271
output spend 0.00017281199689023197 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006939134000276681 time
recovery_state_mcts_prob spend 0.2658539049953106 time
state_batch spend 0.0017655320043559186 time
mcts_probs_batch spend 0.006692971001029946 time
winner_batch spend 0.0002890510004363023 time
policy_value spend 0.2095863449940225 time
train_step spend 0.6147465629983344 time
policy_value spend 0.2094105709984433 time
train_step spend 0.6130750279990025 time
policy_value spend 0.2100157329987269 time
train_step spend 0.6199709920038003 time
policy_value spend 0.20930061899707653 time
train_step spend 0.6135999359976267 time
policy_value spend 0.20962966000661254 time
train_step spend 0.6148480359988753 time
policy_value spend 0.20956865700281924 time
kl:0.02093,lr_multiplier:11.391,loss:4.9036102294921875,entropy:5.806861877441406,explained_var_old:0.995807767,explained_var_new:0.998401344
output spend 0.00014606799959437922 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007073916000081226 time
recovery_state_mcts_prob spend 0.25600329200096894 time
state_batch spend 0.0018414259975543246 time
mcts_probs_batch spend 0.0046346620001713745 time
winner_batch spend 0.0003335650035296567 time
policy_value spend 0.2086927329946775 time
train_step spend 0.6130138989974512 time
policy_value spend 0.20923729900096077 time
train_step spend 0.6139104710018728 time
policy_value spend 0.20964529499906348 time
train_step spend 0.6142861769985757 time
policy_value spend 0.2183636010013288 time
kl:0.09049,lr_multiplier:7.594,loss:4.936047554016113,entropy:5.787281036376953,explained_var_old:0.986664295,explained_var_new:0.988189161
output spend 0.0001468580012442544 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.014784166996832937 time
recovery_state_mcts_prob spend 0.3018678810040001 time
state_batch spend 0.0020594929956132546 time
mcts_probs_batch spend 0.00653192800382385 time
winner_batch spend 0.000340726001013536 time
policy_value spend 0.24223731299571227 time
train_step spend 0.6737152190034976 time
policy_value spend 0.2308425509982044 time
train_step spend 0.6652184900012799 time
policy_value spend 0.22554565199970966 time
train_step spend 0.6616282090035384 time
policy_value spend 0.22649634000117658 time
train_step spend 0.6625971629982814 time
policy_value spend 0.22612597300030757 time
kl:0.08343,lr_multiplier:5.062,loss:4.877845287322998,entropy:5.758275032043457,explained_var_old:0.983718991,explained_var_new:0.989964724
output spend 0.00021135099814273417 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011080865006078966 time
recovery_state_mcts_prob spend 0.2899293070004205 time
state_batch spend 0.0018676670006243512 time
mcts_probs_batch spend 0.017380924997269176 time
winner_batch spend 0.00032224899769062176 time
policy_value spend 0.22866876199987018 time
train_step spend 0.6605677780025871 time
policy_value spend 0.22926789499615552 time
train_step spend 0.6622640540008433 time
policy_value spend 0.2262441690036212 time
train_step spend 0.6607311500047217 time
policy_value spend 0.22594141399895307 time
train_step spend 0.6612206049976521 time
policy_value spend 0.2265635280054994 time
train_step spend 0.6609968279954046 time
policy_value spend 0.22576218000176596 time
kl:0.03475,lr_multiplier:5.062,loss:4.866464614868164,entropy:5.768059730529785,explained_var_old:0.991817117,explained_var_new:0.995364249
output spend 0.0001545409977552481 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007115865999367088 time
recovery_state_mcts_prob spend 0.29293325299659045 time
state_batch spend 0.001892876003694255 time
mcts_probs_batch spend 0.006654573997366242 time
winner_batch spend 0.0003347489982843399 time
policy_value spend 0.2308765960042365 time
train_step spend 0.6696577340044314 time
policy_value spend 0.2287699949956732 time
train_step spend 0.6719525389999035 time
policy_value spend 0.22934935800003586 time
train_step spend 0.6700512489987887 time
policy_value spend 0.22930211299535586 time
train_step spend 0.6703708869972616 time
policy_value spend 0.22948872599954484 time
train_step spend 0.6705943460037815 time
policy_value spend 0.22860106299776817 time
kl:0.01475,lr_multiplier:5.062,loss:4.874688625335693,entropy:5.7808756828308105,explained_var_old:0.992939830,explained_var_new:0.995832682
output spend 0.00015587700181640685 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012845186996855773 time
recovery_state_mcts_prob spend 0.2881324539994239 time
state_batch spend 0.0020055380009580404 time
mcts_probs_batch spend 0.0065988839996862225 time
winner_batch spend 0.00030028100445633754 time
policy_value spend 0.22933043199736858 time
train_step spend 0.6694608990001143 time
policy_value spend 0.22964003200468142 time
train_step spend 0.6515641030055122 time
policy_value spend 0.21017654900060734 time
train_step spend 0.6130924400058575 time
policy_value spend 0.20935106599790743 time
train_step spend 0.6126097839951399 time
policy_value spend 0.2102803509988007 time
train_step spend 0.6140849540024647 time
policy_value spend 0.2093313289951766 time
kl:0.00540,lr_multiplier:7.594,loss:4.862369537353516,entropy:5.7981109619140625,explained_var_old:0.994320452,explained_var_new:0.995576799
output spend 0.00014527900202665478 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008041320004849695 time
recovery_state_mcts_prob spend 0.26691488099459093 time
state_batch spend 0.0021989340020809323 time
mcts_probs_batch spend 0.004382307997730095 time
winner_batch spend 0.000278765000985004 time
policy_value spend 0.2090239930039388 time
train_step spend 0.6138529060044675 time
policy_value spend 0.20989128699875437 time
train_step spend 0.6172544240034767 time
policy_value spend 0.21057136099989293 time
train_step spend 0.6136914140006411 time
policy_value spend 0.2097096099969349 time
train_step spend 0.6137243300036062 time
policy_value spend 0.21035573299741372 time
train_step spend 0.6130425299998024 time
policy_value spend 0.2101682400025311 time
kl:0.01731,lr_multiplier:7.594,loss:4.865464210510254,entropy:5.761593818664551,explained_var_old:0.990384519,explained_var_new:0.991605341
output spend 0.0001801309990696609 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008481445001962129 time
recovery_state_mcts_prob spend 0.26107907199912006 time
state_batch spend 0.002020492000156082 time
mcts_probs_batch spend 0.006167970997921657 time
winner_batch spend 0.0002746879981714301 time
policy_value spend 0.21010520800336963 time
train_step spend 0.613587052001094 time
policy_value spend 0.21038436600065324 time
train_step spend 0.6139786429994274 time
policy_value spend 0.21053366200067103 time
train_step spend 0.6133417599994573 time
policy_value spend 0.2102225820053718 time
train_step spend 0.6146090869951877 time
policy_value spend 0.20941425199998775 time
train_step spend 0.6152726520012948 time
policy_value spend 0.21393166099733207 time
kl:0.00900,lr_multiplier:11.391,loss:4.906441688537598,entropy:5.768814563751221,explained_var_old:0.985274076,explained_var_new:0.989997029
output spend 0.00015876899851718917 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007599550001032185 time
recovery_state_mcts_prob spend 0.29337051499896916 time
state_batch spend 0.002253856000606902 time
mcts_probs_batch spend 0.005694936000509188 time
winner_batch spend 0.0002935579977929592 time
policy_value spend 0.22842195299745072 time
train_step spend 0.6712291009971523 time
policy_value spend 0.228518885000085 time
train_step spend 0.6698583110046457 time
policy_value spend 0.22746674899826758 time
train_step spend 0.6574384340055985 time
policy_value spend 0.2243071199991391 time
train_step spend 0.6578583829978015 time
policy_value spend 0.22534021800674964 time
train_step spend 0.6574260130000766 time
policy_value spend 0.22589294300269103 time
kl:0.00535,lr_multiplier:11.391,loss:4.84838342666626,entropy:5.77420711517334,explained_var_old:0.989108920,explained_var_new:0.994643807
output spend 0.00016409700037911534 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008450351997453254 time
recovery_state_mcts_prob spend 0.284838955005398 time
state_batch spend 0.0018629240003065206 time
mcts_probs_batch spend 0.006604397000046447 time
winner_batch spend 0.0003133859936497174 time
policy_value spend 0.2247339000023203 time
train_step spend 0.6577958900015801 time
policy_value spend 0.22478129799856106 time
train_step spend 0.6569944069997291 time
policy_value spend 0.2249282180055161 time
train_step spend 0.6576669880014379 time
policy_value spend 0.22474203199817566 time
train_step spend 0.6573487589994329 time
policy_value spend 0.22504957800265402 time
train_step spend 0.6602472539962037 time
policy_value spend 0.22824670800036984 time
kl:0.01650,lr_multiplier:11.391,loss:4.843959808349609,entropy:5.740219593048096,explained_var_old:0.981670499,explained_var_new:0.990518570
output spend 0.00020649200450861827 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007273807997989934 time
recovery_state_mcts_prob spend 0.2885553340020124 time
state_batch spend 0.001870385000074748 time
mcts_probs_batch spend 0.004725350998342037 time
winner_batch spend 0.00042521699651842937 time
policy_value spend 0.22835471800499363 time
train_step spend 0.6689374929992482 time
policy_value spend 0.22794723200058797 time
train_step spend 0.6857958970067557 time
policy_value spend 0.24216408799838973 time
train_step spend 0.7005338189992472 time
policy_value spend 0.23032009199960157 time
train_step spend 0.6724262209972949 time
policy_value spend 0.2283203980041435 time
train_step spend 0.6689683369986597 time
policy_value spend 0.22866807899845298 time
kl:0.04210,lr_multiplier:7.594,loss:4.833380222320557,entropy:5.7238664627075195,explained_var_old:0.987734497,explained_var_new:0.988986254
output spend 0.00015715599874965847 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007830385999113787 time
recovery_state_mcts_prob spend 0.29002872200362617 time
state_batch spend 0.001953462000528816 time
mcts_probs_batch spend 0.004744584999571089 time
winner_batch spend 0.00031606500124325976 time
policy_value spend 0.22749180100072408 time
train_step spend 0.6700063809985295 time
policy_value spend 0.2290062920001219 time
train_step spend 0.6139885220036376 time
policy_value spend 0.2095551919992431 time
train_step spend 0.6137785520040779 time
policy_value spend 0.20941253299679374 time
train_step spend 0.6141326869983459 time
policy_value spend 0.21023848300683312 time
train_step spend 0.6144999359967187 time
policy_value spend 0.20945076399948448 time
kl:0.03778,lr_multiplier:7.594,loss:4.866798400878906,entropy:5.751830577850342,explained_var_old:0.966292083,explained_var_new:0.981533825
output spend 0.0001428260002285242 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006945131994143594 time
recovery_state_mcts_prob spend 0.2715326820034534 time
state_batch spend 0.0018906149998656474 time
mcts_probs_batch spend 0.005939788999967277 time
winner_batch spend 0.00028170400037197396 time
policy_value spend 0.21011274900229182 time
train_step spend 0.612818221001362 time
policy_value spend 0.2124929030032945 time
train_step spend 0.6132283080005436 time
policy_value spend 0.20921412499592407 time
train_step spend 0.6148826999997254 time
policy_value spend 0.20919464900362073 time
train_step spend 0.6137910749966977 time
policy_value spend 0.20971916500275256 time
train_step spend 0.6145691900019301 time
policy_value spend 0.21011921699391678 time
kl:0.01005,lr_multiplier:7.594,loss:4.78431510925293,entropy:5.712843894958496,explained_var_old:0.975153863,explained_var_new:0.992269397
output spend 0.0001490989961894229 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010509485997317825 time
recovery_state_mcts_prob spend 0.2594398529981845 time
state_batch spend 0.0017198319983435795 time
mcts_probs_batch spend 0.005836409000039566 time
winner_batch spend 0.00027577100263442844 time
policy_value spend 0.21033870999963256 time
train_step spend 0.6133911500000977 time
policy_value spend 0.20905514899641275 time
train_step spend 0.6129251899983501 time
policy_value spend 0.20965679200162413 time
train_step spend 0.6132984549985849 time
policy_value spend 0.20995168999797897 time
train_step spend 0.6135029090000899 time
policy_value spend 0.20930509099707706 time
train_step spend 0.6174963000012212 time
policy_value spend 0.22913912199874176 time
kl:0.01302,lr_multiplier:7.594,loss:4.833908557891846,entropy:5.759778022766113,explained_var_old:0.991729677,explained_var_new:0.994791389
output spend 0.00016114099707920104 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007697483000811189 time
recovery_state_mcts_prob spend 0.2989717170057702 time
state_batch spend 0.001969263998034876 time
mcts_probs_batch spend 0.007386714001768269 time
winner_batch spend 0.0003633579981396906 time
policy_value spend 0.2291220199986128 time
train_step spend 0.6681343039963394 time
policy_value spend 0.229530122000142 time
train_step spend 0.6605193400027929 time
policy_value spend 0.22343513899977552 time
train_step spend 0.6536086030027946 time
policy_value spend 0.22398806199635146 time
train_step spend 0.6538054280026699 time
policy_value spend 0.22400019299675478 time
train_step spend 0.652648624003632 time
policy_value spend 0.22366923200024758 time
kl:0.03622,lr_multiplier:7.594,loss:4.836160182952881,entropy:5.716907501220703,explained_var_old:0.974094331,explained_var_new:0.975867093
output spend 0.00015288700524251908 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070885099994484335 time
recovery_state_mcts_prob spend 0.280639409997093 time
state_batch spend 0.0018714680045377463 time
mcts_probs_batch spend 0.006204740995599423 time
winner_batch spend 0.00030288699781522155 time
policy_value spend 0.22344993900333066 time
train_step spend 0.6537777670018841 time
policy_value spend 0.22458892800204922 time
train_step spend 0.6530246179972892 time
policy_value spend 0.22292028200172354 time
train_step spend 0.6533512750029331 time
policy_value spend 0.22465685500355903 time
train_step spend 0.6535109659962473 time
policy_value spend 0.22314275900134817 time
train_step spend 0.6656955870057573 time
policy_value spend 0.22895104399503907 time
kl:0.02364,lr_multiplier:7.594,loss:4.8111772537231445,entropy:5.713890075683594,explained_var_old:0.991021931,explained_var_new:0.991594434
output spend 0.00016462200437672436 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00946375000057742 time
recovery_state_mcts_prob spend 0.28618591299891705 time
state_batch spend 0.0019325079992995597 time
mcts_probs_batch spend 0.006587734998902306 time
winner_batch spend 0.00030327200511237606 time
policy_value spend 0.22923903499759035 time
train_step spend 0.6694821889977902 time
policy_value spend 0.2283023689960828 time
train_step spend 0.6681735849997494 time
policy_value spend 0.2288606529982644 time
train_step spend 0.6692361770037678 time
policy_value spend 0.22982619499816792 time
train_step spend 0.6700443480003742 time
policy_value spend 0.2282027749970439 time
train_step spend 0.6686499890056439 time
policy_value spend 0.22895340700051747 time
kl:0.01126,lr_multiplier:7.594,loss:4.9020094871521,entropy:5.787137985229492,explained_var_old:0.982644022,explained_var_new:0.987202346
output spend 0.00017040900274878368 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008060268999543041 time
recovery_state_mcts_prob spend 0.2817566950034234 time
state_batch spend 0.0019719769989023916 time
mcts_probs_batch spend 0.004637042999092955 time
winner_batch spend 0.00032766200456535444 time
policy_value spend 0.22661678099393612 time
train_step spend 0.6568323589963256 time
policy_value spend 0.21000011700380128 time
train_step spend 0.6128164089968777 time
policy_value spend 0.20985260900488356 time
train_step spend 0.613763587003632 time
policy_value spend 0.20940515199617948 time
train_step spend 0.6132011660010903 time
policy_value spend 0.20955774700269103 time
train_step spend 0.6133614600039436 time
policy_value spend 0.20975458199973218 time
kl:0.00923,lr_multiplier:11.391,loss:4.856321334838867,entropy:5.77247428894043,explained_var_old:0.995347798,explained_var_new:0.998822272
output spend 0.00014400200598174706 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007207945003756322 time
recovery_state_mcts_prob spend 0.26048597099725157 time
state_batch spend 0.002002070003072731 time
mcts_probs_batch spend 0.0063329670010716654 time
winner_batch spend 0.0002699489996302873 time
policy_value spend 0.2094630639985553 time
train_step spend 0.6145788819994777 time
policy_value spend 0.20982365399686387 time
train_step spend 0.6132004399987636 time
policy_value spend 0.21039840199955506 time
train_step spend 0.6172605019964976 time
policy_value spend 0.20965029400394997 time
train_step spend 0.613903167002718 time
policy_value spend 0.21069514299597358 time
train_step spend 0.6138202939982875 time
policy_value spend 0.20929036699817516 time
kl:0.01550,lr_multiplier:11.391,loss:4.857161998748779,entropy:5.753183364868164,explained_var_old:0.994230449,explained_var_new:0.995360434
output spend 0.0001467120018787682 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010139798992895521 time
recovery_state_mcts_prob spend 0.2979464970048866 time
state_batch spend 0.002494659995136317 time
mcts_probs_batch spend 0.012321576999966055 time
winner_batch spend 0.00033184800122398883 time
policy_value spend 0.22526183300215052 time
train_step spend 0.6375161379983183 time
policy_value spend 0.21409616400342202 time
train_step spend 0.6168139000001247 time
policy_value spend 0.21097405399632407 time
train_step spend 0.6131046209993656 time
policy_value spend 0.20964841299428372 time
train_step spend 0.6134851379974862 time
policy_value spend 0.21079565500258468 time
train_step spend 0.6683019870033604 time
policy_value spend 0.22852505699847825 time
kl:0.00626,lr_multiplier:11.391,loss:4.825474739074707,entropy:5.73106575012207,explained_var_old:0.994161010,explained_var_new:0.995758116
output spend 0.00016007799422368407 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008612210003775544 time
recovery_state_mcts_prob spend 0.284936726995511 time
state_batch spend 0.0020595630048774183 time
mcts_probs_batch spend 0.013919452998379711 time
winner_batch spend 0.00031962699722498655 time
policy_value spend 0.23205528299877187 time
train_step spend 0.6683846209998592 time
policy_value spend 0.2272917569935089 time
train_step spend 0.6493620690016542 time
policy_value spend 0.22189262499887263 time
train_step spend 0.6497919710018323 time
policy_value spend 0.22138402499695076 time
train_step spend 0.649632623004436 time
policy_value spend 0.22130896499584196 time
train_step spend 0.6492822830041405 time
policy_value spend 0.22204326299834065 time
kl:0.00496,lr_multiplier:11.391,loss:4.824375629425049,entropy:5.741365432739258,explained_var_old:0.994459391,explained_var_new:0.995689392
output spend 0.00015514800179516897 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007684299001994077 time
recovery_state_mcts_prob spend 0.27170317599666305 time
state_batch spend 0.002410451001196634 time
mcts_probs_batch spend 0.00714430000516586 time
winner_batch spend 0.00029343899950617924 time
policy_value spend 0.22211503699509194 time
train_step spend 0.6486648220015923 time
policy_value spend 0.22355658699962078 time
train_step spend 0.6493785340062459 time
policy_value spend 0.22203320199332666 time
train_step spend 0.6490550580056151 time
policy_value spend 0.22159981799632078 time
train_step spend 0.6667671630057157 time
policy_value spend 0.22897681199538056 time
train_step spend 0.6693053530034376 time
policy_value spend 0.22804046699457103 time
kl:0.00849,lr_multiplier:11.391,loss:4.876002788543701,entropy:5.782536506652832,explained_var_old:0.992120624,explained_var_new:0.995267510
output spend 0.00016899099864531308 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008750868000788614 time
recovery_state_mcts_prob spend 0.2896378440054832 time
state_batch spend 0.0020809529960388318 time
mcts_probs_batch spend 0.006011964003846515 time
winner_batch spend 0.00036431099579203874 time
policy_value spend 0.22892340300313663 time
train_step spend 0.6711563810022199 time
policy_value spend 0.22845109299669275 time
train_step spend 0.6683463660010602 time
policy_value spend 0.2289554630042403 time
train_step spend 0.6698176770005375 time
policy_value spend 0.22843678499339148 time
train_step spend 0.6692635340004927 time
policy_value spend 0.2284915690033813 time
train_step spend 0.6807277400002931 time
policy_value spend 0.22840290400199592 time
kl:0.00631,lr_multiplier:11.391,loss:4.826083183288574,entropy:5.699830532073975,explained_var_old:0.987102389,explained_var_new:0.994460166
output spend 0.00016033500287448987 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008586436000769027 time
recovery_state_mcts_prob spend 0.2869469669967657 time
state_batch spend 0.001918734000355471 time
mcts_probs_batch spend 0.0049162549985339865 time
winner_batch spend 0.00030749600409762934 time
policy_value spend 0.2276525529960054 time
train_step spend 0.6145330369981821 time
policy_value spend 0.20932803500181763 time
train_step spend 0.6131651189934928 time
policy_value spend 0.20985412700247252 time
train_step spend 0.6138244239991764 time
policy_value spend 0.2091006040063803 time
train_step spend 0.6165103619932779 time
policy_value spend 0.2107957520056516 time
train_step spend 0.6126913289990625 time
policy_value spend 0.21011492799880216 time
kl:0.02295,lr_multiplier:11.391,loss:4.817281246185303,entropy:5.752807140350342,explained_var_old:0.988035500,explained_var_new:0.991915107
output spend 0.00015100000018719584 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007539452999481 time
recovery_state_mcts_prob spend 0.26386286199704045 time
state_batch spend 0.0019925650049117394 time
mcts_probs_batch spend 0.005728092997742351 time
winner_batch spend 0.00030371799948625267 time
policy_value spend 0.21019652499671793 time
train_step spend 0.61412118300359 time
policy_value spend 0.20935133600141853 time
train_step spend 0.612916332000168 time
policy_value spend 0.20945419700001366 time
train_step spend 0.6138118010057951 time
policy_value spend 0.2092087229975732 time
train_step spend 0.6136863240026287 time
policy_value spend 0.20946344199910527 time
train_step spend 0.6134773550002137 time
policy_value spend 0.20981553599995095 time
kl:0.01706,lr_multiplier:11.391,loss:4.848104000091553,entropy:5.740292549133301,explained_var_old:0.995257378,explained_var_new:0.998715341
output spend 0.00023585800227010623 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070934129980742 time
recovery_state_mcts_prob spend 0.2665830609985278 time
state_batch spend 0.00193295200006105 time
mcts_probs_batch spend 0.004859509004745632 time
winner_batch spend 0.00032682399614714086 time
policy_value spend 0.20857909099868266 time
train_step spend 0.6140047219960252 time
policy_value spend 0.20949889199982863 time
train_step spend 0.6139651439953013 time
policy_value spend 0.21004757300397614 time
train_step spend 0.6141474649994052 time
policy_value spend 0.20955948199843988 time
train_step spend 0.6144539300003089 time
policy_value spend 0.20964495099906344 time
train_step spend 0.6528684219956631 time
policy_value spend 0.22850159300287487 time
kl:0.01111,lr_multiplier:11.391,loss:4.829662799835205,entropy:5.742877960205078,explained_var_old:0.989360690,explained_var_new:0.991115987
output spend 0.00015433799853781238 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00738171400007559 time
recovery_state_mcts_prob spend 0.284203900002467 time
state_batch spend 0.001855101996625308 time
mcts_probs_batch spend 0.006920783998793922 time
winner_batch spend 0.00030597099976148456 time
policy_value spend 0.2294934329984244 time
train_step spend 0.6634263089945307 time
policy_value spend 0.2279286850025528 time
train_step spend 0.6577302829973632 time
policy_value spend 0.22537496800214285 time
train_step spend 0.657726511999499 time
policy_value spend 0.22563212199747795 time
train_step spend 0.6585175299987895 time
policy_value spend 0.22545640399766853 time
train_step spend 0.657966350998322 time
policy_value spend 0.22504437300085556 time
kl:0.02300,lr_multiplier:11.391,loss:4.796840667724609,entropy:5.719931602478027,explained_var_old:0.991965592,explained_var_new:0.996931314
output spend 0.00016845299978740513 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010556190005445387 time
recovery_state_mcts_prob spend 0.2796009879966732 time
state_batch spend 0.0019078469995292835 time
mcts_probs_batch spend 0.006485058001999278 time
winner_batch spend 0.00036134500260232016 time
policy_value spend 0.2252119769982528 time
train_step spend 0.6575493089985684 time
policy_value spend 0.22615121099806856 time
train_step spend 0.6583483270005672 time
policy_value spend 0.22557859899825417 time
train_step spend 0.6585400190015207 time
policy_value spend 0.2360950380025315 time
train_step spend 0.6975837849968229 time
policy_value spend 0.2449287839990575 time
train_step spend 0.6903488640018622 time
policy_value spend 0.2324466299978667 time
kl:0.01014,lr_multiplier:11.391,loss:4.795539379119873,entropy:5.744603157043457,explained_var_old:0.988568127,explained_var_new:0.995131075
output spend 0.0001601209951331839 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008915983999031596 time
recovery_state_mcts_prob spend 0.2957859929956612 time
state_batch spend 0.002002453002205584 time
mcts_probs_batch spend 0.006653411001025233 time
winner_batch spend 0.0003164489971823059 time
policy_value spend 0.2308000000048196 time
train_step spend 0.674278628997854 time
policy_value spend 0.22983596700214548 time
train_step spend 0.6743662789958762 time
policy_value spend 0.23104030799731845 time
train_step spend 0.6736771629948635 time
policy_value spend 0.2303203539995593 time
train_step spend 0.6741317790001631 time
policy_value spend 0.23067643600370502 time
train_step spend 0.6739851060046931 time
policy_value spend 0.2301228079959401 time
kl:0.01412,lr_multiplier:11.391,loss:4.815286636352539,entropy:5.725578308105469,explained_var_old:0.988193929,explained_var_new:0.991287827
output spend 0.0001538969954708591 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013278145001095254 time
recovery_state_mcts_prob spend 0.26122053900326136 time
state_batch spend 0.002089837995299604 time
mcts_probs_batch spend 0.00618196700088447 time
winner_batch spend 0.0002759909984888509 time
policy_value spend 0.21098324700142257 time
train_step spend 0.6168801610037917 time
policy_value spend 0.2105449679947924 time
train_step spend 0.6132781150008668 time
policy_value spend 0.20967318199836882 time
train_step spend 0.6139084269962041 time
policy_value spend 0.2095241770002758 time
train_step spend 0.6139835949943517 time
policy_value spend 0.2093414430055418 time
train_step spend 0.6141011229992728 time
policy_value spend 0.20937274099560454 time
kl:0.01132,lr_multiplier:11.391,loss:4.833555698394775,entropy:5.759838104248047,explained_var_old:0.987452507,explained_var_new:0.993294537
output spend 0.0001429639960406348 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007384272998024244 time
recovery_state_mcts_prob spend 0.27327583599981153 time
state_batch spend 0.0019762160009122454 time
mcts_probs_batch spend 0.006671593000646681 time
winner_batch spend 0.0003092010010732338 time
policy_value spend 0.21084929899370763 time
train_step spend 0.6145849719978287 time
policy_value spend 0.20898052700067637 time
train_step spend 0.6137369020070764 time
policy_value spend 0.2112720159930177 time
train_step spend 0.6145088260018383 time
policy_value spend 0.20953993500006618 time
train_step spend 0.6141088169970317 time
policy_value spend 0.21113693100051023 time
train_step spend 0.613986947995727 time
policy_value spend 0.2099773370064213 time
kl:0.02963,lr_multiplier:11.391,loss:4.83650541305542,entropy:5.727915287017822,explained_var_old:0.983098388,explained_var_new:0.992908597
output spend 0.00016284699813695624 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007356806003372185 time
recovery_state_mcts_prob spend 0.26996578999387566 time
state_batch spend 0.0019040780025534332 time
mcts_probs_batch spend 0.005469679999805521 time
winner_batch spend 0.0002725470039877109 time
policy_value spend 0.21009702799346996 time
train_step spend 0.6142055040036212 time
policy_value spend 0.20963087199925212 time
train_step spend 0.6152183879967197 time
policy_value spend 0.21056218999729026 time
train_step spend 0.6140104579972103 time
policy_value spend 0.20996320999984164 time
train_step spend 0.6135790569969686 time
policy_value spend 0.21011998999892967 time
train_step spend 0.614270612000837 time
policy_value spend 0.20991721600148594 time
kl:0.00608,lr_multiplier:11.391,loss:4.764887809753418,entropy:5.682487487792969,explained_var_old:0.980036795,explained_var_new:0.983530760
output spend 0.00015505000192206353 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007503361004637554 time
recovery_state_mcts_prob spend 0.2886889860019437 time
state_batch spend 0.0018725139962043613 time
mcts_probs_batch spend 0.006422454003768507 time
winner_batch spend 0.0003047889986191876 time
policy_value spend 0.22789083599491278 time
train_step spend 0.6478572189953411 time
policy_value spend 0.22117778900428675 time
train_step spend 0.6478961350003374 time
policy_value spend 0.22091100800025743 time
train_step spend 0.6470355569981621 time
policy_value spend 0.22123581400228431 time
train_step spend 0.6477977779941284 time
policy_value spend 0.22078459300246323 time
train_step spend 0.6480132659999072 time
policy_value spend 0.22624649899807991 time
kl:0.01478,lr_multiplier:11.391,loss:4.817977428436279,entropy:5.696223735809326,explained_var_old:0.976735950,explained_var_new:0.983128488
output spend 0.00018182599887950346 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0074570290016708896 time
recovery_state_mcts_prob spend 0.27872796099836705 time
state_batch spend 0.001806362000934314 time
mcts_probs_batch spend 0.004495875000429805 time
winner_batch spend 0.00029411599825834855 time
policy_value spend 0.2200817159973667 time
train_step spend 0.6484615640001721 time
policy_value spend 0.22158570300234715 time
train_step spend 0.646861788998649 time
policy_value spend 0.22139289500046289 time
train_step spend 0.6476430690017878 time
policy_value spend 0.229712266002025 time
train_step spend 0.689820007995877 time
policy_value spend 0.23609685000701575 time
train_step spend 0.6898887540010037 time
policy_value spend 0.23569783600396477 time
kl:0.00994,lr_multiplier:11.391,loss:4.797224521636963,entropy:5.68598747253418,explained_var_old:0.983412385,explained_var_new:0.989093959
output spend 0.00017179299902636558 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010408668000309262 time
recovery_state_mcts_prob spend 0.2928985399994417 time
state_batch spend 0.0019321660001878627 time
mcts_probs_batch spend 0.007065416000841651 time
winner_batch spend 0.0003087500008405186 time
policy_value spend 0.23587493599916343 time
train_step spend 0.6901441629961482 time
policy_value spend 0.23910191200411646 time
train_step spend 0.6883255499997176 time
policy_value spend 0.23658519799937494 time
train_step spend 0.6896724609978264 time
policy_value spend 0.236549699002353 time
train_step spend 0.6894836909996229 time
policy_value spend 0.23206153699720744 time
train_step spend 0.6685377169997082 time
policy_value spend 0.22915864900278393 time
kl:0.00503,lr_multiplier:11.391,loss:4.835460662841797,entropy:5.723757743835449,explained_var_old:0.995193422,explained_var_new:0.998774409
output spend 0.00020158600091235712 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00818913200055249 time
recovery_state_mcts_prob spend 0.2610625439992873 time
state_batch spend 0.0021172519991523586 time
mcts_probs_batch spend 0.01587210100115044 time
winner_batch spend 0.0003111749974777922 time
policy_value spend 0.2126060829978087 time
train_step spend 0.6136542940002983 time
policy_value spend 0.21348763100104406 time
train_step spend 0.6134893779963022 time
policy_value spend 0.20985894199839095 time
train_step spend 0.6141519920056453 time
policy_value spend 0.2095523649986717 time
train_step spend 0.6142945339961443 time
policy_value spend 0.21024690799822565 time
train_step spend 0.6148292470024899 time
policy_value spend 0.2105203229948529 time
kl:0.02090,lr_multiplier:11.391,loss:4.779752254486084,entropy:5.688915252685547,explained_var_old:0.984195232,explained_var_new:0.991691291
output spend 0.00014351500431075692 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006870081997476518 time
recovery_state_mcts_prob spend 0.2697697630064795 time
state_batch spend 0.002242188995296601 time
mcts_probs_batch spend 0.006313285004580393 time
winner_batch spend 0.00027726899861590937 time
policy_value spend 0.21875358899706043 time
train_step spend 0.6338754489988787 time
policy_value spend 0.23489121699822135 time
train_step spend 0.6851694829965709 time
policy_value spend 0.2316138710011728 time
train_step spend 0.6321894950015121 time
policy_value spend 0.20989680099592078 time
train_step spend 0.613462483001058 time
policy_value spend 0.21016665200295392 time
train_step spend 0.6138724040065426 time
policy_value spend 0.2099894429993583 time
kl:0.02472,lr_multiplier:11.391,loss:4.847204685211182,entropy:5.733699321746826,explained_var_old:0.992099762,explained_var_new:0.993063033
output spend 0.00017826599651016295 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007726379000814632 time
recovery_state_mcts_prob spend 0.26603614299529 time
state_batch spend 0.0016999130020849407 time
mcts_probs_batch spend 0.015802688998519443 time
winner_batch spend 0.00028192500030854717 time
policy_value spend 0.21279692000098294 time
train_step spend 0.6135552509949775 time
policy_value spend 0.21338474500225857 time
train_step spend 0.6139394290003111 time
policy_value spend 0.20941231399774551 time
train_step spend 0.6149192070006393 time
policy_value spend 0.22856275800586445 time
train_step spend 0.6693075860021054 time
policy_value spend 0.2293208990013227 time
train_step spend 0.6700801770057296 time
policy_value spend 0.2284039509977447 time
kl:0.01463,lr_multiplier:11.391,loss:4.79855489730835,entropy:5.709436893463135,explained_var_old:0.980881155,explained_var_new:0.985960186
output spend 0.00015169300604611635 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007246339002449531 time
recovery_state_mcts_prob spend 0.277280181995593 time
state_batch spend 0.001929251004185062 time
mcts_probs_batch spend 0.006939451996004209 time
winner_batch spend 0.000304229004541412 time
policy_value spend 0.2211995499965269 time
train_step spend 0.6476325179974083 time
policy_value spend 0.2223717650049366 time
train_step spend 0.643981253997481 time
policy_value spend 0.22068512500118231 time
kl:0.08183,lr_multiplier:7.594,loss:4.834007740020752,entropy:5.70589542388916,explained_var_old:0.973168015,explained_var_new:0.981181204
output spend 0.00014977299724705517 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007600846001878381 time
recovery_state_mcts_prob spend 0.2860696759962593 time
state_batch spend 0.0019375750052859075 time
mcts_probs_batch spend 0.007153287995606661 time
winner_batch spend 0.00029786999948555604 time
policy_value spend 0.21999736499856226 time
train_step spend 0.6436266880045878 time
policy_value spend 0.22290235499531263 time
train_step spend 0.6444859939947492 time
policy_value spend 0.2204312710018712 time
kl:0.09957,lr_multiplier:5.062,loss:4.798964500427246,entropy:5.702663421630859,explained_var_old:0.993712723,explained_var_new:0.992247164
output spend 0.00015459900168934837 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0076421259946073405 time
recovery_state_mcts_prob spend 0.2759578270051861 time
state_batch spend 0.0019082599974353798 time
mcts_probs_batch spend 0.007713616003456991 time
winner_batch spend 0.00033348599390592426 time
policy_value spend 0.22066673500376055 time
train_step spend 0.6437231700037955 time
policy_value spend 0.2293001229991205 time
train_step spend 0.6696616439949139 time
policy_value spend 0.22489910700096516 time
train_step spend 0.6446184519954841 time
policy_value spend 0.2204317159994389 time
train_step spend 0.6488710289995652 time
policy_value spend 0.22081977599737002 time
train_step spend 0.6467468019982334 time
policy_value spend 0.22029093800665578 time
kl:0.00971,lr_multiplier:7.594,loss:4.757662296295166,entropy:5.686184883117676,explained_var_old:0.985647202,explained_var_new:0.995488703
output spend 0.0001493379968451336 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00758692800445715 time
recovery_state_mcts_prob spend 0.2771103119957843 time
state_batch spend 0.0018004970042966306 time
mcts_probs_batch spend 0.004610512994986493 time
winner_batch spend 0.0003312780027044937 time
policy_value spend 0.21902783500263467 time
train_step spend 0.6449742289987626 time
policy_value spend 0.2225022610000451 time
train_step spend 0.6448059140020632 time
policy_value spend 0.22093948400288355 time
train_step spend 0.6460660270022345 time
policy_value spend 0.2295655479974812 time
train_step spend 0.6696340419948683 time
policy_value spend 0.22875873300654348 time
train_step spend 0.6680159609968541 time
policy_value spend 0.20973616000264883 time
kl:0.01790,lr_multiplier:7.594,loss:4.761083602905273,entropy:5.702841758728027,explained_var_old:0.997410953,explained_var_new:0.998686373
output spend 0.0001384190036333166 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006965620996197686 time
recovery_state_mcts_prob spend 0.2585587650028174 time
state_batch spend 0.0020464920016820543 time
mcts_probs_batch spend 0.007032166999124456 time
winner_batch spend 0.00027468700136523694 time
policy_value spend 0.21068891499453457 time
train_step spend 0.6134698590030894 time
policy_value spend 0.21036310600175057 time
train_step spend 0.6142706949976855 time
policy_value spend 0.21011782900313847 time
train_step spend 0.6139999380029622 time
policy_value spend 0.21014708800066728 time
train_step spend 0.6147044719982659 time
policy_value spend 0.2097959599996102 time
train_step spend 0.6134339249983896 time
policy_value spend 0.21051175799948396 time
kl:0.00991,lr_multiplier:11.391,loss:4.806175708770752,entropy:5.711582183837891,explained_var_old:0.994577348,explained_var_new:0.995681405
output spend 0.00014144900342216715 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008611312994617037 time
recovery_state_mcts_prob spend 0.26453944600507384 time
state_batch spend 0.0018657999971765094 time
mcts_probs_batch spend 0.007744506998278666 time
winner_batch spend 0.00031220300297718495 time
policy_value spend 0.21001475900266087 time
train_step spend 0.613600286997098 time
policy_value spend 0.21110326400230406 time
train_step spend 0.6490865250016213 time
policy_value spend 0.22147762899840018 time
train_step spend 0.6136219280015212 time
policy_value spend 0.20979396699840436 time
train_step spend 0.6135323679991416 time
policy_value spend 0.2096527760004392 time
train_step spend 0.6126802599974326 time
policy_value spend 0.20985524600109784 time
kl:0.01066,lr_multiplier:11.391,loss:4.792831897735596,entropy:5.74388313293457,explained_var_old:0.995014012,explained_var_new:0.995893896
output spend 0.0001524600011180155 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006829910998931155 time
recovery_state_mcts_prob spend 0.2627574200014351 time
state_batch spend 0.0016912430000957102 time
mcts_probs_batch spend 0.006576163999852724 time
winner_batch spend 0.0002758720002020709 time
policy_value spend 0.20994779500324512 time
train_step spend 0.6283648070020718 time
policy_value spend 0.23048102599568665 time
train_step spend 0.6694197629985865 time
policy_value spend 0.22920883200276876 time
train_step spend 0.6702707129952614 time
policy_value spend 0.22911586800182704 time
train_step spend 0.668594545997621 time
policy_value spend 0.22884554500342347 time
train_step spend 0.6692163629995775 time
policy_value spend 0.22914061800111085 time
kl:0.01590,lr_multiplier:11.391,loss:4.758859634399414,entropy:5.671285629272461,explained_var_old:0.983095229,explained_var_new:0.989731491
output spend 0.00016101799701573327 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008837997003865894 time
recovery_state_mcts_prob spend 0.2882709959958447 time
state_batch spend 0.001912051004183013 time
mcts_probs_batch spend 0.005914599001698662 time
winner_batch spend 0.0002967569962493144 time
policy_value spend 0.23759554800199112 time
train_step spend 0.6896358930025599 time
policy_value spend 0.24242149199562846 time
train_step spend 0.68602493799699 time
policy_value spend 0.23087575800309423 time
train_step spend 0.6702442159948987 time
policy_value spend 0.22885962200234644 time
train_step spend 0.6687743229995249 time
policy_value spend 0.22910263200174086 time
train_step spend 0.6685760550026316 time
policy_value spend 0.22845838899957016 time
kl:0.00814,lr_multiplier:11.391,loss:4.736399173736572,entropy:5.672670364379883,explained_var_old:0.991321266,explained_var_new:0.991802752
output spend 0.00019752799562411383 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008195747002901044 time
recovery_state_mcts_prob spend 0.28897376299573807 time
state_batch spend 0.0018688429991016164 time
mcts_probs_batch spend 0.0065411500036134385 time
winner_batch spend 0.00035733499680645764 time
policy_value spend 0.22778459500113968 time
train_step spend 0.6686067479968187 time
policy_value spend 0.23172327499923995 time
train_step spend 0.6649193599951104 time
policy_value spend 0.22684105799999088 time
train_step spend 0.6636923480036785 time
policy_value spend 0.22671182899648556 time
train_step spend 0.6641727919995901 time
policy_value spend 0.22694466900429688 time
train_step spend 0.6638094009977067 time
policy_value spend 0.22803562299668556 time
kl:0.02149,lr_multiplier:11.391,loss:4.764781475067139,entropy:5.6873884201049805,explained_var_old:0.988347590,explained_var_new:0.991250038
output spend 0.0001580520038260147 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007638525006768759 time
recovery_state_mcts_prob spend 0.2856478019966744 time
state_batch spend 0.001898520000395365 time
mcts_probs_batch spend 0.006930864001333248 time
winner_batch spend 0.00029563700081780553 time
policy_value spend 0.22792192499764496 time
train_step spend 0.6638535279998905 time
policy_value spend 0.22821595199638978 time
train_step spend 0.6627694870039704 time
policy_value spend 0.22605825500068022 time
train_step spend 0.6628689619974466 time
policy_value spend 0.22883929499948863 time
train_step spend 0.6627877020000597 time
policy_value spend 0.22019288599403808 time
train_step spend 0.6135749309978564 time
policy_value spend 0.20971556800213875 time
kl:0.02137,lr_multiplier:11.391,loss:4.813748836517334,entropy:5.746203422546387,explained_var_old:0.988431215,explained_var_new:0.992188513
output spend 0.0001379770037601702 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008994514995720237 time
recovery_state_mcts_prob spend 0.28150097400066443 time
state_batch spend 0.0017817039988585748 time
mcts_probs_batch spend 0.006616306003706995 time
winner_batch spend 0.0002790039943647571 time
policy_value spend 0.211194671006524 time
train_step spend 0.61346196699742 time
policy_value spend 0.20938384300097823 time
train_step spend 0.6133735460025491 time
policy_value spend 0.20951004599919543 time
train_step spend 0.613448377000168 time
policy_value spend 0.20977462700102478 time
train_step spend 0.613925402998575 time
policy_value spend 0.20961591599916574 time
train_step spend 0.613976527005434 time
policy_value spend 0.2096838409997872 time
kl:0.03594,lr_multiplier:11.391,loss:4.745471477508545,entropy:5.677184581756592,explained_var_old:0.986486256,explained_var_new:0.988280535
output spend 0.00014273499982664362 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008754119000514038 time
recovery_state_mcts_prob spend 0.2689458620006917 time
state_batch spend 0.001736362995870877 time
mcts_probs_batch spend 0.0066756700034602545 time
winner_batch spend 0.00027390699688112363 time
policy_value spend 0.21050517899857368 time
train_step spend 0.6152128340036143 time
policy_value spend 0.20954853299917886 time
train_step spend 0.6139508619962726 time
policy_value spend 0.21035812300397083 time
train_step spend 0.6130481459986186 time
policy_value spend 0.2097267040007864 time
train_step spend 0.6128717020037584 time
policy_value spend 0.21105716600141022 time
train_step spend 0.6168637750015478 time
policy_value spend 0.20905862800282193 time
kl:0.01897,lr_multiplier:11.391,loss:4.786881923675537,entropy:5.706073760986328,explained_var_old:0.998810053,explained_var_new:0.999192417
output spend 0.0002244889983558096 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0073934769970946945 time
recovery_state_mcts_prob spend 0.25687667700549355 time
state_batch spend 0.0019549659991753288 time
mcts_probs_batch spend 0.006532218998472672 time
winner_batch spend 0.0002955070012831129 time
policy_value spend 0.21034009900176898 time
train_step spend 0.6144001339998795 time
policy_value spend 0.21014561699848855 time
train_step spend 0.6699724739955855 time
policy_value spend 0.22947846600436606 time
train_step spend 0.670233852993988 time
policy_value spend 0.2289471530020819 time
train_step spend 0.6702651029991102 time
policy_value spend 0.22978058900480391 time
train_step spend 0.6676679450029042 time
policy_value spend 0.2277894689977984 time
kl:0.02419,lr_multiplier:11.391,loss:4.821835994720459,entropy:5.69108772277832,explained_var_old:0.987296760,explained_var_new:0.988509834
output spend 0.00015926500054774806 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0091373030008981 time
recovery_state_mcts_prob spend 0.29331176599953324 time
state_batch spend 0.002156964997993782 time
mcts_probs_batch spend 0.0067178020035498776 time
winner_batch spend 0.00030502499430440366 time
policy_value spend 0.22881021899956977 time
train_step spend 0.6671723400068004 time
policy_value spend 0.2274695009982679 time
train_step spend 0.6708819699997548 time
policy_value spend 0.22831227400456555 time
train_step spend 0.6669962580053834 time
policy_value spend 0.22934297900064848 time
train_step spend 0.6680210740014445 time
policy_value spend 0.22821895399829373 time
train_step spend 0.6674765569987358 time
policy_value spend 0.22779250299936393 time
kl:0.02572,lr_multiplier:11.391,loss:4.815377712249756,entropy:5.747118949890137,explained_var_old:0.984989643,explained_var_new:0.989939272
output spend 0.00015505299961660057 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009647375001804903 time
recovery_state_mcts_prob spend 0.2893587349972222 time
state_batch spend 0.0018926320044556633 time
mcts_probs_batch spend 0.006562898997799493 time
winner_batch spend 0.00031455700082005933 time
policy_value spend 0.22853852000116603 time
train_step spend 0.6670751759957056 time
policy_value spend 0.2297749420031323 time
train_step spend 0.6701136249976116 time
policy_value spend 0.22895057799905771 time
train_step spend 0.6711096200015163 time
policy_value spend 0.22922213099809596 time
train_step spend 0.6708447970013367 time
policy_value spend 0.22893737199774478 time
train_step spend 0.6724677480015089 time
policy_value spend 0.23139672899560537 time
kl:0.03140,lr_multiplier:11.391,loss:4.8083319664001465,entropy:5.735182285308838,explained_var_old:0.987074673,explained_var_new:0.989004374
output spend 0.0001674759987508878 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009109601996897254 time
recovery_state_mcts_prob spend 0.2949075030046515 time
state_batch spend 0.0022181879976415075 time
mcts_probs_batch spend 0.017258831998333335 time
winner_batch spend 0.0003241240046918392 time
policy_value spend 0.23312748099851888 time
train_step spend 0.6703648159964359 time
policy_value spend 0.2331124800039106 time
train_step spend 0.6707241120020626 time
policy_value spend 0.22893569900043076 time
train_step spend 0.6702229479997186 time
policy_value spend 0.2292698380042566 time
train_step spend 0.6244902699982049 time
policy_value spend 0.2093791160004912 time
train_step spend 0.6140376469993498 time
policy_value spend 0.20974444199964637 time
kl:0.00685,lr_multiplier:11.391,loss:4.756608963012695,entropy:5.6773176193237305,explained_var_old:0.991090596,explained_var_new:0.995604813
output spend 0.0002614630066091195 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013613243005238473 time
recovery_state_mcts_prob spend 0.30262087099981727 time
state_batch spend 0.0018509219953557476 time
mcts_probs_batch spend 0.012192223999591079 time
winner_batch spend 0.00028119900525780395 time
policy_value spend 0.22620915599691216 time
train_step spend 0.6275828510042629 time
policy_value spend 0.21459740799764404 time
train_step spend 0.6136681159987347 time
policy_value spend 0.20981165199918905 time
train_step spend 0.6143875749985455 time
policy_value spend 0.2097730980021879 time
train_step spend 0.6136988400030532 time
policy_value spend 0.21000689300126396 time
train_step spend 0.6141073149992735 time
policy_value spend 0.21001541000441648 time
kl:0.00689,lr_multiplier:11.391,loss:4.7302680015563965,entropy:5.647350311279297,explained_var_old:0.988333285,explained_var_new:0.993614137
output spend 0.00013896900054533035 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007614071000716649 time
recovery_state_mcts_prob spend 0.2621781670022756 time
state_batch spend 0.001761948995408602 time
mcts_probs_batch spend 0.006364430002577137 time
winner_batch spend 0.00029063099646009505 time
policy_value spend 0.2096799010032555 time
train_step spend 0.6144005639944226 time
policy_value spend 0.20957924899994396 time
train_step spend 0.6135476919953362 time
policy_value spend 0.2095081880033831 time
train_step spend 0.614129650995892 time
policy_value spend 0.20963858200411778 time
train_step spend 0.6134799489955185 time
policy_value spend 0.20996949700202094 time
train_step spend 0.6130077049965621 time
policy_value spend 0.21002174699970055 time
kl:0.00940,lr_multiplier:11.391,loss:4.842339038848877,entropy:5.736927032470703,explained_var_old:0.992977381,explained_var_new:0.998730600
output spend 0.00013933599984738976 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01093435400252929 time
recovery_state_mcts_prob spend 0.2621763610004564 time
state_batch spend 0.001870850996056106 time
mcts_probs_batch spend 0.004465836005692836 time
winner_batch spend 0.0003057469948544167 time
policy_value spend 0.20928072400420206 time
train_step spend 0.6131387839996023 time
policy_value spend 0.20908547299768543 time
train_step spend 0.630647368998325 time
policy_value spend 0.22873955700197257 time
train_step spend 0.6696159400016768 time
policy_value spend 0.23301067499414785 time
train_step spend 0.669158675998915 time
policy_value spend 0.22894155899848556 time
train_step spend 0.6701661300030537 time
policy_value spend 0.2289775399985956 time
kl:0.01060,lr_multiplier:11.391,loss:4.7756757736206055,entropy:5.723276615142822,explained_var_old:0.994538009,explained_var_new:0.995427847
output spend 0.00015225999959511682 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0076605009962804615 time
recovery_state_mcts_prob spend 0.28302009100298164 time
state_batch spend 0.002175838002585806 time
mcts_probs_batch spend 0.006169540996779688 time
winner_batch spend 0.0003386750031495467 time
policy_value spend 0.22751746599533362 time
train_step spend 0.6715407910014619 time
policy_value spend 0.22953012699872488 time
train_step spend 0.669704558000376 time
policy_value spend 0.22902590299781878 time
train_step spend 0.6709697729966138 time
policy_value spend 0.22934429300221382 time
train_step spend 0.669877981999889 time
policy_value spend 0.229230399003427 time
train_step spend 0.6708506389986724 time
policy_value spend 0.22899398000299698 time
kl:0.01838,lr_multiplier:11.391,loss:4.766411781311035,entropy:5.707800388336182,explained_var_old:0.984972000,explained_var_new:0.987308025
output spend 0.0001513679962954484 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007518115999118891 time
recovery_state_mcts_prob spend 0.27855874200031394 time
state_batch spend 0.002225101001386065 time
mcts_probs_batch spend 0.005299853000906296 time
winner_batch spend 0.00032051000016508624 time
policy_value spend 0.22828248699806863 time
train_step spend 0.6719691210018937 time
policy_value spend 0.22975166000105673 time
train_step spend 0.6727796129998751 time
policy_value spend 0.23011813499761047 time
train_step spend 0.6712403100027586 time
policy_value spend 0.2297973370004911 time
train_step spend 0.6715768680005567 time
policy_value spend 0.22970660700229928 time
train_step spend 0.6716758869952173 time
policy_value spend 0.22957013100676704 time
kl:0.01560,lr_multiplier:11.391,loss:4.773784160614014,entropy:5.712104797363281,explained_var_old:0.987836599,explained_var_new:0.991157949
output spend 0.00015875599638093263 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007900593998783734 time
recovery_state_mcts_prob spend 0.2944624579977244 time
state_batch spend 0.0018280919975950383 time
mcts_probs_batch spend 0.00702473600540543 time
winner_batch spend 0.000330094997480046 time
policy_value spend 0.22996053499809932 time
train_step spend 0.6725655539994477 time
policy_value spend 0.2295178330023191 time
train_step spend 0.6712082220037701 time
policy_value spend 0.2298771610003314 time
train_step spend 0.6660554129994125 time
policy_value spend 0.22480641600122908 time
train_step spend 0.6581472850011778 time
policy_value spend 0.22715464599605184 time
train_step spend 0.6580131879964028 time
policy_value spend 0.22505929700128036 time
kl:0.01010,lr_multiplier:11.391,loss:4.775018215179443,entropy:5.689241409301758,explained_var_old:0.989127934,explained_var_new:0.992453516
output spend 0.0001675990060903132 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070852260032552294 time
recovery_state_mcts_prob spend 0.28443317100027343 time
state_batch spend 0.0018888599952333607 time
mcts_probs_batch spend 0.006875270999444183 time
winner_batch spend 0.0003180679996148683 time
policy_value spend 0.22606685099890456 time
train_step spend 0.6606407439976465 time
policy_value spend 0.22516660299879732 time
train_step spend 0.6591786080025486 time
policy_value spend 0.22658001800300553 time
train_step spend 0.6574965609979699 time
policy_value spend 0.22536213800049154 time
train_step spend 0.658227309002541 time
policy_value spend 0.22536681599740405 time
train_step spend 0.6596728490039823 time
policy_value spend 0.22468863899848657 time
kl:0.01091,lr_multiplier:11.391,loss:4.673147201538086,entropy:5.644924163818359,explained_var_old:0.998087227,explained_var_new:0.999005556
output spend 0.00015169100515777245 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007813619005901273 time
recovery_state_mcts_prob spend 0.27197076399897924 time
state_batch spend 0.0018320979943382554 time
mcts_probs_batch spend 0.004673674004152417 time
winner_batch spend 0.00032846099929884076 time
policy_value spend 0.22185124400130007 time
train_step spend 0.6512188410051749 time
policy_value spend 0.22235802700015483 time
train_step spend 0.651460027002031 time
policy_value spend 0.22239405599975726 time
train_step spend 0.6517495789958048 time
policy_value spend 0.22265236100065522 time
train_step spend 0.6502456779999193 time
policy_value spend 0.2223792160002631 time
train_step spend 0.6510367449955083 time
policy_value spend 0.22282672800065484 time
kl:0.01568,lr_multiplier:11.391,loss:4.714026927947998,entropy:5.658398628234863,explained_var_old:0.994759500,explained_var_new:0.995570004
output spend 0.0002501920025679283 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007550001006165985 time
recovery_state_mcts_prob spend 0.27455986899440177 time
state_batch spend 0.001850131004175637 time
mcts_probs_batch spend 0.004997069998353254 time
winner_batch spend 0.00030700000206707045 time
policy_value spend 0.22178875399549725 time
train_step spend 0.653340595003101 time
policy_value spend 0.22240198499639519 time
train_step spend 0.6503720280015841 time
policy_value spend 0.22281022099923575 time
train_step spend 0.6695787729986478 time
policy_value spend 0.24020094399747904 time
train_step spend 0.6807633569987956 time
policy_value spend 0.22451326900045387 time
train_step spend 0.6564565480002784 time
policy_value spend 0.22375292400101898 time
kl:0.02390,lr_multiplier:11.391,loss:4.739712238311768,entropy:5.655539512634277,explained_var_old:0.989796221,explained_var_new:0.992423177
output spend 0.00016001499898266047 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007473391997336876 time
recovery_state_mcts_prob spend 0.27985713700036285 time
state_batch spend 0.0019101750003756024 time
mcts_probs_batch spend 0.012267677004274447 time
winner_batch spend 0.0002651690010679886 time
policy_value spend 0.22326208899903577 time
train_step spend 0.6545198169987998 time
policy_value spend 0.22245196700532688 time
train_step spend 0.6530803120040218 time
policy_value spend 0.22281279899470974 time
train_step spend 0.6539283120000619 time
policy_value spend 0.22355382599926088 time
train_step spend 0.6536762629984878 time
policy_value spend 0.22359270499873674 time
train_step spend 0.6521704059996409 time
policy_value spend 0.2220080270053586 time
kl:0.01499,lr_multiplier:11.391,loss:4.724371910095215,entropy:5.611029624938965,explained_var_old:0.987227559,explained_var_new:0.991221964
output spend 0.00014739600010216236 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007691541002714075 time
recovery_state_mcts_prob spend 0.2786759559967322 time
state_batch spend 0.001936155000294093 time
mcts_probs_batch spend 0.004996082003344782 time
winner_batch spend 0.00030356799834407866 time
policy_value spend 0.22113197400176432 time
train_step spend 0.6504352850024588 time
policy_value spend 0.22233714700269047 time
train_step spend 0.6495890129954205 time
policy_value spend 0.22205787699931534 time
train_step spend 0.6491112229996361 time
policy_value spend 0.22184971000388032 time
train_step spend 0.650393867996172 time
policy_value spend 0.222881445006351 time
train_step spend 0.6497070740006166 time
policy_value spend 0.22215823199803708 time
kl:0.01433,lr_multiplier:11.391,loss:4.758265018463135,entropy:5.639651298522949,explained_var_old:0.994156361,explained_var_new:0.999167442
output spend 0.000160905001393985 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00952836299984483 time
recovery_state_mcts_prob spend 0.28235803799907444 time
state_batch spend 0.002035935001913458 time
mcts_probs_batch spend 0.004790448998392094 time
winner_batch spend 0.0002980470017064363 time
policy_value spend 0.22147359099471942 time
train_step spend 0.6493255560053512 time
policy_value spend 0.2214701119955862 time
train_step spend 0.6262543220000225 time
policy_value spend 0.20948433200101135 time
train_step spend 0.6145188369991956 time
policy_value spend 0.20978832700347994 time
train_step spend 0.6139970699950936 time
policy_value spend 0.20958466700540157 time
train_step spend 0.6135045330011053 time
policy_value spend 0.20937938799761469 time
kl:0.01180,lr_multiplier:11.391,loss:4.720907688140869,entropy:5.623996734619141,explained_var_old:0.994973540,explained_var_new:0.995379448
output spend 0.00020903199765598401 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006941733998246491 time
recovery_state_mcts_prob spend 0.27199008900061017 time
state_batch spend 0.0018530070010456257 time
mcts_probs_batch spend 0.004772565000166651 time
winner_batch spend 0.00029601199639728293 time
policy_value spend 0.2098198189996765 time
train_step spend 0.612950668000849 time
policy_value spend 0.20968665299733402 time
train_step spend 0.6132271170063177 time
policy_value spend 0.21001642199553316 time
train_step spend 0.613422032998642 time
policy_value spend 0.2105780150013743 time
train_step spend 0.6131806029952713 time
policy_value spend 0.20956138399924384 time
train_step spend 0.6135865379983443 time
policy_value spend 0.21008183900266886 time
kl:0.01407,lr_multiplier:11.391,loss:4.7042131423950195,entropy:5.683967590332031,explained_var_old:0.995713770,explained_var_new:0.999199390
output spend 0.000187368001206778 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008860560003085993 time
recovery_state_mcts_prob spend 0.26617741299560294 time
state_batch spend 0.0017166090037790127 time
mcts_probs_batch spend 0.005244097999820951 time
winner_batch spend 0.00027575300191529095 time
policy_value spend 0.2101119840008323 time
train_step spend 0.6147381030023098 time
policy_value spend 0.20956773899524705 time
train_step spend 0.6135107059963048 time
policy_value spend 0.20981151400337694 time
train_step spend 0.6139696970058139 time
policy_value spend 0.20930571899953065 time
train_step spend 0.6139841789990896 time
policy_value spend 0.20994486100244103 time
train_step spend 0.6133212829954573 time
policy_value spend 0.20910809800261632 time
kl:0.01084,lr_multiplier:11.391,loss:4.6582231521606445,entropy:5.552949905395508,explained_var_old:0.993282259,explained_var_new:0.995661795
output spend 0.00014229400403564796 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007502750006096903 time
recovery_state_mcts_prob spend 0.2806187219975982 time
state_batch spend 0.0018662229995243251 time
mcts_probs_batch spend 0.007261769998876844 time
winner_batch spend 0.00032771100086392835 time
policy_value spend 0.2300218689997564 time
train_step spend 0.6703316439961782 time
policy_value spend 0.22780149699974572 time
train_step spend 0.6680479150018073 time
policy_value spend 0.22577175999322208 time
train_step spend 0.6588059979985701 time
policy_value spend 0.22504778599977726 time
train_step spend 0.6587445699988166 time
policy_value spend 0.22568967400002293 time
train_step spend 0.6581374739980674 time
policy_value spend 0.22521686099935323 time
kl:0.00984,lr_multiplier:11.391,loss:4.739350318908691,entropy:5.683051109313965,explained_var_old:0.995424926,explained_var_new:0.997356176
output spend 0.00016071900608949363 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007626154001627583 time
recovery_state_mcts_prob spend 0.29062623900244944 time
state_batch spend 0.001957082000444643 time
mcts_probs_batch spend 0.0068570590010494925 time
winner_batch spend 0.00030684399825986475 time
policy_value spend 0.22498029500275152 time
train_step spend 0.6571088749988121 time
policy_value spend 0.22908311399805825 time
train_step spend 0.6588106909985072 time
policy_value spend 0.2253591310000047 time
train_step spend 0.6588138329971116 time
policy_value spend 0.22495132600306533 time
train_step spend 0.6589748960032011 time
policy_value spend 0.22539766599948052 time
train_step spend 0.6640276519974577 time
policy_value spend 0.22884774500562344 time
kl:0.02120,lr_multiplier:11.391,loss:4.699710369110107,entropy:5.606091499328613,explained_var_old:0.983800709,explained_var_new:0.991725802
output spend 0.0001564840058563277 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007974177999130916 time
recovery_state_mcts_prob spend 0.2931177470018156 time
state_batch spend 0.0019553709935280494 time
mcts_probs_batch spend 0.006922174005012494 time
winner_batch spend 0.0002972509973915294 time
policy_value spend 0.2303245049988618 time
train_step spend 0.6707897949963808 time
policy_value spend 0.22892485999909695 time
train_step spend 0.6698028430037084 time
policy_value spend 0.22870101599983172 time
train_step spend 0.6687814719989547 time
policy_value spend 0.22940165500040166 time
train_step spend 0.6696927409939235 time
policy_value spend 0.22897325400117552 time
train_step spend 0.6688581880007405 time
policy_value spend 0.22899393899569986 time
kl:0.04318,lr_multiplier:7.594,loss:4.690730571746826,entropy:5.644435882568359,explained_var_old:0.985270500,explained_var_new:0.986399829
output spend 0.00016499899356858805 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009147537006356288 time
recovery_state_mcts_prob spend 0.29687644099612953 time
state_batch spend 0.0018217760007246397 time
mcts_probs_batch spend 0.006055072997696698 time
winner_batch spend 0.00030060700373724103 time
policy_value spend 0.23130084599688416 time
train_step spend 0.7034358349992544 time
policy_value spend 0.23491041300439974 time
train_step spend 0.6470544299954781 time
policy_value spend 0.22038242700364208 time
train_step spend 0.6432326860012836 time
policy_value spend 0.21914273199945455 time
train_step spend 0.6431482439948013 time
policy_value spend 0.22072984900296433 time
train_step spend 0.6422185340052238 time
policy_value spend 0.22064622299512848 time
kl:0.03851,lr_multiplier:7.594,loss:4.7268967628479,entropy:5.635417461395264,explained_var_old:0.992651105,explained_var_new:0.999151051
output spend 0.00016026099910959601 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00764442599756876 time
recovery_state_mcts_prob spend 0.28397434599901317 time
state_batch spend 0.0017868150025606155 time
mcts_probs_batch spend 0.00708748800389003 time
winner_batch spend 0.00030891499773133546 time
policy_value spend 0.22104573199612787 time
train_step spend 0.6417063759945449 time
policy_value spend 0.2207613870050409 time
train_step spend 0.6421894209997845 time
policy_value spend 0.22025849900091998 time
train_step spend 0.6430052579962648 time
policy_value spend 0.22297391200118 time
train_step spend 0.6416716569947312 time
policy_value spend 0.2169982190025621 time
train_step spend 0.6351943429981475 time
policy_value spend 0.21645135300059337 time
kl:0.01135,lr_multiplier:7.594,loss:4.744893550872803,entropy:5.624743938446045,explained_var_old:0.986960173,explained_var_new:0.987996340
output spend 0.0001804470011848025 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010534649998589884 time
recovery_state_mcts_prob spend 0.27277722600410925 time
state_batch spend 0.00176212999940617 time
mcts_probs_batch spend 0.00688287999946624 time
winner_batch spend 0.0003291750035714358 time
policy_value spend 0.21823583299556049 time
train_step spend 0.6356473970008665 time
policy_value spend 0.21648121099860873 time
train_step spend 0.6354516119972686 time
policy_value spend 0.2169975990036619 time
train_step spend 0.6345163400037563 time
policy_value spend 0.21672039500117535 time
train_step spend 0.6418447309988551 time
policy_value spend 0.21741630799806444 time
train_step spend 0.6349899009946967 time
policy_value spend 0.21644390200526686 time
kl:0.01569,lr_multiplier:7.594,loss:4.693554401397705,entropy:5.648737907409668,explained_var_old:0.995610774,explained_var_new:0.995940268
output spend 0.000145771999086719 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007627853003214113 time
recovery_state_mcts_prob spend 0.28979561499727424 time
state_batch spend 0.0024426480013062246 time
mcts_probs_batch spend 0.024471763004839886 time
winner_batch spend 0.0003141659981338307 time
policy_value spend 0.2327784539957065 time
train_step spend 0.6606338170022354 time
policy_value spend 0.22227979399758624 time
train_step spend 0.6501802460043109 time
policy_value spend 0.22253493899916066 time
train_step spend 0.650058025996259 time
policy_value spend 0.22195740600000136 time
train_step spend 0.6504942899991875 time
policy_value spend 0.22259615499933716 time
train_step spend 0.6494506800008821 time
policy_value spend 0.22300642399932258 time
kl:0.03089,lr_multiplier:7.594,loss:4.695167064666748,entropy:5.657914161682129,explained_var_old:0.994187117,explained_var_new:0.995529592
output spend 0.0001605829966138117 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007392298997729085 time
recovery_state_mcts_prob spend 0.2751647969998885 time
state_batch spend 0.001846126004238613 time
mcts_probs_batch spend 0.005988653996610083 time
winner_batch spend 0.00031049300014274195 time
policy_value spend 0.22202100700087612 time
train_step spend 0.6507405520023894 time
policy_value spend 0.22179986499395454 time
train_step spend 0.6496462209979654 time
policy_value spend 0.22230567700171378 time
train_step spend 0.6500867180002388 time
policy_value spend 0.22195034500327893 time
train_step spend 0.6448760630009929 time
policy_value spend 0.21925366399955237 time
train_step spend 0.6420718709996436 time
policy_value spend 0.21944221000012476 time
kl:0.00752,lr_multiplier:11.391,loss:4.719509124755859,entropy:5.640754699707031,explained_var_old:0.991056204,explained_var_new:0.991540253
output spend 0.00015494300168938935 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0073458129991195165 time
recovery_state_mcts_prob spend 0.276798056998814 time
state_batch spend 0.0018360140020377003 time
mcts_probs_batch spend 0.008068195995292626 time
winner_batch spend 0.0003064560005441308 time
policy_value spend 0.22257194700068794 time
train_step spend 0.6418706039985409 time
policy_value spend 0.2229220300068846 time
train_step spend 0.6417002409943962 time
policy_value spend 0.22044111400464317 time
train_step spend 0.6456636609946145 time
policy_value spend 0.21905288500420284 time
train_step spend 0.6436483409997891 time
policy_value spend 0.21988112899998669 time
train_step spend 0.6531449340036488 time
policy_value spend 0.22917362699809019 time
kl:0.02608,lr_multiplier:11.391,loss:4.711608409881592,entropy:5.623424053192139,explained_var_old:0.989046931,explained_var_new:0.991184592
output spend 0.0001526849955553189 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00991536199580878 time
recovery_state_mcts_prob spend 0.284950203000335 time
state_batch spend 0.002034306002315134 time
mcts_probs_batch spend 0.007456202998582739 time
winner_batch spend 0.0002993790039909072 time
policy_value spend 0.22666449599637417 time
train_step spend 0.6428871750031249 time
policy_value spend 0.21932109900080832 time
train_step spend 0.6412257109986967 time
policy_value spend 0.22032430399849545 time
train_step spend 0.6418387800003984 time
policy_value spend 0.21937190699827624 time
train_step spend 0.6424052649963414 time
policy_value spend 0.21955751300265547 time
train_step spend 0.6414278540032683 time
policy_value spend 0.2195161579948035 time
kl:0.02623,lr_multiplier:11.391,loss:4.70833158493042,entropy:5.686056613922119,explained_var_old:0.994710922,explained_var_new:0.995623887
output spend 0.00015768600133014843 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009493546996964142 time
recovery_state_mcts_prob spend 0.27438007399905473 time
state_batch spend 0.0018083719987771474 time
mcts_probs_batch spend 0.006151768000563607 time
winner_batch spend 0.0002845030030584894 time
policy_value spend 0.2196569180014194 time
train_step spend 0.6427627079974627 time
policy_value spend 0.21837167400371982 time
train_step spend 0.6420156839958508 time
policy_value spend 0.2200407210038975 time
train_step spend 0.6414761490013916 time
policy_value spend 0.21793367099598981 time
train_step spend 0.6238560940037132 time
policy_value spend 0.21361941099894466 time
train_step spend 0.6239572840058827 time
policy_value spend 0.21339457199792378 time
kl:0.01773,lr_multiplier:11.391,loss:4.677884101867676,entropy:5.608086109161377,explained_var_old:0.995846391,explained_var_new:0.997005522
output spend 0.00014444399857893586 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007515608005633112 time
recovery_state_mcts_prob spend 0.2675038749948726 time
state_batch spend 0.0020367309989524074 time
mcts_probs_batch spend 0.006452341003750917 time
winner_batch spend 0.0002753610024228692 time
policy_value spend 0.21287500899779843 time
train_step spend 0.6224884029943496 time
policy_value spend 0.21403880700381706 time
train_step spend 0.6240756050028722 time
policy_value spend 0.21293198200146435 time
train_step spend 0.6235186619960587 time
policy_value spend 0.2131856640044134 time
train_step spend 0.6585730380029418 time
policy_value spend 0.22941739200177835 time
train_step spend 0.6881061530002626 time
policy_value spend 0.2426095089977025 time
kl:0.04345,lr_multiplier:7.594,loss:4.7309889793396,entropy:5.668456077575684,explained_var_old:0.998138309,explained_var_new:0.999074996
output spend 0.00016784299805294722 time
已保存最新模型
current self-play batch: 500
load data begin
已加载数据
step i 372: 
random.sample spend 0.008721334001165815 time
recovery_state_mcts_prob spend 0.28278251200390514 time
state_batch spend 0.0018687659976421855 time
mcts_probs_batch spend 0.006416187003196683 time
winner_batch spend 0.0002945849992102012 time
policy_value spend 0.22420101700117812 time
train_step spend 0.682661579005071 time
policy_value spend 0.22491786199680064 time
train_step spend 0.6501150089970906 time
policy_value spend 0.2212651680019917 time
train_step spend 0.6465676570005598 time
policy_value spend 0.22128128899930744 time
train_step spend 0.6480828730054782 time
policy_value spend 0.22075257200049236 time
train_step spend 0.6477486470030271 time
policy_value spend 0.22125064399733674 time
kl:0.04975,lr_multiplier:5.062,loss:4.704769611358643,entropy:5.616774082183838,explained_var_old:0.988717139,explained_var_new:0.993118584
output spend 0.00015801800327608362 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0075344469951232895 time
recovery_state_mcts_prob spend 0.2891216530042584 time
state_batch spend 0.0019079739940934815 time
mcts_probs_batch spend 0.006576633000804577 time
winner_batch spend 0.00033319200156256557 time
policy_value spend 0.2214175039989641 time
train_step spend 0.6462609290028922 time
policy_value spend 0.22145142299996223 time
train_step spend 0.6464236879983218 time
policy_value spend 0.22098935300164158 time
train_step spend 0.6503983659931691 time
policy_value spend 0.2256097910067183 time
train_step spend 0.6591563729962218 time
policy_value spend 0.2236558650038205 time
train_step spend 0.6560095980021288 time
policy_value spend 0.22372129099676386 time
kl:0.01083,lr_multiplier:5.062,loss:4.712959289550781,entropy:5.640249252319336,explained_var_old:0.990175784,explained_var_new:0.994755208
output spend 0.00015171899576671422 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007564726998680271 time
recovery_state_mcts_prob spend 0.2895926299970597 time
state_batch spend 0.0022676740045426413 time
mcts_probs_batch spend 0.006763794997823425 time
winner_batch spend 0.0003002500016009435 time
policy_value spend 0.22364590899815084 time
train_step spend 0.6554883830031031 time
policy_value spend 0.2248110189975705 time
train_step spend 0.6565387540031224 time
policy_value spend 0.22431598699768074 time
train_step spend 0.6572227299984661 time
policy_value spend 0.22475261500221677 time
train_step spend 0.6560954070009757 time
policy_value spend 0.2242611429974204 time
train_step spend 0.6553793729981408 time
policy_value spend 0.2239041159991757 time
kl:0.00966,lr_multiplier:7.594,loss:4.7101311683654785,entropy:5.666393756866455,explained_var_old:0.997929931,explained_var_new:0.999396861
output spend 0.0001571629982208833 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007175468002969865 time
recovery_state_mcts_prob spend 0.2769082160011749 time
state_batch spend 0.0020117879976169206 time
mcts_probs_batch spend 0.016292137996060774 time
winner_batch spend 0.0003062270043301396 time
policy_value spend 0.22089857499668142 time
train_step spend 0.6418912959998124 time
policy_value spend 0.21738368100341177 time
train_step spend 0.6355232710047858 time
policy_value spend 0.21787871400010772 time
train_step spend 0.6359041160030756 time
policy_value spend 0.21734273699985351 time
train_step spend 0.6365572530048667 time
policy_value spend 0.21812467099516653 time
train_step spend 0.6350944689984317 time
policy_value spend 0.21759155800100416 time
kl:0.00740,lr_multiplier:11.391,loss:4.668697357177734,entropy:5.615462779998779,explained_var_old:0.988298476,explained_var_new:0.991724789
output spend 0.00014815400209045038 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007083851996867452 time
recovery_state_mcts_prob spend 0.26876895999885164 time
state_batch spend 0.0018701220033108257 time
mcts_probs_batch spend 0.006003538001095876 time
winner_batch spend 0.0003088809971814044 time
policy_value spend 0.2185553939998499 time
train_step spend 0.6519567819996155 time
policy_value spend 0.2292521700001089 time
train_step spend 0.6691549310053233 time
policy_value spend 0.22871576699981233 time
train_step spend 0.6425858980001067 time
policy_value spend 0.2194628439974622 time
train_step spend 0.6426759759997367 time
policy_value spend 0.21977550200244877 time
train_step spend 0.642148927996459 time
policy_value spend 0.21952837600110797 time
kl:0.01855,lr_multiplier:11.391,loss:4.706011772155762,entropy:5.637084007263184,explained_var_old:0.982562661,explained_var_new:0.987802625
output spend 0.00018453500524628907 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011361033997673076 time
recovery_state_mcts_prob spend 0.27682164999714587 time
state_batch spend 0.0018187419991591014 time
mcts_probs_batch spend 0.006629912000789773 time
winner_batch spend 0.00033628399978624657 time
policy_value spend 0.21930137700110208 time
train_step spend 0.643644760006282 time
policy_value spend 0.219399847999739 time
train_step spend 0.6422201749956002 time
policy_value spend 0.21949219800444553 time
train_step spend 0.642761242997949 time
policy_value spend 0.21920723200310022 time
train_step spend 0.6432189810002455 time
policy_value spend 0.22620861099858303 time
train_step spend 0.6688801180062001 time
policy_value spend 0.22521960699668853 time
kl:0.02069,lr_multiplier:11.391,loss:4.705176830291748,entropy:5.628709316253662,explained_var_old:0.992862344,explained_var_new:0.995509923
output spend 0.0001526929991086945 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009669389997725375 time
recovery_state_mcts_prob spend 0.27120072200341383 time
state_batch spend 0.0017970059998333454 time
mcts_probs_batch spend 0.006244793999940157 time
winner_batch spend 0.00028530599956866354 time
policy_value spend 0.2202509700000519 time
train_step spend 0.6445215739950072 time
policy_value spend 0.2232251940004062 time
train_step spend 0.6442857479996746 time
policy_value spend 0.22010074600257212 time
train_step spend 0.6434447470019222 time
policy_value spend 0.219508832997235 time
train_step spend 0.6440200970027945 time
policy_value spend 0.21990511899639387 time
train_step spend 0.6460737219967996 time
policy_value spend 0.22016837399860378 time
kl:0.00755,lr_multiplier:11.391,loss:4.708512783050537,entropy:5.629321575164795,explained_var_old:0.991244912,explained_var_new:0.994739056
output spend 0.0003208560010534711 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008752191002713516 time
recovery_state_mcts_prob spend 0.28357260799384676 time
state_batch spend 0.0018325650016777217 time
mcts_probs_batch spend 0.006738028001564089 time
winner_batch spend 0.00031971799762686715 time
policy_value spend 0.22010724899882916 time
train_step spend 0.6450668729958124 time
policy_value spend 0.2226764550068765 time
train_step spend 0.6649744079986704 time
policy_value spend 0.21999976199731464 time
train_step spend 0.644657663993712 time
policy_value spend 0.2201650690039969 time
train_step spend 0.6452176740058349 time
policy_value spend 0.2207451750000473 time
train_step spend 0.6445913950010436 time
policy_value spend 0.22045818299375242 time
kl:0.00538,lr_multiplier:11.391,loss:4.71298360824585,entropy:5.648135185241699,explained_var_old:0.993284225,explained_var_new:0.995571852
output spend 0.00014821000513620675 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006840943002316635 time
recovery_state_mcts_prob spend 0.27773844599869335 time
state_batch spend 0.0018267880004714243 time
mcts_probs_batch spend 0.006943483000213746 time
winner_batch spend 0.00041212599899154156 time
policy_value spend 0.22831028400105424 time
train_step spend 0.6662081879985635 time
policy_value spend 0.2352218520027236 time
train_step spend 0.661671337998996 time
policy_value spend 0.22182168300059857 time
train_step spend 0.6545362990000285 time
policy_value spend 0.22947017999831587 time
train_step spend 0.6694373760037706 time
policy_value spend 0.22877435099508148 time
train_step spend 0.6541961490001995 time
policy_value spend 0.21701324999594362 time
kl:0.03809,lr_multiplier:11.391,loss:4.672998905181885,entropy:5.587804317474365,explained_var_old:0.991683304,explained_var_new:0.998080313
output spend 0.00014376099716173485 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009104919001401868 time
recovery_state_mcts_prob spend 0.27348637799877906 time
state_batch spend 0.0017906680004671216 time
mcts_probs_batch spend 0.006375749995640945 time
winner_batch spend 0.00028290900081628934 time
policy_value spend 0.21770856800139882 time
train_step spend 0.634811746997002 time
policy_value spend 0.2167824490024941 time
train_step spend 0.6350727190001635 time
policy_value spend 0.21775130800233455 time
train_step spend 0.6342845209946972 time
policy_value spend 0.21662634600215824 time
train_step spend 0.6356546259994502 time
policy_value spend 0.216836752006202 time
train_step spend 0.6352659530020901 time
policy_value spend 0.21643428199604386 time
kl:0.03982,lr_multiplier:11.391,loss:4.672983646392822,entropy:5.600132942199707,explained_var_old:0.986179471,explained_var_new:0.995821059
output spend 0.0002215209970017895 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008391990995733067 time
recovery_state_mcts_prob spend 0.27622491100191837 time
state_batch spend 0.002101598998706322 time
mcts_probs_batch spend 0.004395137999381404 time
winner_batch spend 0.0002870460011763498 time
policy_value spend 0.2259650209962274 time
train_step spend 0.669186899001943 time
policy_value spend 0.22835096099879593 time
train_step spend 0.6486842300000717 time
policy_value spend 0.21960909700283082 time
train_step spend 0.641034578999097 time
policy_value spend 0.2201340669998899 time
train_step spend 0.6407479199988302 time
policy_value spend 0.21916606300510466 time
train_step spend 0.6415104469997459 time
policy_value spend 0.21964733300410444 time
kl:0.00669,lr_multiplier:11.391,loss:4.674584865570068,entropy:5.5959014892578125,explained_var_old:0.981117547,explained_var_new:0.992286563
output spend 0.00015384700236609206 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008323732996359468 time
recovery_state_mcts_prob spend 0.27201927300484385 time
state_batch spend 0.002056654993793927 time
mcts_probs_batch spend 0.004561844005365856 time
winner_batch spend 0.00040383699524682015 time
policy_value spend 0.2172598570032278 time
train_step spend 0.6422585700056516 time
policy_value spend 0.21890221299690893 time
train_step spend 0.6413949029956711 time
policy_value spend 0.2198541550023947 time
train_step spend 0.6424621769983787 time
policy_value spend 0.2192272820029757 time
train_step spend 0.6669728989945725 time
policy_value spend 0.22857940700487234 time
train_step spend 0.6498085860002902 time
policy_value spend 0.2209241460004705 time
kl:0.00629,lr_multiplier:11.391,loss:4.679153919219971,entropy:5.589006423950195,explained_var_old:0.993001997,explained_var_new:0.997162580
output spend 0.00015585299843223765 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00865213799988851 time
recovery_state_mcts_prob spend 0.28491351599950576 time
state_batch spend 0.0018475260003469884 time
mcts_probs_batch spend 0.006711341004120186 time
winner_batch spend 0.00028789199859602377 time
policy_value spend 0.22188062100030947 time
train_step spend 0.6463187449990073 time
policy_value spend 0.22356848000345053 time
train_step spend 0.6454302489946713 time
policy_value spend 0.225182787005906 time
train_step spend 0.6443090559987468 time
policy_value spend 0.2219426809970173 time
train_step spend 0.6447511369988206 time
policy_value spend 0.22011577500234125 time
train_step spend 0.6448044950011536 time
policy_value spend 0.22015689299587393 time
kl:0.00540,lr_multiplier:11.391,loss:4.663970470428467,entropy:5.572766304016113,explained_var_old:0.991998017,explained_var_new:0.995165050
output spend 0.00015003400039859116 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007334412999625783 time
recovery_state_mcts_prob spend 0.2748028760033776 time
state_batch spend 0.0020681589958257973 time
mcts_probs_batch spend 0.006399656005669385 time
winner_batch spend 0.00028872199618490413 time
policy_value spend 0.22162122999725398 time
train_step spend 0.6578785699966829 time
policy_value spend 0.22553532200254267 time
train_step spend 0.6490945179975824 time
policy_value spend 0.22124919400084764 time
train_step spend 0.6481236090039602 time
policy_value spend 0.22100435900210869 time
train_step spend 0.6482097799962503 time
policy_value spend 0.22166111600381555 time
train_step spend 0.6508015759973205 time
policy_value spend 0.22206281599937938 time
kl:0.00916,lr_multiplier:11.391,loss:4.6539387702941895,entropy:5.6040358543396,explained_var_old:0.987657428,explained_var_new:0.992868006
output spend 0.00015100600285222754 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009554698001011275 time
recovery_state_mcts_prob spend 0.2729279069972108 time
state_batch spend 0.0020171650030533783 time
mcts_probs_batch spend 0.006453094996686559 time
winner_batch spend 0.0003043670003535226 time
policy_value spend 0.22408501199970488 time
train_step spend 0.6481974069974967 time
policy_value spend 0.22194466699875193 time
train_step spend 0.6479128010032582 time
policy_value spend 0.22439102099451702 time
train_step spend 0.6688649670031737 time
policy_value spend 0.22889026799384737 time
train_step spend 0.6681384240000625 time
policy_value spend 0.21455290999438148 time
train_step spend 0.6289712420038995 time
policy_value spend 0.21399014000053285 time
kl:0.00993,lr_multiplier:11.391,loss:4.67242956161499,entropy:5.602620601654053,explained_var_old:0.994403183,explained_var_new:0.995495319
output spend 0.0001534609982627444 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011271244002273306 time
recovery_state_mcts_prob spend 0.2641310289982357 time
state_batch spend 0.0017219220026163384 time
mcts_probs_batch spend 0.004512667997914832 time
winner_batch spend 0.00029001900111325085 time
policy_value spend 0.21410773000388872 time
train_step spend 0.6278579969948623 time
policy_value spend 0.21490561100654304 time
train_step spend 0.627931663999334 time
policy_value spend 0.21364603599795373 time
train_step spend 0.6283523829988553 time
policy_value spend 0.2145320960044046 time
train_step spend 0.6356865729976562 time
policy_value spend 0.2143791490016156 time
train_step spend 0.6571790070011048 time
policy_value spend 0.22893352900428 time
kl:0.04862,lr_multiplier:7.594,loss:4.682818412780762,entropy:5.622387886047363,explained_var_old:0.998552680,explained_var_new:0.999217153
output spend 0.0001686950054136105 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007716628999332897 time
recovery_state_mcts_prob spend 0.2876504419982666 time
state_batch spend 0.002028114002314396 time
mcts_probs_batch spend 0.006861893998575397 time
winner_batch spend 0.00032070899760583416 time
policy_value spend 0.2297267180038034 time
train_step spend 0.6581900739984121 time
policy_value spend 0.21686925899848575 time
train_step spend 0.6327430500023183 time
policy_value spend 0.21681849299784517 time
train_step spend 0.634423258001334 time
policy_value spend 0.21665369300171733 time
train_step spend 0.633541506002075 time
policy_value spend 0.21646275199600495 time
train_step spend 0.6346728610005812 time
policy_value spend 0.21659839600033592 time
kl:0.02002,lr_multiplier:7.594,loss:4.663049221038818,entropy:5.630855560302734,explained_var_old:0.990196109,explained_var_new:0.995608211
output spend 0.0002704359940253198 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010321522997401189 time
recovery_state_mcts_prob spend 0.3017909830014105 time
state_batch spend 0.0019033280041185208 time
mcts_probs_batch spend 0.006749483996827621 time
winner_batch spend 0.0003224340034648776 time
policy_value spend 0.22993099799350603 time
train_step spend 0.6522035689995391 time
policy_value spend 0.22634029899927555 time
train_step spend 0.6703048449999187 time
policy_value spend 0.22869861000071978 time
train_step spend 0.6698829449960613 time
policy_value spend 0.2292432469985215 time
train_step spend 0.6551344950057683 time
policy_value spend 0.2186892829995486 time
train_step spend 0.6392249609998544 time
policy_value spend 0.21825636900030077 time
kl:0.02744,lr_multiplier:7.594,loss:4.666630744934082,entropy:5.593902587890625,explained_var_old:0.997009993,explained_var_new:0.999074578
output spend 0.00024679600028321147 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0075923219992546365 time
recovery_state_mcts_prob spend 0.27897116300300695 time
state_batch spend 0.002469088001816999 time
mcts_probs_batch spend 0.018613692998769693 time
winner_batch spend 0.00032706699857953936 time
policy_value spend 0.22260019600071246 time
train_step spend 0.638722648996918 time
policy_value spend 0.22240783500456018 time
train_step spend 0.6388119510011165 time
policy_value spend 0.2186447119966033 time
train_step spend 0.6389206220046617 time
policy_value spend 0.21806723599729594 time
train_step spend 0.6383917879938963 time
policy_value spend 0.21892538200336276 time
train_step spend 0.6618694490025518 time
policy_value spend 0.22940518999530468 time
kl:0.02536,lr_multiplier:7.594,loss:4.6953558921813965,entropy:5.648035049438477,explained_var_old:0.991009355,explained_var_new:0.995029926
output spend 0.00015398699906654656 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008162198995705694 time
recovery_state_mcts_prob spend 0.2914160290019936 time
state_batch spend 0.0018596700028865598 time
mcts_probs_batch spend 0.007191668999439571 time
winner_batch spend 0.0003155390004394576 time
policy_value spend 0.22910492699884344 time
train_step spend 0.648040261999995 time
policy_value spend 0.21969555899704574 time
train_step spend 0.6454874370028847 time
policy_value spend 0.2200797369951033 time
train_step spend 0.645203453997965 time
policy_value spend 0.21964040199964074 time
train_step spend 0.6448198650032282 time
policy_value spend 0.2197618810023414 time
train_step spend 0.6440471460009576 time
policy_value spend 0.21999178700207267 time
kl:0.01294,lr_multiplier:7.594,loss:4.642264366149902,entropy:5.622171878814697,explained_var_old:0.994333506,explained_var_new:0.997633696
output spend 0.00015698200149927288 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007491671996831428 time
recovery_state_mcts_prob spend 0.27206057500006864 time
state_batch spend 0.0018018620030488819 time
mcts_probs_batch spend 0.0042789219951373525 time
winner_batch spend 0.00029194600210757926 time
policy_value spend 0.22122938199754572 time
train_step spend 0.6658352930026012 time
policy_value spend 0.23003878199961036 time
train_step spend 0.6699562439971487 time
policy_value spend 0.22852466500626178 time
train_step spend 0.6692271159990923 time
policy_value spend 0.22080318599910242 time
train_step spend 0.6140296170051442 time
policy_value spend 0.2099620539956959 time
train_step spend 0.6140760820053401 time
policy_value spend 0.21099746899562888 time
kl:0.01143,lr_multiplier:7.594,loss:4.627069473266602,entropy:5.581853866577148,explained_var_old:0.985771954,explained_var_new:0.987655878
output spend 0.00014140700659481809 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008854839004925452 time
recovery_state_mcts_prob spend 0.259647466999013 time
state_batch spend 0.0019162419994245283 time
mcts_probs_batch spend 0.00795866399857914 time
winner_batch spend 0.000387740001315251 time
policy_value spend 0.21116281199647347 time
train_step spend 0.6149135489977198 time
policy_value spend 0.2099581959992065 time
train_step spend 0.615009758999804 time
policy_value spend 0.2097227100020973 time
train_step spend 0.6536670679997769 time
policy_value spend 0.22901421999995364 time
train_step spend 0.6696468970039859 time
policy_value spend 0.22931860799872084 time
train_step spend 0.6702948079982889 time
policy_value spend 0.2286279550025938 time
kl:0.00654,lr_multiplier:11.391,loss:4.615060329437256,entropy:5.5824689865112305,explained_var_old:0.984027028,explained_var_new:0.987924218
output spend 0.0001555800045025535 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012401750005665235 time
recovery_state_mcts_prob spend 0.2845734399961657 time
state_batch spend 0.0019996289993287064 time
mcts_probs_batch spend 0.004025230999104679 time
winner_batch spend 0.00031166800181381404 time
policy_value spend 0.21197142299934058 time
train_step spend 0.6189233199984301 time
policy_value spend 0.2126951280006324 time
train_step spend 0.6194251549968612 time
policy_value spend 0.21185165100177983 time
train_step spend 0.6189602149970597 time
policy_value spend 0.21198056700086454 time
train_step spend 0.6194380289962282 time
policy_value spend 0.21159250599885127 time
train_step spend 0.6226341709989356 time
policy_value spend 0.2141378660016926 time
kl:0.02376,lr_multiplier:11.391,loss:4.68709135055542,entropy:5.631721496582031,explained_var_old:0.978953302,explained_var_new:0.989377618
output spend 0.00015399700350826606 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007855038005800452 time
recovery_state_mcts_prob spend 0.30099646400049096 time
state_batch spend 0.002043162996415049 time
mcts_probs_batch spend 0.006341852997138631 time
winner_batch spend 0.00039849400491220877 time
policy_value spend 0.2293568589957431 time
train_step spend 0.6699849970027572 time
policy_value spend 0.22925060099805705 time
train_step spend 0.6699978140022722 time
policy_value spend 0.22892187799880048 time
train_step spend 0.6676383890007855 time
policy_value spend 0.21571951900114072 time
train_step spend 0.6335923989972798 time
policy_value spend 0.21627719100069953 time
train_step spend 0.6317382769993856 time
policy_value spend 0.2162843719997909 time
kl:0.01091,lr_multiplier:11.391,loss:4.657743453979492,entropy:5.558647632598877,explained_var_old:0.988798916,explained_var_new:0.993208110
output spend 0.00015670599532313645 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008132067996484693 time
recovery_state_mcts_prob spend 0.2717309200015734 time
state_batch spend 0.0018208869951195084 time
mcts_probs_batch spend 0.00611815600132104 time
winner_batch spend 0.00028432199906092137 time
policy_value spend 0.21593346699955873 time
train_step spend 0.6322757610032568 time
policy_value spend 0.21720591399935074 time
train_step spend 0.6322535049985163 time
policy_value spend 0.21933698400243884 time
train_step spend 0.6497697779996088 time
policy_value spend 0.2283493590002763 time
train_step spend 0.6699888970033498 time
policy_value spend 0.22935072499967646 time
train_step spend 0.6698410809985944 time
policy_value spend 0.22900681600003736 time
kl:0.01354,lr_multiplier:11.391,loss:4.62874698638916,entropy:5.535130023956299,explained_var_old:0.991796970,explained_var_new:0.995183885
output spend 0.00015557999722659588 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007317273004446179 time
recovery_state_mcts_prob spend 0.2776066489968798 time
state_batch spend 0.0018545479979366064 time
mcts_probs_batch spend 0.006681220002064947 time
winner_batch spend 0.0002947200046037324 time
policy_value spend 0.21956290299567627 time
train_step spend 0.6418826410008478 time
policy_value spend 0.21933932200045092 time
train_step spend 0.6422732379942317 time
policy_value spend 0.2192968520030263 time
train_step spend 0.6618486029983615 time
policy_value spend 0.2327043289988069 time
train_step spend 0.6695496719985385 time
policy_value spend 0.2214816769992467 time
train_step spend 0.651781127002323 time
policy_value spend 0.22889412500080653 time
kl:0.00601,lr_multiplier:11.391,loss:4.650132656097412,entropy:5.5444865226745605,explained_var_old:0.990648210,explained_var_new:0.994233310
output spend 0.00016026900266297162 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00925723399996059 time
recovery_state_mcts_prob spend 0.29265378799755126 time
state_batch spend 0.0019272860008641146 time
mcts_probs_batch spend 0.006851664998976048 time
winner_batch spend 0.00031683099950896576 time
policy_value spend 0.2286383280006703 time
train_step spend 0.669331377997878 time
policy_value spend 0.2323629790043924 time
train_step spend 0.6688640879947343 time
policy_value spend 0.2286735940069775 time
train_step spend 0.6258192150053219 time
policy_value spend 0.210470259997237 time
train_step spend 0.614428995999333 time
policy_value spend 0.20954548600275302 time
train_step spend 0.613855183000851 time
policy_value spend 0.20993421200546436 time
kl:0.01144,lr_multiplier:11.391,loss:4.609371185302734,entropy:5.610360145568848,explained_var_old:0.988361955,explained_var_new:0.991510034
output spend 0.00022583900135941803 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007760928994684946 time
recovery_state_mcts_prob spend 0.2644018840001081 time
state_batch spend 0.0021365110005717725 time
mcts_probs_batch spend 0.015597789999446832 time
winner_batch spend 0.0002863789995899424 time
policy_value spend 0.21304063700517872 time
train_step spend 0.6146471959946211 time
policy_value spend 0.2090255889997934 time
train_step spend 0.6141957350046141 time
policy_value spend 0.21067218799726106 time
train_step spend 0.6467558820004342 time
policy_value spend 0.22849901900190162 time
train_step spend 0.6700465030007763 time
policy_value spend 0.22834916699503083 time
train_step spend 0.6684682479972253 time
policy_value spend 0.22932110200054012 time
kl:0.00880,lr_multiplier:11.391,loss:4.612415313720703,entropy:5.5879106521606445,explained_var_old:0.983593166,explained_var_new:0.987625241
output spend 0.00015751399769214913 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007222947999252938 time
recovery_state_mcts_prob spend 0.26309995599876856 time
state_batch spend 0.0017424879988539033 time
mcts_probs_batch spend 0.0066000660008285195 time
winner_batch spend 0.0002800579968607053 time
policy_value spend 0.20983906000037678 time
train_step spend 0.6156261439973605 time
policy_value spend 0.21007015400391538 time
train_step spend 0.6146225490010693 time
policy_value spend 0.2097295839994331 time
train_step spend 0.6147429659977206 time
policy_value spend 0.2100945850033895 time
train_step spend 0.6163419829972554 time
policy_value spend 0.22876280100172153 time
train_step spend 0.6692830689935363 time
policy_value spend 0.2280734830055735 time
kl:0.00802,lr_multiplier:11.391,loss:4.639026165008545,entropy:5.549684524536133,explained_var_old:0.983801365,explained_var_new:0.987650573
output spend 0.0001599180031917058 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008075688005192205 time
recovery_state_mcts_prob spend 0.28777200100012124 time
state_batch spend 0.001946340998983942 time
mcts_probs_batch spend 0.006792043997847941 time
winner_batch spend 0.00035295900306664407 time
policy_value spend 0.2295837279962143 time
train_step spend 0.6701106339969556 time
policy_value spend 0.2293573409988312 time
train_step spend 0.6689611069959938 time
policy_value spend 0.22880838600394782 time
train_step spend 0.6278585399995791 time
policy_value spend 0.21375424700090662 time
train_step spend 0.6260776900016936 time
policy_value spend 0.21389669399650302 time
train_step spend 0.6250401010038331 time
policy_value spend 0.21315712000068743 time
kl:0.00709,lr_multiplier:11.391,loss:4.683579921722412,entropy:5.605508327484131,explained_var_old:0.990306437,explained_var_new:0.994354188
output spend 0.00015686600090702996 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00692768300359603 time
recovery_state_mcts_prob spend 0.26299818299594335 time
state_batch spend 0.0017442719981772825 time
mcts_probs_batch spend 0.006007253999996465 time
winner_batch spend 0.0002797269989969209 time
policy_value spend 0.21452825200685766 time
train_step spend 0.6257098190035322 time
policy_value spend 0.22598572299466468 time
train_step spend 0.6686888210024335 time
policy_value spend 0.22825745799491415 time
train_step spend 0.6685841369981063 time
policy_value spend 0.22838181800034363 time
train_step spend 0.6695277040053043 time
policy_value spend 0.22865046999504557 time
train_step spend 0.6692268350016093 time
policy_value spend 0.22821058399858885 time
kl:0.01647,lr_multiplier:11.391,loss:4.6417975425720215,entropy:5.574596405029297,explained_var_old:0.987051189,explained_var_new:0.990551353
output spend 0.00020209899957990274 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012119130005885381 time
recovery_state_mcts_prob spend 0.28339479499845766 time
state_batch spend 0.0022135839972179383 time
mcts_probs_batch spend 0.006407628003216814 time
winner_batch spend 0.0003337699963594787 time
policy_value spend 0.21788632799871266 time
train_step spend 0.6380426910036476 time
policy_value spend 0.21695061100035673 time
train_step spend 0.6375186910008779 time
policy_value spend 0.21787713300000178 time
train_step spend 0.6372914649982704 time
policy_value spend 0.21812981800030684 time
train_step spend 0.6656627479969757 time
policy_value spend 0.22882626600039657 time
train_step spend 0.6697826620002161 time
policy_value spend 0.22920899000018835 time
kl:0.01764,lr_multiplier:11.391,loss:4.641209602355957,entropy:5.583334445953369,explained_var_old:0.995174468,explained_var_new:0.998457849
output spend 0.00015540499589405954 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009059540003363509 time
recovery_state_mcts_prob spend 0.2826297520005028 time
state_batch spend 0.0018703729947446845 time
mcts_probs_batch spend 0.007218997001473326 time
winner_batch spend 0.0003137560051982291 time
policy_value spend 0.23028556499775732 time
train_step spend 0.6707563639938598 time
policy_value spend 0.22796904800634366 time
train_step spend 0.658965435999562 time
policy_value spend 0.21006526900600875 time
train_step spend 0.6128249019966461 time
policy_value spend 0.2099393919997965 time
train_step spend 0.6135964090062771 time
policy_value spend 0.20969557899661595 time
train_step spend 0.614000424000551 time
policy_value spend 0.20972897799947532 time
kl:0.04531,lr_multiplier:7.594,loss:4.593185901641846,entropy:5.563046455383301,explained_var_old:0.991924226,explained_var_new:0.992611766
output spend 0.0001501829974586144 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007197621998784598 time
recovery_state_mcts_prob spend 0.2623316410026746 time
state_batch spend 0.0020868260035058483 time
mcts_probs_batch spend 0.007258291996549815 time
winner_batch spend 0.00027806700381916016 time
policy_value spend 0.21163361700018868 time
train_step spend 0.6138135139990482 time
policy_value spend 0.2138764959963737 time
train_step spend 0.6140021570026875 time
policy_value spend 0.21174684300058288 time
kl:0.10480,lr_multiplier:5.062,loss:4.596116065979004,entropy:5.595293998718262,explained_var_old:0.998110056,explained_var_new:0.998543561
output spend 0.00015084400365594774 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013831598997057881 time
recovery_state_mcts_prob spend 0.2835980000018026 time
state_batch spend 0.0018539699958637357 time
mcts_probs_batch spend 0.006809997001255397 time
winner_batch spend 0.0002964230006909929 time
policy_value spend 0.22910041899740463 time
train_step spend 0.669069319999835 time
policy_value spend 0.2365556530057802 time
train_step spend 0.6755133850019774 time
policy_value spend 0.22234189399750903 time
train_step spend 0.6274531960007153 time
policy_value spend 0.2110247519958648 time
train_step spend 0.6147954830012168 time
policy_value spend 0.20942179200210376 time
train_step spend 0.6144182930001989 time
policy_value spend 0.21028823500091676 time
kl:0.04075,lr_multiplier:3.375,loss:4.609533309936523,entropy:5.548914909362793,explained_var_old:0.997899950,explained_var_new:0.999164402
output spend 0.00018105799972545356 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006954610005777795 time
recovery_state_mcts_prob spend 0.26584235100017395 time
state_batch spend 0.0017195019972859882 time
mcts_probs_batch spend 0.006766111997421831 time
winner_batch spend 0.00028613099857466295 time
policy_value spend 0.22346658700553235 time
train_step spend 0.6702801409992389 time
policy_value spend 0.22909784500370733 time
train_step spend 0.6688280680027674 time
policy_value spend 0.22917480999603868 time
train_step spend 0.6720565549985622 time
policy_value spend 0.22845464300189633 time
train_step spend 0.6703252750012325 time
policy_value spend 0.2283968179981457 time
train_step spend 0.6469364419972408 time
policy_value spend 0.20958978799899342 time
kl:0.01084,lr_multiplier:3.375,loss:4.650087356567383,entropy:5.570744514465332,explained_var_old:0.990529656,explained_var_new:0.995073855
output spend 0.00016102699737530202 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006659062004473526 time
recovery_state_mcts_prob spend 0.2646976439937134 time
state_batch spend 0.0021613270000671037 time
mcts_probs_batch spend 0.005823134000820573 time
winner_batch spend 0.0002758570044534281 time
policy_value spend 0.20917128099972615 time
train_step spend 0.6132995119987754 time
policy_value spend 0.2117358880059328 time
train_step spend 0.6129731630062452 time
policy_value spend 0.20923912299622316 time
train_step spend 0.6461612850034726 time
policy_value spend 0.2283485469961306 time
train_step spend 0.6690847580030095 time
policy_value spend 0.22839311999996426 time
train_step spend 0.668790160001663 time
policy_value spend 0.22851127899775747 time
kl:0.00653,lr_multiplier:5.062,loss:4.594605922698975,entropy:5.563013553619385,explained_var_old:0.988497257,explained_var_new:0.991876900
output spend 0.0001613610002095811 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010025717994722072 time
recovery_state_mcts_prob spend 0.28137442099978216 time
state_batch spend 0.0019056560049648397 time
mcts_probs_batch spend 0.0070665849998476915 time
winner_batch spend 0.00030261500069173053 time
policy_value spend 0.22863323899946408 time
train_step spend 0.6697571429976961 time
policy_value spend 0.22828342499997234 time
train_step spend 0.642789317003917 time
policy_value spend 0.2166133259961498 time
train_step spend 0.6328473760004272 time
policy_value spend 0.2160851190055837 time
train_step spend 0.6322908469956019 time
policy_value spend 0.2222970510047162 time
train_step spend 0.6335154859989416 time
policy_value spend 0.2160188229972846 time
kl:0.01243,lr_multiplier:5.062,loss:4.624775409698486,entropy:5.548123359680176,explained_var_old:0.982741237,explained_var_new:0.983992755
output spend 0.00021203800133662298 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007011142995906994 time
recovery_state_mcts_prob spend 0.2720456860042759 time
state_batch spend 0.002842778994818218 time
mcts_probs_batch spend 0.00780883600236848 time
winner_batch spend 0.0003328480015625246 time
policy_value spend 0.23003003600024385 time
train_step spend 0.6745763560029445 time
policy_value spend 0.2319028959973366 time
train_step spend 0.6723810589974164 time
policy_value spend 0.2313165890009259 time
train_step spend 0.6727975379981217 time
policy_value spend 0.2302574619970983 time
train_step spend 0.6734538909950061 time
policy_value spend 0.2294501020005555 time
train_step spend 0.6147359599999618 time
policy_value spend 0.20995980599400355 time
kl:0.00396,lr_multiplier:7.594,loss:4.576518535614014,entropy:5.562117576599121,explained_var_old:0.990747631,explained_var_new:0.991992831
output spend 0.00014814799942541867 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007615004004037473 time
recovery_state_mcts_prob spend 0.27283203299884917 time
state_batch spend 0.001906191995658446 time
mcts_probs_batch spend 0.006559177003509831 time
winner_batch spend 0.0002797659981297329 time
policy_value spend 0.20996812500379747 time
train_step spend 0.612975338997785 time
policy_value spend 0.20989118600118672 time
train_step spend 0.6134458629967412 time
policy_value spend 0.20946070900390623 time
train_step spend 0.6138271040035761 time
policy_value spend 0.2092070349972346 time
train_step spend 0.6130293000023812 time
policy_value spend 0.2172375619993545 time
train_step spend 0.6692564460026915 time
policy_value spend 0.22899317200062796 time
kl:0.01765,lr_multiplier:7.594,loss:4.601130485534668,entropy:5.533488750457764,explained_var_old:0.985007346,explained_var_new:0.986849308
output spend 0.0001580400057719089 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00991372099815635 time
recovery_state_mcts_prob spend 0.2895580229960615 time
state_batch spend 0.0021462340009748004 time
mcts_probs_batch spend 0.0074131670044153 time
winner_batch spend 0.00031307400058722124 time
policy_value spend 0.2304591869979049 time
train_step spend 0.6700147970041144 time
policy_value spend 0.22245434199430747 time
train_step spend 0.6024577540010796 time
policy_value spend 0.20581181399757043 time
train_step spend 0.603366613999242 time
policy_value spend 0.20640023500163807 time
train_step spend 0.602542214001005 time
policy_value spend 0.20619559899932938 time
train_step spend 0.6033044249998056 time
policy_value spend 0.20604896699660458 time
kl:0.01329,lr_multiplier:7.594,loss:4.568334579467773,entropy:5.548705577850342,explained_var_old:0.989836872,explained_var_new:0.995861113
output spend 0.00014677600120194256 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007281800004420802 time
recovery_state_mcts_prob spend 0.2654640289983945 time
state_batch spend 0.001930701000674162 time
mcts_probs_batch spend 0.006081407998863142 time
winner_batch spend 0.00029860199720133096 time
policy_value spend 0.2074747440055944 time
train_step spend 0.6159140110030421 time
policy_value spend 0.22226705199864227 time
train_step spend 0.6483352150025894 time
policy_value spend 0.22192174299561884 time
train_step spend 0.649185883004975 time
policy_value spend 0.22162134399695788 time
train_step spend 0.6488090040002135 time
policy_value spend 0.22159852900222177 time
train_step spend 0.6436307190015214 time
policy_value spend 0.22075941700313706 time
kl:0.00564,lr_multiplier:11.391,loss:4.553764343261719,entropy:5.509640693664551,explained_var_old:0.987969279,explained_var_new:0.991450131
output spend 0.00015451099898200482 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010076491002109833 time
recovery_state_mcts_prob spend 0.28119585099921096 time
state_batch spend 0.001842928002588451 time
mcts_probs_batch spend 0.006387317996995989 time
winner_batch spend 0.0002993669986608438 time
policy_value spend 0.21988636899914127 time
train_step spend 0.6420505860005505 time
policy_value spend 0.2221483819957939 time
train_step spend 0.6434150350032724 time
policy_value spend 0.22011740999732865 time
train_step spend 0.6422851070019533 time
policy_value spend 0.21933727800205816 time
train_step spend 0.6432998649979709 time
policy_value spend 0.2199564679976902 time
train_step spend 0.6423507010040339 time
policy_value spend 0.2198878419949324 time
kl:0.00850,lr_multiplier:11.391,loss:4.663322448730469,entropy:5.560915470123291,explained_var_old:0.989682972,explained_var_new:0.995534182
output spend 0.0001591850013937801 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01054223500250373 time
recovery_state_mcts_prob spend 0.3150865249990602 time
state_batch spend 0.002167297003325075 time
mcts_probs_batch spend 0.016850494997925125 time
winner_batch spend 0.00030435799999395385 time
policy_value spend 0.23613640099938493 time
train_step spend 0.6575131459976546 time
policy_value spend 0.22462615100084804 time
train_step spend 0.6460154350061202 time
policy_value spend 0.22044719599944074 time
train_step spend 0.6452723129987135 time
policy_value spend 0.22066701400035527 time
train_step spend 0.6460665510021499 time
policy_value spend 0.22014762399339816 time
train_step spend 0.6460104750003666 time
policy_value spend 0.22134796799946344 time
kl:0.00867,lr_multiplier:11.391,loss:4.63981819152832,entropy:5.529882907867432,explained_var_old:0.987094104,explained_var_new:0.991299629
output spend 0.0001486790060880594 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009424005998880602 time
recovery_state_mcts_prob spend 0.2723873860013555 time
state_batch spend 0.0017798089975258335 time
mcts_probs_batch spend 0.006753474997822195 time
winner_batch spend 0.0002853450059774332 time
policy_value spend 0.22266514699731488 time
train_step spend 0.6449567900053808 time
policy_value spend 0.22183840399520705 time
train_step spend 0.6460085460057599 time
policy_value spend 0.22067338299530093 time
train_step spend 0.6479575909979758 time
policy_value spend 0.22266040399699705 time
train_step spend 0.6468755070018233 time
policy_value spend 0.22050733199284878 time
train_step spend 0.6452772509946954 time
policy_value spend 0.22084514200105332 time
kl:0.00815,lr_multiplier:11.391,loss:4.610631465911865,entropy:5.557625770568848,explained_var_old:0.990472734,explained_var_new:0.995805502
output spend 0.00016048600082285702 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008832986997731496 time
recovery_state_mcts_prob spend 0.2741471490007825 time
state_batch spend 0.002270290002343245 time
mcts_probs_batch spend 0.00515489299868932 time
winner_batch spend 0.0003240709993406199 time
policy_value spend 0.21969006700237514 time
train_step spend 0.6447757719943183 time
policy_value spend 0.22034498600260122 time
train_step spend 0.6451814009997179 time
policy_value spend 0.21995485099614598 time
train_step spend 0.6448018010050873 time
policy_value spend 0.21990904699487146 time
train_step spend 0.6455236289984896 time
policy_value spend 0.2206680720046279 time
train_step spend 0.6451383249950595 time
policy_value spend 0.22023840399924666 time
kl:0.01062,lr_multiplier:11.391,loss:4.6333231925964355,entropy:5.572499752044678,explained_var_old:0.998857021,explained_var_new:0.999313176
output spend 0.000148892002471257 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011775657003454398 time
recovery_state_mcts_prob spend 0.27613574900169624 time
state_batch spend 0.0017931949987541884 time
mcts_probs_batch spend 0.006440275996283162 time
winner_batch spend 0.0003046749989152886 time
policy_value spend 0.22138064300088445 time
train_step spend 0.646307071998308 time
policy_value spend 0.22449158300150884 time
train_step spend 0.6443518300002324 time
policy_value spend 0.22042607500043232 time
train_step spend 0.6445116260001669 time
policy_value spend 0.21990856400225312 time
train_step spend 0.6442560959985713 time
policy_value spend 0.22028030000365106 time
train_step spend 0.6440090430041892 time
policy_value spend 0.22048890400037635 time
kl:0.02166,lr_multiplier:11.391,loss:4.566875457763672,entropy:5.520891189575195,explained_var_old:0.981299758,explained_var_new:0.985728562
output spend 0.00014773599832551554 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009395442000823095 time
recovery_state_mcts_prob spend 0.2744528879993595 time
state_batch spend 0.0018444039960741065 time
mcts_probs_batch spend 0.007082351999997627 time
winner_batch spend 0.00031753800431033596 time
policy_value spend 0.2212544989961316 time
train_step spend 0.6451929050017498 time
policy_value spend 0.2200478149970877 time
train_step spend 0.6444863760043518 time
policy_value spend 0.22021485099685378 time
train_step spend 0.6442591860031825 time
policy_value spend 0.2195721979951486 time
train_step spend 0.6374930439997115 time
policy_value spend 0.21445637400029227 time
train_step spend 0.6272231890034163 time
policy_value spend 0.21497506499872543 time
kl:0.00981,lr_multiplier:11.391,loss:4.665987968444824,entropy:5.625831604003906,explained_var_old:0.990119994,explained_var_new:0.992595315
output spend 0.00014680899766972288 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007047348997730296 time
recovery_state_mcts_prob spend 0.27716844800306717 time
state_batch spend 0.0018770819951896556 time
mcts_probs_batch spend 0.0062425560026895255 time
winner_batch spend 0.0002825069968821481 time
policy_value spend 0.21478042400121922 time
train_step spend 0.6274251049981103 time
policy_value spend 0.2153894750008476 time
train_step spend 0.6279844110031263 time
policy_value spend 0.21401107199926628 time
train_step spend 0.6278389939980116 time
policy_value spend 0.21452104600029998 time
train_step spend 0.6284760900016408 time
policy_value spend 0.21685190900461748 time
train_step spend 0.6272628579972661 time
policy_value spend 0.21448896700167097 time
kl:0.00863,lr_multiplier:11.391,loss:4.543095111846924,entropy:5.514255046844482,explained_var_old:0.991797626,explained_var_new:0.994702041
output spend 0.00015520600572926924 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008230143997934647 time
recovery_state_mcts_prob spend 0.2687080350005999 time
state_batch spend 0.0024066190017038025 time
mcts_probs_batch spend 0.007804228000168223 time
winner_batch spend 0.0003491300012683496 time
policy_value spend 0.21529789199848892 time
train_step spend 0.6354668600033619 time
policy_value spend 0.2231505140007357 time
train_step spend 0.6445135100002517 time
policy_value spend 0.2209686900023371 time
train_step spend 0.6451358580015949 time
policy_value spend 0.22022542199556483 time
train_step spend 0.645544733000861 time
policy_value spend 0.21997199299948988 time
train_step spend 0.6449756959991646 time
policy_value spend 0.22056612499727635 time
kl:0.01196,lr_multiplier:11.391,loss:4.595158576965332,entropy:5.568512916564941,explained_var_old:0.980803967,explained_var_new:0.983556330
output spend 0.00016003700147848576 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007364129996858537 time
recovery_state_mcts_prob spend 0.2891930269979639 time
state_batch spend 0.0017720350006129593 time
mcts_probs_batch spend 0.006616664999455679 time
winner_batch spend 0.0002927189998445101 time
policy_value spend 0.22069697400002042 time
train_step spend 0.6451239909947617 time
policy_value spend 0.22009905199956847 time
train_step spend 0.6543713479986764 time
policy_value spend 0.2203306250012247 time
train_step spend 0.6443831720025628 time
policy_value spend 0.22111261200188892 time
train_step spend 0.6439168869983405 time
policy_value spend 0.21965718700084835 time
train_step spend 0.6446169120026752 time
policy_value spend 0.21948126400093315 time
kl:0.01181,lr_multiplier:11.391,loss:4.598554611206055,entropy:5.538180351257324,explained_var_old:0.980276823,explained_var_new:0.984279096
output spend 0.00018018500122707337 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012363365000055637 time
recovery_state_mcts_prob spend 0.26928482000221265 time
state_batch spend 0.0018425320013193414 time
mcts_probs_batch spend 0.006695948999549728 time
winner_batch spend 0.00029491000168491155 time
policy_value spend 0.22021451700129546 time
train_step spend 0.6458527300055721 time
policy_value spend 0.21981650599627756 time
train_step spend 0.6430758610003977 time
policy_value spend 0.22013837800477631 time
train_step spend 0.6437946900041425 time
policy_value spend 0.22863978399982443 time
train_step spend 0.6659104240025044 time
policy_value spend 0.2341072580020409 time
train_step spend 0.660355067004275 time
policy_value spend 0.22171754499868257 time
kl:0.01096,lr_multiplier:11.391,loss:4.623193264007568,entropy:5.582380771636963,explained_var_old:0.991147518,explained_var_new:0.995244861
output spend 0.00014936899970052764 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007037600000330713 time
recovery_state_mcts_prob spend 0.2776753709986224 time
state_batch spend 0.002056571000139229 time
mcts_probs_batch spend 0.006761477001418825 time
winner_batch spend 0.00031911399855744094 time
policy_value spend 0.21968533000472235 time
train_step spend 0.6358234630024526 time
policy_value spend 0.2169232629967155 time
train_step spend 0.6359398679996957 time
policy_value spend 0.21702493200427853 time
train_step spend 0.6349976570054423 time
policy_value spend 0.21686870999837993 time
train_step spend 0.6364776900009019 time
policy_value spend 0.2171804319950752 time
train_step spend 0.6363307349965908 time
policy_value spend 0.21724032200290821 time
kl:0.01617,lr_multiplier:11.391,loss:4.592624664306641,entropy:5.542603969573975,explained_var_old:0.996527731,explained_var_new:0.998895943
output spend 0.0001543769976706244 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007936745998449624 time
recovery_state_mcts_prob spend 0.27727537199825747 time
state_batch spend 0.0018143740016967058 time
mcts_probs_batch spend 0.01187085900164675 time
winner_batch spend 0.00028966499667149037 time
policy_value spend 0.21996520800166763 time
train_step spend 0.6371971379994648 time
policy_value spend 0.216699296994193 time
train_step spend 0.6357825789964409 time
policy_value spend 0.21763976399961393 time
train_step spend 0.6361075839959085 time
policy_value spend 0.21741077800106723 time
train_step spend 0.6306842160047381 time
policy_value spend 0.21603294799569994 time
train_step spend 0.6309103200037498 time
policy_value spend 0.21577629799867282 time
kl:0.02064,lr_multiplier:11.391,loss:4.571142673492432,entropy:5.4981465339660645,explained_var_old:0.990664840,explained_var_new:0.993154764
output spend 0.0001514999967184849 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00693731499632122 time
recovery_state_mcts_prob spend 0.28750824600138003 time
state_batch spend 0.0018352780025452375 time
mcts_probs_batch spend 0.006200094998348504 time
winner_batch spend 0.00031840099836699665 time
policy_value spend 0.215874082998198 time
train_step spend 0.6306863540012273 time
policy_value spend 0.21816881500126328 time
train_step spend 0.6303303270033211 time
policy_value spend 0.21635597499698633 time
train_step spend 0.6303990349988453 time
policy_value spend 0.2151199820000329 time
train_step spend 0.63061014500272 time
policy_value spend 0.21533700099826092 time
train_step spend 0.6308932739993907 time
policy_value spend 0.21592113799852086 time
kl:0.01323,lr_multiplier:11.391,loss:4.616197109222412,entropy:5.574683666229248,explained_var_old:0.990496755,explained_var_new:0.995085537
output spend 0.00015479399735340849 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009932320994266775 time
recovery_state_mcts_prob spend 0.2774110520040267 time
state_batch spend 0.0020694819977506995 time
mcts_probs_batch spend 0.005616980997729115 time
winner_batch spend 0.0002847480063792318 time
policy_value spend 0.21761139999580337 time
train_step spend 0.6474591070000315 time
policy_value spend 0.22051913899485953 time
train_step spend 0.6442818710056599 time
policy_value spend 0.21990106099838158 time
train_step spend 0.6443660989971249 time
policy_value spend 0.2205561690061586 time
train_step spend 0.6448219059966505 time
policy_value spend 0.22036286599904997 time
train_step spend 0.6445788800047012 time
policy_value spend 0.2204581080004573 time
kl:0.02869,lr_multiplier:11.391,loss:4.611016273498535,entropy:5.567311763763428,explained_var_old:0.982127607,explained_var_new:0.985351920
output spend 0.0001455550009268336 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007245578999572899 time
recovery_state_mcts_prob spend 0.2809836609958438 time
state_batch spend 0.0018208030014648102 time
mcts_probs_batch spend 0.00678273100493243 time
winner_batch spend 0.00030574399715987965 time
policy_value spend 0.22070441299729282 time
train_step spend 0.6448288070023409 time
policy_value spend 0.21949329500057502 time
train_step spend 0.6436715599993477 time
policy_value spend 0.22104368599684676 time
train_step spend 0.643755703997158 time
policy_value spend 0.22000141299940879 time
train_step spend 0.6430279240012169 time
policy_value spend 0.2237579389984603 time
train_step spend 0.6428542840003502 time
policy_value spend 0.21986959099740488 time
kl:0.02324,lr_multiplier:11.391,loss:4.591888427734375,entropy:5.540713787078857,explained_var_old:0.987796545,explained_var_new:0.994500399
output spend 0.00016490399866597727 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009216792997904122 time
recovery_state_mcts_prob spend 0.2707280989998253 time
state_batch spend 0.0022259690013015643 time
mcts_probs_batch spend 0.006257376000576187 time
winner_batch spend 0.00033016299857990816 time
policy_value spend 0.22024698400491616 time
train_step spend 0.6442525790043874 time
policy_value spend 0.21965220799756935 time
train_step spend 0.6429126980001456 time
policy_value spend 0.21997633099817904 time
train_step spend 0.6427608960002544 time
policy_value spend 0.22084333500242792 time
train_step spend 0.643485269996745 time
policy_value spend 0.21993436499906238 time
train_step spend 0.6437956320005469 time
policy_value spend 0.2193487160038785 time
kl:0.05973,lr_multiplier:7.594,loss:4.623732566833496,entropy:5.5505146980285645,explained_var_old:0.990243316,explained_var_new:0.999151409
output spend 0.00014801300130784512 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008185145001334604 time
recovery_state_mcts_prob spend 0.2769655879965285 time
state_batch spend 0.0022089630001573823 time
mcts_probs_batch spend 0.006276202002482023 time
winner_batch spend 0.00028759799897670746 time
policy_value spend 0.21586128800117876 time
train_step spend 0.6318847549991915 time
policy_value spend 0.21550471799855586 time
train_step spend 0.6330187030034722 time
policy_value spend 0.21560929199767997 time
train_step spend 0.630906127000344 time
policy_value spend 0.21996662099991227 time
train_step spend 0.66293406800105 time
policy_value spend 0.23040905599918915 time
train_step spend 0.6318317749974085 time
policy_value spend 0.21539729300275212 time
kl:0.05552,lr_multiplier:5.062,loss:4.544307708740234,entropy:5.5567827224731445,explained_var_old:0.982813001,explained_var_new:0.990200639
output spend 0.00015078999422257766 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008283640003355686 time
recovery_state_mcts_prob spend 0.2762758809985826 time
state_batch spend 0.0017524920040159486 time
mcts_probs_batch spend 0.004501204995904118 time
winner_batch spend 0.0002926239976659417 time
policy_value spend 0.21596337700611912 time
train_step spend 0.6315774650065578 time
policy_value spend 0.2152874659950612 time
train_step spend 0.6312600870005554 time
policy_value spend 0.21545346500352025 time
train_step spend 0.6336165460015764 time
policy_value spend 0.2188086989990552 time
train_step spend 0.640262723005435 time
policy_value spend 0.21884029899956658 time
train_step spend 0.6406719630031148 time
policy_value spend 0.21927730099559994 time
kl:0.03398,lr_multiplier:5.062,loss:4.588851451873779,entropy:5.535353183746338,explained_var_old:0.984404445,explained_var_new:0.990224421
output spend 0.00014830299915047362 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007158971995522734 time
recovery_state_mcts_prob spend 0.2826978000011877 time
state_batch spend 0.0019211580001865514 time
mcts_probs_batch spend 0.006730101005814504 time
winner_batch spend 0.0003207199988537468 time
policy_value spend 0.2281776899981196 time
train_step spend 0.6617542300009518 time
policy_value spend 0.23249011999723734 time
train_step spend 0.6568414010034758 time
policy_value spend 0.22100052300083917 time
train_step spend 0.6538812910002889 time
policy_value spend 0.23783336499764118 time
train_step spend 0.6535447249989375 time
policy_value spend 0.2188262090057833 time
train_step spend 0.6409408070030622 time
policy_value spend 0.21923858400259633 time
kl:0.00765,lr_multiplier:7.594,loss:4.531592845916748,entropy:5.521844387054443,explained_var_old:0.992069542,explained_var_new:0.994879663
output spend 0.00014805399405304343 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009809019000385888 time
recovery_state_mcts_prob spend 0.27365606799867237 time
state_batch spend 0.0021691910005756654 time
mcts_probs_batch spend 0.007101381001120899 time
winner_batch spend 0.00028528599796118215 time
policy_value spend 0.22097752999980003 time
train_step spend 0.6440144410007633 time
policy_value spend 0.22074313399934908 time
train_step spend 0.6427799070006586 time
policy_value spend 0.2204531829993357 time
train_step spend 0.6433975100007956 time
policy_value spend 0.21907871100120246 time
train_step spend 0.6428993509980501 time
policy_value spend 0.21977461100323126 time
train_step spend 0.6424823899942567 time
policy_value spend 0.22050587000558153 time
kl:0.00676,lr_multiplier:11.391,loss:4.579686641693115,entropy:5.5277581214904785,explained_var_old:0.991049469,explained_var_new:0.994541526
output spend 0.00028313200164120644 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008623076006188057 time
recovery_state_mcts_prob spend 0.2724639389998629 time
state_batch spend 0.0018191089984611608 time
mcts_probs_batch spend 0.006386636996467132 time
winner_batch spend 0.0002922979983850382 time
policy_value spend 0.2198283360048663 time
train_step spend 0.6426131129992427 time
policy_value spend 0.2208997019988601 time
train_step spend 0.642885715002194 time
policy_value spend 0.21893756799545372 time
train_step spend 0.6421405110013438 time
policy_value spend 0.2189555820004898 time
train_step spend 0.6418697870030883 time
policy_value spend 0.21900054899742827 time
train_step spend 0.6426814100050251 time
policy_value spend 0.21878395800013095 time
kl:0.03193,lr_multiplier:11.391,loss:4.571841716766357,entropy:5.562719821929932,explained_var_old:0.991878927,explained_var_new:0.995496213
output spend 0.0001533049944555387 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012711057999695186 time
recovery_state_mcts_prob spend 0.27003878699906636 time
state_batch spend 0.0021310919983079657 time
mcts_probs_batch spend 0.0067003430012846366 time
winner_batch spend 0.0002924369982792996 time
policy_value spend 0.22003103700262727 time
train_step spend 0.6428646920030587 time
policy_value spend 0.21966831499594264 time
train_step spend 0.6414141080022091 time
policy_value spend 0.21942037400003755 time
train_step spend 0.6414953310013516 time
policy_value spend 0.21927614299784182 time
train_step spend 0.6418106950004585 time
policy_value spend 0.21984761199564673 time
train_step spend 0.6414730139949825 time
policy_value spend 0.21981686600338435 time
kl:0.02247,lr_multiplier:11.391,loss:4.532503604888916,entropy:5.518631935119629,explained_var_old:0.991715848,explained_var_new:0.998456180
output spend 0.00015067400090629235 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006674323005427141 time
recovery_state_mcts_prob spend 0.27092031599750044 time
state_batch spend 0.001885712001239881 time
mcts_probs_batch spend 0.006096619996242225 time
winner_batch spend 0.00027530499937711284 time
policy_value spend 0.21265040400612634 time
train_step spend 0.6242179689943441 time
policy_value spend 0.21234271700086538 time
train_step spend 0.6227120330004254 time
policy_value spend 0.21382595599425258 time
train_step spend 0.6219177919992944 time
policy_value spend 0.21283379699889338 time
train_step spend 0.6227390589992865 time
policy_value spend 0.212526996001543 time
train_step spend 0.6238942589989165 time
policy_value spend 0.21262773299531545 time
kl:0.00964,lr_multiplier:11.391,loss:4.540935516357422,entropy:5.508945465087891,explained_var_old:0.993371606,explained_var_new:0.998584390
output spend 0.00014286599616752937 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008562098002585117 time
recovery_state_mcts_prob spend 0.28043690499907825 time
state_batch spend 0.0017535259976284578 time
mcts_probs_batch spend 0.006393962998117786 time
winner_batch spend 0.00028053700225427747 time
policy_value spend 0.21329579099983675 time
train_step spend 0.6232251030014595 time
policy_value spend 0.21269416600262048 time
train_step spend 0.6224423860039678 time
policy_value spend 0.21335861300030956 time
train_step spend 0.6329890039996826 time
policy_value spend 0.21916321000026073 time
train_step spend 0.6425061249974533 time
policy_value spend 0.21952629199950024 time
train_step spend 0.6425333829974988 time
policy_value spend 0.2183881980017759 time
kl:0.00644,lr_multiplier:11.391,loss:4.611402988433838,entropy:5.542364120483398,explained_var_old:0.990890265,explained_var_new:0.994245470
output spend 0.00015234600141411647 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00713888400059659 time
recovery_state_mcts_prob spend 0.2786712430024636 time
state_batch spend 0.0017487679942860268 time
mcts_probs_batch spend 0.016286959005810786 time
winner_batch spend 0.00031523600046057254 time
policy_value spend 0.22262085099646356 time
train_step spend 0.6421396090008784 time
policy_value spend 0.2234587749990169 time
train_step spend 0.6407094550013426 time
policy_value spend 0.2196853880013805 time
train_step spend 0.6411289340030635 time
policy_value spend 0.21946808799839346 time
train_step spend 0.6410395630009589 time
policy_value spend 0.2193737730049179 time
train_step spend 0.6408302780037047 time
policy_value spend 0.21892663100152276 time
kl:0.00876,lr_multiplier:11.391,loss:4.635608673095703,entropy:5.5583577156066895,explained_var_old:0.988477051,explained_var_new:0.994153678
output spend 0.00015705099940532818 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012178616001619957 time
recovery_state_mcts_prob spend 0.27766790599707747 time
state_batch spend 0.0018981410030391999 time
mcts_probs_batch spend 0.008020950997888576 time
winner_batch spend 0.0003194189994246699 time
policy_value spend 0.22025229900464183 time
train_step spend 0.6437217570055509 time
policy_value spend 0.2199023959983606 time
train_step spend 0.6465167860005749 time
policy_value spend 0.22001891300169518 time
train_step spend 0.6420635419999599 time
policy_value spend 0.22039863700047135 time
train_step spend 0.6428363769955467 time
policy_value spend 0.2201616099991952 time
train_step spend 0.6427055790045415 time
policy_value spend 0.219959852998727 time
kl:0.00957,lr_multiplier:11.391,loss:4.563504695892334,entropy:5.53139066696167,explained_var_old:0.981572151,explained_var_new:0.984084189
output spend 0.00014776399621041492 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070411050037364475 time
recovery_state_mcts_prob spend 0.27178352099872427 time
state_batch spend 0.0018092219979735091 time
mcts_probs_batch spend 0.006630370000493713 time
winner_batch spend 0.00029661600274266675 time
policy_value spend 0.22132910599611932 time
train_step spend 0.6424982560056378 time
policy_value spend 0.22010612399753882 time
train_step spend 0.6436429129971657 time
policy_value spend 0.21972385400295025 time
train_step spend 0.6415441749995807 time
policy_value spend 0.21979767899756553 time
train_step spend 0.6415635640005348 time
policy_value spend 0.21928647100139642 time
train_step spend 0.6405600850048359 time
policy_value spend 0.22916536199772963 time
kl:0.00669,lr_multiplier:11.391,loss:4.550860404968262,entropy:5.519468307495117,explained_var_old:0.983757496,explained_var_new:0.988126636
output spend 0.00015263299428625032 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010706931003369391 time
recovery_state_mcts_prob spend 0.29979084800288547 time
state_batch spend 0.0022963899973547086 time
mcts_probs_batch spend 0.012963105000380892 time
winner_batch spend 0.000285750997136347 time
policy_value spend 0.2350370570056839 time
train_step spend 0.6477210140001262 time
policy_value spend 0.2210568049995345 time
train_step spend 0.6457784939993871 time
policy_value spend 0.2196959809953114 time
train_step spend 0.6413018929961254 time
policy_value spend 0.21901883000100497 time
train_step spend 0.6412985639981343 time
policy_value spend 0.2196280479984125 time
train_step spend 0.6403522220061859 time
policy_value spend 0.21878734499478014 time
kl:0.01668,lr_multiplier:11.391,loss:4.629456520080566,entropy:5.593840599060059,explained_var_old:0.988833308,explained_var_new:0.993882000
output spend 0.00014742399798706174 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009905718005029485 time
recovery_state_mcts_prob spend 0.2723305769977742 time
state_batch spend 0.0017996460010181181 time
mcts_probs_batch spend 0.0076492119987960905 time
winner_batch spend 0.0002835650011547841 time
policy_value spend 0.21538318599777995 time
train_step spend 0.629639305996534 time
policy_value spend 0.2204911090011592 time
train_step spend 0.6302379120024852 time
policy_value spend 0.2153805080015445 time
train_step spend 0.6308233899981133 time
policy_value spend 0.21545250700000906 time
train_step spend 0.6311010689969407 time
policy_value spend 0.21543694099818822 time
train_step spend 0.6309703549995902 time
policy_value spend 0.21546882900292985 time
kl:0.00652,lr_multiplier:11.391,loss:4.536001682281494,entropy:5.456653118133545,explained_var_old:0.981145680,explained_var_new:0.982849836
output spend 0.0001540809971629642 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008347581002453808 time
recovery_state_mcts_prob spend 0.27171495399670675 time
state_batch spend 0.0017534910002723336 time
mcts_probs_batch spend 0.006449432999943383 time
winner_batch spend 0.00028993799787713215 time
policy_value spend 0.21561924100387841 time
train_step spend 0.6316342930003884 time
policy_value spend 0.21494303199870046 time
train_step spend 0.6305477310015704 time
policy_value spend 0.21741148099681595 time
train_step spend 0.6381271899954299 time
policy_value spend 0.21833464100200217 time
train_step spend 0.6387433829950169 time
policy_value spend 0.2181314680055948 time
train_step spend 0.6401189079988399 time
policy_value spend 0.2184928040005616 time
kl:0.00809,lr_multiplier:11.391,loss:4.536581993103027,entropy:5.501387596130371,explained_var_old:0.981206477,explained_var_new:0.985927880
output spend 0.00016445799701614305 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00845315200422192 time
recovery_state_mcts_prob spend 0.2749569289953797 time
state_batch spend 0.001867293001851067 time
mcts_probs_batch spend 0.004528941004537046 time
winner_batch spend 0.00029916499624960124 time
policy_value spend 0.21721288999833632 time
train_step spend 0.638077126997814 time
policy_value spend 0.2184738260039012 time
train_step spend 0.638372421002714 time
policy_value spend 0.2187120159942424 time
train_step spend 0.6374026490011602 time
policy_value spend 0.21828445999562973 time
train_step spend 0.6388495060018613 time
policy_value spend 0.21837672800029395 time
train_step spend 0.6387153530013165 time
policy_value spend 0.2189768259995617 time
kl:0.00799,lr_multiplier:11.391,loss:4.547201633453369,entropy:5.510610580444336,explained_var_old:0.984665096,explained_var_new:0.986919761
output spend 0.0001567759973113425 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008052044999203645 time
recovery_state_mcts_prob spend 0.2665286549963639 time
state_batch spend 0.0019053180003538728 time
mcts_probs_batch spend 0.00648661500599701 time
winner_batch spend 0.00028465799550758675 time
policy_value spend 0.22003550799854565 time
train_step spend 0.6429365090007195 time
policy_value spend 0.21908086800249293 time
train_step spend 0.6419905430011568 time
policy_value spend 0.2195424550009193 time
train_step spend 0.641461494997202 time
policy_value spend 0.21970794999651844 time
train_step spend 0.641328521000105 time
policy_value spend 0.21980589499435155 time
train_step spend 0.6416790290022618 time
policy_value spend 0.21895945899450453 time
kl:0.01659,lr_multiplier:11.391,loss:4.627965450286865,entropy:5.556440353393555,explained_var_old:0.989890933,explained_var_new:0.990984738
output spend 0.00016130899894051254 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007793357995979022 time
recovery_state_mcts_prob spend 0.27919309600110864 time
state_batch spend 0.001838504002080299 time
mcts_probs_batch spend 0.00651127199671464 time
winner_batch spend 0.0003039270013687201 time
policy_value spend 0.2192716530043981 time
train_step spend 0.6424633240021649 time
policy_value spend 0.2200553719958407 time
train_step spend 0.6423715939963586 time
policy_value spend 0.21907258999999613 time
train_step spend 0.6404129660004401 time
policy_value spend 0.2190678900005878 time
train_step spend 0.64037046500016 time
policy_value spend 0.2186249910009792 time
train_step spend 0.6407173039988265 time
policy_value spend 0.21850397299567703 time
kl:0.01062,lr_multiplier:11.391,loss:4.563357353210449,entropy:5.505990028381348,explained_var_old:0.992337584,explained_var_new:0.996137798
output spend 0.0001573209956404753 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007420410998747684 time
recovery_state_mcts_prob spend 0.27014397099992493 time
state_batch spend 0.0018115619968739338 time
mcts_probs_batch spend 0.007607113002450205 time
winner_batch spend 0.0005330830026650801 time
policy_value spend 0.21861610600171844 time
train_step spend 0.6404341890010983 time
policy_value spend 0.2194813520036405 time
train_step spend 0.6403254020042368 time
policy_value spend 0.21892592599760974 time
train_step spend 0.641205899999477 time
policy_value spend 0.21824276000552345 time
train_step spend 0.6401147249998758 time
policy_value spend 0.21853139599988936 time
train_step spend 0.639946929004509 time
policy_value spend 0.21353878499940038 time
kl:0.01225,lr_multiplier:11.391,loss:4.612839698791504,entropy:5.552889347076416,explained_var_old:0.979611218,explained_var_new:0.988853276
output spend 0.0001440579944755882 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007333686997299083 time
recovery_state_mcts_prob spend 0.2700340419978602 time
state_batch spend 0.00223492800432723 time
mcts_probs_batch spend 0.005607103994407225 time
winner_batch spend 0.0002927759996964596 time
policy_value spend 0.21256514400010929 time
train_step spend 0.6273522679985035 time
policy_value spend 0.2148615219994099 time
train_step spend 0.6281327000033343 time
policy_value spend 0.2145942439965438 time
train_step spend 0.6253835890020127 time
policy_value spend 0.2135806340011186 time
train_step spend 0.6248541259992635 time
policy_value spend 0.21326190199761186 time
train_step spend 0.6250403239973821 time
policy_value spend 0.21419992799928878 time
kl:0.01954,lr_multiplier:11.391,loss:4.529392242431641,entropy:5.48136568069458,explained_var_old:0.984700263,explained_var_new:0.988692403
output spend 0.0001447789982194081 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0072808459954103455 time
recovery_state_mcts_prob spend 0.2616614990038215 time
state_batch spend 0.001780173995939549 time
mcts_probs_batch spend 0.006005432005622424 time
winner_batch spend 0.00031277299422072247 time
policy_value spend 0.21511011400434654 time
train_step spend 0.6418878529948415 time
policy_value spend 0.22601692800526507 time
train_step spend 0.6643870129992138 time
policy_value spend 0.22051970900065498 time
train_step spend 0.6414506039945991 time
policy_value spend 0.2182643280029879 time
train_step spend 0.638231012999313 time
policy_value spend 0.2192011779989116 time
train_step spend 0.6388085920043522 time
policy_value spend 0.21829608299594838 time
kl:0.00740,lr_multiplier:11.391,loss:4.589369773864746,entropy:5.516575336456299,explained_var_old:0.990233064,explained_var_new:0.994630098
output spend 0.00015303899999707937 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00805137399584055 time
recovery_state_mcts_prob spend 0.2806712170058745 time
state_batch spend 0.001783231993613299 time
mcts_probs_batch spend 0.006753325003955979 time
winner_batch spend 0.0003148749965475872 time
policy_value spend 0.218670258000202 time
train_step spend 0.6388459040026646 time
policy_value spend 0.21810100799484644 time
train_step spend 0.6385854379986995 time
policy_value spend 0.2179918340043514 time
train_step spend 0.6394154289955623 time
policy_value spend 0.21830095300538233 time
train_step spend 0.6393322259973502 time
policy_value spend 0.21841789000609424 time
train_step spend 0.6409709669969743 time
policy_value spend 0.220199045004847 time
kl:0.00665,lr_multiplier:11.391,loss:4.508359432220459,entropy:5.5046586990356445,explained_var_old:0.991872728,explained_var_new:0.996675014
output spend 0.0001501950027886778 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007984479998413008 time
recovery_state_mcts_prob spend 0.2784320490027312 time
state_batch spend 0.0019268830001237802 time
mcts_probs_batch spend 0.004883534995315131 time
winner_batch spend 0.0003203209998901002 time
policy_value spend 0.2203657430000021 time
train_step spend 0.6441812039993238 time
policy_value spend 0.2194529219996184 time
train_step spend 0.6435217999969609 time
policy_value spend 0.21974903600494144 time
train_step spend 0.6427514149982017 time
policy_value spend 0.21975881900289096 time
train_step spend 0.6432986410000012 time
policy_value spend 0.21980025000084424 time
train_step spend 0.6436352200034889 time
policy_value spend 0.21978180199948838 time
kl:0.00648,lr_multiplier:11.391,loss:4.580574989318848,entropy:5.4963483810424805,explained_var_old:0.983298779,explained_var_new:0.990333915
output spend 0.00014982900029281154 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007217906997539103 time
recovery_state_mcts_prob spend 0.272392219005269 time
state_batch spend 0.0018939259971375577 time
mcts_probs_batch spend 0.007096105997334234 time
winner_batch spend 0.0002995140021084808 time
policy_value spend 0.2202579209988471 time
train_step spend 0.6434377130062785 time
policy_value spend 0.22045342799538048 time
train_step spend 0.6413476829984575 time
policy_value spend 0.21903682599804597 time
train_step spend 0.6407320229991456 time
policy_value spend 0.2189896720010438 time
train_step spend 0.6406110109965084 time
policy_value spend 0.2185837669967441 time
train_step spend 0.6416443630005233 time
policy_value spend 0.2184023910012911 time
kl:0.01575,lr_multiplier:11.391,loss:4.523101806640625,entropy:5.513720989227295,explained_var_old:0.991336524,explained_var_new:0.998251259
output spend 0.0001469589988118969 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008027957002923358 time
recovery_state_mcts_prob spend 0.2802444419940002 time
state_batch spend 0.0019353630050318316 time
mcts_probs_batch spend 0.006743393998476677 time
winner_batch spend 0.00028746000316459686 time
policy_value spend 0.22057194799708668 time
train_step spend 0.6403844550004578 time
policy_value spend 0.2189646340048057 time
train_step spend 0.639629839999543 time
policy_value spend 0.21905423600401264 time
train_step spend 0.6395844619983109 time
policy_value spend 0.21894109199638478 time
train_step spend 0.640355046998593 time
policy_value spend 0.22532527500152355 time
train_step spend 0.6320193939973251 time
policy_value spend 0.2137304500065511 time
kl:0.01097,lr_multiplier:11.391,loss:4.542499542236328,entropy:5.492805480957031,explained_var_old:0.992276132,explained_var_new:0.999061108
output spend 0.00014746699889656156 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007106174001819454 time
recovery_state_mcts_prob spend 0.2717160550018889 time
state_batch spend 0.0023494699998991564 time
mcts_probs_batch spend 0.007856112999434117 time
winner_batch spend 0.0004303480018279515 time
policy_value spend 0.21531384399713716 time
train_step spend 0.626516932999948 time
policy_value spend 0.21316300200123806 time
train_step spend 0.6269001480031875 time
policy_value spend 0.21405234999838285 time
train_step spend 0.6256157559982967 time
policy_value spend 0.21381834000203526 time
train_step spend 0.626882486998511 time
policy_value spend 0.21401960300136125 time
train_step spend 0.626814708004531 time
policy_value spend 0.2137530969994259 time
kl:0.01009,lr_multiplier:11.391,loss:4.56453800201416,entropy:5.493589401245117,explained_var_old:0.980911851,explained_var_new:0.987795293
output spend 0.00015407399769173935 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007299696000700351 time
recovery_state_mcts_prob spend 0.2724670939933276 time
state_batch spend 0.0017336970049655065 time
mcts_probs_batch spend 0.007298694996279664 time
winner_batch spend 0.0003758470047614537 time
policy_value spend 0.21447381299367407 time
train_step spend 0.6268574209971121 time
policy_value spend 0.21327460100292228 time
train_step spend 0.6365123220020905 time
policy_value spend 0.2188347050032462 time
train_step spend 0.6397966360018472 time
policy_value spend 0.21859675699670333 time
train_step spend 0.6408182320010383 time
policy_value spend 0.2189397529946291 time
train_step spend 0.6390469749967451 time
policy_value spend 0.21872299000096973 time
kl:0.00566,lr_multiplier:11.391,loss:4.501591205596924,entropy:5.497807025909424,explained_var_old:0.991527259,explained_var_new:0.996922672
output spend 0.00014498699601972476 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009920322998368647 time
recovery_state_mcts_prob spend 0.26962473500316264 time
state_batch spend 0.0017910719980136491 time
mcts_probs_batch spend 0.006130107001808938 time
winner_batch spend 0.0002831979945767671 time
policy_value spend 0.21918804100278066 time
train_step spend 0.6420199499989394 time
policy_value spend 0.21820435400150018 time
train_step spend 0.6397201219951967 time
policy_value spend 0.21850847000314388 time
train_step spend 0.6392941089943633 time
policy_value spend 0.22329831000388367 time
train_step spend 0.6393225110005005 time
policy_value spend 0.2184396519951406 time
train_step spend 0.6408812750014476 time
policy_value spend 0.2196719240018865 time
kl:0.02331,lr_multiplier:11.391,loss:4.565361499786377,entropy:5.501744747161865,explained_var_old:0.974816144,explained_var_new:0.983253181
output spend 0.00015107900253497064 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007298461001482792 time
recovery_state_mcts_prob spend 0.27908790500077885 time
state_batch spend 0.0018263620004290715 time
mcts_probs_batch spend 0.006674566000583582 time
winner_batch spend 0.00032561999978497624 time
policy_value spend 0.2195321769977454 time
train_step spend 0.6419698280005832 time
policy_value spend 0.22209198599739466 time
train_step spend 0.6412363269992056 time
policy_value spend 0.21970026000053622 time
train_step spend 0.6408562130018254 time
policy_value spend 0.21935263599880273 time
train_step spend 0.6413415310016717 time
policy_value spend 0.21930101000180002 time
train_step spend 0.6414208359929034 time
policy_value spend 0.2196718250052072 time
kl:0.02568,lr_multiplier:11.391,loss:4.531806468963623,entropy:5.47823429107666,explained_var_old:0.979533195,explained_var_new:0.988491833
output spend 0.00027412999770604074 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010427851004351396 time
recovery_state_mcts_prob spend 0.2947410209962982 time
state_batch spend 0.0022658420057268813 time
mcts_probs_batch spend 0.006136997995781712 time
winner_batch spend 0.00030151299870340154 time
policy_value spend 0.23272561799967661 time
train_step spend 0.6611797830046271 time
policy_value spend 0.2207169379980769 time
train_step spend 0.6399449090022244 time
policy_value spend 0.2184342119944631 time
train_step spend 0.638914711002144 time
policy_value spend 0.21942021699942416 time
train_step spend 0.6397165739981574 time
policy_value spend 0.21939215100428555 time
train_step spend 0.6385795680034789 time
policy_value spend 0.21901058300136356 time
kl:0.04181,lr_multiplier:7.594,loss:4.534152984619141,entropy:5.494240760803223,explained_var_old:0.995544612,explained_var_new:0.997264624
output spend 0.0001488900015829131 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007147623000491876 time
recovery_state_mcts_prob spend 0.28544792399770813 time
state_batch spend 0.002105065002979245 time
mcts_probs_batch spend 0.0068177579960320145 time
winner_batch spend 0.00028661700343945995 time
policy_value spend 0.21854200799862156 time
train_step spend 0.6383736380012124 time
policy_value spend 0.21900917799939634 time
train_step spend 0.6393148380011553 time
policy_value spend 0.21807148100197082 time
train_step spend 0.6387694820004981 time
policy_value spend 0.21778718999848934 time
train_step spend 0.6382221160019981 time
policy_value spend 0.2181779589955113 time
train_step spend 0.6282363499994972 time
policy_value spend 0.21427078900160268 time
kl:0.01672,lr_multiplier:7.594,loss:4.518514633178711,entropy:5.487480163574219,explained_var_old:0.990571380,explained_var_new:0.992091060
output spend 0.0001714350000838749 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00690067200048361 time
recovery_state_mcts_prob spend 0.2657701909993193 time
state_batch spend 0.00195538599655265 time
mcts_probs_batch spend 0.0072562740024295636 time
winner_batch spend 0.00036076099786441773 time
policy_value spend 0.21455347400478786 time
train_step spend 0.6276270989983459 time
policy_value spend 0.21607411299919477 time
train_step spend 0.6280795279963058 time
policy_value spend 0.2145877900038613 time
train_step spend 0.6283968779971474 time
policy_value spend 0.21788227900105994 time
train_step spend 0.6275040239997907 time
policy_value spend 0.21419911500561284 time
train_step spend 0.6276163860020461 time
policy_value spend 0.21420650700019905 time
kl:0.00570,lr_multiplier:11.391,loss:4.52509069442749,entropy:5.494502067565918,explained_var_old:0.996065080,explained_var_new:0.999197662
output spend 0.00017244100308744237 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006746714003384113 time
recovery_state_mcts_prob spend 0.2676494859988452 time
state_batch spend 0.0018637449975358322 time
mcts_probs_batch spend 0.011823378001281526 time
winner_batch spend 0.0003490529998089187 time
policy_value spend 0.21765671300090617 time
train_step spend 0.6274325470003532 time
policy_value spend 0.2180830680008512 time
train_step spend 0.6385667739959899 time
policy_value spend 0.21865425500436686 time
train_step spend 0.6395344789998489 time
policy_value spend 0.21940285899472656 time
train_step spend 0.63941156600049 time
policy_value spend 0.2192742580009508 time
train_step spend 0.6395126369970967 time
policy_value spend 0.21867252299853135 time
kl:0.01769,lr_multiplier:11.391,loss:4.524512767791748,entropy:5.480227947235107,explained_var_old:0.992076397,explained_var_new:0.995223403
output spend 0.000148248000186868 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007218694998300634 time
recovery_state_mcts_prob spend 0.27673968900489854 time
state_batch spend 0.001820900994061958 time
mcts_probs_batch spend 0.005516159006219823 time
winner_batch spend 0.0004946599947288632 time
policy_value spend 0.21864974300115136 time
train_step spend 0.6414776899982826 time
policy_value spend 0.22156502900179476 time
train_step spend 0.6421536810012185 time
policy_value spend 0.21882693899533479 time
train_step spend 0.6395457499966142 time
policy_value spend 0.21860651400493225 time
train_step spend 0.6401360240051872 time
policy_value spend 0.21888813999976264 time
train_step spend 0.6416715710001881 time
policy_value spend 0.2193031599963433 time
kl:0.01486,lr_multiplier:11.391,loss:4.484004974365234,entropy:5.475595951080322,explained_var_old:0.988554657,explained_var_new:0.994700432
output spend 0.00018950500088976696 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008387226997001562 time
recovery_state_mcts_prob spend 0.2729951470028027 time
state_batch spend 0.0018297970018466003 time
mcts_probs_batch spend 0.007155445993703324 time
winner_batch spend 0.00028314399969531223 time
policy_value spend 0.21933902599994326 time
train_step spend 0.6412530000015977 time
policy_value spend 0.21944723300111946 time
train_step spend 0.6414374050000333 time
policy_value spend 0.21919264800089877 time
train_step spend 0.6414118489992688 time
policy_value spend 0.2189460270019481 time
train_step spend 0.6424365190032404 time
policy_value spend 0.2196430149997468 time
train_step spend 0.6417389639973408 time
policy_value spend 0.21936796200316167 time
kl:0.02053,lr_multiplier:11.391,loss:4.528204441070557,entropy:5.468084812164307,explained_var_old:0.979414165,explained_var_new:0.986193359
output spend 0.0001489610003773123 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008196724003937561 time
recovery_state_mcts_prob spend 0.28239165199920535 time
state_batch spend 0.0019259969994891435 time
mcts_probs_batch spend 0.006542431998241227 time
winner_batch spend 0.00040879700100049376 time
policy_value spend 0.2196090860015829 time
train_step spend 0.6436200179959997 time
policy_value spend 0.21853748200373957 time
train_step spend 0.6393867890001275 time
policy_value spend 0.2190314559993567 time
train_step spend 0.6395743219982251 time
policy_value spend 0.21850169200479286 time
train_step spend 0.6386548029986443 time
policy_value spend 0.21849168199696578 time
train_step spend 0.639832587003184 time
policy_value spend 0.2176981979937409 time
kl:0.04203,lr_multiplier:7.594,loss:4.48512601852417,entropy:5.449529647827148,explained_var_old:0.985814631,explained_var_new:0.991263926
output spend 0.00015810399781912565 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008015686005819589 time
recovery_state_mcts_prob spend 0.2794989739995799 time
state_batch spend 0.0021135649949428625 time
mcts_probs_batch spend 0.004511209001066163 time
winner_batch spend 0.0002905180008383468 time
policy_value spend 0.21724544600147055 time
train_step spend 0.6393027480007731 time
policy_value spend 0.21864339699823176 time
train_step spend 0.6393633859988768 time
policy_value spend 0.21842268399632303 time
train_step spend 0.6379622669992386 time
policy_value spend 0.21822938499826705 time
train_step spend 0.6388578410042101 time
policy_value spend 0.21549320399935823 time
train_step spend 0.6287427589995787 time
policy_value spend 0.2149934379995102 time
kl:0.01743,lr_multiplier:7.594,loss:4.522491931915283,entropy:5.52425479888916,explained_var_old:0.992974520,explained_var_new:0.995887697
output spend 0.00018336799985263497 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007857127995521296 time
recovery_state_mcts_prob spend 0.2614395720011089 time
state_batch spend 0.0019553259990061633 time
mcts_probs_batch spend 0.006333616001938935 time
winner_batch spend 0.0002812040038406849 time
policy_value spend 0.2157218840002315 time
train_step spend 0.6294650899944827 time
policy_value spend 0.21549970500200288 time
train_step spend 0.628914631997759 time
policy_value spend 0.21513571799732745 time
train_step spend 0.6459056940002483 time
policy_value spend 0.22830048800096847 time
train_step spend 0.656906746000459 time
policy_value spend 0.2165881220062147 time
train_step spend 0.6311188699983177 time
policy_value spend 0.21464805400319165 time
kl:0.00607,lr_multiplier:11.391,loss:4.557141304016113,entropy:5.490240573883057,explained_var_old:0.992560089,explained_var_new:0.994778275
output spend 0.00017512899648863822 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007673619002162013 time
recovery_state_mcts_prob spend 0.2637204369966639 time
state_batch spend 0.0019286710012238473 time
mcts_probs_batch spend 0.006524584998260252 time
winner_batch spend 0.00031366199982585385 time
policy_value spend 0.21507677100453293 time
train_step spend 0.6320088270003907 time
policy_value spend 0.21872236600029282 time
train_step spend 0.6395042250005645 time
policy_value spend 0.21882277699478436 time
train_step spend 0.639724964996276 time
policy_value spend 0.21868054800143 time
train_step spend 0.6399499669932993 time
policy_value spend 0.2197356460019364 time
train_step spend 0.639383996000106 time
policy_value spend 0.21850980599992909 time
kl:0.02407,lr_multiplier:11.391,loss:4.519653797149658,entropy:5.467105865478516,explained_var_old:0.987650275,explained_var_new:0.994376242
output spend 0.00014476600335910916 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00915974700183142 time
recovery_state_mcts_prob spend 0.2774379399997997 time
state_batch spend 0.0018458429985912517 time
mcts_probs_batch spend 0.0067406480011413805 time
winner_batch spend 0.00035724099871004 time
policy_value spend 0.21860912499687402 time
train_step spend 0.6401341559976572 time
policy_value spend 0.2180513819985208 time
train_step spend 0.6389209089975338 time
policy_value spend 0.2191134390013758 time
train_step spend 0.6380331539985491 time
policy_value spend 0.21917630400275812 time
train_step spend 0.6400083920016186 time
policy_value spend 0.21826734700152883 time
train_step spend 0.6406149879985605 time
policy_value spend 0.21867409099650104 time
kl:0.00629,lr_multiplier:11.391,loss:4.530310153961182,entropy:5.4538726806640625,explained_var_old:0.986057341,explained_var_new:0.991176844
output spend 0.00018158600141759962 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0069852140004513785 time
recovery_state_mcts_prob spend 0.2705087089998415 time
state_batch spend 0.001975117003894411 time
mcts_probs_batch spend 0.006493740998848807 time
winner_batch spend 0.0002996580005856231 time
policy_value spend 0.21937515399622498 time
train_step spend 0.6404962270025862 time
policy_value spend 0.21936113899573684 time
train_step spend 0.640770429999975 time
policy_value spend 0.2186906499991892 time
train_step spend 0.6407655610018992 time
policy_value spend 0.21983099399949424 time
train_step spend 0.6423678410064895 time
policy_value spend 0.2186149779954576 time
train_step spend 0.640387652994832 time
policy_value spend 0.21939854600350372 time
kl:0.03078,lr_multiplier:11.391,loss:4.572173118591309,entropy:5.505521297454834,explained_var_old:0.988981307,explained_var_new:0.997019410
output spend 0.00015105099737411365 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007404823001706973 time
recovery_state_mcts_prob spend 0.28473319899785565 time
state_batch spend 0.0019435760041233152 time
mcts_probs_batch spend 0.006764457000826951 time
winner_batch spend 0.00029828799597453326 time
policy_value spend 0.21901566199812805 time
train_step spend 0.6406581670016749 time
policy_value spend 0.2196457179961726 time
train_step spend 0.6389898990018992 time
policy_value spend 0.21818454699678114 time
train_step spend 0.6393238689997816 time
policy_value spend 0.2179823429978569 time
train_step spend 0.6389984720008215 time
policy_value spend 0.21875762099807616 time
train_step spend 0.6395486219989834 time
policy_value spend 0.21804676600004314 time
kl:0.02352,lr_multiplier:11.391,loss:4.552327632904053,entropy:5.470791816711426,explained_var_old:0.981637478,explained_var_new:0.988505423
output spend 0.00014698500308440998 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010859663001610897 time
recovery_state_mcts_prob spend 0.26864964100241195 time
state_batch spend 0.0021423860016511753 time
mcts_probs_batch spend 0.01592952400096692 time
winner_batch spend 0.0003421689980314113 time
policy_value spend 0.22066520799853606 time
train_step spend 0.6436192129986011 time
policy_value spend 0.21826444000180345 time
train_step spend 0.6393165560002672 time
policy_value spend 0.2187490050055203 time
train_step spend 0.6389080410008319 time
policy_value spend 0.21844044300087262 time
train_step spend 0.6361530590002076 time
policy_value spend 0.21582349800155498 time
train_step spend 0.628234921998228 time
policy_value spend 0.21514473400020506 time
kl:0.02393,lr_multiplier:11.391,loss:4.519726753234863,entropy:5.503019332885742,explained_var_old:0.990080357,explained_var_new:0.997609913
output spend 0.00014611100050387904 time
已保存最新模型
current self-play batch: 600
load data begin
已加载数据
step i 372: 
random.sample spend 0.010279629001161084 time
recovery_state_mcts_prob spend 0.27725404300144874 time
state_batch spend 0.0020276579962228425 time
mcts_probs_batch spend 0.006648339003731962 time
winner_batch spend 0.00032104499405249953 time
policy_value spend 0.2161136830036412 time
train_step spend 0.6649361130039324 time
policy_value spend 0.220253880994278 time
train_step spend 0.6312890729968785 time
policy_value spend 0.21459173699986422 time
train_step spend 0.6292060830019182 time
policy_value spend 0.21532445499906316 time
train_step spend 0.6292214029963361 time
policy_value spend 0.21461050300422357 time
train_step spend 0.6286334510004963 time
policy_value spend 0.21522307299892418 time
kl:0.02175,lr_multiplier:11.391,loss:4.499418258666992,entropy:5.463632583618164,explained_var_old:0.989244938,explained_var_new:0.993931651
output spend 0.00014585600001737475 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008111674003885128 time
recovery_state_mcts_prob spend 0.2760721550002927 time
state_batch spend 0.0019794179970631376 time
mcts_probs_batch spend 0.004756330999953207 time
winner_batch spend 0.00033060200075851753 time
policy_value spend 0.21503680900059408 time
train_step spend 0.6423424600070575 time
policy_value spend 0.21780522499466315 time
train_step spend 0.638490201003151 time
policy_value spend 0.21843587899638806 time
train_step spend 0.6380434230013634 time
policy_value spend 0.21848676499939756 time
train_step spend 0.6395495449978625 time
policy_value spend 0.21919295500265434 time
train_step spend 0.6391326309967553 time
policy_value spend 0.21930429900385207 time
kl:0.00904,lr_multiplier:11.391,loss:4.510554313659668,entropy:5.476249694824219,explained_var_old:0.990658343,explained_var_new:0.995562017
output spend 0.0001612920023035258 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008458902004349511 time
recovery_state_mcts_prob spend 0.2694037289984408 time
state_batch spend 0.00207928800227819 time
mcts_probs_batch spend 0.006384981999872252 time
winner_batch spend 0.000364218998583965 time
policy_value spend 0.21741320099681616 time
train_step spend 0.6404124740001862 time
policy_value spend 0.21889723899948876 time
train_step spend 0.6442217479998362 time
policy_value spend 0.2182689789988217 time
train_step spend 0.6388837920021615 time
policy_value spend 0.21837891400355147 time
train_step spend 0.6402017700020224 time
policy_value spend 0.21887389900075505 time
train_step spend 0.6399355819958146 time
policy_value spend 0.21882317500421777 time
kl:0.01051,lr_multiplier:11.391,loss:4.519138336181641,entropy:5.437829971313477,explained_var_old:0.989440441,explained_var_new:0.992735505
output spend 0.000192478000826668 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007708751996688079 time
recovery_state_mcts_prob spend 0.28059512600157177 time
state_batch spend 0.0018428429975756444 time
mcts_probs_batch spend 0.004629360999388155 time
winner_batch spend 0.00032050799927674234 time
policy_value spend 0.21884080300515052 time
train_step spend 0.6734725190035533 time
policy_value spend 0.2322411139975884 time
train_step spend 0.6435934430046473 time
policy_value spend 0.2192162589999498 time
train_step spend 0.6392873590011732 time
policy_value spend 0.2186765469959937 time
train_step spend 0.6402887570002349 time
policy_value spend 0.21984642199822702 time
train_step spend 0.6401486799950362 time
policy_value spend 0.21907003300293582 time
kl:0.01088,lr_multiplier:11.391,loss:4.500588893890381,entropy:5.458948135375977,explained_var_old:0.986410797,explained_var_new:0.993146956
output spend 0.00018261399964103475 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0069517029987764545 time
recovery_state_mcts_prob spend 0.2914997219995712 time
state_batch spend 0.0020061899995198473 time
mcts_probs_batch spend 0.007215607001853641 time
winner_batch spend 0.00035773999843513593 time
policy_value spend 0.21872395100217545 time
train_step spend 0.6390004080021754 time
policy_value spend 0.21806804499647114 time
train_step spend 0.6391955989965936 time
policy_value spend 0.2188901560002705 time
train_step spend 0.6399441940011457 time
policy_value spend 0.21843646100023761 time
train_step spend 0.6398373089978122 time
policy_value spend 0.21904406899557216 time
train_step spend 0.6393362910021096 time
policy_value spend 0.21855440599756548 time
kl:0.00830,lr_multiplier:11.391,loss:4.488495349884033,entropy:5.4618940353393555,explained_var_old:0.985707223,explained_var_new:0.995048046
output spend 0.00016745000175433233 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070823290006956086 time
recovery_state_mcts_prob spend 0.27454107900121016 time
state_batch spend 0.0019385980049264617 time
mcts_probs_batch spend 0.006871314995805733 time
winner_batch spend 0.0003185780005878769 time
policy_value spend 0.22021469900209922 time
train_step spend 0.6406820060001337 time
policy_value spend 0.21828109500347637 time
train_step spend 0.6399242759944173 time
policy_value spend 0.21862274700106354 time
train_step spend 0.6379138920019614 time
policy_value spend 0.21846931399340974 time
train_step spend 0.6302991320044384 time
policy_value spend 0.21497849199658958 time
train_step spend 0.6284888920054073 time
policy_value spend 0.21542878499894869 time
kl:0.01380,lr_multiplier:11.391,loss:4.499990463256836,entropy:5.449474334716797,explained_var_old:0.991190076,explained_var_new:0.992051661
output spend 0.0001515199983259663 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00648967699817149 time
recovery_state_mcts_prob spend 0.2699470500010648 time
state_batch spend 0.0017719870011205785 time
mcts_probs_batch spend 0.00604393299727235 time
winner_batch spend 0.00027826100267702714 time
policy_value spend 0.2153767709969543 time
train_step spend 0.6283137840000563 time
policy_value spend 0.21501677900232607 time
train_step spend 0.6284201679955004 time
policy_value spend 0.21434099999896716 time
train_step spend 0.6271347139991121 time
policy_value spend 0.21427055100502912 time
train_step spend 0.6282719930022722 time
policy_value spend 0.21427973799291067 time
train_step spend 0.6286663400023826 time
policy_value spend 0.2141443509972305 time
kl:0.01876,lr_multiplier:11.391,loss:4.456897258758545,entropy:5.423117637634277,explained_var_old:0.997647822,explained_var_new:0.999303341
output spend 0.000143596000270918 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007243431995448191 time
recovery_state_mcts_prob spend 0.28357567400234984 time
state_batch spend 0.002221255999756977 time
mcts_probs_batch spend 0.004961494996678084 time
winner_batch spend 0.0002945160013041459 time
policy_value spend 0.2199057360048755 time
train_step spend 0.6234794080010033 time
policy_value spend 0.21272094499727245 time
train_step spend 0.6223314990056679 time
policy_value spend 0.21230483599356376 time
train_step spend 0.6228643380018184 time
policy_value spend 0.21479235599690583 time
train_step spend 0.6234701610010234 time
policy_value spend 0.21313092399941524 time
train_step spend 0.6219222859945148 time
policy_value spend 0.21312447200034512 time
kl:0.01283,lr_multiplier:11.391,loss:4.487739562988281,entropy:5.445324897766113,explained_var_old:0.981185675,explained_var_new:0.985399187
output spend 0.0001459259947296232 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007640144998731557 time
recovery_state_mcts_prob spend 0.26526316000672523 time
state_batch spend 0.0018410829943604767 time
mcts_probs_batch spend 0.006350144001771696 time
winner_batch spend 0.0003127800009679049 time
policy_value spend 0.21403499499865575 time
train_step spend 0.6270584940066328 time
policy_value spend 0.21404842899937648 time
train_step spend 0.62219759200525 time
policy_value spend 0.21318865999637637 time
train_step spend 0.6426671730005182 time
policy_value spend 0.22050064799987013 time
train_step spend 0.6428097870011698 time
policy_value spend 0.21999442399828695 time
train_step spend 0.6424381489996449 time
policy_value spend 0.21950834799645236 time
kl:0.00755,lr_multiplier:11.391,loss:4.481621742248535,entropy:5.4660325050354,explained_var_old:0.995369971,explained_var_new:0.999302030
output spend 0.00014759299665456638 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01420934699854115 time
recovery_state_mcts_prob spend 0.28354912800568854 time
state_batch spend 0.0021176899972488172 time
mcts_probs_batch spend 0.006415219999325927 time
winner_batch spend 0.0002878140003303997 time
policy_value spend 0.2210946370032616 time
train_step spend 0.6432561460023862 time
policy_value spend 0.2203635600017151 time
train_step spend 0.6429468330024974 time
policy_value spend 0.22054472799936775 time
train_step spend 0.644278285006294 time
policy_value spend 0.21911146899947198 time
train_step spend 0.6433089740021387 time
policy_value spend 0.21920072599459672 time
train_step spend 0.6462543019952136 time
policy_value spend 0.22024264500214485 time
kl:0.01253,lr_multiplier:11.391,loss:4.532907009124756,entropy:5.524935722351074,explained_var_old:0.993511856,explained_var_new:0.998575509
output spend 0.00015305100532714278 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007739624998066574 time
recovery_state_mcts_prob spend 0.2747352489968762 time
state_batch spend 0.0020003579993499443 time
mcts_probs_batch spend 0.006342414002574515 time
winner_batch spend 0.00033416000223951414 time
policy_value spend 0.22106701599841472 time
train_step spend 0.6461225599996396 time
policy_value spend 0.22145027499936987 time
train_step spend 0.6443310200047563 time
policy_value spend 0.22064982899610186 time
train_step spend 0.6497204129991587 time
policy_value spend 0.22033640099834884 time
train_step spend 0.6456284899977618 time
policy_value spend 0.22040096700220602 time
train_step spend 0.6450283379963366 time
policy_value spend 0.2209902989998227 time
kl:0.01533,lr_multiplier:11.391,loss:4.474645137786865,entropy:5.451654434204102,explained_var_old:0.989667356,explained_var_new:0.992019653
output spend 0.00015965400234563276 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007973558000230696 time
recovery_state_mcts_prob spend 0.27413134100061143 time
state_batch spend 0.0019261740017100237 time
mcts_probs_batch spend 0.00657045999832917 time
winner_batch spend 0.00029333400016184896 time
policy_value spend 0.2215317230002256 time
train_step spend 0.6442256820009788 time
policy_value spend 0.2215428650015383 time
train_step spend 0.6452579550023074 time
policy_value spend 0.22085718999733217 time
train_step spend 0.6443648370041046 time
policy_value spend 0.21529368399933446 time
train_step spend 0.6031924180060741 time
policy_value spend 0.2115517819984234 time
train_step spend 0.6218365740060108 time
policy_value spend 0.21837216499989154 time
kl:0.03139,lr_multiplier:11.391,loss:4.4917988777160645,entropy:5.453583717346191,explained_var_old:0.982577324,explained_var_new:0.984497905
output spend 0.00019459299801383168 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009005627995065879 time
recovery_state_mcts_prob spend 0.2566213630052516 time
state_batch spend 0.0020406879993970506 time
mcts_probs_batch spend 0.006659729995590169 time
winner_batch spend 0.00027356100326869637 time
policy_value spend 0.20717829700151924 time
train_step spend 0.6027206029975787 time
policy_value spend 0.2060778110026149 time
train_step spend 0.6024392879990046 time
policy_value spend 0.2063850780032226 time
train_step spend 0.6034903769977973 time
policy_value spend 0.20554465500026708 time
train_step spend 0.603050017998612 time
policy_value spend 0.2102748090037494 time
train_step spend 0.6448245480059995 time
policy_value spend 0.2212219439970795 time
kl:0.00834,lr_multiplier:11.391,loss:4.481531620025635,entropy:5.455901622772217,explained_var_old:0.987133682,explained_var_new:0.991395473
output spend 0.00017717800074024126 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008409654998104088 time
recovery_state_mcts_prob spend 0.2822521699999925 time
state_batch spend 0.00198303099750774 time
mcts_probs_batch spend 0.004500839000684209 time
winner_batch spend 0.00029611799982376397 time
policy_value spend 0.21961458900477737 time
train_step spend 0.6415698810014874 time
policy_value spend 0.21988490299554542 time
train_step spend 0.6429368249955587 time
policy_value spend 0.2192792220012052 time
train_step spend 0.6417548350000288 time
policy_value spend 0.21998983700177632 time
train_step spend 0.64043085299636 time
policy_value spend 0.21922234700468834 time
train_step spend 0.6417667499990785 time
policy_value spend 0.21879017000173917 time
kl:0.01745,lr_multiplier:11.391,loss:4.528140544891357,entropy:5.458081245422363,explained_var_old:0.986503661,explained_var_new:0.991965830
output spend 0.00014764100342290476 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.016166769004485104 time
recovery_state_mcts_prob spend 0.27591293300065445 time
state_batch spend 0.0018913329986389726 time
mcts_probs_batch spend 0.007227062997117173 time
winner_batch spend 0.0002845530034392141 time
policy_value spend 0.21978723900247132 time
train_step spend 0.6421188699969207 time
policy_value spend 0.2193881080020219 time
train_step spend 0.6417566960008116 time
policy_value spend 0.21943191200261936 time
train_step spend 0.6421446230015135 time
policy_value spend 0.218579441003385 time
train_step spend 0.6444516140036285 time
policy_value spend 0.22102089299733052 time
train_step spend 0.6441159280002466 time
policy_value spend 0.22042836799664656 time
kl:0.00909,lr_multiplier:11.391,loss:4.414322853088379,entropy:5.4480743408203125,explained_var_old:0.995543838,explained_var_new:0.996093810
output spend 0.00021435999951791018 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007121832997654565 time
recovery_state_mcts_prob spend 0.2861696309992112 time
state_batch spend 0.001920326001709327 time
mcts_probs_batch spend 0.006336984995868988 time
winner_batch spend 0.0002883609995478764 time
policy_value spend 0.22053554200101644 time
train_step spend 0.6461669079944841 time
policy_value spend 0.22131937900121557 time
train_step spend 0.6449832650032477 time
policy_value spend 0.2198090969977784 time
train_step spend 0.6443239219952375 time
policy_value spend 0.22111916900030337 time
train_step spend 0.644751929998165 time
policy_value spend 0.22206820900464663 time
train_step spend 0.6461892490042374 time
policy_value spend 0.22065080299944384 time
kl:0.01227,lr_multiplier:11.391,loss:4.471783638000488,entropy:5.450026035308838,explained_var_old:0.988660157,explained_var_new:0.991702974
output spend 0.00020064200361957774 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008622209003078751 time
recovery_state_mcts_prob spend 0.2795333149988437 time
state_batch spend 0.00208699799986789 time
mcts_probs_batch spend 0.0063644990004831925 time
winner_batch spend 0.00031623299582861364 time
policy_value spend 0.22365179800544865 time
train_step spend 0.646621423002216 time
policy_value spend 0.22337118699942948 time
train_step spend 0.6450585490019876 time
policy_value spend 0.22002723399782553 time
train_step spend 0.6442947119940072 time
policy_value spend 0.22024539500125684 time
train_step spend 0.6446736600046279 time
policy_value spend 0.22006094699463574 time
train_step spend 0.6453899309999542 time
policy_value spend 0.22100211700308137 time
kl:0.01201,lr_multiplier:11.391,loss:4.571163177490234,entropy:5.4641828536987305,explained_var_old:0.992662311,explained_var_new:0.995170832
output spend 0.00014933900092728436 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009654788998886943 time
recovery_state_mcts_prob spend 0.28025794800487347 time
state_batch spend 0.0019705369995790534 time
mcts_probs_batch spend 0.005423015994892921 time
winner_batch spend 0.00039198000013129786 time
policy_value spend 0.2213255599999684 time
train_step spend 0.6461113200057298 time
policy_value spend 0.21995870799582917 time
train_step spend 0.6459173830007785 time
policy_value spend 0.22074155599693768 time
train_step spend 0.6390860169994994 time
policy_value spend 0.20599833699816372 time
train_step spend 0.6034387929976219 time
policy_value spend 0.2059896899954765 time
train_step spend 0.6020844570011832 time
policy_value spend 0.20600077199924272 time
kl:0.00990,lr_multiplier:11.391,loss:4.502633571624756,entropy:5.464693546295166,explained_var_old:0.989979684,explained_var_new:0.992221892
output spend 0.000144315003126394 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009649429994169623 time
recovery_state_mcts_prob spend 0.2578444140017382 time
state_batch spend 0.001846744999056682 time
mcts_probs_batch spend 0.005921602998569142 time
winner_batch spend 0.0002882950066123158 time
policy_value spend 0.20548634399892762 time
train_step spend 0.6038170580068254 time
policy_value spend 0.2067740819984465 time
train_step spend 0.6016292169952067 time
policy_value spend 0.20581716900051106 time
train_step spend 0.602456781998626 time
policy_value spend 0.2059092029958265 time
train_step spend 0.63597076300357 time
policy_value spend 0.22186179499840364 time
train_step spend 0.6495536900038132 time
policy_value spend 0.22013223899557488 time
kl:0.03958,lr_multiplier:11.391,loss:4.486663818359375,entropy:5.454738616943359,explained_var_old:0.986297071,explained_var_new:0.990272403
output spend 0.00014728200039826334 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011464962997706607 time
recovery_state_mcts_prob spend 0.27201449000131106 time
state_batch spend 0.0018658960034372285 time
mcts_probs_batch spend 0.0045058190007694066 time
winner_batch spend 0.00029486399580491707 time
policy_value spend 0.21804945800249698 time
train_step spend 0.6397242579987505 time
policy_value spend 0.2183827340049902 time
train_step spend 0.6392838890023995 time
policy_value spend 0.21862486499594525 time
train_step spend 0.6395957249987987 time
policy_value spend 0.21864868499687873 time
train_step spend 0.6399002839971217 time
policy_value spend 0.2189194380043773 time
train_step spend 0.6406494240000029 time
policy_value spend 0.21816288300033193 time
kl:0.04856,lr_multiplier:7.594,loss:4.468302249908447,entropy:5.455182075500488,explained_var_old:0.996731102,explained_var_new:0.999234021
output spend 0.0001539069999125786 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00988488800066989 time
recovery_state_mcts_prob spend 0.28253479699924355 time
state_batch spend 0.0021870330019737594 time
mcts_probs_batch spend 0.006895206002809573 time
winner_batch spend 0.0004493629967328161 time
policy_value spend 0.22715243600396207 time
train_step spend 0.6609510089983814 time
policy_value spend 0.23490043800120475 time
train_step spend 0.6586638810040313 time
policy_value spend 0.21992071899876464 time
train_step spend 0.6407115510010044 time
policy_value spend 0.21966562000307022 time
train_step spend 0.6429069069999969 time
policy_value spend 0.22000183999625733 time
train_step spend 0.644800205998763 time
policy_value spend 0.21977425899967784 time
kl:0.02781,lr_multiplier:7.594,loss:4.486165523529053,entropy:5.421057224273682,explained_var_old:0.997428000,explained_var_new:0.999234855
output spend 0.00015617099415976554 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0077240940008778125 time
recovery_state_mcts_prob spend 0.27001392200327246 time
state_batch spend 0.0022224739950615913 time
mcts_probs_batch spend 0.005934345004789066 time
winner_batch spend 0.0002985909959534183 time
policy_value spend 0.21918283300328767 time
train_step spend 0.6436889600008726 time
policy_value spend 0.21920707200479228 time
train_step spend 0.6426989459941979 time
policy_value spend 0.22024824900290696 time
train_step spend 0.6462300159982988 time
policy_value spend 0.22036427399871172 time
train_step spend 0.6426324829953955 time
policy_value spend 0.21973781599808717 time
train_step spend 0.6430631019975408 time
policy_value spend 0.2204034610040253 time
kl:0.01451,lr_multiplier:7.594,loss:4.495342254638672,entropy:5.436879634857178,explained_var_old:0.996673524,explained_var_new:0.999438643
output spend 0.00016082900401670486 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011710929997207131 time
recovery_state_mcts_prob spend 0.27188733399816556 time
state_batch spend 0.002283394002006389 time
mcts_probs_batch spend 0.00686592300189659 time
winner_batch spend 0.0002966129977721721 time
policy_value spend 0.22079088100144872 time
train_step spend 0.6466254359984305 time
policy_value spend 0.22070146600162843 time
train_step spend 0.6453425309955492 time
policy_value spend 0.2201875610044226 time
train_step spend 0.6456322659942089 time
policy_value spend 0.2204836150049232 time
train_step spend 0.6455667179980082 time
policy_value spend 0.22007896099967184 time
train_step spend 0.6455031719960971 time
policy_value spend 0.22042601400607964 time
kl:0.01679,lr_multiplier:7.594,loss:4.423509120941162,entropy:5.40988826751709,explained_var_old:0.989099681,explained_var_new:0.992387950
output spend 0.00022432400146499276 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011192903999472037 time
recovery_state_mcts_prob spend 0.27697053399606375 time
state_batch spend 0.001937041997734923 time
mcts_probs_batch spend 0.007197595004981849 time
winner_batch spend 0.00032800099870655686 time
policy_value spend 0.22060784300265368 time
train_step spend 0.6463991540003917 time
policy_value spend 0.22024982599396026 time
train_step spend 0.6452034790054313 time
policy_value spend 0.22022435799590312 time
train_step spend 0.6270754359939019 time
policy_value spend 0.20614279599976726 time
train_step spend 0.6024392690014793 time
policy_value spend 0.20598146699921926 time
train_step spend 0.6017560180043802 time
policy_value spend 0.20562107299338095 time
kl:0.01094,lr_multiplier:7.594,loss:4.436690330505371,entropy:5.435657978057861,explained_var_old:0.993321538,explained_var_new:0.995255888
output spend 0.00013759700232185423 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007290203997399658 time
recovery_state_mcts_prob spend 0.2526219299979857 time
state_batch spend 0.001958004002517555 time
mcts_probs_batch spend 0.006368071000906639 time
winner_batch spend 0.0002747609978541732 time
policy_value spend 0.20614554500207305 time
train_step spend 0.6016993310040561 time
policy_value spend 0.20674282899562968 time
train_step spend 0.6023026930051856 time
policy_value spend 0.20554852100030985 time
train_step spend 0.6026444639937836 time
policy_value spend 0.20603806500002975 time
train_step spend 0.6031312929990236 time
policy_value spend 0.2064410719976877 time
train_step spend 0.6027752270019846 time
policy_value spend 0.2084926839961554 time
kl:0.00704,lr_multiplier:11.391,loss:4.534518241882324,entropy:5.456459999084473,explained_var_old:0.987306893,explained_var_new:0.988024235
output spend 0.00020035800116602331 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011113219996332191 time
recovery_state_mcts_prob spend 0.2781664380017901 time
state_batch spend 0.0019387799984542653 time
mcts_probs_batch spend 0.006286930001806468 time
winner_batch spend 0.0002869949967134744 time
policy_value spend 0.2188189840017003 time
train_step spend 0.6407769840006949 time
policy_value spend 0.21931623099953867 time
train_step spend 0.6405562389991246 time
policy_value spend 0.2188297489992692 time
train_step spend 0.640108006002265 time
policy_value spend 0.2188970149945817 time
train_step spend 0.6417410549984197 time
policy_value spend 0.21862602300097933 time
train_step spend 0.6413883269997314 time
policy_value spend 0.21869726900331443 time
kl:0.01045,lr_multiplier:11.391,loss:4.432877540588379,entropy:5.432353973388672,explained_var_old:0.989664793,explained_var_new:0.995181501
output spend 0.00015718999929958954 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010452741000335664 time
recovery_state_mcts_prob spend 0.2801061709978967 time
state_batch spend 0.002392722002696246 time
mcts_probs_batch spend 0.0072508279990870506 time
winner_batch spend 0.00030774599872529507 time
policy_value spend 0.2188685190049 time
train_step spend 0.6400843230003375 time
policy_value spend 0.2195811630008393 time
train_step spend 0.6403143489951617 time
policy_value spend 0.21922406300291186 time
train_step spend 0.6404321979935048 time
policy_value spend 0.22007263500563568 time
train_step spend 0.6443850419964292 time
policy_value spend 0.22058550600195304 time
train_step spend 0.6442258299939567 time
policy_value spend 0.22033981900312938 time
kl:0.01512,lr_multiplier:11.391,loss:4.520445346832275,entropy:5.455056667327881,explained_var_old:0.994964540,explained_var_new:0.995625019
output spend 0.00017758099420461804 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010751658002845943 time
recovery_state_mcts_prob spend 0.2802627269993536 time
state_batch spend 0.001905611999973189 time
mcts_probs_batch spend 0.005202954002015758 time
winner_batch spend 0.00030523099849233404 time
policy_value spend 0.2200051749969134 time
train_step spend 0.6446438170023612 time
policy_value spend 0.2213864930017735 time
train_step spend 0.6449412319998373 time
policy_value spend 0.2204291580055724 time
train_step spend 0.6448381950031035 time
policy_value spend 0.22006426900043152 time
train_step spend 0.6453294689999893 time
policy_value spend 0.21973626800172497 time
train_step spend 0.6445841179956915 time
policy_value spend 0.22016859200084582 time
kl:0.01741,lr_multiplier:11.391,loss:4.50966215133667,entropy:5.461362838745117,explained_var_old:0.987064183,explained_var_new:0.988188386
output spend 0.0002103689985233359 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008572812002967112 time
recovery_state_mcts_prob spend 0.2757650689964066 time
state_batch spend 0.001973869002540596 time
mcts_probs_batch spend 0.007537435994890984 time
winner_batch spend 0.0003002760058734566 time
policy_value spend 0.22354288299538894 time
train_step spend 0.6545206399969175 time
policy_value spend 0.22435080600553192 time
train_step spend 0.6545922810037155 time
policy_value spend 0.224783617995854 time
train_step spend 0.6552688430019771 time
policy_value spend 0.22376150499621872 time
train_step spend 0.6550801230041543 time
policy_value spend 0.224069297000824 time
train_step spend 0.655586916996981 time
policy_value spend 0.22434756199800177 time
kl:0.00853,lr_multiplier:11.391,loss:4.507052898406982,entropy:5.386773109436035,explained_var_old:0.995412052,explained_var_new:0.995753527
output spend 0.0002773929954855703 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009351650995085947 time
recovery_state_mcts_prob spend 0.3075287340034265 time
state_batch spend 0.0023530469989054836 time
mcts_probs_batch spend 0.006767281003703829 time
winner_batch spend 0.0003003550009452738 time
policy_value spend 0.23754198999813525 time
train_step spend 0.6737025800030096 time
policy_value spend 0.22586720399704063 time
train_step spend 0.6584874379987014 time
policy_value spend 0.22568189199955668 time
train_step spend 0.613604113998008 time
policy_value spend 0.20576630700088572 time
train_step spend 0.6038309190043947 time
policy_value spend 0.205852965998929 time
train_step spend 0.6024609119995148 time
policy_value spend 0.2061521889991127 time
kl:0.01839,lr_multiplier:11.391,loss:4.479625701904297,entropy:5.443960666656494,explained_var_old:0.994665265,explained_var_new:0.998882592
output spend 0.00013793000107398257 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009429357000044547 time
recovery_state_mcts_prob spend 0.25053488699632 time
state_batch spend 0.0017278490049648099 time
mcts_probs_batch spend 0.014593499996408354 time
winner_batch spend 0.0002836519997799769 time
policy_value spend 0.2086182999992161 time
train_step spend 0.6019002430039109 time
policy_value spend 0.21040808899851982 time
train_step spend 0.6024917280010413 time
policy_value spend 0.20651065600395668 time
train_step spend 0.6027475189985125 time
policy_value spend 0.20617420099733863 time
train_step spend 0.602741208000225 time
policy_value spend 0.20626076200278476 time
train_step spend 0.6020011800064822 time
policy_value spend 0.20655624099890701 time
kl:0.02146,lr_multiplier:11.391,loss:4.450229167938232,entropy:5.418356418609619,explained_var_old:0.993052423,explained_var_new:0.995539546
output spend 0.00013464799849316478 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009264383996196557 time
recovery_state_mcts_prob spend 0.2720801079994999 time
state_batch spend 0.0018780540049192496 time
mcts_probs_batch spend 0.006179607997182757 time
winner_batch spend 0.0002930269984062761 time
policy_value spend 0.21443654299946502 time
train_step spend 0.6274655910019646 time
policy_value spend 0.21520948700344888 time
train_step spend 0.6271053470045445 time
policy_value spend 0.21435499099607114 time
train_step spend 0.6279308599987417 time
policy_value spend 0.21550370499608107 time
train_step spend 0.6275249680038542 time
policy_value spend 0.21482407599978615 time
train_step spend 0.6284087789972546 time
policy_value spend 0.21446024099714123 time
kl:0.04324,lr_multiplier:7.594,loss:4.467087745666504,entropy:5.438755035400391,explained_var_old:0.991370857,explained_var_new:0.993735313
output spend 0.00014622299931943417 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007067612998071127 time
recovery_state_mcts_prob spend 0.2680026660018484 time
state_batch spend 0.001786310000170488 time
mcts_probs_batch spend 0.006457948999013752 time
winner_batch spend 0.00028746799944201484 time
policy_value spend 0.21474050300457748 time
train_step spend 0.6273045440029819 time
policy_value spend 0.21461349499440985 time
train_step spend 0.6277956050034845 time
policy_value spend 0.21429555299982894 time
train_step spend 0.6288331500036293 time
policy_value spend 0.22082398700149497 time
train_step spend 0.6464095249975799 time
policy_value spend 0.22063646300375694 time
train_step spend 0.6460392430017237 time
policy_value spend 0.22070816600171383 time
kl:0.00895,lr_multiplier:11.391,loss:4.354568958282471,entropy:5.3291425704956055,explained_var_old:0.994812787,explained_var_new:0.995995939
output spend 0.00014959600230213255 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008688726004038472 time
recovery_state_mcts_prob spend 0.2824539849971188 time
state_batch spend 0.0019246730007580481 time
mcts_probs_batch spend 0.006534143001772463 time
winner_batch spend 0.0003016379996552132 time
policy_value spend 0.22101670000120066 time
train_step spend 0.6457384129971615 time
policy_value spend 0.22178186899691354 time
train_step spend 0.6453265789969009 time
policy_value spend 0.22044696700322675 time
train_step spend 0.6447549899967271 time
policy_value spend 0.22065780500270193 time
train_step spend 0.6455836609966354 time
policy_value spend 0.22117852800147375 time
train_step spend 0.645828854998399 time
policy_value spend 0.22096946900273906 time
kl:0.01880,lr_multiplier:11.391,loss:4.444640636444092,entropy:5.399019241333008,explained_var_old:0.977499723,explained_var_new:0.985636294
output spend 0.0001478669946664013 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008556808999856003 time
recovery_state_mcts_prob spend 0.2811002350063063 time
state_batch spend 0.0020259499942767434 time
mcts_probs_batch spend 0.006320789005258121 time
winner_batch spend 0.0003448029965511523 time
policy_value spend 0.2250362260019756 time
train_step spend 0.6577123959941673 time
policy_value spend 0.22595379200356547 time
train_step spend 0.6570583780048764 time
policy_value spend 0.22480955599894514 time
train_step spend 0.6571076920008636 time
policy_value spend 0.22520593099761754 time
train_step spend 0.6593383419967722 time
policy_value spend 0.22446164800203405 time
train_step spend 0.6586678969979403 time
policy_value spend 0.2249654150000424 time
kl:0.01719,lr_multiplier:11.391,loss:4.43496036529541,entropy:5.436554908752441,explained_var_old:0.987250090,explained_var_new:0.994104087
output spend 0.00015975299902493134 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009331183005997445 time
recovery_state_mcts_prob spend 0.2813489420004771 time
state_batch spend 0.0022498779944726266 time
mcts_probs_batch spend 0.005295634000503924 time
winner_batch spend 0.0003316950023872778 time
policy_value spend 0.225566572000389 time
train_step spend 0.6572161799995229 time
policy_value spend 0.2254296829996747 time
train_step spend 0.6577690129997791 time
policy_value spend 0.22462747400277294 time
train_step spend 0.6144474499960779 time
policy_value spend 0.20586257000104524 time
train_step spend 0.6014103419947787 time
policy_value spend 0.2061073220029357 time
train_step spend 0.6018754670003545 time
policy_value spend 0.2064328030028264 time
kl:0.00603,lr_multiplier:11.391,loss:4.447118759155273,entropy:5.426900863647461,explained_var_old:0.997573853,explained_var_new:0.999369681
output spend 0.00021786500292364508 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0067011609935434535 time
recovery_state_mcts_prob spend 0.2554504560030182 time
state_batch spend 0.0018150600008084439 time
mcts_probs_batch spend 0.005859386998054106 time
winner_batch spend 0.0002760499992291443 time
policy_value spend 0.2056417310013785 time
train_step spend 0.6018326449993765 time
policy_value spend 0.20722386899433332 time
train_step spend 0.6013051240006462 time
policy_value spend 0.20520759099599672 time
train_step spend 0.6021136809940799 time
policy_value spend 0.2054230900030234 time
train_step spend 0.601997110999946 time
policy_value spend 0.20552302400028566 time
train_step spend 0.6029699830032769 time
policy_value spend 0.20619785999588203 time
kl:0.00689,lr_multiplier:11.391,loss:4.44443941116333,entropy:5.424515724182129,explained_var_old:0.994880795,explained_var_new:0.996756375
output spend 0.00014445000124396756 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007263469000463374 time
recovery_state_mcts_prob spend 0.2559014959988417 time
state_batch spend 0.0018776959987008013 time
mcts_probs_batch spend 0.00596428700373508 time
winner_batch spend 0.00028304499574005604 time
policy_value spend 0.20973840200167615 time
train_step spend 0.613134021004953 time
policy_value spend 0.21019040099781705 time
train_step spend 0.6137746840031468 time
policy_value spend 0.21041643799981102 time
train_step spend 0.6343680019999738 time
policy_value spend 0.22148885299975518 time
train_step spend 0.6398867719981354 time
policy_value spend 0.21023584600334289 time
train_step spend 0.6149844219980878 time
policy_value spend 0.20976420599617995 time
kl:0.02153,lr_multiplier:11.391,loss:4.409748077392578,entropy:5.421565055847168,explained_var_old:0.991464913,explained_var_new:0.995264411
output spend 0.00014302300405688584 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006587067000509705 time
recovery_state_mcts_prob spend 0.26410710699565243 time
state_batch spend 0.00187647500570165 time
mcts_probs_batch spend 0.006036729995685164 time
winner_batch spend 0.00027759499789681286 time
policy_value spend 0.2093484030046966 time
train_step spend 0.6136542259991984 time
policy_value spend 0.20944275699730497 time
train_step spend 0.6126806389947888 time
policy_value spend 0.20943305900436826 time
train_step spend 0.6202970010053832 time
policy_value spend 0.22177661699970486 time
train_step spend 0.6490537330028019 time
policy_value spend 0.22256559500237927 time
train_step spend 0.6494176500054891 time
policy_value spend 0.22194506499363342 time
kl:0.01366,lr_multiplier:11.391,loss:4.434971332550049,entropy:5.3744049072265625,explained_var_old:0.988299906,explained_var_new:0.991365671
output spend 0.00015208999684546143 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00794736499665305 time
recovery_state_mcts_prob spend 0.27809123400220415 time
state_batch spend 0.0021471889995154925 time
mcts_probs_batch spend 0.004766248996020295 time
winner_batch spend 0.0003151480050291866 time
policy_value spend 0.22084620899840957 time
train_step spend 0.6494684169956599 time
policy_value spend 0.22084888000244973 time
train_step spend 0.6488250799957314 time
policy_value spend 0.22231886400550138 time
train_step spend 0.6496327759959968 time
policy_value spend 0.22186238300491823 time
train_step spend 0.6490139349989477 time
policy_value spend 0.22148092599672964 time
train_step spend 0.6494963020013529 time
policy_value spend 0.22173961299995426 time
kl:0.02729,lr_multiplier:11.391,loss:4.41201114654541,entropy:5.351181507110596,explained_var_old:0.985834897,explained_var_new:0.987953544
output spend 0.00015890999929979444 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006766059996152762 time
recovery_state_mcts_prob spend 0.27958547700109193 time
state_batch spend 0.002007332004723139 time
mcts_probs_batch spend 0.005878809999558143 time
winner_batch spend 0.0003054739936487749 time
policy_value spend 0.2267330500035314 time
train_step spend 0.6633884879993275 time
policy_value spend 0.22649542200088035 time
train_step spend 0.6638429099984933 time
policy_value spend 0.22731732000102056 time
train_step spend 0.6646521799993934 time
policy_value spend 0.22685710399673553 time
train_step spend 0.6644992809960968 time
policy_value spend 0.22628046599857043 time
train_step spend 0.6632345850011916 time
policy_value spend 0.2269060409962549 time
kl:0.01991,lr_multiplier:11.391,loss:4.4436354637146,entropy:5.428070068359375,explained_var_old:0.996354520,explained_var_new:0.998697460
output spend 0.000189973994565662 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010912063997238874 time
recovery_state_mcts_prob spend 0.28162989699922036 time
state_batch spend 0.001825148006901145 time
mcts_probs_batch spend 0.005619568997644819 time
winner_batch spend 0.00029972199990879744 time
policy_value spend 0.22589938600140158 time
train_step spend 0.6631335999991279 time
policy_value spend 0.22652901599940378 time
train_step spend 0.664057715999661 time
policy_value spend 0.2272717410014593 time
train_step spend 0.6213020040013362 time
policy_value spend 0.20600306899723364 time
train_step spend 0.6063051170058316 time
policy_value spend 0.20555565499671502 time
train_step spend 0.6023188590042992 time
policy_value spend 0.20592754599783802 time
kl:0.02129,lr_multiplier:11.391,loss:4.426772594451904,entropy:5.412271499633789,explained_var_old:0.987135828,explained_var_new:0.991048098
output spend 0.00014003099931869656 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00844816100288881 time
recovery_state_mcts_prob spend 0.2697093229944585 time
state_batch spend 0.0017601299987290986 time
mcts_probs_batch spend 0.00497346500196727 time
winner_batch spend 0.00027734900504583493 time
policy_value spend 0.20446343899675412 time
train_step spend 0.6036045590008143 time
policy_value spend 0.20678813900303794 time
train_step spend 0.6022945190052269 time
policy_value spend 0.20632844400097383 time
train_step spend 0.6044766310005798 time
policy_value spend 0.20590634099789895 time
train_step spend 0.6035860610063537 time
policy_value spend 0.20691471499594627 time
train_step spend 0.6043007780026528 time
policy_value spend 0.20608707799692638 time
kl:0.04416,lr_multiplier:7.594,loss:4.409736156463623,entropy:5.367727756500244,explained_var_old:0.996988654,explained_var_new:0.998999476
output spend 0.0001377320004394278 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007778402003168594 time
recovery_state_mcts_prob spend 0.25868056699982844 time
state_batch spend 0.0017001949963741936 time
mcts_probs_batch spend 0.004247700999258086 time
winner_batch spend 0.0002766820034594275 time
policy_value spend 0.2068760959955398 time
train_step spend 0.6028975969966268 time
policy_value spend 0.20592308999766828 time
train_step spend 0.6018590460007545 time
policy_value spend 0.20567644499533344 time
train_step spend 0.6019208920042729 time
policy_value spend 0.20561137099866755 time
train_step spend 0.6018382160036708 time
policy_value spend 0.20622973600256955 time
train_step spend 0.6022003410034813 time
policy_value spend 0.20628149299591314 time
kl:0.00850,lr_multiplier:11.391,loss:4.45305061340332,entropy:5.439035892486572,explained_var_old:0.994643271,explained_var_new:0.995658875
output spend 0.00014159100101096556 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0072384650047752075 time
recovery_state_mcts_prob spend 0.2674629959947197 time
state_batch spend 0.0018001280041062273 time
mcts_probs_batch spend 0.004304688001866452 time
winner_batch spend 0.00027466099709272385 time
policy_value spend 0.2054819539989694 time
train_step spend 0.6046069040021393 time
policy_value spend 0.20742319399869302 time
train_step spend 0.6233675670009688 time
policy_value spend 0.21928579499945045 time
train_step spend 0.644961375001003 time
policy_value spend 0.21956961099931505 time
train_step spend 0.6425035029969877 time
policy_value spend 0.2197620770020876 time
train_step spend 0.642513675004011 time
policy_value spend 0.21964689000014914 time
kl:0.05225,lr_multiplier:7.594,loss:4.42533540725708,entropy:5.391302108764648,explained_var_old:0.991489291,explained_var_new:0.991784513
output spend 0.00016778000281192362 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00735748100123601 time
recovery_state_mcts_prob spend 0.27672778800479136 time
state_batch spend 0.0024851489943102933 time
mcts_probs_batch spend 0.00693867100198986 time
winner_batch spend 0.0003342220006743446 time
policy_value spend 0.21852675200352678 time
train_step spend 0.6458917440031655 time
policy_value spend 0.22013642399542732 time
train_step spend 0.6425913790008053 time
policy_value spend 0.21957769899745472 time
train_step spend 0.6433816520002438 time
policy_value spend 0.2195093230038765 time
train_step spend 0.6430568799987668 time
policy_value spend 0.2194664519993239 time
train_step spend 0.6436273979998077 time
policy_value spend 0.2203606420007418 time
kl:0.01561,lr_multiplier:7.594,loss:4.390737533569336,entropy:5.343045711517334,explained_var_old:0.995428324,explained_var_new:0.998152435
output spend 0.0001450870040571317 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008457374999125022 time
recovery_state_mcts_prob spend 0.30371430199738825 time
state_batch spend 0.001955373001692351 time
mcts_probs_batch spend 0.005719480999687221 time
winner_batch spend 0.0003159100015182048 time
policy_value spend 0.22836471300252015 time
train_step spend 0.7084055140003329 time
policy_value spend 0.24510391899821116 time
train_step spend 0.6727952840010403 time
policy_value spend 0.22906011900340673 time
train_step spend 0.6714611849965877 time
policy_value spend 0.2287023169992608 time
train_step spend 0.6702434699982405 time
policy_value spend 0.23219108900229912 time
train_step spend 0.6717992319972836 time
policy_value spend 0.22880582300422247 time
kl:0.01404,lr_multiplier:7.594,loss:4.422985553741455,entropy:5.355226516723633,explained_var_old:0.995586455,explained_var_new:0.995836675
output spend 0.00015366900333901867 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070947970016277395 time
recovery_state_mcts_prob spend 0.2878023680023034 time
state_batch spend 0.0019841760004055686 time
mcts_probs_batch spend 0.004729733998829033 time
winner_batch spend 0.000444058001448866 time
policy_value spend 0.2277472610003315 time
train_step spend 0.6691578300014953 time
policy_value spend 0.229708181002934 time
train_step spend 0.6616834239976015 time
policy_value spend 0.22064780200162204 time
train_step spend 0.6222803970013047 time
policy_value spend 0.20624250499531627 time
train_step spend 0.6027049950062064 time
policy_value spend 0.2056684469935135 time
train_step spend 0.6039422840040061 time
policy_value spend 0.2065511679975316 time
kl:0.01716,lr_multiplier:7.594,loss:4.415141582489014,entropy:5.365322113037109,explained_var_old:0.987764418,explained_var_new:0.988255799
output spend 0.000139634998049587 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006816703004005831 time
recovery_state_mcts_prob spend 0.2567115849960828 time
state_batch spend 0.001855743998021353 time
mcts_probs_batch spend 0.0043041919998358935 time
winner_batch spend 0.0003109900062554516 time
policy_value spend 0.2052592999971239 time
train_step spend 0.6020786510052858 time
policy_value spend 0.2059541269991314 time
train_step spend 0.60130724299961 time
policy_value spend 0.20816995000495808 time
train_step spend 0.6045784970046952 time
policy_value spend 0.20667528999911156 time
train_step spend 0.6023389789988869 time
policy_value spend 0.20597516000270844 time
train_step spend 0.6023668999987422 time
policy_value spend 0.20585781900445 time
kl:0.04628,lr_multiplier:5.062,loss:4.334227561950684,entropy:5.307018756866455,explained_var_old:0.998503089,explained_var_new:0.999350488
output spend 0.00014900300448061898 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006759130999853369 time
recovery_state_mcts_prob spend 0.25846507100504823 time
state_batch spend 0.0017324029977316968 time
mcts_probs_batch spend 0.011105664998467546 time
winner_batch spend 0.0002975190000142902 time
policy_value spend 0.20819730700168293 time
train_step spend 0.6023485149999033 time
policy_value spend 0.209711231997062 time
train_step spend 0.6035566070058849 time
policy_value spend 0.20543181899847696 time
train_step spend 0.6026681799994549 time
policy_value spend 0.2056350200000452 time
train_step spend 0.6029727610002737 time
policy_value spend 0.2068197320040781 time
train_step spend 0.6027461129997391 time
policy_value spend 0.20576972299750196 time
kl:0.01776,lr_multiplier:5.062,loss:4.431834697723389,entropy:5.393904685974121,explained_var_old:0.979990005,explained_var_new:0.980780602
output spend 0.00013920200581196696 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0066119679977418855 time
recovery_state_mcts_prob spend 0.2557035760037252 time
state_batch spend 0.002030011994065717 time
mcts_probs_batch spend 0.006244891999813262 time
winner_batch spend 0.0002781060029519722 time
policy_value spend 0.20511996099958196 time
train_step spend 0.6026535069977399 time
policy_value spend 0.20689255299657816 time
train_step spend 0.6028590029964107 time
policy_value spend 0.20573141400382156 time
train_step spend 0.6443172509971191 time
policy_value spend 0.22167421300400747 time
train_step spend 0.6412543240003288 time
policy_value spend 0.21688170899869874 time
train_step spend 0.6352980679948814 time
policy_value spend 0.21928202900016913 time
kl:0.00987,lr_multiplier:7.594,loss:4.357290267944336,entropy:5.352049827575684,explained_var_old:0.989669800,explained_var_new:0.994191587
output spend 0.00016613800107734278 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007322631005081348 time
recovery_state_mcts_prob spend 0.27419276000000536 time
state_batch spend 0.0018995680002262816 time
mcts_probs_batch spend 0.006434479000745341 time
winner_batch spend 0.00029177800024626777 time
policy_value spend 0.21752995199494762 time
train_step spend 0.6359281549957814 time
policy_value spend 0.21849934900092194 time
train_step spend 0.6372947639974882 time
policy_value spend 0.21728039500158047 time
train_step spend 0.635032913996838 time
policy_value spend 0.2167394750067615 time
train_step spend 0.6357191989955027 time
policy_value spend 0.2183290470056818 time
train_step spend 0.6366203129946371 time
policy_value spend 0.21685741300461814 time
kl:0.00903,lr_multiplier:11.391,loss:4.405234336853027,entropy:5.347112655639648,explained_var_old:0.991754234,explained_var_new:0.994867682
output spend 0.00016524399688933045 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007970145001308993 time
recovery_state_mcts_prob spend 0.2653130059989053 time
state_batch spend 0.001910675004182849 time
mcts_probs_batch spend 0.006389739995938726 time
winner_batch spend 0.0002941840066341683 time
policy_value spend 0.21757190499920398 time
train_step spend 0.657335730997147 time
policy_value spend 0.22787992200028384 time
train_step spend 0.6596686039993074 time
policy_value spend 0.22538963999977568 time
train_step spend 0.6597239260008791 time
policy_value spend 0.22588799899676815 time
train_step spend 0.6599674979952397 time
policy_value spend 0.22489170700282557 time
train_step spend 0.6593496770001366 time
policy_value spend 0.22546278899972094 time
kl:0.01292,lr_multiplier:11.391,loss:4.486003875732422,entropy:5.417130470275879,explained_var_old:0.985649168,explained_var_new:0.987368107
output spend 0.00016602800315013155 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013417242000286933 time
recovery_state_mcts_prob spend 0.2934079939950607 time
state_batch spend 0.002067469002213329 time
mcts_probs_batch spend 0.004705703002400696 time
winner_batch spend 0.0003074019987252541 time
policy_value spend 0.22413022899854695 time
train_step spend 0.6592408290016465 time
policy_value spend 0.2248647649976192 time
train_step spend 0.6587566579983104 time
policy_value spend 0.22590718600258697 time
train_step spend 0.6588990870004636 time
policy_value spend 0.2081990959995892 time
train_step spend 0.6029344220005441 time
policy_value spend 0.20590550599445123 time
train_step spend 0.6039631849998841 time
policy_value spend 0.20552603599935537 time
kl:0.00908,lr_multiplier:11.391,loss:4.381233215332031,entropy:5.397491931915283,explained_var_old:0.986926794,explained_var_new:0.995180368
output spend 0.00015156400331761688 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007672947998798918 time
recovery_state_mcts_prob spend 0.2596245450040442 time
state_batch spend 0.0018990159951499663 time
mcts_probs_batch spend 0.006372037001710851 time
winner_batch spend 0.00028864700288977474 time
policy_value spend 0.20666112599428743 time
train_step spend 0.603031551996537 time
policy_value spend 0.20642243800102733 time
train_step spend 0.6018303270029719 time
policy_value spend 0.2054757689984399 time
train_step spend 0.6020165560039459 time
policy_value spend 0.2051557149970904 time
train_step spend 0.6023820299960789 time
policy_value spend 0.20523941799910972 time
train_step spend 0.6188020429981407 time
policy_value spend 0.21854557500046212 time
kl:0.02465,lr_multiplier:11.391,loss:4.401472568511963,entropy:5.383166313171387,explained_var_old:0.990821302,explained_var_new:0.992571950
output spend 0.00015652299771318212 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007758042003843002 time
recovery_state_mcts_prob spend 0.2640002479965915 time
state_batch spend 0.001797477998479735 time
mcts_probs_batch spend 0.006153876005555503 time
winner_batch spend 0.0003235059994040057 time
policy_value spend 0.20778289299778407 time
train_step spend 0.6099148749999586 time
policy_value spend 0.20898674899945036 time
train_step spend 0.609870330998092 time
policy_value spend 0.208273566000571 time
train_step spend 0.6099453429997084 time
policy_value spend 0.2084640009998111 time
train_step spend 0.6097407970009954 time
policy_value spend 0.20817730399721768 time
train_step spend 0.6093463279976277 time
policy_value spend 0.20814439999958267 time
kl:0.01266,lr_multiplier:11.391,loss:4.3774800300598145,entropy:5.326053619384766,explained_var_old:0.983647227,explained_var_new:0.990917265
output spend 0.00014701499458169565 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007560905993159395 time
recovery_state_mcts_prob spend 0.2617413790067076 time
state_batch spend 0.0017752569983713329 time
mcts_probs_batch spend 0.006355762001476251 time
winner_batch spend 0.00028845699853263795 time
policy_value spend 0.2082889619996422 time
train_step spend 0.6100943769997684 time
policy_value spend 0.20980306599813048 time
train_step spend 0.6293542990024434 time
policy_value spend 0.22550427300302545 time
train_step spend 0.6443276339996373 time
policy_value spend 0.2204011149951839 time
train_step spend 0.6437609879940283 time
policy_value spend 0.21980450900446158 time
train_step spend 0.6425530490014353 time
policy_value spend 0.21990013999311486 time
kl:0.05997,lr_multiplier:7.594,loss:4.381953239440918,entropy:5.3408589363098145,explained_var_old:0.988834620,explained_var_new:0.991633594
output spend 0.00017082600243156776 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008857139000610914 time
recovery_state_mcts_prob spend 0.27850722100265557 time
state_batch spend 0.0022008059968356974 time
mcts_probs_batch spend 0.007026061000942718 time
winner_batch spend 0.00029073599580442533 time
policy_value spend 0.21947128600004362 time
train_step spend 0.6432346799992956 time
policy_value spend 0.21940527200058568 time
train_step spend 0.6430360480007948 time
policy_value spend 0.2193745129989111 time
train_step spend 0.6424231139972107 time
policy_value spend 0.2191375960028381 time
train_step spend 0.6427561999953468 time
policy_value spend 0.219298913005332 time
train_step spend 0.6417294119964936 time
policy_value spend 0.22005554700444918 time
kl:0.06274,lr_multiplier:5.062,loss:4.371417999267578,entropy:5.356886863708496,explained_var_old:0.983058870,explained_var_new:0.988822460
output spend 0.00015049600187921897 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00805667600070592 time
recovery_state_mcts_prob spend 0.2758639969979413 time
state_batch spend 0.0019907340029021725 time
mcts_probs_batch spend 0.006253991996345576 time
winner_batch spend 0.0002887840018956922 time
policy_value spend 0.22130940199713223 time
train_step spend 0.6524633829976665 time
policy_value spend 0.22462856100173667 time
train_step spend 0.6559379429963883 time
policy_value spend 0.22393121400091331 time
train_step spend 0.6569906720033032 time
policy_value spend 0.22404911900230218 time
train_step spend 0.6562677740002982 time
policy_value spend 0.23143058200366795 time
train_step spend 0.6555919849997736 time
policy_value spend 0.22441574100230355 time
kl:0.01676,lr_multiplier:5.062,loss:4.408605575561523,entropy:5.309279918670654,explained_var_old:0.987816632,explained_var_new:0.992090702
output spend 0.00015077900025062263 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008142833998135757 time
recovery_state_mcts_prob spend 0.2810364120014128 time
state_batch spend 0.00193555199803086 time
mcts_probs_batch spend 0.007275948002643418 time
winner_batch spend 0.0005178630017326213 time
policy_value spend 0.226765081002668 time
train_step spend 0.655150592996506 time
policy_value spend 0.22530907799955457 time
train_step spend 0.6566636380011914 time
policy_value spend 0.2250274179968983 time
train_step spend 0.65628044600453 time
policy_value spend 0.22001854299742263 time
train_step spend 0.6032534940022742 time
policy_value spend 0.20608511499449378 time
train_step spend 0.6025605899994844 time
policy_value spend 0.2064579439975205 time
kl:0.03782,lr_multiplier:5.062,loss:4.457291603088379,entropy:5.384590148925781,explained_var_old:0.990719080,explained_var_new:0.993877351
output spend 0.00014630700025008991 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006692073002341203 time
recovery_state_mcts_prob spend 0.2685760250024032 time
state_batch spend 0.0023810829952708445 time
mcts_probs_batch spend 0.007176700004492886 time
winner_batch spend 0.0002933629948529415 time
policy_value spend 0.2064054010043037 time
train_step spend 0.6032155189968762 time
policy_value spend 0.20648876300401753 time
train_step spend 0.6022385440010112 time
policy_value spend 0.2061159079967183 time
train_step spend 0.6020509609952569 time
policy_value spend 0.20589482200011844 time
train_step spend 0.6019125070015434 time
policy_value spend 0.20638601400423795 time
train_step spend 0.6023186430029455 time
policy_value spend 0.20584256999427453 time
kl:0.05344,lr_multiplier:3.375,loss:4.401065349578857,entropy:5.384969711303711,explained_var_old:0.992670238,explained_var_new:0.997815847
output spend 0.0001531060042907484 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007947022997541353 time
recovery_state_mcts_prob spend 0.2612961280028685 time
state_batch spend 0.0019475890003377572 time
mcts_probs_batch spend 0.006127194996224716 time
winner_batch spend 0.00027033300284529105 time
policy_value spend 0.2056356989996857 time
train_step spend 0.6100650189982844 time
policy_value spend 0.21090585800266126 time
train_step spend 0.611313194000104 time
policy_value spend 0.20940985199558781 time
train_step spend 0.6151429000019561 time
policy_value spend 0.20880055799352704 time
train_step spend 0.6117933119967347 time
policy_value spend 0.20916925599885872 time
train_step spend 0.6107213349969243 time
policy_value spend 0.21170084999903338 time
kl:0.02292,lr_multiplier:3.375,loss:4.374167442321777,entropy:5.3719868659973145,explained_var_old:0.998706043,explained_var_new:0.999285698
output spend 0.00016481599595863372 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01059639299637638 time
recovery_state_mcts_prob spend 0.25874067000404466 time
state_batch spend 0.0017451879975851625 time
mcts_probs_batch spend 0.005718906999391038 time
winner_batch spend 0.00028426100470824167 time
policy_value spend 0.20883829800004605 time
train_step spend 0.6108802469971124 time
policy_value spend 0.21094565800012788 time
train_step spend 0.645169914001599 time
policy_value spend 0.22088222800084623 time
train_step spend 0.6452811069975724 time
policy_value spend 0.22091528899909463 time
train_step spend 0.6438088599970797 time
policy_value spend 0.2201603020002949 time
train_step spend 0.6470376470024348 time
policy_value spend 0.2205779759970028 time
kl:0.00754,lr_multiplier:5.062,loss:4.3676910400390625,entropy:5.328314781188965,explained_var_old:0.998832703,explained_var_new:0.999288857
output spend 0.0001519270008429885 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010035780003818218 time
recovery_state_mcts_prob spend 0.26889993799704826 time
state_batch spend 0.001926094999362249 time
mcts_probs_batch spend 0.016161168001417536 time
winner_batch spend 0.00031814399699214846 time
policy_value spend 0.2325631890053046 time
train_step spend 0.6635028569944552 time
policy_value spend 0.23758208499930333 time
train_step spend 0.6580334059981396 time
policy_value spend 0.22180105600273237 time
train_step spend 0.6438465120008914 time
policy_value spend 0.22040341200045077 time
train_step spend 0.6438249890052248 time
policy_value spend 0.21921378499973798 time
train_step spend 0.6434464729973115 time
policy_value spend 0.21982533600385068 time
kl:0.01185,lr_multiplier:5.062,loss:4.360650539398193,entropy:5.362872123718262,explained_var_old:0.984742641,explained_var_new:0.991882086
output spend 0.00015758899826323614 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007143574999645352 time
recovery_state_mcts_prob spend 0.2798724019958172 time
state_batch spend 0.00187353600631468 time
mcts_probs_batch spend 0.006478953997429926 time
winner_batch spend 0.00031851899984758347 time
policy_value spend 0.2235778879985446 time
train_step spend 0.6545968140053446 time
policy_value spend 0.22383704399544513 time
train_step spend 0.6561241160015925 time
policy_value spend 0.22470974099996965 time
train_step spend 0.6553890199938905 time
policy_value spend 0.22403376700094668 time
train_step spend 0.6556246489999467 time
policy_value spend 0.22499059999972815 time
train_step spend 0.6557468230021186 time
policy_value spend 0.22408820599957835 time
kl:0.01020,lr_multiplier:5.062,loss:4.342319488525391,entropy:5.350910663604736,explained_var_old:0.985016346,explained_var_new:0.988491178
output spend 0.0001636949964449741 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0075716959981946275 time
recovery_state_mcts_prob spend 0.2841787619981915 time
state_batch spend 0.002110182998876553 time
mcts_probs_batch spend 0.006473159002780449 time
winner_batch spend 0.00031826899794396013 time
policy_value spend 0.22507989600126166 time
train_step spend 0.6550434629971278 time
policy_value spend 0.226524003999657 time
train_step spend 0.6561050349992001 time
policy_value spend 0.22380685599637218 time
train_step spend 0.6568249370029662 time
policy_value spend 0.22281510899483692 time
train_step spend 0.6029320469970116 time
policy_value spend 0.2055629759997828 time
train_step spend 0.602471792997676 time
policy_value spend 0.20536684400576632 time
kl:0.01595,lr_multiplier:5.062,loss:4.386502265930176,entropy:5.330020427703857,explained_var_old:0.986041665,explained_var_new:0.989017308
output spend 0.0001460089988540858 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006821338000008836 time
recovery_state_mcts_prob spend 0.2654733099989244 time
state_batch spend 0.0022129820063128136 time
mcts_probs_batch spend 0.006536244000017177 time
winner_batch spend 0.00027106299967272207 time
policy_value spend 0.20617006099928403 time
train_step spend 0.6022215220000362 time
policy_value spend 0.20664451899938285 time
train_step spend 0.6022923319978872 time
policy_value spend 0.2062117559980834 time
train_step spend 0.6022059329989133 time
policy_value spend 0.2060784679997596 time
train_step spend 0.6014751839975361 time
policy_value spend 0.20569647799857194 time
train_step spend 0.6030444179996266 time
policy_value spend 0.20641104399692267 time
kl:0.02472,lr_multiplier:5.062,loss:4.393681049346924,entropy:5.364269733428955,explained_var_old:0.998187840,explained_var_new:0.999421537
output spend 0.00014004900003783405 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0068399310039239936 time
recovery_state_mcts_prob spend 0.2533197879965883 time
state_batch spend 0.0020758809987455606 time
mcts_probs_batch spend 0.006431216002965812 time
winner_batch spend 0.0002893589989980683 time
policy_value spend 0.20546412499970756 time
train_step spend 0.6060277680007857 time
policy_value spend 0.21113602400146192 time
train_step spend 0.608095890005643 time
policy_value spend 0.20779503299854696 time
train_step spend 0.6087268920018687 time
policy_value spend 0.2077775629950338 time
train_step spend 0.6099219730022014 time
policy_value spend 0.20769954100251198 time
train_step spend 0.6084465490057482 time
policy_value spend 0.20779353199759498 time
kl:0.01001,lr_multiplier:5.062,loss:4.3695549964904785,entropy:5.348013877868652,explained_var_old:0.988277256,explained_var_new:0.989430070
output spend 0.00014856699999654666 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006945846005692147 time
recovery_state_mcts_prob spend 0.2606541379936971 time
state_batch spend 0.002078757002891507 time
mcts_probs_batch spend 0.015203221002593637 time
winner_batch spend 0.00028056700102752075 time
policy_value spend 0.21117490100004943 time
train_step spend 0.6225668940023752 time
policy_value spend 0.2236269999993965 time
train_step spend 0.6454258730009315 time
policy_value spend 0.22060788799717557 time
train_step spend 0.6454187290000846 time
policy_value spend 0.22026142600225285 time
train_step spend 0.6443084769998677 time
policy_value spend 0.22015058100078022 time
train_step spend 0.6432162010023603 time
policy_value spend 0.21960041899728822 time
kl:0.00640,lr_multiplier:7.594,loss:4.383655071258545,entropy:5.3461809158325195,explained_var_old:0.997524500,explained_var_new:0.999158978
output spend 0.00018782699771691114 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.013528547002351843 time
recovery_state_mcts_prob spend 0.2752818740045768 time
state_batch spend 0.002344994994928129 time
mcts_probs_batch spend 0.006519344002299476 time
winner_batch spend 0.00028899199969600886 time
policy_value spend 0.2196079249988543 time
train_step spend 0.6435914899993804 time
policy_value spend 0.21966795500338776 time
train_step spend 0.6432465870020678 time
policy_value spend 0.21968639799888479 time
train_step spend 0.6428758749971166 time
policy_value spend 0.2194637920038076 time
train_step spend 0.6434166460021515 time
policy_value spend 0.22080188999825623 time
train_step spend 0.6433720240020193 time
policy_value spend 0.21978314199805027 time
kl:0.00941,lr_multiplier:11.391,loss:4.3794474601745605,entropy:5.330806732177734,explained_var_old:0.989907563,explained_var_new:0.995168328
output spend 0.0001526729975012131 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007082090996846091 time
recovery_state_mcts_prob spend 0.28210561999731 time
state_batch spend 0.003263259000959806 time
mcts_probs_batch spend 0.005899299001612235 time
winner_batch spend 0.0004653110008803196 time
policy_value spend 0.22015945299790474 time
train_step spend 0.6541989300021669 time
policy_value spend 0.2288991929963231 time
train_step spend 0.6631800629984355 time
policy_value spend 0.22655315800511744 time
train_step spend 0.6636277020006673 time
policy_value spend 0.2266928739991272 time
train_step spend 0.6644942380007706 time
policy_value spend 0.2266108269977849 time
train_step spend 0.6636301890030154 time
policy_value spend 0.22636201299610548 time
kl:0.00634,lr_multiplier:11.391,loss:4.379461288452148,entropy:5.307290077209473,explained_var_old:0.984615862,explained_var_new:0.989212573
output spend 0.00014940500113880262 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007996909000212327 time
recovery_state_mcts_prob spend 0.2857331749983132 time
state_batch spend 0.001951285004906822 time
mcts_probs_batch spend 0.012610052996024024 time
winner_batch spend 0.0003394840023247525 time
policy_value spend 0.22547595200012438 time
train_step spend 0.6656771130001289 time
policy_value spend 0.2257143399983761 time
train_step spend 0.6631902720037033 time
policy_value spend 0.22696201800135896 time
train_step spend 0.6644314910008688 time
policy_value spend 0.22717029599880334 time
train_step spend 0.6042188979990897 time
policy_value spend 0.2063507060011034 time
train_step spend 0.6049082230019849 time
policy_value spend 0.2059318629981135 time
kl:0.00684,lr_multiplier:11.391,loss:4.410961627960205,entropy:5.428798198699951,explained_var_old:0.989090621,explained_var_new:0.992135525
output spend 0.0002585760012152605 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007034882000880316 time
recovery_state_mcts_prob spend 0.2740501769949333 time
state_batch spend 0.0023375300006591715 time
mcts_probs_batch spend 0.004859808999754023 time
winner_batch spend 0.0004199309987598099 time
policy_value spend 0.21725108499958878 time
train_step spend 0.6223550329959835 time
policy_value spend 0.20666134400380543 time
train_step spend 0.6034837959959987 time
policy_value spend 0.20556378000037512 time
train_step spend 0.6017004879977321 time
policy_value spend 0.205579604000377 time
train_step spend 0.6024694399966393 time
policy_value spend 0.2055461190029746 time
train_step spend 0.6021601519969408 time
policy_value spend 0.20555663800041657 time
kl:0.02971,lr_multiplier:11.391,loss:4.380926609039307,entropy:5.314260959625244,explained_var_old:0.968775630,explained_var_new:0.983634353
output spend 0.0001403279966325499 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007306134997634217 time
recovery_state_mcts_prob spend 0.26196961500681937 time
state_batch spend 0.0018004710000241175 time
mcts_probs_batch spend 0.006292409998422954 time
winner_batch spend 0.00026851199800148606 time
policy_value spend 0.20560278499760898 time
train_step spend 0.6023345430003246 time
policy_value spend 0.2069142140026088 time
train_step spend 0.602247183000145 time
policy_value spend 0.20559610599593725 time
train_step spend 0.6056974550010636 time
policy_value spend 0.20534197499364382 time
train_step spend 0.6035131830067257 time
policy_value spend 0.20578753199515631 time
train_step spend 0.6018086449985276 time
policy_value spend 0.20573150800191797 time
kl:0.07221,lr_multiplier:7.594,loss:4.395373344421387,entropy:5.3544158935546875,explained_var_old:0.991200507,explained_var_new:0.993927121
output spend 0.00013839900202583522 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006888730000355281 time
recovery_state_mcts_prob spend 0.2638632179950946 time
state_batch spend 0.001943784998729825 time
mcts_probs_batch spend 0.006636240002990235 time
winner_batch spend 0.00029871900187572464 time
policy_value spend 0.20594457599509042 time
train_step spend 0.602746611002658 time
policy_value spend 0.2056534229996032 time
train_step spend 0.6013787999982014 time
policy_value spend 0.21054936300060945 time
train_step spend 0.6445595119948848 time
policy_value spend 0.22049067600164562 time
train_step spend 0.6454867479988025 time
policy_value spend 0.21965254300448578 time
train_step spend 0.6446727429938619 time
policy_value spend 0.21966880400577793 time
kl:0.01748,lr_multiplier:7.594,loss:4.348711013793945,entropy:5.322766304016113,explained_var_old:0.985292852,explained_var_new:0.992630541
output spend 0.00023071000032359734 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0069703780027339235 time
recovery_state_mcts_prob spend 0.28621981899777893 time
state_batch spend 0.001915453998662997 time
mcts_probs_batch spend 0.006608982999750879 time
winner_batch spend 0.0002916349985753186 time
policy_value spend 0.2200280129982275 time
train_step spend 0.6433975460022339 time
policy_value spend 0.22078628099552589 time
train_step spend 0.6443212259982829 time
policy_value spend 0.22028512399992906 time
train_step spend 0.6440571540006204 time
policy_value spend 0.22102311300113797 time
train_step spend 0.6450588509978843 time
policy_value spend 0.2208489320037188 time
train_step spend 0.6445835690028616 time
policy_value spend 0.2201693909955793 time
kl:0.02479,lr_multiplier:7.594,loss:4.3799238204956055,entropy:5.310333728790283,explained_var_old:0.985565364,explained_var_new:0.990391374
output spend 0.00015345399879151955 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007014142000116408 time
recovery_state_mcts_prob spend 0.27707101499981945 time
state_batch spend 0.0018518020006013103 time
mcts_probs_batch spend 0.0056263820006279275 time
winner_batch spend 0.0002885040012188256 time
policy_value spend 0.22039857199706603 time
train_step spend 0.6503991650024545 time
policy_value spend 0.22751125999639044 time
train_step spend 0.6651050719956402 time
policy_value spend 0.22668130999954883 time
train_step spend 0.6647395550025976 time
policy_value spend 0.22722812699794304 time
train_step spend 0.6657883029984077 time
policy_value spend 0.22736890200030757 time
train_step spend 0.6649040229967795 time
policy_value spend 0.22760759000084363 time
kl:0.03683,lr_multiplier:7.594,loss:4.486886501312256,entropy:5.402294158935547,explained_var_old:0.988444269,explained_var_new:0.991649270
output spend 0.000155226000060793 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007703775001573376 time
recovery_state_mcts_prob spend 0.2806819559991709 time
state_batch spend 0.0024322089957422577 time
mcts_probs_batch spend 0.0068084020022070035 time
winner_batch spend 0.000298969003779348 time
policy_value spend 0.22732430399628356 time
train_step spend 0.6650658119979198 time
policy_value spend 0.23060883400466992 time
train_step spend 0.6648445669998182 time
policy_value spend 0.22738359100185335 time
train_step spend 0.6640199750036118 time
policy_value spend 0.22098413499770686 time
train_step spend 0.612053612996533 time
policy_value spend 0.20640227400144795 time
train_step spend 0.6031365140006528 time
policy_value spend 0.20624221300386125 time
kl:0.00791,lr_multiplier:11.391,loss:4.414956092834473,entropy:5.381694793701172,explained_var_old:0.991396546,explained_var_new:0.993625581
output spend 0.00013993200263939798 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007034991002001334 time
recovery_state_mcts_prob spend 0.2661620680009946 time
state_batch spend 0.001719689003948588 time
mcts_probs_batch spend 0.005317033996107057 time
winner_batch spend 0.0002679530007299036 time
policy_value spend 0.20553093899798114 time
train_step spend 0.6030867879962898 time
policy_value spend 0.21174593199975789 time
train_step spend 0.6018746990012005 time
policy_value spend 0.20631751399923814 time
train_step spend 0.6018754109973088 time
policy_value spend 0.20619144199736184 time
train_step spend 0.6017719340015901 time
policy_value spend 0.20594878900010372 time
train_step spend 0.602800032000232 time
policy_value spend 0.2061972289957339 time
kl:0.00664,lr_multiplier:11.391,loss:4.373078346252441,entropy:5.311520576477051,explained_var_old:0.979796827,explained_var_new:0.984606862
output spend 0.00014663200272480026 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0066605859974515624 time
recovery_state_mcts_prob spend 0.25564325000596 time
state_batch spend 0.001858340998296626 time
mcts_probs_batch spend 0.006298839994997252 time
winner_batch spend 0.00029678800638066605 time
policy_value spend 0.2063037119951332 time
train_step spend 0.6031046779971803 time
policy_value spend 0.2080670020004618 time
train_step spend 0.6069143549975706 time
policy_value spend 0.20761107400176115 time
train_step spend 0.6068632360038464 time
policy_value spend 0.2078836250002496 time
train_step spend 0.6069796289957594 time
policy_value spend 0.20740512700285763 time
train_step spend 0.6066181719943415 time
policy_value spend 0.20809544200164964 time
kl:0.02064,lr_multiplier:11.391,loss:4.3834004402160645,entropy:5.345321178436279,explained_var_old:0.995736957,explained_var_new:0.998967052
output spend 0.00015002200234448537 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006848638993687928 time
recovery_state_mcts_prob spend 0.2669304780065431 time
state_batch spend 0.0018427229952067137 time
mcts_probs_batch spend 0.01380469799914863 time
winner_batch spend 0.00029345900111366063 time
policy_value spend 0.21097686699795304 time
train_step spend 0.6061310259974562 time
policy_value spend 0.21109097299631685 time
train_step spend 0.6228270270003122 time
policy_value spend 0.22027533099753782 time
train_step spend 0.6587804690061603 time
policy_value spend 0.23389401199528947 time
train_step spend 0.6727397280046716 time
policy_value spend 0.22149929899751442 time
train_step spend 0.646466190002684 time
policy_value spend 0.21982467100315262 time
kl:0.01672,lr_multiplier:11.391,loss:4.391442775726318,entropy:5.359187126159668,explained_var_old:0.984651268,explained_var_new:0.986983538
output spend 0.00014813699817750603 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008517222995578777 time
recovery_state_mcts_prob spend 0.29241996000200743 time
state_batch spend 0.0019419630043557845 time
mcts_probs_batch spend 0.005685138996341266 time
winner_batch spend 0.0002987710031447932 time
policy_value spend 0.22036354799638502 time
train_step spend 0.6444419140025275 time
policy_value spend 0.2211242499979562 time
train_step spend 0.6449698859942146 time
policy_value spend 0.2204264830070315 time
train_step spend 0.6441243320005015 time
policy_value spend 0.2206266279972624 time
train_step spend 0.6443141469935654 time
policy_value spend 0.2215586460006307 time
train_step spend 0.6449326259971713 time
policy_value spend 0.22049683400109643 time
kl:0.02089,lr_multiplier:11.391,loss:4.359470367431641,entropy:5.357826232910156,explained_var_old:0.995675564,explained_var_new:0.999136984
output spend 0.00015135699504753575 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00867223500245018 time
recovery_state_mcts_prob spend 0.271323722001398 time
state_batch spend 0.001892654996481724 time
mcts_probs_batch spend 0.006197036003868561 time
winner_batch spend 0.00028741099959006533 time
policy_value spend 0.2206943630008027 time
train_step spend 0.6513872490031645 time
policy_value spend 0.22556540399818914 time
train_step spend 0.6612662530023954 time
policy_value spend 0.22704145400348352 time
train_step spend 0.663227827004448 time
policy_value spend 0.22571842899924377 time
train_step spend 0.660764301996096 time
policy_value spend 0.22627020700019784 time
train_step spend 0.6603652330013574 time
policy_value spend 0.22565330000361428 time
kl:0.01325,lr_multiplier:11.391,loss:4.349969387054443,entropy:5.341938018798828,explained_var_old:0.996604741,explained_var_new:0.999185383
output spend 0.00015839400293771178 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007752842000627425 time
recovery_state_mcts_prob spend 0.2815400050021708 time
state_batch spend 0.0019864170026266947 time
mcts_probs_batch spend 0.006738546995620709 time
winner_batch spend 0.0002968769986182451 time
policy_value spend 0.22556687700125622 time
train_step spend 0.6608906749970629 time
policy_value spend 0.2267334269999992 time
train_step spend 0.6598919099997147 time
policy_value spend 0.22528721099661198 time
train_step spend 0.6610091010006727 time
policy_value spend 0.22482493400457315 time
train_step spend 0.6161792499988223 time
policy_value spend 0.20617388400569325 time
train_step spend 0.6016421370004537 time
policy_value spend 0.20540212600462837 time
kl:0.01476,lr_multiplier:11.391,loss:4.321353435516357,entropy:5.2838454246521,explained_var_old:0.986577213,explained_var_new:0.988533020
output spend 0.00014094200014369562 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006638124999881256 time
recovery_state_mcts_prob spend 0.25866380300431047 time
state_batch spend 0.0017646749984123744 time
mcts_probs_batch spend 0.00612354300392326 time
winner_batch spend 0.0002768439953797497 time
policy_value spend 0.2090314200031571 time
train_step spend 0.6035221540005296 time
policy_value spend 0.20739851600228576 time
train_step spend 0.6015304179964005 time
policy_value spend 0.20557326300331624 time
train_step spend 0.602241568005411 time
policy_value spend 0.2065611829966656 time
train_step spend 0.6027191600005608 time
policy_value spend 0.20666862199868774 time
train_step spend 0.6032177460001549 time
policy_value spend 0.2061020399996778 time
kl:0.01187,lr_multiplier:11.391,loss:4.350568771362305,entropy:5.317021369934082,explained_var_old:0.995141447,explained_var_new:0.997568846
output spend 0.00013681300333701074 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006637646998569835 time
recovery_state_mcts_prob spend 0.2606358890043339 time
state_batch spend 0.0018712449964368716 time
mcts_probs_batch spend 0.00653242900443729 time
winner_batch spend 0.00031736600067233667 time
policy_value spend 0.2061232919950271 time
train_step spend 0.6213808450047509 time
policy_value spend 0.21011344699945766 time
train_step spend 0.6100396479960182 time
policy_value spend 0.20827938400179846 time
train_step spend 0.6095000929999514 time
policy_value spend 0.20811402300023474 time
train_step spend 0.6103708489972632 time
policy_value spend 0.20819295100227464 time
train_step spend 0.6103467459979584 time
policy_value spend 0.2088868530045147 time
kl:0.01341,lr_multiplier:11.391,loss:4.320176124572754,entropy:5.304562568664551,explained_var_old:0.991029918,explained_var_new:0.993496537
output spend 0.0001400440014549531 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006837698994786479 time
recovery_state_mcts_prob spend 0.2721354590030387 time
state_batch spend 0.0018528549990151078 time
mcts_probs_batch spend 0.006333700999675784 time
winner_batch spend 0.00030626099760411307 time
policy_value spend 0.20893874800094636 time
train_step spend 0.6096908159961458 time
policy_value spend 0.21110290499927942 time
train_step spend 0.6400094640048337 time
policy_value spend 0.22018416699575027 time
train_step spend 0.6452070610030205 time
policy_value spend 0.2203986369931954 time
train_step spend 0.6455965770001058 time
policy_value spend 0.22163551700214157 time
train_step spend 0.6438851440034341 time
policy_value spend 0.2202760469954228 time
kl:0.00838,lr_multiplier:11.391,loss:4.425965309143066,entropy:5.359004020690918,explained_var_old:0.982246220,explained_var_new:0.989126623
output spend 0.00015092999819898978 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00765232300182106 time
recovery_state_mcts_prob spend 0.27044155600015074 time
state_batch spend 0.001893574997666292 time
mcts_probs_batch spend 0.006648583002970554 time
winner_batch spend 0.00029793100111419335 time
policy_value spend 0.22109497799829114 time
train_step spend 0.6448493599964422 time
policy_value spend 0.2205930750060361 time
train_step spend 0.6445269670002745 time
policy_value spend 0.21939106399804587 time
train_step spend 0.6427312329979031 time
policy_value spend 0.21972141999867745 time
train_step spend 0.6456938749979599 time
policy_value spend 0.22010212099849014 time
train_step spend 0.6439253389980877 time
policy_value spend 0.21973414000240155 time
kl:0.02477,lr_multiplier:11.391,loss:4.355955600738525,entropy:5.31803560256958,explained_var_old:0.993400633,explained_var_new:0.996702194
output spend 0.0001554280024720356 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008365342997421976 time
recovery_state_mcts_prob spend 0.2724178540011053 time
state_batch spend 0.0019090980058535933 time
mcts_probs_batch spend 0.008374539000215009 time
winner_batch spend 0.00033378299849573523 time
policy_value spend 0.21980144499684684 time
train_step spend 0.6475064570040558 time
policy_value spend 0.22562745299364906 time
train_step spend 0.6629516059983871 time
policy_value spend 0.22698752699943725 time
train_step spend 0.662852464003663 time
policy_value spend 0.22696286299469648 time
train_step spend 0.6628129669988994 time
policy_value spend 0.22653424300369807 time
train_step spend 0.6626837299991166 time
policy_value spend 0.22638257100334158 time
kl:0.01561,lr_multiplier:11.391,loss:4.373169898986816,entropy:5.346707344055176,explained_var_old:0.992120683,explained_var_new:0.996940732
output spend 0.00015567099762847647 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009414100997673813 time
recovery_state_mcts_prob spend 0.28656921299989335 time
state_batch spend 0.0025406429995200597 time
mcts_probs_batch spend 0.006977422002819367 time
winner_batch spend 0.0003268470027251169 time
policy_value spend 0.2279069609940052 time
train_step spend 0.6979210059944307 time
policy_value spend 0.24256427700311178 time
train_step spend 0.6666066449979553 time
policy_value spend 0.22752072699950077 time
train_step spend 0.663173900997208 time
policy_value spend 0.22742868299974361 time
train_step spend 0.6494289199981722 time
policy_value spend 0.22035081500507658 time
train_step spend 0.6436825179989683 time
policy_value spend 0.21944704199995613 time
kl:0.01578,lr_multiplier:11.391,loss:4.3606719970703125,entropy:5.313661575317383,explained_var_old:0.992416561,explained_var_new:0.995327473
output spend 0.00019173399778082967 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011197425999853294 time
recovery_state_mcts_prob spend 0.2732022460040753 time
state_batch spend 0.0018747219946817495 time
mcts_probs_batch spend 0.004668484005378559 time
winner_batch spend 0.00033387499570380896 time
policy_value spend 0.21959366200462682 time
train_step spend 0.6425814260001061 time
policy_value spend 0.21989388299698476 time
train_step spend 0.6442806940031005 time
policy_value spend 0.22004396599368192 time
train_step spend 0.6443297160003567 time
policy_value spend 0.22028311299800407 time
train_step spend 0.6433430530014448 time
policy_value spend 0.22062092999840388 time
train_step spend 0.6432229729980463 time
policy_value spend 0.22000783400289947 time
kl:0.00965,lr_multiplier:11.391,loss:4.306646347045898,entropy:5.269162178039551,explained_var_old:0.988243520,explained_var_new:0.989830792
output spend 0.000217831002373714 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006970791997446213 time
recovery_state_mcts_prob spend 0.27049755299958633 time
state_batch spend 0.0021742480021202937 time
mcts_probs_batch spend 0.004585834001773037 time
winner_batch spend 0.0002835970008163713 time
policy_value spend 0.21835712399479235 time
train_step spend 0.641021476003516 time
policy_value spend 0.21905135599809 time
train_step spend 0.6406295349952416 time
policy_value spend 0.2192580060000182 time
train_step spend 0.64134276999539 time
policy_value spend 0.2189096759975655 time
train_step spend 0.6407873240023036 time
policy_value spend 0.2192656229963177 time
train_step spend 0.6408874550033943 time
policy_value spend 0.21893779099627864 time
kl:0.02132,lr_multiplier:11.391,loss:4.336045265197754,entropy:5.35713529586792,explained_var_old:0.996535778,explained_var_new:0.999162853
output spend 0.0001545650011394173 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007258477999130264 time
recovery_state_mcts_prob spend 0.2727536400052486 time
state_batch spend 0.00191298799472861 time
mcts_probs_batch spend 0.004875413003901485 time
winner_batch spend 0.00033112299570348114 time
policy_value spend 0.21872323500429047 time
train_step spend 0.6402337559993612 time
policy_value spend 0.2191243970009964 time
train_step spend 0.6413092840011814 time
policy_value spend 0.2199169890009216 time
train_step spend 0.6486075729990262 time
policy_value spend 0.21883360700303456 time
train_step spend 0.6383581649934058 time
policy_value spend 0.21869942100602202 time
train_step spend 0.6392787110016798 time
policy_value spend 0.21844935699482448 time
kl:0.02906,lr_multiplier:11.391,loss:4.351882457733154,entropy:5.337615966796875,explained_var_old:0.991139829,explained_var_new:0.992217362
output spend 0.00014784700033487752 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007330508997256402 time
recovery_state_mcts_prob spend 0.2793151180012501 time
state_batch spend 0.0018996419967152178 time
mcts_probs_batch spend 0.0066124980003223754 time
winner_batch spend 0.00032140000257641077 time
policy_value spend 0.2208374609981547 time
train_step spend 0.6415621929991175 time
policy_value spend 0.21764043100120034 time
train_step spend 0.639030405000085 time
policy_value spend 0.21863683700212277 time
train_step spend 0.639263736004068 time
policy_value spend 0.21827698199922452 time
train_step spend 0.6396380309961387 time
policy_value spend 0.21780990499973996 time
train_step spend 0.639158349003992 time
policy_value spend 0.21898839799541747 time
kl:0.01126,lr_multiplier:11.391,loss:4.332112789154053,entropy:5.2798848152160645,explained_var_old:0.990877032,explained_var_new:0.995098889
output spend 0.00014706300135003403 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009763263995409943 time
recovery_state_mcts_prob spend 0.2733849130017916 time
state_batch spend 0.0018973629994434305 time
mcts_probs_batch spend 0.007516099001804832 time
winner_batch spend 0.00029761900077573955 time
policy_value spend 0.23735369299538434 time
train_step spend 0.6975116989997332 time
policy_value spend 0.23960792100115214 time
train_step spend 0.6986653350031702 time
policy_value spend 0.2392624549975153 time
train_step spend 0.6982861560027231 time
policy_value spend 0.2398054239965859 time
train_step spend 0.703388204005023 time
policy_value spend 0.23923186299361987 time
train_step spend 0.6982001869982923 time
policy_value spend 0.23892272700322792 time
kl:0.01782,lr_multiplier:11.391,loss:4.34207820892334,entropy:5.289763927459717,explained_var_old:0.992083907,explained_var_new:0.994962215
output spend 0.00019969000277342275 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00827382200077409 time
recovery_state_mcts_prob spend 0.30629009599942947 time
state_batch spend 0.002127603998815175 time
mcts_probs_batch spend 0.007301224999537226 time
winner_batch spend 0.00033667500247247517 time
policy_value spend 0.23925169299764093 time
train_step spend 0.6992724480005563 time
policy_value spend 0.23848515300051076 time
train_step spend 0.6984601699950872 time
policy_value spend 0.2394008510018466 time
train_step spend 0.6031085700014955 time
policy_value spend 0.20583989299484529 time
train_step spend 0.602004495995061 time
policy_value spend 0.2062438380016829 time
train_step spend 0.6019368449997273 time
policy_value spend 0.20568995000212453 time
kl:0.01887,lr_multiplier:11.391,loss:4.330005168914795,entropy:5.289347171783447,explained_var_old:0.981763244,explained_var_new:0.987822831
output spend 0.00014450399612542242 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009523376000288408 time
recovery_state_mcts_prob spend 0.25346572499984177 time
state_batch spend 0.0020936169967171736 time
mcts_probs_batch spend 0.005639277005684562 time
winner_batch spend 0.00028003599436488 time
policy_value spend 0.20564602900412865 time
train_step spend 0.6028013769973768 time
policy_value spend 0.20566303500527283 time
train_step spend 0.6020616359965061 time
policy_value spend 0.2054914460022701 time
train_step spend 0.6029208580002887 time
policy_value spend 0.2060787669979618 time
train_step spend 0.6022619619980105 time
policy_value spend 0.20605579300172394 time
train_step spend 0.6027480859993375 time
policy_value spend 0.20613936099834973 time
kl:0.04362,lr_multiplier:7.594,loss:4.363863468170166,entropy:5.279988765716553,explained_var_old:0.991438270,explained_var_new:0.995586455
output spend 0.00013793000107398257 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007322782003029715 time
recovery_state_mcts_prob spend 0.26210297199577326 time
state_batch spend 0.0017839880019892007 time
mcts_probs_batch spend 0.004538396002317313 time
winner_batch spend 0.00043567499960772693 time
policy_value spend 0.2050895659995149 time
train_step spend 0.6011683830001857 time
policy_value spend 0.20598200800304767 time
train_step spend 0.6024667249948834 time
policy_value spend 0.20658928300690604 time
train_step spend 0.6022414960025344 time
policy_value spend 0.20595453099667793 time
train_step spend 0.6024097029949189 time
policy_value spend 0.20562408400292043 time
train_step spend 0.6177379750006367 time
policy_value spend 0.21840302100463305 time
kl:0.01063,lr_multiplier:7.594,loss:4.380334377288818,entropy:5.309272289276123,explained_var_old:0.991898239,explained_var_new:0.992213368
output spend 0.00019553899619495496 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006460142001742497 time
recovery_state_mcts_prob spend 0.25745887299854076 time
state_batch spend 0.0020661969974753447 time
mcts_probs_batch spend 0.006938367005204782 time
winner_batch spend 0.00027560899616219103 time
policy_value spend 0.20743109199975152 time
train_step spend 0.6038820070025395 time
policy_value spend 0.20523853199847508 time
train_step spend 0.6030280319973826 time
policy_value spend 0.20567075900180498 time
train_step spend 0.6021762999953353 time
policy_value spend 0.2092961460002698 time
train_step spend 0.630786394001916 time
policy_value spend 0.21572246200230438 time
train_step spend 0.6311914409961901 time
policy_value spend 0.21556661499926122 time
kl:0.02693,lr_multiplier:7.594,loss:4.362573623657227,entropy:5.321210861206055,explained_var_old:0.986944735,explained_var_new:0.989791512
output spend 0.0005076980014564469 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007369892002316192 time
recovery_state_mcts_prob spend 0.26579690699873026 time
state_batch spend 0.0018984039998031221 time
mcts_probs_batch spend 0.006248621997656301 time
winner_batch spend 0.00027942400629399344 time
policy_value spend 0.2150787849968765 time
train_step spend 0.6293129479963682 time
policy_value spend 0.21876137800427387 time
train_step spend 0.6296989990005386 time
policy_value spend 0.21577602599427337 time
train_step spend 0.630500347004272 time
policy_value spend 0.2152813389984658 time
train_step spend 0.6301208940058132 time
policy_value spend 0.21485742399818264 time
train_step spend 0.6300254950037925 time
policy_value spend 0.21511597499920754 time
kl:0.04368,lr_multiplier:5.062,loss:4.310908794403076,entropy:5.28532075881958,explained_var_old:0.990378380,explained_var_new:0.996244669
output spend 0.00014696000289404765 time
已保存最新模型
current self-play batch: 700
load data begin
已加载数据
step i 372: 
random.sample spend 0.007984879004652612 time
recovery_state_mcts_prob spend 0.2732017599992105 time
state_batch spend 0.0018852089997380972 time
mcts_probs_batch spend 0.006760447999113239 time
winner_batch spend 0.0003426979965297505 time
policy_value spend 0.22431232300004922 time
train_step spend 0.6918651720043272 time
policy_value spend 0.22861292499874253 time
train_step spend 0.6559926699992502 time
policy_value spend 0.22220610299700638 time
train_step spend 0.6517372939997585 time
policy_value spend 0.22360982299869647 time
train_step spend 0.6531372739991639 time
policy_value spend 0.2233028929986176 time
train_step spend 0.6527363390050596 time
policy_value spend 0.222742448997451 time
kl:0.03739,lr_multiplier:5.062,loss:4.392727375030518,entropy:5.333717346191406,explained_var_old:0.967145562,explained_var_new:0.990422904
output spend 0.0001852690038504079 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008402166997257154 time
recovery_state_mcts_prob spend 0.2897717720043147 time
state_batch spend 0.0019095409952569753 time
mcts_probs_batch spend 0.006141246005427092 time
winner_batch spend 0.0002890599935199134 time
policy_value spend 0.22289350100618321 time
train_step spend 0.6519923239975469 time
policy_value spend 0.2240365660036332 time
train_step spend 0.6519703039957676 time
policy_value spend 0.2236107710050419 time
train_step spend 0.6501347539960989 time
policy_value spend 0.21971776000282262 time
train_step spend 0.6437601529978565 time
policy_value spend 0.21964695699716685 time
train_step spend 0.6439287340035662 time
policy_value spend 0.21939392700005556 time
kl:0.04953,lr_multiplier:3.375,loss:4.33487606048584,entropy:5.292415618896484,explained_var_old:0.978938043,explained_var_new:0.986487389
output spend 0.00014714600547449663 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007660217001102865 time
recovery_state_mcts_prob spend 0.2739321769986418 time
state_batch spend 0.00198198200087063 time
mcts_probs_batch spend 0.006702790000417735 time
winner_batch spend 0.0003093760024057701 time
policy_value spend 0.2204529939990607 time
train_step spend 0.6448941220005509 time
policy_value spend 0.22258779899857473 time
train_step spend 0.6433530770009384 time
policy_value spend 0.22013455299747875 time
train_step spend 0.6430816749998485 time
policy_value spend 0.2203220989977126 time
train_step spend 0.6443683010002133 time
policy_value spend 0.21996778299944708 time
train_step spend 0.6447283739980776 time
policy_value spend 0.21975715100415982 time
kl:0.01739,lr_multiplier:3.375,loss:4.337438583374023,entropy:5.290226936340332,explained_var_old:0.989559174,explained_var_new:0.995347261
output spend 0.00016142000094987452 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070524089969694614 time
recovery_state_mcts_prob spend 0.2720658450052724 time
state_batch spend 0.0019636779979919083 time
mcts_probs_batch spend 0.006607258997973986 time
winner_batch spend 0.00028414699772838503 time
policy_value spend 0.21495801400305936 time
train_step spend 0.630577316005656 time
policy_value spend 0.21466041999519803 time
train_step spend 0.6294704200045089 time
policy_value spend 0.21550442399893655 time
train_step spend 0.6293036060014856 time
policy_value spend 0.2148213569962536 time
train_step spend 0.6343205869998201 time
policy_value spend 0.21560732899524737 time
train_step spend 0.6288465570032713 time
policy_value spend 0.21514728899637703 time
kl:0.01394,lr_multiplier:3.375,loss:4.289627552032471,entropy:5.298017501831055,explained_var_old:0.989047170,explained_var_new:0.991512060
output spend 0.00048353499732911587 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007140264999179635 time
recovery_state_mcts_prob spend 0.2760353980047512 time
state_batch spend 0.0018297220012755133 time
mcts_probs_batch spend 0.006373559997882694 time
winner_batch spend 0.00035297100112074986 time
policy_value spend 0.21781380199536216 time
train_step spend 0.6302863309974782 time
policy_value spend 0.2151413550018333 time
train_step spend 0.6287098590037203 time
policy_value spend 0.21491638099541888 time
train_step spend 0.6308480200023041 time
policy_value spend 0.2158180260012159 time
train_step spend 0.632910260996141 time
policy_value spend 0.21606747600162635 time
train_step spend 0.6322321289990214 time
policy_value spend 0.21574119800061453 time
kl:0.03499,lr_multiplier:3.375,loss:4.280226707458496,entropy:5.260466575622559,explained_var_old:0.994111776,explained_var_new:0.995834649
output spend 0.00014824299432802945 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009155854000709951 time
recovery_state_mcts_prob spend 0.26929676700092386 time
state_batch spend 0.0017905979984789155 time
mcts_probs_batch spend 0.0045095649984432384 time
winner_batch spend 0.0003130309996777214 time
policy_value spend 0.21557646799919894 time
train_step spend 0.633394741002121 time
policy_value spend 0.2148654729971895 time
train_step spend 0.6358815529965796 time
policy_value spend 0.21630916100548347 time
train_step spend 0.6332440879996284 time
policy_value spend 0.21638597999844933 time
train_step spend 0.6330163960010395 time
policy_value spend 0.21571875600056956 time
train_step spend 0.6326097170021967 time
policy_value spend 0.2160001519951038 time
kl:0.01815,lr_multiplier:3.375,loss:4.434808254241943,entropy:5.33793830871582,explained_var_old:0.988929927,explained_var_new:0.994665682
output spend 0.0001504300016677007 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007793900993419811 time
recovery_state_mcts_prob spend 0.28275619400665164 time
state_batch spend 0.0018939059955300763 time
mcts_probs_batch spend 0.0067047280026599765 time
winner_batch spend 0.0004242349968990311 time
policy_value spend 0.22753461899992544 time
train_step spend 0.660232903996075 time
policy_value spend 0.23352996300673112 time
train_step spend 0.6563617069987231 time
policy_value spend 0.2205746170002385 time
train_step spend 0.6408414339966839 time
policy_value spend 0.21870362300251145 time
train_step spend 0.6402623589965515 time
policy_value spend 0.21932401200319873 time
train_step spend 0.6411582970031304 time
policy_value spend 0.21943618299701484 time
kl:0.02931,lr_multiplier:3.375,loss:4.2870259284973145,entropy:5.291134834289551,explained_var_old:0.990835607,explained_var_new:0.995724082
output spend 0.00015802000416442752 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007770670999889262 time
recovery_state_mcts_prob spend 0.26993194699753076 time
state_batch spend 0.0018060459988191724 time
mcts_probs_batch spend 0.006260455003939569 time
winner_batch spend 0.0003036919952137396 time
policy_value spend 0.21904565799923148 time
train_step spend 0.6392907070039655 time
policy_value spend 0.21976669199648313 time
train_step spend 0.6394127559979097 time
policy_value spend 0.21826696499920217 time
train_step spend 0.6354212779988302 time
policy_value spend 0.21698144000401953 time
train_step spend 0.6341091279973625 time
policy_value spend 0.21645766599976923 time
train_step spend 0.6341502779978327 time
policy_value spend 0.21767494700179668 time
kl:0.01090,lr_multiplier:3.375,loss:4.3286943435668945,entropy:5.287212371826172,explained_var_old:0.995296597,explained_var_new:0.996008515
output spend 0.00014840599760646 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007633546003489755 time
recovery_state_mcts_prob spend 0.2795604389975779 time
state_batch spend 0.0019265330047346652 time
mcts_probs_batch spend 0.005051050000474788 time
winner_batch spend 0.00028294999356148764 time
policy_value spend 0.21678479300317122 time
train_step spend 0.6351105079957051 time
policy_value spend 0.2164688990014838 time
train_step spend 0.6331594600051176 time
policy_value spend 0.2238105039941729 time
train_step spend 0.6340680170033011 time
policy_value spend 0.21708117699745344 time
train_step spend 0.634578187004081 time
policy_value spend 0.21633017800195375 time
train_step spend 0.6373849879964837 time
policy_value spend 0.21662318000016967 time
kl:0.01405,lr_multiplier:3.375,loss:4.326933860778809,entropy:5.288749694824219,explained_var_old:0.978985906,explained_var_new:0.986176193
output spend 0.00014561499847332016 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007383242998912465 time
recovery_state_mcts_prob spend 0.2670728790035355 time
state_batch spend 0.002253097001812421 time
mcts_probs_batch spend 0.004490750994591508 time
winner_batch spend 0.00029255000117700547 time
policy_value spend 0.2117620330027421 time
train_step spend 0.6212018419973901 time
policy_value spend 0.2122417430000496 time
train_step spend 0.6214138610012014 time
policy_value spend 0.21212672300316626 time
train_step spend 0.6215044670025236 time
policy_value spend 0.21273792700230842 time
train_step spend 0.6214754409957095 time
policy_value spend 0.21272965199750615 time
train_step spend 0.6219918189963209 time
policy_value spend 0.21208810999814887 time
kl:0.01667,lr_multiplier:3.375,loss:4.296799659729004,entropy:5.297332763671875,explained_var_old:0.993249536,explained_var_new:0.998149812
output spend 0.00014506599836749956 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007987860000866931 time
recovery_state_mcts_prob spend 0.2703594019985758 time
state_batch spend 0.00196064000192564 time
mcts_probs_batch spend 0.006837291002739221 time
winner_batch spend 0.00029352599813137203 time
policy_value spend 0.21175334500003373 time
train_step spend 0.621538690997113 time
policy_value spend 0.21214282599976286 time
train_step spend 0.6206601690064417 time
policy_value spend 0.21313745499355718 time
train_step spend 0.6292846860014834 time
policy_value spend 0.21892815100000007 time
train_step spend 0.6398630760013475 time
policy_value spend 0.21897556699695997 time
train_step spend 0.6409078290016623 time
policy_value spend 0.21937155300111044 time
kl:0.02947,lr_multiplier:3.375,loss:4.363348484039307,entropy:5.291014194488525,explained_var_old:0.994711757,explained_var_new:0.996867418
output spend 0.00014922300033504143 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009305824001785368 time
recovery_state_mcts_prob spend 0.27909315199940465 time
state_batch spend 0.002217636996647343 time
mcts_probs_batch spend 0.005211399002291728 time
winner_batch spend 0.0003057709982385859 time
policy_value spend 0.22044959000049857 time
train_step spend 0.6421128140063956 time
policy_value spend 0.22044256899971515 time
train_step spend 0.6404942329972982 time
policy_value spend 0.2192459459984093 time
train_step spend 0.6401986929995473 time
policy_value spend 0.22006355700432323 time
train_step spend 0.6401632570050424 time
policy_value spend 0.21980350599915255 time
train_step spend 0.6409192249993794 time
policy_value spend 0.21869547700043768 time
kl:0.01190,lr_multiplier:3.375,loss:4.275424003601074,entropy:5.241170406341553,explained_var_old:0.990150213,explained_var_new:0.994939208
output spend 0.00017616200057091191 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007858939003199339 time
recovery_state_mcts_prob spend 0.2800385739974445 time
state_batch spend 0.0019337420017109253 time
mcts_probs_batch spend 0.0046043539987294935 time
winner_batch spend 0.0002928769972641021 time
policy_value spend 0.2180772360006813 time
train_step spend 0.6439437589942827 time
policy_value spend 0.2192407410038868 time
train_step spend 0.6430686830062768 time
policy_value spend 0.22010951699485304 time
train_step spend 0.6435112859981018 time
policy_value spend 0.21960195300198393 time
train_step spend 0.6435796580044553 time
policy_value spend 0.22012400799576426 time
train_step spend 0.6435586220031837 time
policy_value spend 0.21980738399724942 time
kl:0.01428,lr_multiplier:3.375,loss:4.342036724090576,entropy:5.255468845367432,explained_var_old:0.986123145,explained_var_new:0.990296423
output spend 0.0001554889968247153 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010749316999863368 time
recovery_state_mcts_prob spend 0.2725625669991132 time
state_batch spend 0.001963526003237348 time
mcts_probs_batch spend 0.0071848719962872565 time
winner_batch spend 0.0002989370041177608 time
policy_value spend 0.22125407600105973 time
train_step spend 0.6448260320030386 time
policy_value spend 0.21975037999800406 time
train_step spend 0.6438097240024945 time
policy_value spend 0.22139063500071643 time
train_step spend 0.6376272130000871 time
policy_value spend 0.21684872100013308 time
train_step spend 0.6362622270025895 time
policy_value spend 0.21815331299876561 time
train_step spend 0.6357537309959298 time
policy_value spend 0.21731985700171208 time
kl:0.02203,lr_multiplier:3.375,loss:4.383120536804199,entropy:5.318758487701416,explained_var_old:0.986424804,explained_var_new:0.991103768
output spend 0.00014687299699289724 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007755036000162363 time
recovery_state_mcts_prob spend 0.2781090509961359 time
state_batch spend 0.001894514003652148 time
mcts_probs_batch spend 0.005724410999391694 time
winner_batch spend 0.00030744999821763486 time
policy_value spend 0.21658412700344343 time
train_step spend 0.635680860003049 time
policy_value spend 0.2190206249943003 time
train_step spend 0.6381068779955967 time
policy_value spend 0.21796510200510966 time
train_step spend 0.6369226850001724 time
policy_value spend 0.21685694299958413 time
train_step spend 0.6358874629950151 time
policy_value spend 0.21681955399981234 time
train_step spend 0.6354337599987048 time
policy_value spend 0.21735381100006634 time
kl:0.00871,lr_multiplier:5.062,loss:4.3106913566589355,entropy:5.288403511047363,explained_var_old:0.989868581,explained_var_new:0.994746506
output spend 0.0006186489990795963 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007623182995303068 time
recovery_state_mcts_prob spend 0.2825118390028365 time
state_batch spend 0.0021631639974657446 time
mcts_probs_batch spend 0.00553394400049001 time
winner_batch spend 0.0002909120012191124 time
policy_value spend 0.22483024399843998 time
train_step spend 0.6389318049987196 time
policy_value spend 0.21342833500239067 time
train_step spend 0.6219241630024044 time
policy_value spend 0.2128618849965278 time
train_step spend 0.6212311180061079 time
policy_value spend 0.2121906179963844 time
train_step spend 0.6220669369940879 time
policy_value spend 0.21247266000136733 time
train_step spend 0.6210742150069564 time
policy_value spend 0.21259479199943598 time
kl:0.04127,lr_multiplier:3.375,loss:4.322689533233643,entropy:5.26767635345459,explained_var_old:0.985484362,explained_var_new:0.988377094
output spend 0.00014316499436972663 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008597842999733984 time
recovery_state_mcts_prob spend 0.2627490820013918 time
state_batch spend 0.002005246999033261 time
mcts_probs_batch spend 0.004696333999163471 time
winner_batch spend 0.0002781689981929958 time
policy_value spend 0.21094416800042382 time
train_step spend 0.6216539820015896 time
policy_value spend 0.21296463599719573 time
train_step spend 0.6209514009970007 time
policy_value spend 0.21787150300224312 time
train_step spend 0.6406980489991838 time
policy_value spend 0.2189680759984185 time
train_step spend 0.6401480380009161 time
policy_value spend 0.2180127019964857 time
train_step spend 0.6391502010010299 time
policy_value spend 0.21966585100017255 time
kl:0.07325,lr_multiplier:2.250,loss:4.333386421203613,entropy:5.283928871154785,explained_var_old:0.993306220,explained_var_new:0.995659113
output spend 0.0001450220006518066 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010215560003416613 time
recovery_state_mcts_prob spend 0.27047674499772256 time
state_batch spend 0.002157843002351001 time
mcts_probs_batch spend 0.006418468001356814 time
winner_batch spend 0.0002836459971149452 time
policy_value spend 0.21906080900225788 time
train_step spend 0.6409811600024113 time
policy_value spend 0.2192988989991136 time
train_step spend 0.6401210159965558 time
policy_value spend 0.21875549600372324 time
train_step spend 0.6393295989983017 time
policy_value spend 0.2189595130039379 time
train_step spend 0.6395289939973736 time
policy_value spend 0.2195074100018246 time
train_step spend 0.6398016490056762 time
policy_value spend 0.21831160699366592 time
kl:0.03146,lr_multiplier:2.250,loss:4.360612392425537,entropy:5.304665565490723,explained_var_old:0.992837369,explained_var_new:0.998865545
output spend 0.00014526200538966805 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00831655000365572 time
recovery_state_mcts_prob spend 0.2795174880011473 time
state_batch spend 0.0018477539997547865 time
mcts_probs_batch spend 0.0066638179996516556 time
winner_batch spend 0.00029092699696775526 time
policy_value spend 0.21907782400376163 time
train_step spend 0.6415858510008547 time
policy_value spend 0.21943416499561863 time
train_step spend 0.6418803140040836 time
policy_value spend 0.21973095699650003 time
train_step spend 0.6417565110023133 time
policy_value spend 0.21863220999512123 time
train_step spend 0.6424931529982132 time
policy_value spend 0.21997748099965975 time
train_step spend 0.6432173979992513 time
policy_value spend 0.21979258400097024 time
kl:0.00873,lr_multiplier:3.375,loss:4.323109149932861,entropy:5.287990093231201,explained_var_old:0.989528179,explained_var_new:0.991888463
output spend 0.00016621300164842978 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01171769999928074 time
recovery_state_mcts_prob spend 0.28249647700431524 time
state_batch spend 0.0018469170026946813 time
mcts_probs_batch spend 0.0044851200000266545 time
winner_batch spend 0.00028905299404868856 time
policy_value spend 0.21897769800125388 time
train_step spend 0.6416054220026126 time
policy_value spend 0.2183642960008001 time
train_step spend 0.6416209270028048 time
policy_value spend 0.2194352680016891 time
train_step spend 0.6339618149941089 time
policy_value spend 0.21604603200103156 time
train_step spend 0.6335641249970649 time
policy_value spend 0.2163191090003238 time
train_step spend 0.6368955840007402 time
policy_value spend 0.21632703299837885 time
kl:0.03553,lr_multiplier:3.375,loss:4.293931484222412,entropy:5.28352165222168,explained_var_old:0.998712420,explained_var_new:0.999226868
output spend 0.00014625300536863506 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00795793900033459 time
recovery_state_mcts_prob spend 0.27001789300265955 time
state_batch spend 0.0020157239996478893 time
mcts_probs_batch spend 0.006293796002864838 time
winner_batch spend 0.0003120479959761724 time
policy_value spend 0.21664524199877633 time
train_step spend 0.6359914819986443 time
policy_value spend 0.21679021300224122 time
train_step spend 0.6336673819969292 time
policy_value spend 0.21660040500137256 time
train_step spend 0.6344608340004925 time
policy_value spend 0.2166114240026218 time
train_step spend 0.6347865389980143 time
policy_value spend 0.21693269700335804 time
train_step spend 0.6343900640058564 time
policy_value spend 0.21671606699965196 time
kl:0.01055,lr_multiplier:3.375,loss:4.316555023193359,entropy:5.291003227233887,explained_var_old:0.995427608,explained_var_new:0.995877147
output spend 0.00014817000192124397 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009432020000531338 time
recovery_state_mcts_prob spend 0.2660359680012334 time
state_batch spend 0.0018089399964082986 time
mcts_probs_batch spend 0.004547470001853071 time
winner_batch spend 0.00030920800054445863 time
policy_value spend 0.21234401700348826 time
train_step spend 0.6215282269986346 time
policy_value spend 0.21275005899951793 time
train_step spend 0.6226691039992147 time
policy_value spend 0.21292256400192855 time
train_step spend 0.6227405130048282 time
policy_value spend 0.21297694199893158 time
train_step spend 0.6229157760026283 time
policy_value spend 0.2124405310023576 time
train_step spend 0.6226569889986422 time
policy_value spend 0.21353913500206545 time
kl:0.00921,lr_multiplier:5.062,loss:4.319174766540527,entropy:5.257312774658203,explained_var_old:0.986088157,explained_var_new:0.988254607
output spend 0.00015420300042023882 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007075900000927504 time
recovery_state_mcts_prob spend 0.2651117810019059 time
state_batch spend 0.0018650029960554093 time
mcts_probs_batch spend 0.006585390001419 time
winner_batch spend 0.00031160299840848893 time
policy_value spend 0.21218319699983113 time
train_step spend 0.6220190259991796 time
policy_value spend 0.21385325699520763 time
train_step spend 0.6370027280063368 time
policy_value spend 0.22034335599892074 time
train_step spend 0.6397584619990084 time
policy_value spend 0.21858036900084699 time
train_step spend 0.6397668569989037 time
policy_value spend 0.218741760996636 time
train_step spend 0.6392010359995766 time
policy_value spend 0.21876319500006502 time
kl:0.01665,lr_multiplier:5.062,loss:4.309826850891113,entropy:5.2543182373046875,explained_var_old:0.993862271,explained_var_new:0.995173514
output spend 0.00014861299860058352 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00916231799783418 time
recovery_state_mcts_prob spend 0.2757704499963438 time
state_batch spend 0.0018883370066760108 time
mcts_probs_batch spend 0.006694059993606061 time
winner_batch spend 0.00028395900153554976 time
policy_value spend 0.21869377400435042 time
train_step spend 0.6400537829977111 time
policy_value spend 0.21794870900339447 time
train_step spend 0.639421415005927 time
policy_value spend 0.21829850599897327 time
train_step spend 0.6546061240005656 time
policy_value spend 0.23105376300372882 time
train_step spend 0.6677908750061761 time
policy_value spend 0.2194990849966416 time
train_step spend 0.64102659800119 time
policy_value spend 0.21860663499683142 time
kl:0.01149,lr_multiplier:5.062,loss:4.279922962188721,entropy:5.244994163513184,explained_var_old:0.981879771,explained_var_new:0.984762311
output spend 0.00015544200141448528 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009136433000094257 time
recovery_state_mcts_prob spend 0.27816146700206446 time
state_batch spend 0.0020432000019354746 time
mcts_probs_batch spend 0.006247366996831261 time
winner_batch spend 0.0003033800021512434 time
policy_value spend 0.2200316809976357 time
train_step spend 0.6416402889954043 time
policy_value spend 0.21885072200529976 time
train_step spend 0.641090514996904 time
policy_value spend 0.2197100550038158 time
train_step spend 0.6417301280016545 time
policy_value spend 0.21930523499759147 time
train_step spend 0.6421000670015928 time
policy_value spend 0.2187610670007416 time
train_step spend 0.6431112579957698 time
policy_value spend 0.2202678300018306 time
kl:0.00822,lr_multiplier:7.594,loss:4.363971710205078,entropy:5.314040660858154,explained_var_old:0.994061410,explained_var_new:0.995388925
output spend 0.0001550029992358759 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0077767870025127195 time
recovery_state_mcts_prob spend 0.27470980999351013 time
state_batch spend 0.0019233290004194714 time
mcts_probs_batch spend 0.004531913000391796 time
winner_batch spend 0.0003029850049642846 time
policy_value spend 0.2192945159986266 time
train_step spend 0.642967118001252 time
policy_value spend 0.21948193299613195 time
train_step spend 0.6423519660020247 time
policy_value spend 0.2175274379987968 time
train_step spend 0.6333487189986045 time
policy_value spend 0.21632313000009162 time
train_step spend 0.6334096459977445 time
policy_value spend 0.21689770700322697 time
train_step spend 0.6336793279988342 time
policy_value spend 0.21625654899980873 time
kl:0.01194,lr_multiplier:7.594,loss:4.304106712341309,entropy:5.310694694519043,explained_var_old:0.987617612,explained_var_new:0.994809449
output spend 0.00014956400264054537 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007715239997196477 time
recovery_state_mcts_prob spend 0.27439334700466134 time
state_batch spend 0.0019216619984945282 time
mcts_probs_batch spend 0.007072392996633425 time
winner_batch spend 0.00033291600266238675 time
policy_value spend 0.216843248999794 time
train_step spend 0.6322098809978343 time
policy_value spend 0.21735839499888243 time
train_step spend 0.6351345959992614 time
policy_value spend 0.21646498100017197 time
train_step spend 0.6332397719961591 time
policy_value spend 0.21677932199963834 time
train_step spend 0.6335700199997518 time
policy_value spend 0.21557204700366128 time
train_step spend 0.6331843410007423 time
policy_value spend 0.21630164499947568 time
kl:0.01233,lr_multiplier:7.594,loss:4.2847490310668945,entropy:5.178997039794922,explained_var_old:0.990305245,explained_var_new:0.992029667
output spend 0.0001410609984304756 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006877151005028281 time
recovery_state_mcts_prob spend 0.2667981470003724 time
state_batch spend 0.0018619719994603656 time
mcts_probs_batch spend 0.006664494998403825 time
winner_batch spend 0.0002995510003529489 time
policy_value spend 0.21280784600094194 time
train_step spend 0.6229222870024387 time
policy_value spend 0.2144275539976661 time
train_step spend 0.6235434370028088 time
policy_value spend 0.2134995300002629 time
train_step spend 0.6229441789982957 time
policy_value spend 0.21349945700058015 time
train_step spend 0.6239650990028167 time
policy_value spend 0.21317167000233894 time
train_step spend 0.6235344910019194 time
policy_value spend 0.21380741499888245 time
kl:0.02366,lr_multiplier:7.594,loss:4.319746971130371,entropy:5.257736682891846,explained_var_old:0.989226460,explained_var_new:0.992392302
output spend 0.00017572399519849569 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006525844997668173 time
recovery_state_mcts_prob spend 0.2749330770020606 time
state_batch spend 0.0019286530005047098 time
mcts_probs_batch spend 0.006463170000643004 time
winner_batch spend 0.00028815500263590366 time
policy_value spend 0.21354392799548805 time
train_step spend 0.6234665759984637 time
policy_value spend 0.2177747520036064 time
train_step spend 0.6448261300029117 time
policy_value spend 0.22015710699633928 time
train_step spend 0.6388032839968218 time
policy_value spend 0.2178051549999509 time
train_step spend 0.639188405002642 time
policy_value spend 0.21759540999482851 time
train_step spend 0.6391081580004538 time
policy_value spend 0.2185955719978665 time
kl:0.02055,lr_multiplier:7.594,loss:4.29890775680542,entropy:5.26885986328125,explained_var_old:0.987726152,explained_var_new:0.992093444
output spend 0.00015575100405840203 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007790401003148872 time
recovery_state_mcts_prob spend 0.27811381300125504 time
state_batch spend 0.001891585998237133 time
mcts_probs_batch spend 0.006328825998934917 time
winner_batch spend 0.0002930190021288581 time
policy_value spend 0.21896960699814372 time
train_step spend 0.6381409059977159 time
policy_value spend 0.2211769749992527 time
train_step spend 0.6396017989973188 time
policy_value spend 0.21872936500585638 time
train_step spend 0.6396134599999641 time
policy_value spend 0.21883690400136402 time
train_step spend 0.6404034810038866 time
policy_value spend 0.2183740510008647 time
train_step spend 0.639529025000229 time
policy_value spend 0.21875272599572781 time
kl:0.03664,lr_multiplier:7.594,loss:4.274709701538086,entropy:5.274920463562012,explained_var_old:0.994219542,explained_var_new:0.996489823
output spend 0.00014527599705616012 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00756161999743199 time
recovery_state_mcts_prob spend 0.2782836740007042 time
state_batch spend 0.0028796820042771287 time
mcts_probs_batch spend 0.008756808994803578 time
winner_batch spend 0.0003905460034729913 time
policy_value spend 0.21917671599658206 time
train_step spend 0.6397710250021191 time
policy_value spend 0.21796211499895435 time
train_step spend 0.6404962550004711 time
policy_value spend 0.21858607800095342 time
train_step spend 0.6392090190056479 time
policy_value spend 0.2180597679980565 time
train_step spend 0.6412762179970741 time
policy_value spend 0.21926950300257886 time
train_step spend 0.6407311880029738 time
policy_value spend 0.21947267100040335 time
kl:0.10355,lr_multiplier:5.062,loss:4.401036739349365,entropy:5.298183441162109,explained_var_old:0.992243350,explained_var_new:0.996080935
output spend 0.0001456300014979206 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011602316997596063 time
recovery_state_mcts_prob spend 0.2726796440038015 time
state_batch spend 0.0020184679960948415 time
mcts_probs_batch spend 0.006316332001006231 time
winner_batch spend 0.00028777400439139456 time
policy_value spend 0.21847999199962942 time
train_step spend 0.6400260849986807 time
policy_value spend 0.21977658299874747 time
train_step spend 0.6393401180030196 time
policy_value spend 0.2175190810012282 time
train_step spend 0.6340064510004595 time
policy_value spend 0.21663488099875394 time
train_step spend 0.638299841004482 time
policy_value spend 0.21649985399562865 time
train_step spend 0.6332412050032872 time
policy_value spend 0.21666123600152787 time
kl:0.05555,lr_multiplier:3.375,loss:4.272665500640869,entropy:5.238880634307861,explained_var_old:0.996181488,explained_var_new:0.999029756
output spend 0.00018898399866884574 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006988284992985427 time
recovery_state_mcts_prob spend 0.2771884170069825 time
state_batch spend 0.0019817099964711815 time
mcts_probs_batch spend 0.006894651000038721 time
winner_batch spend 0.0002843449983629398 time
policy_value spend 0.22534757600078592 time
train_step spend 0.6550972550030565 time
policy_value spend 0.23407274999772198 time
train_step spend 0.6486029270017752 time
policy_value spend 0.21787241200217977 time
train_step spend 0.6341817290012841 time
policy_value spend 0.2166991069971118 time
train_step spend 0.633576444000937 time
policy_value spend 0.21603007500380045 time
train_step spend 0.6333758420005324 time
policy_value spend 0.21417335200385423 time
kl:0.01915,lr_multiplier:3.375,loss:4.327010631561279,entropy:5.225374221801758,explained_var_old:0.982626081,explained_var_new:0.988624275
output spend 0.0001458890037611127 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007080842995492276 time
recovery_state_mcts_prob spend 0.26588850100233685 time
state_batch spend 0.0018170569965150207 time
mcts_probs_batch spend 0.007030165004834998 time
winner_batch spend 0.00029296499997144565 time
policy_value spend 0.21371527999872342 time
train_step spend 0.6243151559974649 time
policy_value spend 0.21407275299861794 time
train_step spend 0.623857667997072 time
policy_value spend 0.21284790799836628 time
train_step spend 0.6245040490030078 time
policy_value spend 0.21321886299847392 time
train_step spend 0.6242911090012058 time
policy_value spend 0.21337212200160138 time
train_step spend 0.6245446979955886 time
policy_value spend 0.21315017100278055 time
kl:0.00764,lr_multiplier:5.062,loss:4.238632678985596,entropy:5.231191635131836,explained_var_old:0.987106025,explained_var_new:0.991796792
output spend 0.0001581329997861758 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00910739200480748 time
recovery_state_mcts_prob spend 0.2663966159962001 time
state_batch spend 0.0019081479986198246 time
mcts_probs_batch spend 0.014871268002025317 time
winner_batch spend 0.0002987039988511242 time
policy_value spend 0.2179039120019297 time
train_step spend 0.6327171829980216 time
policy_value spend 0.2206873200047994 time
train_step spend 0.6439663380006095 time
policy_value spend 0.21884731300087878 time
train_step spend 0.639183849998517 time
policy_value spend 0.21791485600260785 time
train_step spend 0.6394729079984245 time
policy_value spend 0.21878414999810047 time
train_step spend 0.6395342090036138 time
policy_value spend 0.21853301399823977 time
kl:0.01031,lr_multiplier:5.062,loss:4.34081506729126,entropy:5.258345603942871,explained_var_old:0.991687417,explained_var_new:0.995162666
output spend 0.00015516400162596256 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006989999004872516 time
recovery_state_mcts_prob spend 0.28732386399497045 time
state_batch spend 0.001851619002991356 time
mcts_probs_batch spend 0.0063286610020441 time
winner_batch spend 0.00033692599390633404 time
policy_value spend 0.2188267050005379 time
train_step spend 0.6389832639979431 time
policy_value spend 0.2203297090018168 time
train_step spend 0.6384686980018159 time
policy_value spend 0.2177820220022113 time
train_step spend 0.6414068419981049 time
policy_value spend 0.218951607006602 time
train_step spend 0.638850941999408 time
policy_value spend 0.2183092539999052 time
train_step spend 0.6385501539989491 time
policy_value spend 0.21782385800179327 time
kl:0.01839,lr_multiplier:5.062,loss:4.286009788513184,entropy:5.282196044921875,explained_var_old:0.986106634,explained_var_new:0.990789771
output spend 0.0001487849949626252 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007334841997362673 time
recovery_state_mcts_prob spend 0.2745214099995792 time
state_batch spend 0.0020076700020581484 time
mcts_probs_batch spend 0.01476443000137806 time
winner_batch spend 0.00030418199457926676 time
policy_value spend 0.22245990900410106 time
train_step spend 0.6387762360027409 time
policy_value spend 0.22227716299676104 time
train_step spend 0.6393030879989965 time
policy_value spend 0.21862013700592797 time
train_step spend 0.6401165349961957 time
policy_value spend 0.21867850299895508 time
train_step spend 0.6401738670028863 time
policy_value spend 0.21826391699869419 time
train_step spend 0.6390001580002718 time
policy_value spend 0.21839384099439485 time
kl:0.04673,lr_multiplier:3.375,loss:4.294843673706055,entropy:5.216207981109619,explained_var_old:0.990504324,explained_var_new:0.992067516
output spend 0.00031414399563800544 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008123034000163898 time
recovery_state_mcts_prob spend 0.2694551480017253 time
state_batch spend 0.0019388089931453578 time
mcts_probs_batch spend 0.0066797110048355535 time
winner_batch spend 0.0002940299964393489 time
policy_value spend 0.21879857800377067 time
train_step spend 0.640768058001413 time
policy_value spend 0.2186385099994368 time
train_step spend 0.6382754110018141 time
policy_value spend 0.21731676899798913 time
train_step spend 0.6341488219986786 time
policy_value spend 0.21669874600047478 time
train_step spend 0.6340328959995531 time
policy_value spend 0.21694701699743746 time
train_step spend 0.6343911119984114 time
policy_value spend 0.2168585070030531 time
kl:0.01688,lr_multiplier:3.375,loss:4.3375020027160645,entropy:5.275854110717773,explained_var_old:0.979017377,explained_var_new:0.984982193
output spend 0.00016575000336160883 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00731156599795213 time
recovery_state_mcts_prob spend 0.27226385999529157 time
state_batch spend 0.0023188470004242845 time
mcts_probs_batch spend 0.006417934004275594 time
winner_batch spend 0.0002870149983209558 time
policy_value spend 0.217189793002035 time
train_step spend 0.6336539240001002 time
policy_value spend 0.21726472000591457 time
train_step spend 0.6340951879974455 time
policy_value spend 0.21573140899999999 time
train_step spend 0.6334635949970107 time
policy_value spend 0.21687035300419666 time
train_step spend 0.6345471729946439 time
policy_value spend 0.2165824820040143 time
train_step spend 0.6330098030011868 time
policy_value spend 0.21307238799636252 time
kl:0.02684,lr_multiplier:3.375,loss:4.257862091064453,entropy:5.242921829223633,explained_var_old:0.988616705,explained_var_new:0.994119108
output spend 0.0001448479961254634 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0067732120005530305 time
recovery_state_mcts_prob spend 0.2695280659972923 time
state_batch spend 0.001961903995834291 time
mcts_probs_batch spend 0.006337210004858207 time
winner_batch spend 0.00031476599542656913 time
policy_value spend 0.21345523900527041 time
train_step spend 0.6251262719961233 time
policy_value spend 0.21383820199844195 time
train_step spend 0.6248864919980406 time
policy_value spend 0.21356562900473364 time
train_step spend 0.6245598230016185 time
policy_value spend 0.2132452329969965 time
train_step spend 0.6247829009953421 time
policy_value spend 0.2129706210034783 time
train_step spend 0.6238350150015322 time
policy_value spend 0.21315832500113174 time
kl:0.01094,lr_multiplier:3.375,loss:4.252236366271973,entropy:5.187822341918945,explained_var_old:0.989868402,explained_var_new:0.993626475
output spend 0.0001499900026828982 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00750136799615575 time
recovery_state_mcts_prob spend 0.2749114149992238 time
state_batch spend 0.0018478970014257357 time
mcts_probs_batch spend 0.006394839998392854 time
winner_batch spend 0.000306451998767443 time
policy_value spend 0.2138169740064768 time
train_step spend 0.6376036860019667 time
policy_value spend 0.22023212000203785 time
train_step spend 0.6433012750057969 time
policy_value spend 0.21917558199493214 time
train_step spend 0.6385080659965752 time
policy_value spend 0.2192998649989022 time
train_step spend 0.6386050170040107 time
policy_value spend 0.2183348600010504 time
train_step spend 0.6387463319988456 time
policy_value spend 0.2255894879999687 time
kl:0.00946,lr_multiplier:5.062,loss:4.275121212005615,entropy:5.211319446563721,explained_var_old:0.985962272,explained_var_new:0.991037011
output spend 0.0001924620009958744 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011412652995204553 time
recovery_state_mcts_prob spend 0.31353602000308456 time
state_batch spend 0.002589935000287369 time
mcts_probs_batch spend 0.0075880840013269335 time
winner_batch spend 0.00031026599754113704 time
policy_value spend 0.23146608300157823 time
train_step spend 0.6441795819991967 time
policy_value spend 0.22010707900335547 time
train_step spend 0.6397619880008278 time
policy_value spend 0.21929076599917607 time
train_step spend 0.6390477559980354 time
policy_value spend 0.21914422899862984 time
train_step spend 0.6399469899988617 time
policy_value spend 0.21884132600098383 time
train_step spend 0.6386189709955943 time
policy_value spend 0.2182569880023948 time
kl:0.01420,lr_multiplier:5.062,loss:4.299683094024658,entropy:5.222660064697266,explained_var_old:0.990258455,explained_var_new:0.992528498
output spend 0.00014860900409985334 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009192314006213564 time
recovery_state_mcts_prob spend 0.280686115998833 time
state_batch spend 0.0021235089952824637 time
mcts_probs_batch spend 0.007237532001454383 time
winner_batch spend 0.00029951300530228764 time
policy_value spend 0.21794115299417172 time
train_step spend 0.6392781009999453 time
policy_value spend 0.2224015239989967 time
train_step spend 0.6387443450003047 time
policy_value spend 0.21829727000294952 time
train_step spend 0.6380550649992074 time
policy_value spend 0.21817312000348466 time
train_step spend 0.6392214029983734 time
policy_value spend 0.2181849010012229 time
train_step spend 0.6380622659999062 time
policy_value spend 0.2187136550055584 time
kl:0.03223,lr_multiplier:5.062,loss:4.32763147354126,entropy:5.255774974822998,explained_var_old:0.995267153,explained_var_new:0.995779574
output spend 0.00015360999532276765 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009386495003127493 time
recovery_state_mcts_prob spend 0.27573631899576867 time
state_batch spend 0.0021207840036367998 time
mcts_probs_batch spend 0.006419311997888144 time
winner_batch spend 0.00031789000058779493 time
policy_value spend 0.21848802799650002 time
train_step spend 0.638199496002926 time
policy_value spend 0.21930624899687245 time
train_step spend 0.6354682250021142 time
policy_value spend 0.2164278740019654 time
train_step spend 0.6342163029985386 time
policy_value spend 0.2173175780044403 time
train_step spend 0.6344610770029249 time
policy_value spend 0.21653317999880528 time
train_step spend 0.6373042900013388 time
policy_value spend 0.2177662589965621 time
kl:0.01669,lr_multiplier:5.062,loss:4.27821683883667,entropy:5.211822986602783,explained_var_old:0.995368361,explained_var_new:0.995640814
output spend 0.00016017600137274712 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007708375997026451 time
recovery_state_mcts_prob spend 0.269796001004579 time
state_batch spend 0.0018652169965207577 time
mcts_probs_batch spend 0.006525249998958316 time
winner_batch spend 0.0003131830017082393 time
policy_value spend 0.21715347900317283 time
train_step spend 0.6342166379981791 time
policy_value spend 0.21612446999642998 time
train_step spend 0.6333286270019016 time
policy_value spend 0.21722347300237743 time
train_step spend 0.6334952559991507 time
policy_value spend 0.2169662239975878 time
train_step spend 0.6336693909979658 time
policy_value spend 0.21639420599967707 time
train_step spend 0.6303205910007819 time
policy_value spend 0.21337127599690575 time
kl:0.00889,lr_multiplier:7.594,loss:4.257023811340332,entropy:5.218609809875488,explained_var_old:0.986365616,explained_var_new:0.990668058
output spend 0.0001419649997842498 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008870932004356291 time
recovery_state_mcts_prob spend 0.27720877299725544 time
state_batch spend 0.001895132998470217 time
mcts_probs_batch spend 0.004364535001514014 time
winner_batch spend 0.00028495999868027866 time
policy_value spend 0.21254003700596513 time
train_step spend 0.6236337809968973 time
policy_value spend 0.21306799400190357 time
train_step spend 0.6249232849950204 time
policy_value spend 0.21378627700323705 time
train_step spend 0.624821047000296 time
policy_value spend 0.21407515699684154 time
train_step spend 0.6243761040022946 time
policy_value spend 0.2139029319951078 time
train_step spend 0.6243729369962239 time
policy_value spend 0.2136464170034742 time
kl:0.01264,lr_multiplier:7.594,loss:4.297092437744141,entropy:5.24711799621582,explained_var_old:0.999048233,explained_var_new:0.999597132
output spend 0.00014528600149787962 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006913220000569709 time
recovery_state_mcts_prob spend 0.2763357489966438 time
state_batch spend 0.002014128003793303 time
mcts_probs_batch spend 0.0063485279970336705 time
winner_batch spend 0.00030999699811218306 time
policy_value spend 0.21857566499966197 time
train_step spend 0.6474103799992008 time
policy_value spend 0.220654229997308 time
train_step spend 0.6427273460067227 time
policy_value spend 0.21880684699863195 time
train_step spend 0.6379583900052239 time
policy_value spend 0.21921685800043633 time
train_step spend 0.639289707003627 time
policy_value spend 0.21816709799895762 time
train_step spend 0.6390556859987555 time
policy_value spend 0.21809865700197406 time
kl:0.00806,lr_multiplier:11.391,loss:4.258134841918945,entropy:5.241819858551025,explained_var_old:0.996094108,explained_var_new:0.997156858
output spend 0.00014947300223866478 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008409065994783305 time
recovery_state_mcts_prob spend 0.27517546099988976 time
state_batch spend 0.0019442250049905851 time
mcts_probs_batch spend 0.006972038994717877 time
winner_batch spend 0.00035638500412460417 time
policy_value spend 0.21828149700013455 time
train_step spend 0.637359735002974 time
policy_value spend 0.22018405699782306 time
train_step spend 0.6396445240025059 time
policy_value spend 0.2188188150030328 time
train_step spend 0.6390797559943167 time
policy_value spend 0.21871703200304182 time
train_step spend 0.638755708001554 time
policy_value spend 0.2196345919946907 time
train_step spend 0.6386458440028946 time
policy_value spend 0.2187533539981814 time
kl:0.01273,lr_multiplier:11.391,loss:4.296098709106445,entropy:5.294018745422363,explained_var_old:0.989236057,explained_var_new:0.992707014
output spend 0.0001575679998495616 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008124339001369663 time
recovery_state_mcts_prob spend 0.28197090399771696 time
state_batch spend 0.0020181490035611205 time
mcts_probs_batch spend 0.006556246997206472 time
winner_batch spend 0.00040313700446859 time
policy_value spend 0.21880549599882215 time
train_step spend 0.6375932299997658 time
policy_value spend 0.21882027300307527 time
train_step spend 0.6372719069986488 time
policy_value spend 0.21939764999842737 time
train_step spend 0.6388519710017135 time
policy_value spend 0.2183774090008228 time
train_step spend 0.6382810230061295 time
policy_value spend 0.21832465599436546 time
train_step spend 0.6377810340054566 time
policy_value spend 0.2183485169953201 time
kl:0.01320,lr_multiplier:11.391,loss:4.263388633728027,entropy:5.234946250915527,explained_var_old:0.989501238,explained_var_new:0.992550015
output spend 0.00014565699530066922 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007107895995432045 time
recovery_state_mcts_prob spend 0.2726238290051697 time
state_batch spend 0.00191800799802877 time
mcts_probs_batch spend 0.007620497002790216 time
winner_batch spend 0.00031825900077819824 time
policy_value spend 0.21817033799743513 time
train_step spend 0.6543578019991401 time
policy_value spend 0.24110255800042069 time
train_step spend 0.6652044330039644 time
policy_value spend 0.21792828400066355 time
train_step spend 0.6370220259996131 time
policy_value spend 0.21716518500034 time
train_step spend 0.6369696580004529 time
policy_value spend 0.2181662739967578 time
train_step spend 0.6356893230040441 time
policy_value spend 0.21745864099648315 time
kl:0.02230,lr_multiplier:11.391,loss:4.2921552658081055,entropy:5.271308898925781,explained_var_old:0.994708657,explained_var_new:0.995901644
output spend 0.00021133799600647762 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008177249997970648 time
recovery_state_mcts_prob spend 0.27226102400163654 time
state_batch spend 0.0019387610009289347 time
mcts_probs_batch spend 0.00556343899370404 time
winner_batch spend 0.00029785400693072006 time
policy_value spend 0.21723923799436307 time
train_step spend 0.6364046550006606 time
policy_value spend 0.21621149500424508 time
train_step spend 0.6354814829974202 time
policy_value spend 0.21691923400067026 time
train_step spend 0.6354357469972456 time
policy_value spend 0.21657037000113633 time
train_step spend 0.6346258619960281 time
policy_value spend 0.21721124299801886 time
train_step spend 0.6275177379939123 time
policy_value spend 0.21306625600118423 time
kl:0.03511,lr_multiplier:11.391,loss:4.247821807861328,entropy:5.255873680114746,explained_var_old:0.983082652,explained_var_new:0.987014651
output spend 0.0001816950025386177 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.014096683000389021 time
recovery_state_mcts_prob spend 0.2641624249954475 time
state_batch spend 0.001886439000372775 time
mcts_probs_batch spend 0.006968046000110917 time
winner_batch spend 0.0002854250051314011 time
policy_value spend 0.2138559139930294 time
train_step spend 0.6242202930006897 time
policy_value spend 0.21703133700066246 time
train_step spend 0.6251222649952979 time
policy_value spend 0.21401563900144538 time
train_step spend 0.6257246509994729 time
policy_value spend 0.21394149099796778 time
train_step spend 0.6256738529991708 time
policy_value spend 0.21387934000085806 time
train_step spend 0.6251978049986064 time
policy_value spend 0.2143222130034701 time
kl:0.01773,lr_multiplier:11.391,loss:4.271868705749512,entropy:5.209333896636963,explained_var_old:0.960851431,explained_var_new:0.985540569
output spend 0.00022613900364376605 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007249492999108043 time
recovery_state_mcts_prob spend 0.2879690310001024 time
state_batch spend 0.0019086270040133968 time
mcts_probs_batch spend 0.0068826089991489425 time
winner_batch spend 0.0003403939990676008 time
policy_value spend 0.22054607899917755 time
train_step spend 0.6453285679963301 time
policy_value spend 0.22075299199786969 time
train_step spend 0.6394582270004321 time
policy_value spend 0.2184337439975934 time
train_step spend 0.6394174029992428 time
policy_value spend 0.2194875779969152 time
train_step spend 0.638434494001558 time
policy_value spend 0.21809616899554385 time
train_step spend 0.6425220129967784 time
policy_value spend 0.21859571000095457 time
kl:0.01285,lr_multiplier:11.391,loss:4.190952301025391,entropy:5.146609306335449,explained_var_old:0.991146445,explained_var_new:0.989817739
output spend 0.00016537999908905476 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007462000998202711 time
recovery_state_mcts_prob spend 0.26806768299866235 time
state_batch spend 0.0019345470063854009 time
mcts_probs_batch spend 0.007707160999416374 time
winner_batch spend 0.00036162600008537993 time
policy_value spend 0.21961314999498427 time
train_step spend 0.6387413339980412 time
policy_value spend 0.22168873299960978 time
train_step spend 0.638490217999788 time
policy_value spend 0.21770793000177946 time
train_step spend 0.6391658290012856 time
policy_value spend 0.2176573990000179 time
train_step spend 0.6383334249985637 time
policy_value spend 0.21841730100277346 time
train_step spend 0.6383869979981682 time
policy_value spend 0.21750962599617196 time
kl:0.03126,lr_multiplier:11.391,loss:4.277394771575928,entropy:5.221196174621582,explained_var_old:0.991758406,explained_var_new:0.997203946
output spend 0.00014450699381995946 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007396276007057168 time
recovery_state_mcts_prob spend 0.27505475099314936 time
state_batch spend 0.002370371003053151 time
mcts_probs_batch spend 0.0064053009991766885 time
winner_batch spend 0.0003321730036986992 time
policy_value spend 0.21783571299602045 time
train_step spend 0.637205475999508 time
policy_value spend 0.2191214519989444 time
train_step spend 0.6373935459996574 time
policy_value spend 0.21808646299905377 time
train_step spend 0.6375659490004182 time
policy_value spend 0.21826703699480277 time
train_step spend 0.6379190540028503 time
policy_value spend 0.21821281699521933 time
train_step spend 0.6373600480001187 time
policy_value spend 0.21783715499623213 time
kl:0.02114,lr_multiplier:11.391,loss:4.247705459594727,entropy:5.205672264099121,explained_var_old:0.992178857,explained_var_new:0.994263470
output spend 0.00014826699771219864 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008683086001838092 time
recovery_state_mcts_prob spend 0.27772622700285865 time
state_batch spend 0.0019076999960816465 time
mcts_probs_batch spend 0.006591306002519559 time
winner_batch spend 0.00029989200265845284 time
policy_value spend 0.2179406859941082 time
train_step spend 0.6371799030021066 time
policy_value spend 0.21851857799629215 time
train_step spend 0.6350274969954626 time
policy_value spend 0.21779165100451792 time
train_step spend 0.6356144060046063 time
policy_value spend 0.21730235799623188 time
train_step spend 0.6349008580000373 time
policy_value spend 0.21797908000007737 time
train_step spend 0.6368366710012197 time
policy_value spend 0.2176197160006268 time
kl:0.00781,lr_multiplier:11.391,loss:4.260893821716309,entropy:5.228802680969238,explained_var_old:0.993818343,explained_var_new:0.999026239
output spend 0.00016499100456712767 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008817237998300698 time
recovery_state_mcts_prob spend 0.2822756070017931 time
state_batch spend 0.0019942119979532436 time
mcts_probs_batch spend 0.006600660999538377 time
winner_batch spend 0.000310449002427049 time
policy_value spend 0.2180809909987147 time
train_step spend 0.634825366003497 time
policy_value spend 0.21886522400018293 time
train_step spend 0.6364464689977467 time
policy_value spend 0.21712048399786 time
train_step spend 0.6354383979996783 time
policy_value spend 0.21749154199642362 time
train_step spend 0.6367178410000633 time
policy_value spend 0.2191547139955219 time
train_step spend 0.6213955819985131 time
policy_value spend 0.21258267600205727 time
kl:0.01552,lr_multiplier:11.391,loss:4.221051216125488,entropy:5.229302406311035,explained_var_old:0.998841226,explained_var_new:0.999538362
output spend 0.00014712999836774543 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0069358429973362945 time
recovery_state_mcts_prob spend 0.2752858120002202 time
state_batch spend 0.0019443420023890212 time
mcts_probs_batch spend 0.005489247996592894 time
winner_batch spend 0.00029741600155830383 time
policy_value spend 0.21136655600275844 time
train_step spend 0.6193409629995585 time
policy_value spend 0.21248208500037435 time
train_step spend 0.6190165059961146 time
policy_value spend 0.2124043950025225 time
train_step spend 0.6199072259987588 time
policy_value spend 0.21269807899807347 time
train_step spend 0.6210886479966575 time
policy_value spend 0.2121582120016683 time
train_step spend 0.6203614359983476 time
policy_value spend 0.21165234400541522 time
kl:0.01093,lr_multiplier:11.391,loss:4.274849891662598,entropy:5.227062702178955,explained_var_old:0.995311022,explained_var_new:0.996155322
output spend 0.0002495240041753277 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009604148996004369 time
recovery_state_mcts_prob spend 0.28738283100392437 time
state_batch spend 0.0019112739973934367 time
mcts_probs_batch spend 0.015588948997901753 time
winner_batch spend 0.00031662399851484224 time
policy_value spend 0.2351299710062449 time
train_step spend 0.6555611570001929 time
policy_value spend 0.22438801799580688 time
train_step spend 0.6357815869996557 time
policy_value spend 0.21683073400345165 time
train_step spend 0.6369634139991831 time
policy_value spend 0.21676529399701394 time
train_step spend 0.635210268002993 time
policy_value spend 0.21731122500204947 time
train_step spend 0.6340823760037892 time
policy_value spend 0.21702059300150722 time
kl:0.01409,lr_multiplier:11.391,loss:4.194365978240967,entropy:5.204516887664795,explained_var_old:0.997482598,explained_var_new:0.999280930
output spend 0.00014416699559660628 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009174538994557224 time
recovery_state_mcts_prob spend 0.2734841810015496 time
state_batch spend 0.0018499100042390637 time
mcts_probs_batch spend 0.0069343909999588504 time
winner_batch spend 0.0002892459961003624 time
policy_value spend 0.21660784200503258 time
train_step spend 0.6345686040003784 time
policy_value spend 0.21769300099549582 time
train_step spend 0.6348122599956696 time
policy_value spend 0.21675892200437374 time
train_step spend 0.6339804449962685 time
policy_value spend 0.21701099300116766 time
train_step spend 0.6343801719995099 time
policy_value spend 0.21725412899832008 time
train_step spend 0.6344745440001134 time
policy_value spend 0.2174802939989604 time
kl:0.02902,lr_multiplier:11.391,loss:4.2686357498168945,entropy:5.226537227630615,explained_var_old:0.998296320,explained_var_new:0.998952031
output spend 0.0001441160056856461 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0073731509983190335 time
recovery_state_mcts_prob spend 0.2722211660002358 time
state_batch spend 0.0019425260034040548 time
mcts_probs_batch spend 0.007547241002612282 time
winner_batch spend 0.00028980999923078343 time
policy_value spend 0.2175883329982753 time
train_step spend 0.635426014996483 time
policy_value spend 0.22013100099866278 time
train_step spend 0.6357872299995506 time
policy_value spend 0.21807410499604885 time
train_step spend 0.6355989540024893 time
policy_value spend 0.217636556000798 time
train_step spend 0.6360830999983591 time
policy_value spend 0.21745287100202404 time
train_step spend 0.6350120329952915 time
policy_value spend 0.2181144120040699 time
kl:0.01869,lr_multiplier:11.391,loss:4.175863742828369,entropy:5.146093368530273,explained_var_old:0.998309672,explained_var_new:0.999320090
output spend 0.0002026090005529113 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008295426996483002 time
recovery_state_mcts_prob spend 0.269709120002517 time
state_batch spend 0.0018783650011755526 time
mcts_probs_batch spend 0.006531829996674787 time
winner_batch spend 0.0003272400062996894 time
policy_value spend 0.21767647699743975 time
train_step spend 0.6349392530028126 time
policy_value spend 0.21839783799805446 time
train_step spend 0.6364532980005606 time
policy_value spend 0.21819380600209115 time
train_step spend 0.6354054280018318 time
policy_value spend 0.21746752499893773 time
train_step spend 0.6361012130000745 time
policy_value spend 0.21779997200064827 time
train_step spend 0.6354595020020497 time
policy_value spend 0.21788770700368332 time
kl:0.01881,lr_multiplier:11.391,loss:4.24478006362915,entropy:5.209025859832764,explained_var_old:0.995585561,explained_var_new:0.998777568
output spend 0.0001459359991713427 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007201340005849488 time
recovery_state_mcts_prob spend 0.2795034669979941 time
state_batch spend 0.0020510640024440363 time
mcts_probs_batch spend 0.006536518994835205 time
winner_batch spend 0.0002925549997598864 time
policy_value spend 0.21747248899919214 time
train_step spend 0.6349886129974038 time
policy_value spend 0.21761804400011897 time
train_step spend 0.6350614240000141 time
policy_value spend 0.21676076599396765 time
train_step spend 0.6453491259962902 time
policy_value spend 0.21793668500322383 time
train_step spend 0.6356855920021189 time
policy_value spend 0.21674078200157965 time
train_step spend 0.6347559240020928 time
policy_value spend 0.2167124670013436 time
kl:0.00885,lr_multiplier:11.391,loss:4.264713764190674,entropy:5.16626501083374,explained_var_old:0.990047574,explained_var_new:0.991671085
output spend 0.0001476580000598915 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010601845999190118 time
recovery_state_mcts_prob spend 0.2719232910021674 time
state_batch spend 0.001905384000565391 time
mcts_probs_batch spend 0.0128232860006392 time
winner_batch spend 0.00036013699718751013 time
policy_value spend 0.21989834399573738 time
train_step spend 0.6338235970033566 time
policy_value spend 0.22072997099894565 time
train_step spend 0.6359284159989329 time
policy_value spend 0.21646203799900832 time
train_step spend 0.6342989469994791 time
policy_value spend 0.2167549349978799 time
train_step spend 0.6347789039937197 time
policy_value spend 0.21646569300355623 time
train_step spend 0.6354569699979038 time
policy_value spend 0.21716667900182074 time
kl:0.00634,lr_multiplier:11.391,loss:4.215604782104492,entropy:5.185442924499512,explained_var_old:0.993595660,explained_var_new:0.995666862
output spend 0.00016804699407657608 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007221920001029503 time
recovery_state_mcts_prob spend 0.26812790000258246 time
state_batch spend 0.0019058589969063178 time
mcts_probs_batch spend 0.005176462997042108 time
winner_batch spend 0.0003181450010742992 time
policy_value spend 0.21729873200092698 time
train_step spend 0.6334853669977747 time
policy_value spend 0.21720202999858884 time
train_step spend 0.6336972400022205 time
policy_value spend 0.21684924799774308 time
train_step spend 0.6353038990055211 time
policy_value spend 0.21682189499551896 time
train_step spend 0.6339137559989467 time
policy_value spend 0.21615031600231305 time
train_step spend 0.6333755690066027 time
policy_value spend 0.21699722599441884 time
kl:0.04402,lr_multiplier:7.594,loss:4.282321453094482,entropy:5.198249340057373,explained_var_old:0.987970293,explained_var_new:0.988190949
output spend 0.00016202600090764463 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01085360399883939 time
recovery_state_mcts_prob spend 0.26652744300372433 time
state_batch spend 0.002187054997193627 time
mcts_probs_batch spend 0.007001167003181763 time
winner_batch spend 0.00033135400008177385 time
policy_value spend 0.21693575899553252 time
train_step spend 0.6334956799983047 time
policy_value spend 0.21794958700047573 time
train_step spend 0.6340721489978023 time
policy_value spend 0.21654739599762252 time
train_step spend 0.6343588150048163 time
policy_value spend 0.21727480799745535 time
train_step spend 0.6350140540016582 time
policy_value spend 0.21711459400103195 time
train_step spend 0.6346417979948455 time
policy_value spend 0.2178946230051224 time
kl:0.02375,lr_multiplier:7.594,loss:4.219095230102539,entropy:5.192470550537109,explained_var_old:0.991938710,explained_var_new:0.997537076
output spend 0.0001547010033391416 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007107669000106398 time
recovery_state_mcts_prob spend 0.2793813579992275 time
state_batch spend 0.001896649002446793 time
mcts_probs_batch spend 0.006291081997915171 time
winner_batch spend 0.00028734200168401003 time
policy_value spend 0.2174876629942446 time
train_step spend 0.6344435220016749 time
policy_value spend 0.21836820199678186 time
train_step spend 0.6360012930017547 time
policy_value spend 0.2170529099967098 time
train_step spend 0.6524829310001223 time
policy_value spend 0.2301533690042561 time
train_step spend 0.6655624589984654 time
policy_value spend 0.21876602299744263 time
train_step spend 0.6378972789971158 time
policy_value spend 0.21687977100373246 time
kl:0.01522,lr_multiplier:7.594,loss:4.275966644287109,entropy:5.205615520477295,explained_var_old:0.995367289,explained_var_new:0.996034563
output spend 0.0001474859964218922 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008539615999325179 time
recovery_state_mcts_prob spend 0.2787989030039171 time
state_batch spend 0.0018907560006482527 time
mcts_probs_batch spend 0.0055943929983186536 time
winner_batch spend 0.00035298700095154345 time
policy_value spend 0.21740743699774612 time
train_step spend 0.6369311829985236 time
policy_value spend 0.21772182900167536 time
train_step spend 0.637958074999915 time
policy_value spend 0.21835023200401338 time
train_step spend 0.635356529004639 time
policy_value spend 0.21755698599736206 time
train_step spend 0.6358149259976926 time
policy_value spend 0.21724265500233741 time
train_step spend 0.6346791230025701 time
policy_value spend 0.2171150089998264 time
kl:0.01233,lr_multiplier:7.594,loss:4.299490451812744,entropy:5.209196090698242,explained_var_old:0.978675008,explained_var_new:0.985775113
output spend 0.0001495280012022704 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008018773005460389 time
recovery_state_mcts_prob spend 0.26983013099379605 time
state_batch spend 0.002011657001276035 time
mcts_probs_batch spend 0.005543008002860006 time
winner_batch spend 0.0003055580018553883 time
policy_value spend 0.21685115599393612 time
train_step spend 0.6363041399963549 time
policy_value spend 0.21757366199744865 time
train_step spend 0.634791270000278 time
policy_value spend 0.21682640100334538 time
train_step spend 0.6346435759987799 time
policy_value spend 0.21767695200105663 time
train_step spend 0.6363329659943702 time
policy_value spend 0.21980056600295939 time
train_step spend 0.6341541750007309 time
policy_value spend 0.21623588199872756 time
kl:0.01621,lr_multiplier:7.594,loss:4.234663009643555,entropy:5.239157676696777,explained_var_old:0.987610996,explained_var_new:0.998781025
output spend 0.00018969899974763393 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0078745409991825 time
recovery_state_mcts_prob spend 0.27098967300116783 time
state_batch spend 0.0019672100024763495 time
mcts_probs_batch spend 0.00534821099427063 time
winner_batch spend 0.0002822820024448447 time
policy_value spend 0.21599919699656311 time
train_step spend 0.633769325002504 time
policy_value spend 0.21582344099442707 time
train_step spend 0.6347605539995129 time
policy_value spend 0.2184321680033463 time
train_step spend 0.6350707849996979 time
policy_value spend 0.21675069400225766 time
train_step spend 0.6340431950011407 time
policy_value spend 0.21670973799336934 time
train_step spend 0.6337897259945748 time
policy_value spend 0.21614105900516734 time
kl:0.01460,lr_multiplier:7.594,loss:4.307909965515137,entropy:5.217841148376465,explained_var_old:0.985960543,explained_var_new:0.988883257
output spend 0.00015457099652849138 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007258736004587263 time
recovery_state_mcts_prob spend 0.27248652299749665 time
state_batch spend 0.0018741059975582175 time
mcts_probs_batch spend 0.0063812000007601455 time
winner_batch spend 0.0002933590003522113 time
policy_value spend 0.21688949900271837 time
train_step spend 0.6332520340001793 time
policy_value spend 0.21916095800406765 time
train_step spend 0.6325318409944884 time
policy_value spend 0.21651045700127725 time
train_step spend 0.6334491460002027 time
policy_value spend 0.2164811729962821 time
train_step spend 0.6334430220013019 time
policy_value spend 0.21664484700158937 time
train_step spend 0.6335403490011231 time
policy_value spend 0.216432838999026 time
kl:0.01039,lr_multiplier:7.594,loss:4.2187299728393555,entropy:5.188841819763184,explained_var_old:0.981364310,explained_var_new:0.989781797
output spend 0.00016417799633927643 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007400624999718275 time
recovery_state_mcts_prob spend 0.27500917299767025 time
state_batch spend 0.0019040280021727085 time
mcts_probs_batch spend 0.0064844649969018064 time
winner_batch spend 0.00033742200321285054 time
policy_value spend 0.21643542999663623 time
train_step spend 0.6326622030028375 time
policy_value spend 0.21727395199559396 time
train_step spend 0.6335757079941686 time
policy_value spend 0.21653935700305738 time
train_step spend 0.63347781199991 time
policy_value spend 0.21670464199996786 time
train_step spend 0.6333694839995587 time
policy_value spend 0.21672756600310095 time
train_step spend 0.6347498380055185 time
policy_value spend 0.21687094799563056 time
kl:0.01955,lr_multiplier:7.594,loss:4.203766822814941,entropy:5.192435264587402,explained_var_old:0.986135960,explained_var_new:0.992729664
output spend 0.00015574799908790737 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007683588002691977 time
recovery_state_mcts_prob spend 0.2701302269997541 time
state_batch spend 0.0020728029994643293 time
mcts_probs_batch spend 0.005677326997101773 time
winner_batch spend 0.0003140699991490692 time
policy_value spend 0.21715029400365893 time
train_step spend 0.6356270270043751 time
policy_value spend 0.21876492999581387 time
train_step spend 0.634226229005435 time
policy_value spend 0.21698363999894354 time
train_step spend 0.6340200480044587 time
policy_value spend 0.2174659239972243 time
train_step spend 0.636205324997718 time
policy_value spend 0.21721975300170016 time
train_step spend 0.6350008899971726 time
policy_value spend 0.2171359920030227 time
kl:0.01666,lr_multiplier:7.594,loss:4.2270283699035645,entropy:5.178653717041016,explained_var_old:0.995707452,explained_var_new:0.998788178
output spend 0.0001484870008425787 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009717339999042451 time
recovery_state_mcts_prob spend 0.2702691629965557 time
state_batch spend 0.002076348006085027 time
mcts_probs_batch spend 0.005986454998492263 time
winner_batch spend 0.00033869299659272656 time
policy_value spend 0.21673390600335551 time
train_step spend 0.6345586870011175 time
policy_value spend 0.2177480049940641 time
train_step spend 0.6346923560049618 time
policy_value spend 0.21755608499370283 time
train_step spend 0.6351532389962813 time
policy_value spend 0.21710309800255345 time
train_step spend 0.6355673530051718 time
policy_value spend 0.21698852699773852 time
train_step spend 0.6343357689984259 time
policy_value spend 0.21722601800138364 time
kl:0.00826,lr_multiplier:11.391,loss:4.247932434082031,entropy:5.198416233062744,explained_var_old:0.986369669,explained_var_new:0.991383553
output spend 0.00014654899860033765 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009355603004223667 time
recovery_state_mcts_prob spend 0.274648876998981 time
state_batch spend 0.0019888030001311563 time
mcts_probs_batch spend 0.006465106998803094 time
winner_batch spend 0.0002836029962054454 time
policy_value spend 0.21781574100168655 time
train_step spend 0.6364052259959863 time
policy_value spend 0.2168265500004054 time
train_step spend 0.6343057870035409 time
policy_value spend 0.2173146689965506 time
train_step spend 0.6354101889955928 time
policy_value spend 0.21678559000429232 time
train_step spend 0.6357535640054266 time
policy_value spend 0.2165436039940687 time
train_step spend 0.6335352419991978 time
policy_value spend 0.21641314099542797 time
kl:0.00620,lr_multiplier:11.391,loss:4.232296466827393,entropy:5.166648864746094,explained_var_old:0.986669958,explained_var_new:0.991026282
output spend 0.00020533100177999586 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008238669004640542 time
recovery_state_mcts_prob spend 0.28612442099984037 time
state_batch spend 0.001931810998939909 time
mcts_probs_batch spend 0.005645197001285851 time
winner_batch spend 0.0003026609992957674 time
policy_value spend 0.21832419199927244 time
train_step spend 0.6687262239938718 time
policy_value spend 0.22964957500516903 time
train_step spend 0.6375863200009917 time
policy_value spend 0.21807400000398047 time
train_step spend 0.6341992189991288 time
policy_value spend 0.21657621300255414 time
train_step spend 0.6346155350038316 time
policy_value spend 0.21776645399950212 time
train_step spend 0.6342393480008468 time
policy_value spend 0.21695375199487898 time
kl:0.02052,lr_multiplier:11.391,loss:4.181750297546387,entropy:5.128398895263672,explained_var_old:0.986286223,explained_var_new:0.988561749
output spend 0.00019882299966411665 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00754314599907957 time
recovery_state_mcts_prob spend 0.27964796300511807 time
state_batch spend 0.0018972170000779442 time
mcts_probs_batch spend 0.011446245996921789 time
winner_batch spend 0.00030877099925419316 time
policy_value spend 0.21913093700277386 time
train_step spend 0.6335172640028759 time
policy_value spend 0.2205675470031565 time
train_step spend 0.6342604809979093 time
policy_value spend 0.2161224180017598 time
train_step spend 0.6330235130008077 time
policy_value spend 0.21796527299738955 time
train_step spend 0.6342385329990066 time
policy_value spend 0.21651213300356176 time
train_step spend 0.6332170099994983 time
policy_value spend 0.2171192429959774 time
kl:0.02519,lr_multiplier:11.391,loss:4.176921367645264,entropy:5.182683944702148,explained_var_old:0.995581448,explained_var_new:0.995735466
output spend 0.00014881599781801924 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009134255997196306 time
recovery_state_mcts_prob spend 0.27595610699790996 time
state_batch spend 0.002008417999604717 time
mcts_probs_batch spend 0.005481543004862033 time
winner_batch spend 0.0002934099975391291 time
policy_value spend 0.21614204400248127 time
train_step spend 0.6335062899961486 time
policy_value spend 0.21829929899831768 time
train_step spend 0.6341449639949133 time
policy_value spend 0.21649788600188913 time
train_step spend 0.6338821390017984 time
policy_value spend 0.21632011199835688 time
train_step spend 0.6337548000010429 time
policy_value spend 0.21669058300176403 time
train_step spend 0.6361111689984682 time
policy_value spend 0.2186698920049821 time
kl:0.00770,lr_multiplier:11.391,loss:4.251007556915283,entropy:5.194041728973389,explained_var_old:0.988065183,explained_var_new:0.988764167
output spend 0.0001472770018153824 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007660194001800846 time
recovery_state_mcts_prob spend 0.2678948009997839 time
state_batch spend 0.0022422399997594766 time
mcts_probs_batch spend 0.006323679001070559 time
winner_batch spend 0.00030520500149577856 time
policy_value spend 0.21741711799404584 time
train_step spend 0.634444445000554 time
policy_value spend 0.21790840500034392 time
train_step spend 0.634341058001155 time
policy_value spend 0.21630485000059707 time
train_step spend 0.6343906790061737 time
policy_value spend 0.21672760299406946 time
train_step spend 0.6346083040043595 time
policy_value spend 0.2168238910016953 time
train_step spend 0.6354967879960896 time
policy_value spend 0.21691042499878677 time
kl:0.00652,lr_multiplier:11.391,loss:4.1780314445495605,entropy:5.161004066467285,explained_var_old:0.994318187,explained_var_new:0.995943427
output spend 0.00017658000433584675 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007397281005978584 time
recovery_state_mcts_prob spend 0.2749533699970925 time
state_batch spend 0.0024994269988383166 time
mcts_probs_batch spend 0.0072097540032700635 time
winner_batch spend 0.00029119999817339703 time
policy_value spend 0.21673549700062722 time
train_step spend 0.6355055649983115 time
policy_value spend 0.21802271100023063 time
train_step spend 0.6387444569991203 time
policy_value spend 0.21689364700432634 time
train_step spend 0.6345865969997249 time
policy_value spend 0.2174312290007947 time
train_step spend 0.6347840009984793 time
policy_value spend 0.21746183399955044 time
train_step spend 0.6343167670056573 time
policy_value spend 0.21742119099508272 time
kl:0.00892,lr_multiplier:11.391,loss:4.197497367858887,entropy:5.10330057144165,explained_var_old:0.996557236,explained_var_new:0.999212980
output spend 0.0001548140062368475 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007681953000428621 time
recovery_state_mcts_prob spend 0.2739525090000825 time
state_batch spend 0.002176027002860792 time
mcts_probs_batch spend 0.006260244997974951 time
winner_batch spend 0.00031642399699194357 time
policy_value spend 0.21682070700626355 time
train_step spend 0.6347814940017997 time
policy_value spend 0.2186794329973054 time
train_step spend 0.634715980006149 time
policy_value spend 0.21665307799412403 time
train_step spend 0.6353861710013007 time
policy_value spend 0.21753504699881887 time
train_step spend 0.635212994995527 time
policy_value spend 0.21666191300028004 time
train_step spend 0.6338239469987457 time
policy_value spend 0.21653409300051862 time
kl:0.00626,lr_multiplier:11.391,loss:4.202638626098633,entropy:5.1872358322143555,explained_var_old:0.994847357,explained_var_new:0.995658100
output spend 0.00019443399651208892 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009351783002784941 time
recovery_state_mcts_prob spend 0.2797860220016446 time
state_batch spend 0.00204688999656355 time
mcts_probs_batch spend 0.006538952999108005 time
winner_batch spend 0.000290664000203833 time
policy_value spend 0.21708658499846933 time
train_step spend 0.6333818229977624 time
policy_value spend 0.2179156940037501 time
train_step spend 0.634596497999155 time
policy_value spend 0.2163491960018291 time
train_step spend 0.6340883800003212 time
policy_value spend 0.21698145400296198 time
train_step spend 0.6347887570009334 time
policy_value spend 0.21688353700301377 time
train_step spend 0.6345806570025161 time
policy_value spend 0.21694691999437055 time
kl:0.00714,lr_multiplier:11.391,loss:4.219213962554932,entropy:5.137754440307617,explained_var_old:0.975679934,explained_var_new:0.978213847
output spend 0.00014883400581311435 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007179585001722444 time
recovery_state_mcts_prob spend 0.2693003780004801 time
state_batch spend 0.001994600002944935 time
mcts_probs_batch spend 0.006477513998106588 time
winner_batch spend 0.00029094899946358055 time
policy_value spend 0.21689035600138595 time
train_step spend 0.6329512630036334 time
policy_value spend 0.2179518150005606 time
train_step spend 0.6337484360046801 time
policy_value spend 0.21611533199757105 time
train_step spend 0.6328415890020551 time
policy_value spend 0.21691101799660828 time
train_step spend 0.6342660299997078 time
policy_value spend 0.21686086599947885 time
train_step spend 0.6341389840017655 time
policy_value spend 0.21699850900040474 time
kl:0.01029,lr_multiplier:11.391,loss:4.234943389892578,entropy:5.150934219360352,explained_var_old:0.992301345,explained_var_new:0.995393276
output spend 0.00014191099762683734 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01081467499898281 time
recovery_state_mcts_prob spend 0.26746976799768163 time
state_batch spend 0.002243212999019306 time
mcts_probs_batch spend 0.013203189002524596 time
winner_batch spend 0.00030259900086093694 time
policy_value spend 0.2197326149980654 time
train_step spend 0.6333817429986084 time
policy_value spend 0.22061717700125882 time
train_step spend 0.6335123419994488 time
policy_value spend 0.2161230730052921 time
train_step spend 0.6339468189980835 time
policy_value spend 0.21629720400233055 time
train_step spend 0.6347320070053684 time
policy_value spend 0.21579500699590426 time
train_step spend 0.6517147990016383 time
policy_value spend 0.22946937999950023 time
kl:0.02578,lr_multiplier:11.391,loss:4.2855329513549805,entropy:5.169039249420166,explained_var_old:0.995007634,explained_var_new:0.995815635
output spend 0.0001613729982636869 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01083284100604942 time
recovery_state_mcts_prob spend 0.2750333939984557 time
state_batch spend 0.002084674997604452 time
mcts_probs_batch spend 0.00624347799748648 time
winner_batch spend 0.00031101000058697537 time
policy_value spend 0.21815169000183232 time
train_step spend 0.6352912709990051 time
policy_value spend 0.2173946690018056 time
train_step spend 0.635998074998497 time
policy_value spend 0.21708793099969625 time
train_step spend 0.6355211269983556 time
policy_value spend 0.2165800520015182 time
train_step spend 0.6347745789971668 time
policy_value spend 0.21719906300131697 time
train_step spend 0.6344901710035629 time
policy_value spend 0.21733590199437458 time
kl:0.01265,lr_multiplier:11.391,loss:4.229642391204834,entropy:5.204490661621094,explained_var_old:0.990261137,explained_var_new:0.991864860
output spend 0.0001613730055396445 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009020716002851259 time
recovery_state_mcts_prob spend 0.28024304999416927 time
state_batch spend 0.0019735650057555176 time
mcts_probs_batch spend 0.0055269879958359525 time
winner_batch spend 0.0002964939994853921 time
policy_value spend 0.21626542300509755 time
train_step spend 0.6346918859999278 time
policy_value spend 0.2179681499983417 time
train_step spend 0.6342615100002149 time
policy_value spend 0.2169432769951527 time
train_step spend 0.6346753199977684 time
policy_value spend 0.21757782400527503 time
train_step spend 0.6346866179956123 time
policy_value spend 0.21844976500142366 time
train_step spend 0.6370830259984359 time
policy_value spend 0.2170987450008397 time
kl:0.00673,lr_multiplier:11.391,loss:4.219593048095703,entropy:5.155059814453125,explained_var_old:0.986903608,explained_var_new:0.988712072
output spend 0.00014773599832551554 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007850890993722714 time
recovery_state_mcts_prob spend 0.27851404300599825 time
state_batch spend 0.0018978619991685264 time
mcts_probs_batch spend 0.0058343509954283945 time
winner_batch spend 0.0003101760012214072 time
policy_value spend 0.21692879200418247 time
train_step spend 0.6414614370005438 time
policy_value spend 0.2167989800000214 time
train_step spend 0.6344111510043149 time
policy_value spend 0.21662911000021268 time
train_step spend 0.6348646499973256 time
policy_value spend 0.21667005400377093 time
train_step spend 0.6320281200023601 time
policy_value spend 0.21599667800182942 time
train_step spend 0.6315237289963989 time
policy_value spend 0.21560209300514543 time
kl:0.01797,lr_multiplier:11.391,loss:4.244192600250244,entropy:5.161233425140381,explained_var_old:0.995642841,explained_var_new:0.995665908
output spend 0.00014222099707694724 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006617169005039614 time
recovery_state_mcts_prob spend 0.2678451239989954 time
state_batch spend 0.0018249239947181195 time
mcts_probs_batch spend 0.005032304004998878 time
winner_batch spend 0.00032065800041891634 time
policy_value spend 0.21501218599587446 time
train_step spend 0.6307152750014211 time
policy_value spend 0.21663058400008595 time
train_step spend 0.6307926910012611 time
policy_value spend 0.21617489899654174 time
train_step spend 0.6294275499967625 time
policy_value spend 0.21595697500015376 time
train_step spend 0.6297912820009515 time
policy_value spend 0.21574072799558053 time
train_step spend 0.6306383390037809 time
policy_value spend 0.21546036399377044 time
kl:0.01927,lr_multiplier:11.391,loss:4.2138776779174805,entropy:5.146388053894043,explained_var_old:0.998590589,explained_var_new:0.999355912
output spend 0.00014621399895986542 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006792376996600069 time
recovery_state_mcts_prob spend 0.26825462299893843 time
state_batch spend 0.0018241780053358525 time
mcts_probs_batch spend 0.004496727997320704 time
winner_batch spend 0.00029337400337681174 time
policy_value spend 0.215183578999131 time
train_step spend 0.630347238999093 time
policy_value spend 0.21530943200195907 time
train_step spend 0.63073950400576 time
policy_value spend 0.2166755679936614 time
train_step spend 0.6321858759984025 time
policy_value spend 0.21764283400261775 time
train_step spend 0.6323470340066706 time
policy_value spend 0.21557556399784517 time
train_step spend 0.6319909170051687 time
policy_value spend 0.21592709499964258 time
kl:0.01360,lr_multiplier:11.391,loss:4.230464458465576,entropy:5.148510932922363,explained_var_old:0.982020676,explained_var_new:0.985998273
output spend 0.00014737099991180003 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00797744400188094 time
recovery_state_mcts_prob spend 0.2732860129981418 time
state_batch spend 0.0019977249976363964 time
mcts_probs_batch spend 0.005250229005469009 time
winner_batch spend 0.0003360839982633479 time
policy_value spend 0.2167204200013657 time
train_step spend 0.6300645290029934 time
policy_value spend 0.21559562499896856 time
train_step spend 0.6313430489972234 time
policy_value spend 0.2157082040066598 time
train_step spend 0.6318442390038399 time
policy_value spend 0.21549556499667233 time
train_step spend 0.6326509009959409 time
policy_value spend 0.2166809020054643 time
train_step spend 0.6346177230007015 time
policy_value spend 0.2164145149945398 time
kl:0.03884,lr_multiplier:11.391,loss:4.241191387176514,entropy:5.193697452545166,explained_var_old:0.998104274,explained_var_new:0.998849511
output spend 0.0001482780062360689 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006826529999671038 time
recovery_state_mcts_prob spend 0.2797679139985121 time
state_batch spend 0.0017939040044439025 time
mcts_probs_batch spend 0.00543935699533904 time
winner_batch spend 0.00031306000164477155 time
policy_value spend 0.21565757100324845 time
train_step spend 0.6342880209995201 time
policy_value spend 0.21724615099810762 time
train_step spend 0.6339040390012087 time
policy_value spend 0.21616471000015736 time
train_step spend 0.6338514090020908 time
policy_value spend 0.21701235499494942 time
train_step spend 0.6327397770000971 time
policy_value spend 0.21668741200119257 time
train_step spend 0.6338021819974529 time
policy_value spend 0.21603517400217243 time
kl:0.08436,lr_multiplier:7.594,loss:4.152433395385742,entropy:5.093939304351807,explained_var_old:0.998611927,explained_var_new:0.999637306
output spend 0.00015736000204924494 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010542611998971552 time
recovery_state_mcts_prob spend 0.26854466700024204 time
state_batch spend 0.001833554997574538 time
mcts_probs_batch spend 0.0045023130005574785 time
winner_batch spend 0.0003243629980715923 time
policy_value spend 0.2155653150039143 time
train_step spend 0.6332808480001404 time
policy_value spend 0.21672266100358684 time
train_step spend 0.6336049089950393 time
policy_value spend 0.21616129000176443 time
train_step spend 0.6334991780022392 time
policy_value spend 0.21685196200269274 time
train_step spend 0.6340130630051135 time
policy_value spend 0.21646381399477832 time
train_step spend 0.6349280759968678 time
policy_value spend 0.21768823700404027 time
kl:0.05355,lr_multiplier:5.062,loss:4.183961391448975,entropy:5.093117713928223,explained_var_old:0.991964877,explained_var_new:0.994839847
output spend 0.0001471029972890392 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006941129999177065 time
recovery_state_mcts_prob spend 0.2764252370034228 time
state_batch spend 0.0020015240006614476 time
mcts_probs_batch spend 0.006409772999177221 time
winner_batch spend 0.0002920889965025708 time
policy_value spend 0.2262671060016146 time
train_step spend 0.6537762739972095 time
policy_value spend 0.23275642599764979 time
train_step spend 0.6505700470006559 time
policy_value spend 0.21819611200044164 time
train_step spend 0.6354968000014196 time
policy_value spend 0.2167781259995536 time
train_step spend 0.631814079999458 time
policy_value spend 0.21554469000693643 time
train_step spend 0.6305460250005126 time
policy_value spend 0.2152170319968718 time
kl:0.03897,lr_multiplier:5.062,loss:4.144537925720215,entropy:5.085190773010254,explained_var_old:0.987992764,explained_var_new:0.988391876
output spend 0.00014666499919258058 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007255013995745685 time
recovery_state_mcts_prob spend 0.2814410159990075 time
state_batch spend 0.001853911999205593 time
mcts_probs_batch spend 0.0062079380004433915 time
winner_batch spend 0.0002868189985747449 time
policy_value spend 0.2155444560048636 time
train_step spend 0.6304481269980897 time
policy_value spend 0.21837481400143588 time
train_step spend 0.6309497499969439 time
policy_value spend 0.21536012100114021 time
train_step spend 0.6310413960018195 time
policy_value spend 0.21618422299798112 time
train_step spend 0.6313551249986631 time
policy_value spend 0.21541288099979283 time
train_step spend 0.6309063239968964 time
policy_value spend 0.2152906150004128 time
kl:0.00885,lr_multiplier:7.594,loss:4.20407247543335,entropy:5.17124080657959,explained_var_old:0.997135222,explained_var_new:0.999158323
output spend 0.00014784600352868438 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008693138996022753 time
recovery_state_mcts_prob spend 0.2729479070039815 time
state_batch spend 0.0018440299973008223 time
mcts_probs_batch spend 0.006306609000603203 time
winner_batch spend 0.0003108020027866587 time
policy_value spend 0.2154236049973406 time
train_step spend 0.6329400670001633 time
policy_value spend 0.21740583999780938 time
train_step spend 0.633468191997963 time
policy_value spend 0.21670366800390184 time
train_step spend 0.6318053690047236 time
policy_value spend 0.21647265699721174 time
train_step spend 0.6325968500023009 time
policy_value spend 0.21644549399934476 time
train_step spend 0.632980160000443 time
policy_value spend 0.21788504799769726 time
kl:0.00809,lr_multiplier:11.391,loss:4.203455448150635,entropy:5.149439811706543,explained_var_old:0.983468890,explained_var_new:0.984101415
output spend 0.00017428400315111503 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007887601997936144 time
recovery_state_mcts_prob spend 0.2691020939964801 time
state_batch spend 0.00195647500368068 time
mcts_probs_batch spend 0.0060083249991294 time
winner_batch spend 0.00029521399846998975 time
policy_value spend 0.21594386499782559 time
train_step spend 0.6335068129992578 time
policy_value spend 0.2157940880060778 time
train_step spend 0.633151732996339 time
policy_value spend 0.21613279200391844 time
train_step spend 0.6337353769995389 time
policy_value spend 0.21664557800249895 time
train_step spend 0.6341384620027384 time
policy_value spend 0.2173855029977858 time
train_step spend 0.635782642995764 time
policy_value spend 0.217355316002795 time
kl:0.01143,lr_multiplier:11.391,loss:4.220273017883301,entropy:5.19032096862793,explained_var_old:0.986203730,explained_var_new:0.988189816
output spend 0.00014640900189988315 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006771594002202619 time
recovery_state_mcts_prob spend 0.28872760599915637 time
state_batch spend 0.0020748020033352077 time
mcts_probs_batch spend 0.006702398000925314 time
winner_batch spend 0.0002985519968206063 time
policy_value spend 0.21725972399872262 time
train_step spend 0.6353712679992896 time
policy_value spend 0.21837444999982836 time
train_step spend 0.634401973002241 time
policy_value spend 0.21767728599661496 time
train_step spend 0.6343576769941137 time
policy_value spend 0.21791249699890614 time
train_step spend 0.634582003003743 time
policy_value spend 0.21818250700016506 time
train_step spend 0.6353260160030914 time
policy_value spend 0.2168579499993939 time
kl:0.01806,lr_multiplier:11.391,loss:4.275063514709473,entropy:5.178437232971191,explained_var_old:0.983834088,explained_var_new:0.984981060
output spend 0.00015926299965940416 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007355834997724742 time
recovery_state_mcts_prob spend 0.2640768970013596 time
state_batch spend 0.0020780249978997745 time
mcts_probs_batch spend 0.005597800998657476 time
winner_batch spend 0.0002882839980884455 time
policy_value spend 0.21815517399954842 time
train_step spend 0.6359993490041234 time
policy_value spend 0.21983267700124998 time
train_step spend 0.6353022839975893 time
policy_value spend 0.21697242100344738 time
train_step spend 0.6340975659986725 time
policy_value spend 0.21724184200138552 time
train_step spend 0.6356643210019683 time
policy_value spend 0.21680563099653227 time
train_step spend 0.6351840600036667 time
policy_value spend 0.2169797859969549 time
kl:0.04580,lr_multiplier:7.594,loss:4.192289352416992,entropy:5.178513526916504,explained_var_old:0.990108490,explained_var_new:0.992807388
output spend 0.00018405300215817988 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00737312099954579 time
recovery_state_mcts_prob spend 0.2705953490003594 time
state_batch spend 0.0019520069981808774 time
mcts_probs_batch spend 0.0072883050015661865 time
winner_batch spend 0.0002937950048362836 time
policy_value spend 0.21743970799434464 time
train_step spend 0.6349034669983666 time
policy_value spend 0.21808204400440445 time
train_step spend 0.6347370700023021 time
policy_value spend 0.21703094000258716 time
train_step spend 0.6357424300003913 time
policy_value spend 0.2166497030048049 time
train_step spend 0.6336890910024522 time
policy_value spend 0.21729482999944594 time
train_step spend 0.6344660879985895 time
policy_value spend 0.2164801990002161 time
kl:0.02472,lr_multiplier:7.594,loss:4.177431583404541,entropy:5.162096977233887,explained_var_old:0.992638111,explained_var_new:0.994296193
output spend 0.00016669699834892526 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0074169930012431 time
recovery_state_mcts_prob spend 0.27470519700000295 time
state_batch spend 0.0019194760025129654 time
mcts_probs_batch spend 0.00632876499730628 time
winner_batch spend 0.00028834499971708283 time
policy_value spend 0.21786894900287734 time
train_step spend 0.6357964440030628 time
policy_value spend 0.2175368889948004 time
train_step spend 0.6329425139992964 time
policy_value spend 0.2172756930012838 time
train_step spend 0.6344240179969347 time
policy_value spend 0.21648568400269141 time
train_step spend 0.6334956020000391 time
policy_value spend 0.21670192299643531 time
train_step spend 0.6329028499967535 time
policy_value spend 0.21697023200249532 time
kl:0.00772,lr_multiplier:11.391,loss:4.229173183441162,entropy:5.168673038482666,explained_var_old:0.990990996,explained_var_new:0.994303048
output spend 0.00015558399900328368 time
已保存最新模型
current self-play batch: 800
load data begin
已加载数据
step i 372: 
random.sample spend 0.007585671999549959 time
recovery_state_mcts_prob spend 0.27668339500087313 time
state_batch spend 0.0019844579946948215 time
mcts_probs_batch spend 0.006593803002033383 time
winner_batch spend 0.0002917969977715984 time
policy_value spend 0.21865803800028516 time
train_step spend 0.6686115569973481 time
policy_value spend 0.22317288600606844 time
train_step spend 0.6358403530030046 time
policy_value spend 0.2158971280005062 time
train_step spend 0.6307942330022343 time
policy_value spend 0.2194762829967658 time
train_step spend 0.6312144779949449 time
policy_value spend 0.2159957710027811 time
train_step spend 0.6315932399957092 time
policy_value spend 0.21613249900110532 time
kl:0.00821,lr_multiplier:11.391,loss:4.200577259063721,entropy:5.156543731689453,explained_var_old:0.992532194,explained_var_new:0.995123923
output spend 0.0002663320046849549 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006961193997994997 time
recovery_state_mcts_prob spend 0.2898807610035874 time
state_batch spend 0.0022064559962018393 time
mcts_probs_batch spend 0.005572704001679085 time
winner_batch spend 0.00029573000210803 time
policy_value spend 0.22850870299589587 time
train_step spend 0.6501552699992317 time
policy_value spend 0.2171608409989858 time
train_step spend 0.6324078660036321 time
policy_value spend 0.21624016299756477 time
train_step spend 0.6322398470001644 time
policy_value spend 0.2165451420005411 time
train_step spend 0.6350091719941702 time
policy_value spend 0.21646553700702498 time
train_step spend 0.6357456109981285 time
policy_value spend 0.22158937600033823 time
kl:0.00882,lr_multiplier:11.391,loss:4.224533557891846,entropy:5.148733139038086,explained_var_old:0.995450854,explained_var_new:0.998004675
output spend 0.0001534569964860566 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007215240999357775 time
recovery_state_mcts_prob spend 0.27530144000047585 time
state_batch spend 0.0023016039995127358 time
mcts_probs_batch spend 0.004430824999872129 time
winner_batch spend 0.0002851449971785769 time
policy_value spend 0.21595592200173996 time
train_step spend 0.6347630039963406 time
policy_value spend 0.216344417000073 time
train_step spend 0.633912589000829 time
policy_value spend 0.2167443389989785 time
train_step spend 0.6392836989980424 time
policy_value spend 0.21743517900176812 time
train_step spend 0.6362998660042649 time
policy_value spend 0.218224108000868 time
train_step spend 0.6347249559985357 time
policy_value spend 0.21711781900376081 time
kl:0.00689,lr_multiplier:11.391,loss:4.199491024017334,entropy:5.141622543334961,explained_var_old:0.995071828,explained_var_new:0.996239960
output spend 0.00015092999819898978 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007842070001061074 time
recovery_state_mcts_prob spend 0.26580309300334193 time
state_batch spend 0.001945694995811209 time
mcts_probs_batch spend 0.006407708999176975 time
winner_batch spend 0.0002823630056809634 time
policy_value spend 0.21762997900077607 time
train_step spend 0.6356598799975473 time
policy_value spend 0.21828089599875966 time
train_step spend 0.6358888329996262 time
policy_value spend 0.21730325400130823 time
train_step spend 0.6350578009951278 time
policy_value spend 0.21750499599875184 time
train_step spend 0.6360856880055508 time
policy_value spend 0.21746256199548952 time
train_step spend 0.6355884849981521 time
policy_value spend 0.21772294900438283 time
kl:0.00960,lr_multiplier:11.391,loss:4.153723239898682,entropy:5.1344475746154785,explained_var_old:0.986775339,explained_var_new:0.995168149
output spend 0.0001490479990025051 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008030717996007297 time
recovery_state_mcts_prob spend 0.2670909400039818 time
state_batch spend 0.0022379329966497608 time
mcts_probs_batch spend 0.006115460004366469 time
winner_batch spend 0.00029809500119881704 time
policy_value spend 0.21696653699473245 time
train_step spend 0.6366630129996338 time
policy_value spend 0.21663741700467654 time
train_step spend 0.6350849680020474 time
policy_value spend 0.21677388600073755 time
train_step spend 0.6365667159989243 time
policy_value spend 0.21472005400573835 time
train_step spend 0.6244082959965453 time
policy_value spend 0.21343897400220158 time
train_step spend 0.6247522490011761 time
policy_value spend 0.213382473004458 time
kl:0.01153,lr_multiplier:11.391,loss:4.1682329177856445,entropy:5.139316558837891,explained_var_old:0.992438138,explained_var_new:0.994916201
output spend 0.00014528600149787962 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006833652005298063 time
recovery_state_mcts_prob spend 0.2735777779962518 time
state_batch spend 0.0018203420040663332 time
mcts_probs_batch spend 0.006085908993554767 time
winner_batch spend 0.0002780780050670728 time
policy_value spend 0.21324168000137433 time
train_step spend 0.6242236969992518 time
policy_value spend 0.21654065099573927 time
train_step spend 0.6236507630019332 time
policy_value spend 0.21392490699508926 time
train_step spend 0.6248276350015658 time
policy_value spend 0.21347193499968853 time
train_step spend 0.6248493020029855 time
policy_value spend 0.213702139997622 time
train_step spend 0.6243233189961757 time
policy_value spend 0.21380554500501603 time
kl:0.05995,lr_multiplier:7.594,loss:4.15496301651001,entropy:5.106977462768555,explained_var_old:0.998758197,explained_var_new:0.999592721
output spend 0.00014435100456466898 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007361643001786433 time
recovery_state_mcts_prob spend 0.27454929100349545 time
state_batch spend 0.0018875280002248473 time
mcts_probs_batch spend 0.006223334996320773 time
winner_batch spend 0.000288030001684092 time
policy_value spend 0.2154514419962652 time
train_step spend 0.6324589209980331 time
policy_value spend 0.2173917830004939 time
train_step spend 0.6325135029983358 time
policy_value spend 0.21603259599942248 time
train_step spend 0.6328938690057839 time
policy_value spend 0.2160865219993866 time
train_step spend 0.6320566049980698 time
policy_value spend 0.2160123760040733 time
train_step spend 0.6328288910008268 time
policy_value spend 0.21713915200234624 time
kl:0.01808,lr_multiplier:7.594,loss:4.197689533233643,entropy:5.139734745025635,explained_var_old:0.983638108,explained_var_new:0.984994233
output spend 0.00014661500608781353 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008284985000500455 time
recovery_state_mcts_prob spend 0.2819950409975718 time
state_batch spend 0.001848333005909808 time
mcts_probs_batch spend 0.005650646999129094 time
winner_batch spend 0.00028577999910339713 time
policy_value spend 0.21605145699868444 time
train_step spend 0.6322731530017336 time
policy_value spend 0.21722119799960637 time
train_step spend 0.6316222879977431 time
policy_value spend 0.21646605400019325 time
train_step spend 0.633153217000654 time
policy_value spend 0.2173505379978451 time
train_step spend 0.6344951319988468 time
policy_value spend 0.2170185950017185 time
train_step spend 0.6342227760032983 time
policy_value spend 0.21761340899684 time
kl:0.02190,lr_multiplier:7.594,loss:4.209681034088135,entropy:5.151805877685547,explained_var_old:0.993454635,explained_var_new:0.995810926
output spend 0.0001911569997901097 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007605421997141093 time
recovery_state_mcts_prob spend 0.2700134800033993 time
state_batch spend 0.0018913469975814223 time
mcts_probs_batch spend 0.00618245400255546 time
winner_batch spend 0.00031190700246952474 time
policy_value spend 0.21693240199965658 time
train_step spend 0.6344600529992022 time
policy_value spend 0.2180607299960684 time
train_step spend 0.6349181219993625 time
policy_value spend 0.21771384300518548 time
train_step spend 0.6339606799956528 time
policy_value spend 0.21747093700105324 time
train_step spend 0.6352781840032549 time
policy_value spend 0.21714915699703852 time
train_step spend 0.6351154089934425 time
policy_value spend 0.2174926890002098 time
kl:0.04977,lr_multiplier:5.062,loss:4.194896697998047,entropy:5.15234375,explained_var_old:0.992503881,explained_var_new:0.995412290
output spend 0.00014884799747960642 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007200807995104697 time
recovery_state_mcts_prob spend 0.27530338799988385 time
state_batch spend 0.0018441610009176657 time
mcts_probs_batch spend 0.005773591001343448 time
winner_batch spend 0.0003115639992756769 time
policy_value spend 0.21744190400204388 time
train_step spend 0.6400009510034579 time
policy_value spend 0.21924084599595517 time
train_step spend 0.6392031889990903 time
policy_value spend 0.21837411200249335 time
train_step spend 0.6551683069992578 time
policy_value spend 0.23195089100045152 time
train_step spend 0.6685784869987401 time
policy_value spend 0.22112258100241888 time
train_step spend 0.6427736920013558 time
policy_value spend 0.2184602769993944 time
kl:0.03997,lr_multiplier:5.062,loss:4.169769287109375,entropy:5.151222229003906,explained_var_old:0.991447926,explained_var_new:0.991752028
output spend 0.00014792900037718937 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006980281999858562 time
recovery_state_mcts_prob spend 0.2688842669958831 time
state_batch spend 0.00197667700558668 time
mcts_probs_batch spend 0.005574791997787543 time
winner_batch spend 0.00030108200007816777 time
policy_value spend 0.21785146000183886 time
train_step spend 0.6403807609967771 time
policy_value spend 0.21838735400524456 time
train_step spend 0.637863941003161 time
policy_value spend 0.21874034399661468 time
train_step spend 0.639101473003393 time
policy_value spend 0.2078207119993749 time
train_step spend 0.6019283040004666 time
policy_value spend 0.20678464899538085 time
train_step spend 0.6021926879984676 time
policy_value spend 0.20631661100196652 time
kl:0.02412,lr_multiplier:5.062,loss:4.224146366119385,entropy:5.1491570472717285,explained_var_old:0.993400276,explained_var_new:0.998353541
output spend 0.00014142900181468576 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007439873996190727 time
recovery_state_mcts_prob spend 0.25959834099921864 time
state_batch spend 0.001899052003864199 time
mcts_probs_batch spend 0.00633368000126211 time
winner_batch spend 0.00028695199580397457 time
policy_value spend 0.20553534800274065 time
train_step spend 0.6051442099997075 time
policy_value spend 0.2053080260011484 time
train_step spend 0.604030522001267 time
policy_value spend 0.2053046910004923 time
train_step spend 0.6017838460029452 time
policy_value spend 0.20603264599776594 time
train_step spend 0.6191066969986423 time
policy_value spend 0.21710359700227855 time
train_step spend 0.6355201450060122 time
policy_value spend 0.21690952399512753 time
kl:0.02468,lr_multiplier:5.062,loss:4.217257022857666,entropy:5.150466442108154,explained_var_old:0.988500297,explained_var_new:0.994495213
output spend 0.00014828799612587318 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00888250999560114 time
recovery_state_mcts_prob spend 0.26958628200372914 time
state_batch spend 0.0019712189969141036 time
mcts_probs_batch spend 0.006374474003678188 time
winner_batch spend 0.0002849769953172654 time
policy_value spend 0.21667881100438535 time
train_step spend 0.6348263790059718 time
policy_value spend 0.21738706799806096 time
train_step spend 0.6348401860013837 time
policy_value spend 0.2169696990022203 time
train_step spend 0.6349224040022818 time
policy_value spend 0.21696315499866614 time
train_step spend 0.6350277140008984 time
policy_value spend 0.217609473002085 time
train_step spend 0.635726672000601 time
policy_value spend 0.2172182159993099 time
kl:0.00985,lr_multiplier:7.594,loss:4.151782035827637,entropy:5.130478858947754,explained_var_old:0.992455959,explained_var_new:0.995908320
output spend 0.00015700900257797912 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007422408998536412 time
recovery_state_mcts_prob spend 0.2736103780043777 time
state_batch spend 0.0018623729993123561 time
mcts_probs_batch spend 0.005946820994722657 time
winner_batch spend 0.00032835100137162954 time
policy_value spend 0.2174851200034027 time
train_step spend 0.6343171460030135 time
policy_value spend 0.22090897399903042 time
train_step spend 0.6341613619952113 time
policy_value spend 0.21696220300509594 time
train_step spend 0.6346439690023544 time
policy_value spend 0.2167566110001644 time
train_step spend 0.6364306989999022 time
policy_value spend 0.2174075119983172 time
train_step spend 0.6363813450007001 time
policy_value spend 0.21809154200309422 time
kl:0.01225,lr_multiplier:7.594,loss:4.1743974685668945,entropy:5.127109527587891,explained_var_old:0.994695902,explained_var_new:0.996728957
output spend 0.00015812199853826314 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006913420002092607 time
recovery_state_mcts_prob spend 0.272985552001046 time
state_batch spend 0.0020799220001208596 time
mcts_probs_batch spend 0.005956848995992914 time
winner_batch spend 0.0002891000040108338 time
policy_value spend 0.21699605499452446 time
train_step spend 0.6388267159927636 time
policy_value spend 0.217679796005541 time
train_step spend 0.6356378380005481 time
policy_value spend 0.21716581199871143 time
train_step spend 0.6366934729958302 time
policy_value spend 0.21676588300033472 time
train_step spend 0.636008226996637 time
policy_value spend 0.21728221300145378 time
train_step spend 0.6362908010050887 time
policy_value spend 0.21756400799495168 time
kl:0.00619,lr_multiplier:11.391,loss:4.19545316696167,entropy:5.127386093139648,explained_var_old:0.995093465,explained_var_new:0.995802820
output spend 0.00014476399519480765 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006844394993095193 time
recovery_state_mcts_prob spend 0.27420129700476537 time
state_batch spend 0.0018538250005804002 time
mcts_probs_batch spend 0.007361127994954586 time
winner_batch spend 0.00029612200160045177 time
policy_value spend 0.21964754100190476 time
train_step spend 0.6545117269997718 time
policy_value spend 0.2243244359997334 time
train_step spend 0.6544528509984957 time
policy_value spend 0.22287859100470087 time
train_step spend 0.6540189959996496 time
policy_value spend 0.22289325200108578 time
train_step spend 0.65388645400526 time
policy_value spend 0.2232260859964299 time
train_step spend 0.6538332979980623 time
policy_value spend 0.22310624999954598 time
kl:0.00653,lr_multiplier:11.391,loss:4.197080135345459,entropy:5.134583473205566,explained_var_old:0.990308940,explained_var_new:0.992208898
output spend 0.00016669099568389356 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007212331998744048 time
recovery_state_mcts_prob spend 0.2767636019998463 time
state_batch spend 0.002204131000326015 time
mcts_probs_batch spend 0.012831247004214674 time
winner_batch spend 0.00029887299751862884 time
policy_value spend 0.22706356999697164 time
train_step spend 0.6536143159974017 time
policy_value spend 0.22739933100092458 time
train_step spend 0.655357842995727 time
policy_value spend 0.22502857699873857 time
train_step spend 0.6335993559987401 time
policy_value spend 0.20622887900390197 time
train_step spend 0.6026642930009984 time
policy_value spend 0.20596189999923809 time
train_step spend 0.6036605810004403 time
policy_value spend 0.206409035003162 time
kl:0.00968,lr_multiplier:11.391,loss:4.155343532562256,entropy:5.1022114753723145,explained_var_old:0.991322637,explained_var_new:0.992320657
output spend 0.00015704600082244724 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008004959003301337 time
recovery_state_mcts_prob spend 0.2543326579980203 time
state_batch spend 0.001769570000760723 time
mcts_probs_batch spend 0.005828503999509849 time
winner_batch spend 0.00027653700090013444 time
policy_value spend 0.2071517069998663 time
train_step spend 0.6027990499933367 time
policy_value spend 0.2062769100011792 time
train_step spend 0.6025815210014116 time
policy_value spend 0.20629838800232392 time
train_step spend 0.6033650080062216 time
policy_value spend 0.20661994099646108 time
train_step spend 0.6033935279992875 time
policy_value spend 0.20686685499822488 time
train_step spend 0.6027901229972485 time
policy_value spend 0.20595334300014656 time
kl:0.00563,lr_multiplier:11.391,loss:4.214114189147949,entropy:5.162082195281982,explained_var_old:0.997386634,explained_var_new:0.999517739
output spend 0.00014477399963652715 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007907892999355681 time
recovery_state_mcts_prob spend 0.2719770059993607 time
state_batch spend 0.0018162060005124658 time
mcts_probs_batch spend 0.007225481000205036 time
winner_batch spend 0.0002709280015551485 time
policy_value spend 0.2070383500031312 time
train_step spend 0.6433007219966385 time
policy_value spend 0.22436933400604175 time
train_step spend 0.6156347680007457 time
policy_value spend 0.20977698000206146 time
train_step spend 0.6120524739963003 time
policy_value spend 0.2101272380023147 time
train_step spend 0.6130231610004557 time
policy_value spend 0.21000962000107393 time
train_step spend 0.6124262739976984 time
policy_value spend 0.20932276300300146 time
kl:0.00579,lr_multiplier:11.391,loss:4.1991400718688965,entropy:5.164811611175537,explained_var_old:0.998321533,explained_var_new:0.999368012
output spend 0.00014023499534232542 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007311351000680588 time
recovery_state_mcts_prob spend 0.2636513239995111 time
state_batch spend 0.00177955500112148 time
mcts_probs_batch spend 0.006497389003925491 time
winner_batch spend 0.0003970689940615557 time
policy_value spend 0.20892807600466767 time
train_step spend 0.6119501119974302 time
policy_value spend 0.20945076399948448 time
train_step spend 0.613521336003032 time
policy_value spend 0.20963633099745493 time
train_step spend 0.621998665999854 time
policy_value spend 0.20902475599723402 time
train_step spend 0.626398986998538 time
policy_value spend 0.21936504200130003 time
train_step spend 0.6431101060006768 time
policy_value spend 0.22141989900410408 time
kl:0.01295,lr_multiplier:11.391,loss:4.209577560424805,entropy:5.153152942657471,explained_var_old:0.995744348,explained_var_new:0.995851338
output spend 0.000155337002070155 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008112108000204898 time
recovery_state_mcts_prob spend 0.2750397280033212 time
state_batch spend 0.002126498999132309 time
mcts_probs_batch spend 0.007329244996071793 time
winner_batch spend 0.00029024800460319966 time
policy_value spend 0.22742545099754352 time
train_step spend 0.6442903999995906 time
policy_value spend 0.21950526400178205 time
train_step spend 0.6461319520021789 time
policy_value spend 0.2200201450032182 time
train_step spend 0.6443108829989797 time
policy_value spend 0.21930677800264675 time
train_step spend 0.6436864940042142 time
policy_value spend 0.22013256199716125 time
train_step spend 0.643714063000516 time
policy_value spend 0.21986217000085162 time
kl:0.00882,lr_multiplier:11.391,loss:4.202629089355469,entropy:5.141169548034668,explained_var_old:0.994605362,explained_var_new:0.995919466
output spend 0.00014931100304238498 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00783302600029856 time
recovery_state_mcts_prob spend 0.2717309860017849 time
state_batch spend 0.0018402350033284165 time
mcts_probs_batch spend 0.007171078999817837 time
winner_batch spend 0.00029410799470497295 time
policy_value spend 0.22004919400205836 time
train_step spend 0.6626851780019933 time
policy_value spend 0.23133612899982836 time
train_step spend 0.6675959400017746 time
policy_value spend 0.22855281699594343 time
train_step spend 0.6685208799972315 time
policy_value spend 0.22859942500508623 time
train_step spend 0.6679586850004853 time
policy_value spend 0.2284022849999019 time
train_step spend 0.6715523560051224 time
policy_value spend 0.22922302699589636 time
kl:0.01365,lr_multiplier:11.391,loss:4.159475803375244,entropy:5.089637756347656,explained_var_old:0.994381011,explained_var_new:0.995802164
output spend 0.0001630670012673363 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008202919001632836 time
recovery_state_mcts_prob spend 0.2830771430017194 time
state_batch spend 0.0020524700012174435 time
mcts_probs_batch spend 0.011787415998696815 time
winner_batch spend 0.00031839899747865275 time
policy_value spend 0.23183809200418182 time
train_step spend 0.666935895998904 time
policy_value spend 0.23301570500188973 time
train_step spend 0.6681843610058422 time
policy_value spend 0.22780725600023288 time
train_step spend 0.6653989309997996 time
policy_value spend 0.20525876699684886 time
train_step spend 0.6024986289994558 time
policy_value spend 0.20622418799757725 time
train_step spend 0.6023743500045384 time
policy_value spend 0.2056573820009362 time
kl:0.00813,lr_multiplier:11.391,loss:4.16441535949707,entropy:5.115109920501709,explained_var_old:0.991004467,explained_var_new:0.995695710
output spend 0.00014187099441187456 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007289734996447805 time
recovery_state_mcts_prob spend 0.256106038003054 time
state_batch spend 0.0018318579968763515 time
mcts_probs_batch spend 0.005815933000121731 time
winner_batch spend 0.0002833990001818165 time
policy_value spend 0.20530091500404524 time
train_step spend 0.6021534729952691 time
policy_value spend 0.20596144199953414 time
train_step spend 0.6029317209977307 time
policy_value spend 0.20607851300155744 time
train_step spend 0.6032580239989329 time
policy_value spend 0.2054444959940156 time
train_step spend 0.6030098360060947 time
policy_value spend 0.20561594199534738 time
train_step spend 0.6031036230051541 time
policy_value spend 0.20613672499894165 time
kl:0.01465,lr_multiplier:11.391,loss:4.155252456665039,entropy:5.108480930328369,explained_var_old:0.989069998,explained_var_new:0.991896749
output spend 0.0001381639958708547 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006850614998256788 time
recovery_state_mcts_prob spend 0.27327553299983265 time
state_batch spend 0.0017692539986455813 time
mcts_probs_batch spend 0.004883902001893148 time
winner_batch spend 0.0002712799978326075 time
policy_value spend 0.2060429050034145 time
train_step spend 0.602413478998642 time
policy_value spend 0.20649557700380683 time
train_step spend 0.6025277509979787 time
policy_value spend 0.205672415002482 time
train_step spend 0.601927275005437 time
policy_value spend 0.2060865300009027 time
train_step spend 0.6030988410057034 time
policy_value spend 0.2061102449952159 time
train_step spend 0.6112931530005881 time
policy_value spend 0.20587605000037001 time
kl:0.00592,lr_multiplier:11.391,loss:4.190723419189453,entropy:5.141592979431152,explained_var_old:0.979893923,explained_var_new:0.982304275
output spend 0.00014209600340109318 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007348904000537004 time
recovery_state_mcts_prob spend 0.26032321200182196 time
state_batch spend 0.001872478998848237 time
mcts_probs_batch spend 0.00613592399895424 time
winner_batch spend 0.00027749300352297723 time
policy_value spend 0.2057842219946906 time
train_step spend 0.602071519002493 time
policy_value spend 0.2070479219983099 time
train_step spend 0.6028075100039132 time
policy_value spend 0.20649241199862445 time
train_step spend 0.6032845610025106 time
policy_value spend 0.20636068699968746 time
train_step spend 0.6070754030006356 time
policy_value spend 0.2178854610028793 time
train_step spend 0.6356911260008928 time
policy_value spend 0.21778747200005455 time
kl:0.00998,lr_multiplier:11.391,loss:4.230648517608643,entropy:5.148116588592529,explained_var_old:0.987497807,explained_var_new:0.992212653
output spend 0.00021136099530849606 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006952862997422926 time
recovery_state_mcts_prob spend 0.26783488399814814 time
state_batch spend 0.001975316001335159 time
mcts_probs_batch spend 0.007724565999524202 time
winner_batch spend 0.0004970250010956079 time
policy_value spend 0.2183239939986379 time
train_step spend 0.636116598994704 time
policy_value spend 0.2170165490024374 time
train_step spend 0.6354115819995059 time
policy_value spend 0.21727895699586952 time
train_step spend 0.6352416200024891 time
policy_value spend 0.2170337319985265 time
train_step spend 0.6356432800021139 time
policy_value spend 0.21699354700103868 time
train_step spend 0.6513407759994152 time
policy_value spend 0.23041424099938013 time
kl:0.00800,lr_multiplier:11.391,loss:4.137538433074951,entropy:5.100113391876221,explained_var_old:0.990953445,explained_var_new:0.992528737
output spend 0.00015013899974292144 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00763827700575348 time
recovery_state_mcts_prob spend 0.27583326199965086 time
state_batch spend 0.0019202339972252958 time
mcts_probs_batch spend 0.0068111479995423 time
winner_batch spend 0.00028642600227613 time
policy_value spend 0.21929220300080488 time
train_step spend 0.6527744069971959 time
policy_value spend 0.23393986400333233 time
train_step spend 0.6669553649990121 time
policy_value spend 0.22827088199846912 time
train_step spend 0.668046245998994 time
policy_value spend 0.2284867780035711 time
train_step spend 0.665912106000178 time
policy_value spend 0.2289707689997158 time
train_step spend 0.6670463209957234 time
policy_value spend 0.22786056600307347 time
kl:0.01044,lr_multiplier:11.391,loss:4.165955066680908,entropy:5.10085391998291,explained_var_old:0.987756729,explained_var_new:0.988043070
output spend 0.0001645459997234866 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008804903998679947 time
recovery_state_mcts_prob spend 0.28530289600166725 time
state_batch spend 0.0019574219986679964 time
mcts_probs_batch spend 0.007137941996916197 time
winner_batch spend 0.00034318899997742847 time
policy_value spend 0.22793372299929615 time
train_step spend 0.6675428460002877 time
policy_value spend 0.2281330749974586 time
train_step spend 0.6663145730053657 time
policy_value spend 0.227425069999299 time
train_step spend 0.6672277710022172 time
policy_value spend 0.22832549799932167 time
train_step spend 0.6048573140069493 time
policy_value spend 0.2058576479976182 time
train_step spend 0.6017679750002571 time
policy_value spend 0.20570556099846726 time
kl:0.00964,lr_multiplier:11.391,loss:4.187155723571777,entropy:5.154664039611816,explained_var_old:0.991222382,explained_var_new:0.991668999
output spend 0.00013922899961471558 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007292962996871211 time
recovery_state_mcts_prob spend 0.26074255799903767 time
state_batch spend 0.0017627890047151595 time
mcts_probs_batch spend 0.004210713996144477 time
winner_batch spend 0.0002705770020838827 time
policy_value spend 0.2053406589984661 time
train_step spend 0.6025773260043934 time
policy_value spend 0.20522830900154077 time
train_step spend 0.6018953829989186 time
policy_value spend 0.20611905500118155 time
train_step spend 0.6020379870024044 time
policy_value spend 0.20617390099505428 time
train_step spend 0.6030923590005841 time
policy_value spend 0.2123008180060424 time
train_step spend 0.6034002180022071 time
policy_value spend 0.2057582560009905 time
kl:0.01560,lr_multiplier:11.391,loss:4.159098148345947,entropy:5.093242645263672,explained_var_old:0.993593276,explained_var_new:0.996115804
output spend 0.00015233000158332288 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008870492994901724 time
recovery_state_mcts_prob spend 0.2580925490037771 time
state_batch spend 0.001774295000359416 time
mcts_probs_batch spend 0.007380506998742931 time
winner_batch spend 0.0004405529980431311 time
policy_value spend 0.21276178800326306 time
train_step spend 0.6019198829962988 time
policy_value spend 0.2057923300017137 time
train_step spend 0.6028461799942306 time
policy_value spend 0.20553774000291014 time
train_step spend 0.6032416419984656 time
policy_value spend 0.20527903699985472 time
train_step spend 0.6021474330045749 time
policy_value spend 0.20607272299821489 time
train_step spend 0.6035496839976986 time
policy_value spend 0.2066028230037773 time
kl:0.01205,lr_multiplier:11.391,loss:4.1784281730651855,entropy:5.10403299331665,explained_var_old:0.990157783,explained_var_new:0.992329061
output spend 0.00014201500016497448 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006573149999894667 time
recovery_state_mcts_prob spend 0.2566870820010081 time
state_batch spend 0.00177754999458557 time
mcts_probs_batch spend 0.004446739003469702 time
winner_batch spend 0.0003013870009453967 time
policy_value spend 0.2046763260004809 time
train_step spend 0.6026016809992143 time
policy_value spend 0.20590762999927392 time
train_step spend 0.6030931269997382 time
policy_value spend 0.20576535099826287 time
train_step spend 0.6027966689944151 time
policy_value spend 0.20611062300304184 time
train_step spend 0.601948600000469 time
policy_value spend 0.20714228099677712 time
train_step spend 0.6370000609967974 time
policy_value spend 0.21683551000023726 time
kl:0.02295,lr_multiplier:11.391,loss:4.1639251708984375,entropy:5.058462619781494,explained_var_old:0.998938560,explained_var_new:0.999456704
output spend 0.0001470930001232773 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007341259995882865 time
recovery_state_mcts_prob spend 0.26767317800113233 time
state_batch spend 0.0020674000043072738 time
mcts_probs_batch spend 0.013192966995120514 time
winner_batch spend 0.00030576000426663086 time
policy_value spend 0.2218710849992931 time
train_step spend 0.6368090590040083 time
policy_value spend 0.21733035799843492 time
train_step spend 0.6348337769959471 time
policy_value spend 0.22109038200142095 time
train_step spend 0.6361316090042237 time
policy_value spend 0.21726126599969575 time
train_step spend 0.635937210994598 time
policy_value spend 0.21663962800084846 time
train_step spend 0.6355242409990751 time
policy_value spend 0.21859065799799282 time
kl:0.01963,lr_multiplier:11.391,loss:4.141074180603027,entropy:5.065134525299072,explained_var_old:0.994311750,explained_var_new:0.999083519
output spend 0.00015603900101268664 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007595498005684931 time
recovery_state_mcts_prob spend 0.271947712994006 time
state_batch spend 0.0019475670051178895 time
mcts_probs_batch spend 0.006118992001574952 time
winner_batch spend 0.0003036559937754646 time
policy_value spend 0.21799941300560022 time
train_step spend 0.6367662509946967 time
policy_value spend 0.224768268999469 time
train_step spend 0.6655144809992635 time
policy_value spend 0.2276049759966554 time
train_step spend 0.6647528530011186 time
policy_value spend 0.22747222599718953 time
train_step spend 0.6658948070034967 time
policy_value spend 0.22863743500056444 time
train_step spend 0.6667891850011074 time
policy_value spend 0.2279077999992296 time
kl:0.01235,lr_multiplier:11.391,loss:4.149435520172119,entropy:5.11679744720459,explained_var_old:0.976207197,explained_var_new:0.979432166
output spend 0.00015901900042081252 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007484355002816301 time
recovery_state_mcts_prob spend 0.28408667400071863 time
state_batch spend 0.0022152559977257624 time
mcts_probs_batch spend 0.0126913499989314 time
winner_batch spend 0.00030746400443604216 time
policy_value spend 0.23116784400190227 time
train_step spend 0.664111979000154 time
policy_value spend 0.23164520999853266 time
train_step spend 0.6653715549982735 time
policy_value spend 0.2271669120018487 time
train_step spend 0.6648901350054075 time
policy_value spend 0.22839878099330235 time
train_step spend 0.6396514579973882 time
policy_value spend 0.20640543800254818 time
train_step spend 0.6029818300012266 time
policy_value spend 0.20583902799990028 time
kl:0.01102,lr_multiplier:11.391,loss:4.167717456817627,entropy:5.112613677978516,explained_var_old:0.989255548,explained_var_new:0.991941273
output spend 0.00019076900207437575 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008033299003727734 time
recovery_state_mcts_prob spend 0.26289629099483136 time
state_batch spend 0.0018401450070086867 time
mcts_probs_batch spend 0.006384111999068409 time
winner_batch spend 0.00029698699654545635 time
policy_value spend 0.21405108400358586 time
train_step spend 0.6207291359969531 time
policy_value spend 0.21868532599910395 time
train_step spend 0.6185004200015101 time
policy_value spend 0.20665854000253603 time
train_step spend 0.6033453069976531 time
policy_value spend 0.20558909900137223 time
train_step spend 0.6024985369949718 time
policy_value spend 0.20519485600379994 time
train_step spend 0.60253314399597 time
policy_value spend 0.20562130700272974 time
kl:0.01085,lr_multiplier:11.391,loss:4.129097938537598,entropy:5.088017463684082,explained_var_old:0.995334446,explained_var_new:0.996936262
output spend 0.0001389679964631796 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006903363995661493 time
recovery_state_mcts_prob spend 0.2536546490009641 time
state_batch spend 0.0020454129989957437 time
mcts_probs_batch spend 0.005803943000501022 time
winner_batch spend 0.0002771049985312857 time
policy_value spend 0.20599102700361982 time
train_step spend 0.6032695210014936 time
policy_value spend 0.2058276579991798 time
train_step spend 0.6030247119997512 time
policy_value spend 0.2061956879988429 time
train_step spend 0.6025438729993766 time
policy_value spend 0.2065400400024373 time
train_step spend 0.6013651300017955 time
policy_value spend 0.20639735899749212 time
train_step spend 0.6017734940032824 time
policy_value spend 0.20624201699683908 time
kl:0.01007,lr_multiplier:11.391,loss:4.125661849975586,entropy:5.134085655212402,explained_var_old:0.992451131,explained_var_new:0.994802296
output spend 0.0001507519991719164 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007280808000359684 time
recovery_state_mcts_prob spend 0.26031230200169375 time
state_batch spend 0.0017992899956880137 time
mcts_probs_batch spend 0.00602486300340388 time
winner_batch spend 0.00030593200062867254 time
policy_value spend 0.20861909599625506 time
train_step spend 0.6025158679985907 time
policy_value spend 0.20904259799863212 time
train_step spend 0.6010937329992885 time
policy_value spend 0.20550117600214435 time
train_step spend 0.602333702998294 time
policy_value spend 0.205795672001841 time
train_step spend 0.602146573997743 time
policy_value spend 0.2059311789998901 time
train_step spend 0.6231011780037079 time
policy_value spend 0.2187959909933852 time
kl:0.01098,lr_multiplier:11.391,loss:4.114270210266113,entropy:5.077474594116211,explained_var_old:0.991156578,explained_var_new:0.992257237
output spend 0.00014484499843092635 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007294937000551727 time
recovery_state_mcts_prob spend 0.2717160999964108 time
state_batch spend 0.0018800380057655275 time
mcts_probs_batch spend 0.006634084995312151 time
winner_batch spend 0.0003468770009931177 time
policy_value spend 0.21659331900445977 time
train_step spend 0.6379762910000863 time
policy_value spend 0.2190936339975451 time
train_step spend 0.6362915959980455 time
policy_value spend 0.21764342799724545 time
train_step spend 0.6356350229980308 time
policy_value spend 0.21768585500103654 time
train_step spend 0.6359099990004324 time
policy_value spend 0.218138578995422 time
train_step spend 0.6375808020020486 time
policy_value spend 0.21708498500083806 time
kl:0.01439,lr_multiplier:11.391,loss:4.143422603607178,entropy:5.10437536239624,explained_var_old:0.988885283,explained_var_new:0.991428852
output spend 0.00014582600124413148 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007293420996575151 time
recovery_state_mcts_prob spend 0.27638797600229736 time
state_batch spend 0.0019419210002524778 time
mcts_probs_batch spend 0.007041301003482658 time
winner_batch spend 0.0003021419979631901 time
policy_value spend 0.21725236799829872 time
train_step spend 0.6359771650022594 time
policy_value spend 0.21712699399358826 time
train_step spend 0.6682212349987822 time
policy_value spend 0.23046119199716486 time
train_step spend 0.6761553160031326 time
policy_value spend 0.23056725799688138 time
train_step spend 0.6760338989988668 time
policy_value spend 0.2313545079960022 time
train_step spend 0.6757106829973054 time
policy_value spend 0.23088204600207973 time
kl:0.03167,lr_multiplier:11.391,loss:4.168039321899414,entropy:5.086742401123047,explained_var_old:0.995182514,explained_var_new:0.995658398
output spend 0.0002701170014915988 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010024743001849856 time
recovery_state_mcts_prob spend 0.28310976499778917 time
state_batch spend 0.002019892002863344 time
mcts_probs_batch spend 0.006338866995065473 time
winner_batch spend 0.00028966000536456704 time
policy_value spend 0.21765671199682401 time
train_step spend 0.6346339960000478 time
policy_value spend 0.22011479300272185 time
train_step spend 0.6339857919956557 time
policy_value spend 0.2172016900003655 time
train_step spend 0.6351686669950141 time
policy_value spend 0.21704180000233464 time
train_step spend 0.6351295639979071 time
policy_value spend 0.214991466003994 time
train_step spend 0.6119307260014466 time
policy_value spend 0.20955895799852442 time
kl:0.01629,lr_multiplier:11.391,loss:4.149140357971191,entropy:5.084338188171387,explained_var_old:0.994619370,explained_var_new:0.996021330
output spend 0.00013870600378140807 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0066065139981219545 time
recovery_state_mcts_prob spend 0.2673800409975229 time
state_batch spend 0.0018620490009197965 time
mcts_probs_batch spend 0.0070483880044776015 time
winner_batch spend 0.0005291799971018918 time
policy_value spend 0.21063718799996423 time
train_step spend 0.6120125000015832 time
policy_value spend 0.21030276599776698 time
train_step spend 0.6123377779949806 time
policy_value spend 0.21157263700297335 time
train_step spend 0.6136649519976345 time
policy_value spend 0.21140082600322785 time
train_step spend 0.6134345030004624 time
policy_value spend 0.20946308400016278 time
train_step spend 0.6124155440047616 time
policy_value spend 0.20915076999517623 time
kl:0.04098,lr_multiplier:7.594,loss:4.162693977355957,entropy:5.108262538909912,explained_var_old:0.995910883,explained_var_new:0.996418059
output spend 0.00014224500046111643 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007219036000606138 time
recovery_state_mcts_prob spend 0.2562765640032012 time
state_batch spend 0.001825660998292733 time
mcts_probs_batch spend 0.0061892599987913854 time
winner_batch spend 0.00028331600333331153 time
policy_value spend 0.20968954000272788 time
train_step spend 0.6118856019966188 time
policy_value spend 0.20958724200318102 time
train_step spend 0.6040151229972253 time
policy_value spend 0.20580356700520497 time
train_step spend 0.6026494609977817 time
policy_value spend 0.20576343900029315 time
train_step spend 0.6024434080027277 time
policy_value spend 0.20637337600055616 time
train_step spend 0.602234641002724 time
policy_value spend 0.2060894609967363 time
kl:0.03017,lr_multiplier:7.594,loss:4.177247524261475,entropy:5.059836387634277,explained_var_old:0.988572836,explained_var_new:0.990499616
output spend 0.0001418350002495572 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007002090002060868 time
recovery_state_mcts_prob spend 0.2575850540015381 time
state_batch spend 0.0018328500009374693 time
mcts_probs_batch spend 0.0042428050001035444 time
winner_batch spend 0.0002848779986379668 time
policy_value spend 0.2054581389966188 time
train_step spend 0.6027849300007802 time
policy_value spend 0.20552525100356434 time
train_step spend 0.6012087240014807 time
policy_value spend 0.20554222100327024 time
train_step spend 0.6016890950049856 time
policy_value spend 0.20575669599929824 time
train_step spend 0.6094151080033043 time
policy_value spend 0.2166461309971055 time
train_step spend 0.6343787489968236 time
policy_value spend 0.21716385200124932 time
kl:0.03406,lr_multiplier:7.594,loss:4.160017967224121,entropy:5.114387512207031,explained_var_old:0.985719264,explained_var_new:0.987951696
output spend 0.00032245700276689604 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007234452998091001 time
recovery_state_mcts_prob spend 0.2954978120033047 time
state_batch spend 0.0020521379992715083 time
mcts_probs_batch spend 0.006564763003552798 time
winner_batch spend 0.0004453859946806915 time
policy_value spend 0.23019634500087705 time
train_step spend 0.6504490919978707 time
policy_value spend 0.21711618700646795 time
train_step spend 0.632903947000159 time
policy_value spend 0.21593496199784568 time
train_step spend 0.6323331129970029 time
policy_value spend 0.21663305000402033 time
train_step spend 0.6328220559953479 time
policy_value spend 0.21636017299897503 time
train_step spend 0.6330784350066097 time
policy_value spend 0.21595042799890507 time
kl:0.09208,lr_multiplier:5.062,loss:4.156798362731934,entropy:5.060223579406738,explained_var_old:0.995622814,explained_var_new:0.999328434
output spend 0.00014653299876954406 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008255553999333642 time
recovery_state_mcts_prob spend 0.27968648800015217 time
state_batch spend 0.0021220070048002526 time
mcts_probs_batch spend 0.00636761799978558 time
winner_batch spend 0.0002822899987222627 time
policy_value spend 0.2160997410028358 time
train_step spend 0.6318520109998644 time
policy_value spend 0.21576190199994016 time
train_step spend 0.6417879599976004 time
policy_value spend 0.22437427100521745 time
train_step spend 0.6564934339985484 time
policy_value spend 0.2245278319969657 time
train_step spend 0.6570386929961387 time
policy_value spend 0.22462655900017126 time
train_step spend 0.6562452750004013 time
policy_value spend 0.22491868699580664 time
kl:0.03928,lr_multiplier:5.062,loss:4.119898319244385,entropy:5.054190635681152,explained_var_old:0.998835146,explained_var_new:0.999264538
output spend 0.00024142199981724843 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007636684000317473 time
recovery_state_mcts_prob spend 0.288802561997727 time
state_batch spend 0.001851541004725732 time
mcts_probs_batch spend 0.004654377997212578 time
winner_batch spend 0.0002942319988505915 time
policy_value spend 0.22395459999825107 time
train_step spend 0.6568106949998764 time
policy_value spend 0.22402346599847078 time
train_step spend 0.657846251000592 time
policy_value spend 0.22454287599975942 time
train_step spend 0.6540293540019775 time
policy_value spend 0.21762310099438764 time
train_step spend 0.6351681910018669 time
policy_value spend 0.2169999949983321 time
train_step spend 0.6316740199981723 time
policy_value spend 0.21480467800574843 time
kl:0.00635,lr_multiplier:7.594,loss:4.130459785461426,entropy:5.072789669036865,explained_var_old:0.995053589,explained_var_new:0.995407939
output spend 0.00015568099479423836 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011728974001016468 time
recovery_state_mcts_prob spend 0.2658385019967682 time
state_batch spend 0.0017758090034476481 time
mcts_probs_batch spend 0.00474060599663062 time
winner_batch spend 0.0003053519976674579 time
policy_value spend 0.21376644700649194 time
train_step spend 0.6289612789987586 time
policy_value spend 0.21424863200081745 time
train_step spend 0.6287500670005102 time
policy_value spend 0.21512612500373507 time
train_step spend 0.6285421479988145 time
policy_value spend 0.21495674099423923 time
train_step spend 0.6288438690025941 time
policy_value spend 0.21478151499468368 time
train_step spend 0.6291429940029047 time
policy_value spend 0.2154432809984428 time
kl:0.02254,lr_multiplier:7.594,loss:4.125561714172363,entropy:5.093962669372559,explained_var_old:0.993349493,explained_var_new:0.995646715
output spend 0.00018182900384999812 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006759153999155387 time
recovery_state_mcts_prob spend 0.2635097960010171 time
state_batch spend 0.0020393640006659552 time
mcts_probs_batch spend 0.004537492000963539 time
winner_batch spend 0.00029800600168528035 time
policy_value spend 0.21401808299560798 time
train_step spend 0.6284704770005192 time
policy_value spend 0.21498983100173064 time
train_step spend 0.6117178130007233 time
policy_value spend 0.20516557800146984 time
train_step spend 0.6039246520012966 time
policy_value spend 0.20599294699786697 time
train_step spend 0.6040167699975427 time
policy_value spend 0.20580754399998114 time
train_step spend 0.6027061829954619 time
policy_value spend 0.20843432300171116 time
kl:0.01289,lr_multiplier:7.594,loss:4.139705657958984,entropy:5.071829319000244,explained_var_old:0.997634172,explained_var_new:0.999575973
output spend 0.0001504280007793568 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008404089996474795 time
recovery_state_mcts_prob spend 0.25715039700298803 time
state_batch spend 0.0017241070017917082 time
mcts_probs_batch spend 0.00519677600095747 time
winner_batch spend 0.0004099949946976267 time
policy_value spend 0.20857615800196072 time
train_step spend 0.6037376379972557 time
policy_value spend 0.20679464800196 time
train_step spend 0.6035811080000713 time
policy_value spend 0.20671304500137921 time
train_step spend 0.6029318959990633 time
policy_value spend 0.2068428069978836 time
train_step spend 0.6031459270016057 time
policy_value spend 0.2065078059968073 time
train_step spend 0.602363662001153 time
policy_value spend 0.2140815550010302 time
kl:0.01342,lr_multiplier:7.594,loss:4.141946792602539,entropy:5.107082366943359,explained_var_old:0.995871842,explained_var_new:0.997633517
output spend 0.00014368999836733565 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007661925999855157 time
recovery_state_mcts_prob spend 0.2756759170006262 time
state_batch spend 0.0017954700015252456 time
mcts_probs_batch spend 0.006115538999438286 time
winner_batch spend 0.0003143249996355735 time
policy_value spend 0.21705639900028473 time
train_step spend 0.6344276969975908 time
policy_value spend 0.21789389300101902 time
train_step spend 0.6348074479974457 time
policy_value spend 0.2166332440028782 time
train_step spend 0.6360101669997675 time
policy_value spend 0.21710553900629748 time
train_step spend 0.6349230650012032 time
policy_value spend 0.21700581700133625 time
train_step spend 0.6364208840022911 time
policy_value spend 0.2171481089972076 time
kl:0.00966,lr_multiplier:11.391,loss:4.163947582244873,entropy:5.10053825378418,explained_var_old:0.986225069,explained_var_new:0.991337240
output spend 0.00015031200018711388 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008161944002495147 time
recovery_state_mcts_prob spend 0.27471219599829055 time
state_batch spend 0.001953544000571128 time
mcts_probs_batch spend 0.006605836002563592 time
winner_batch spend 0.00029469599394360557 time
policy_value spend 0.21787568300351268 time
train_step spend 0.6361873760033632 time
policy_value spend 0.2182030420008232 time
train_step spend 0.6367309870038298 time
policy_value spend 0.22391234799579252 time
train_step spend 0.6552701399996295 time
policy_value spend 0.22353767000458902 time
train_step spend 0.6551326260014321 time
policy_value spend 0.2283496039963211 time
train_step spend 0.6550732250034343 time
policy_value spend 0.22346737699990626 time
kl:0.01279,lr_multiplier:11.391,loss:4.17109489440918,entropy:5.070800304412842,explained_var_old:0.990935206,explained_var_new:0.992248178
output spend 0.000161288000526838 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007149959994421806 time
recovery_state_mcts_prob spend 0.28842122400237713 time
state_batch spend 0.0027299590001348406 time
mcts_probs_batch spend 0.008185191996744834 time
winner_batch spend 0.00034635799966054037 time
policy_value spend 0.22401360400544945 time
train_step spend 0.6586717559985118 time
policy_value spend 0.22366423600033158 time
train_step spend 0.6539894160014228 time
policy_value spend 0.22081100400100695 time
train_step spend 0.651136554995901 time
policy_value spend 0.22991326400369871 time
train_step spend 0.6637514570029452 time
policy_value spend 0.21838484399631852 time
train_step spend 0.6315600159941823 time
policy_value spend 0.21242246000474552 time
kl:0.02606,lr_multiplier:11.391,loss:4.212788105010986,entropy:5.12894344329834,explained_var_old:0.994889200,explained_var_new:0.995665431
output spend 0.00019467499805614352 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00817347699921811 time
recovery_state_mcts_prob spend 0.2723687199977576 time
state_batch spend 0.0018273940004291944 time
mcts_probs_batch spend 0.006752861001587007 time
winner_batch spend 0.000315709003189113 time
policy_value spend 0.21343583399720956 time
train_step spend 0.6238608049970935 time
policy_value spend 0.21315824700286612 time
train_step spend 0.6224415569959092 time
policy_value spend 0.21286415900249267 time
train_step spend 0.6223209960007807 time
policy_value spend 0.21283846799633466 time
train_step spend 0.6271261469955789 time
policy_value spend 0.21283056000538636 time
train_step spend 0.6230251630040584 time
policy_value spend 0.2124602469993988 time
kl:0.01246,lr_multiplier:11.391,loss:4.155940055847168,entropy:5.072281837463379,explained_var_old:0.987961769,explained_var_new:0.989305079
output spend 0.00017471399769419804 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007215088000521064 time
recovery_state_mcts_prob spend 0.26898115999938454 time
state_batch spend 0.0017938620003405958 time
mcts_probs_batch spend 0.0060794519959017634 time
winner_batch spend 0.00027844199939863756 time
policy_value spend 0.2132348320010351 time
train_step spend 0.6223421469985624 time
policy_value spend 0.21279017500637565 time
train_step spend 0.6164230690046679 time
policy_value spend 0.20565760300087277 time
train_step spend 0.6021302359949914 time
policy_value spend 0.20587408600113122 time
train_step spend 0.6028080399992177 time
policy_value spend 0.20609919900016394 time
train_step spend 0.6033931779966224 time
policy_value spend 0.20583580800303025 time
kl:0.01030,lr_multiplier:11.391,loss:4.189698219299316,entropy:5.090457916259766,explained_var_old:0.988112628,explained_var_new:0.988890231
output spend 0.00014115899830358103 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006511790001241025 time
recovery_state_mcts_prob spend 0.2566974020010093 time
state_batch spend 0.002154373003577348 time
mcts_probs_batch spend 0.005746206996263936 time
winner_batch spend 0.00026792599965119734 time
policy_value spend 0.20630073500069557 time
train_step spend 0.6025515369983623 time
policy_value spend 0.20668486000067787 time
train_step spend 0.6028954770008568 time
policy_value spend 0.20642387599946233 time
train_step spend 0.602518006999162 time
policy_value spend 0.20631845799653092 time
train_step spend 0.6141962799956673 time
policy_value spend 0.22183330600091722 time
train_step spend 0.6362083810017793 time
policy_value spend 0.21699033299955772 time
kl:0.00941,lr_multiplier:11.391,loss:4.128136157989502,entropy:5.076764106750488,explained_var_old:0.989008605,explained_var_new:0.992323458
output spend 0.00014749300316907465 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0073844580037985 time
recovery_state_mcts_prob spend 0.27195360499899834 time
state_batch spend 0.0018770649985526688 time
mcts_probs_batch spend 0.0057333000004291534 time
winner_batch spend 0.0003248310022172518 time
policy_value spend 0.2171134819946019 time
train_step spend 0.63435279699479 time
policy_value spend 0.21669501200085506 time
train_step spend 0.6349315879997448 time
policy_value spend 0.21710045699728653 time
train_step spend 0.6350452099941322 time
policy_value spend 0.21717778000311228 time
train_step spend 0.6346905649988912 time
policy_value spend 0.21685718100343365 time
train_step spend 0.6342852740053786 time
policy_value spend 0.2176482059949194 time
kl:0.00837,lr_multiplier:11.391,loss:4.168794631958008,entropy:5.04903507232666,explained_var_old:0.990415514,explained_var_new:0.993790627
output spend 0.00015016100223874673 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009000875004858244 time
recovery_state_mcts_prob spend 0.29546447200118564 time
state_batch spend 0.0020408519994816743 time
mcts_probs_batch spend 0.0066146799945272505 time
winner_batch spend 0.0003065900018555112 time
policy_value spend 0.21705345599912107 time
train_step spend 0.6351536259971908 time
policy_value spend 0.21699685900239274 time
train_step spend 0.6345784430013737 time
policy_value spend 0.22626640099770157 time
train_step spend 0.6628123490008875 time
policy_value spend 0.22685197299870197 time
train_step spend 0.6632995410036528 time
policy_value spend 0.22718935200100532 time
train_step spend 0.6632437150037731 time
policy_value spend 0.2268035669985693 time
kl:0.01212,lr_multiplier:11.391,loss:4.112734794616699,entropy:5.049502372741699,explained_var_old:0.990137398,explained_var_new:0.994855404
output spend 0.00015885999891906977 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009256359000573866 time
recovery_state_mcts_prob spend 0.2901561219987343 time
state_batch spend 0.002043138003500644 time
mcts_probs_batch spend 0.006399649995728396 time
winner_batch spend 0.00029458600329235196 time
policy_value spend 0.22706979399663396 time
train_step spend 0.648774624998623 time
policy_value spend 0.21779012499609962 time
train_step spend 0.6348662140007946 time
policy_value spend 0.218604255001992 time
train_step spend 0.6389007030011271 time
policy_value spend 0.21704384199983906 time
train_step spend 0.6347913869976765 time
policy_value spend 0.21738044100493426 time
train_step spend 0.6294401110062608 time
policy_value spend 0.2087640809986624 time
kl:0.01087,lr_multiplier:11.391,loss:4.1067399978637695,entropy:5.032978057861328,explained_var_old:0.988830447,explained_var_new:0.992649794
output spend 0.00018257099873153493 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007201843996881507 time
recovery_state_mcts_prob spend 0.2593378230012604 time
state_batch spend 0.001938364002853632 time
mcts_probs_batch spend 0.006127131993707735 time
winner_batch spend 0.0003001630029757507 time
policy_value spend 0.20860133299720474 time
train_step spend 0.6105583399985335 time
policy_value spend 0.20826070300245192 time
train_step spend 0.6096444419963518 time
policy_value spend 0.20894077800039668 time
train_step spend 0.610414002003381 time
policy_value spend 0.20847927199793048 time
train_step spend 0.6108858010047697 time
policy_value spend 0.20863871799519984 time
train_step spend 0.6095305010021548 time
policy_value spend 0.20872580300056143 time
kl:0.00867,lr_multiplier:11.391,loss:4.1322832107543945,entropy:5.0812835693359375,explained_var_old:0.991252840,explained_var_new:0.994064867
output spend 0.00015293299657059833 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007287223001185339 time
recovery_state_mcts_prob spend 0.25515705900033936 time
state_batch spend 0.0017625420005060732 time
mcts_probs_batch spend 0.005928897000558209 time
winner_batch spend 0.0003151689961669035 time
policy_value spend 0.20869909199973335 time
train_step spend 0.610354569995252 time
policy_value spend 0.20859358500456437 time
train_step spend 0.623512756996206 time
policy_value spend 0.21188236200396204 time
train_step spend 0.6080360389969428 time
policy_value spend 0.207733253002516 time
train_step spend 0.6087311689989292 time
policy_value spend 0.2076942540006712 time
train_step spend 0.6089466129997163 time
policy_value spend 0.20767450099810958 time
kl:0.01668,lr_multiplier:11.391,loss:4.093056678771973,entropy:5.011236667633057,explained_var_old:0.995389462,explained_var_new:0.996401191
output spend 0.00013835099525749683 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007931002000987064 time
recovery_state_mcts_prob spend 0.28774274900206365 time
state_batch spend 0.00206100799550768 time
mcts_probs_batch spend 0.006133872004284058 time
winner_batch spend 0.00027225999656366184 time
policy_value spend 0.21086616100365063 time
train_step spend 0.6414666279961239 time
policy_value spend 0.22234402000322007 time
train_step spend 0.6126969800025108 time
policy_value spend 0.20910127599927364 time
train_step spend 0.6142153890032205 time
policy_value spend 0.21686321599554503 time
train_step spend 0.6347238910020678 time
policy_value spend 0.2177454190023127 time
train_step spend 0.6359276619987213 time
policy_value spend 0.2171527030004654 time
kl:0.01218,lr_multiplier:11.391,loss:4.117827892303467,entropy:5.030102729797363,explained_var_old:0.990996659,explained_var_new:0.991961241
output spend 0.00016334799875039607 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007166700001107529 time
recovery_state_mcts_prob spend 0.27093677800439764 time
state_batch spend 0.0018759109952952713 time
mcts_probs_batch spend 0.006446166000387166 time
winner_batch spend 0.0003106720032519661 time
policy_value spend 0.21732083799724933 time
train_step spend 0.6350691350016859 time
policy_value spend 0.21793964500102447 time
train_step spend 0.6342796169992653 time
policy_value spend 0.21720387200184632 time
train_step spend 0.6340825610022875 time
policy_value spend 0.2177299960021628 time
train_step spend 0.6363020470016636 time
policy_value spend 0.21775665099994512 time
train_step spend 0.6359914150016266 time
policy_value spend 0.21709806899889372 time
kl:0.00781,lr_multiplier:11.391,loss:4.094314098358154,entropy:5.0584492683410645,explained_var_old:0.998633564,explained_var_new:0.999493957
output spend 0.00014580599963665009 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007652690997929312 time
recovery_state_mcts_prob spend 0.2846714850020362 time
state_batch spend 0.0022050260013202205 time
mcts_probs_batch spend 0.006962553998164367 time
winner_batch spend 0.0003044010009034537 time
policy_value spend 0.21669191999535542 time
train_step spend 0.634222045999195 time
policy_value spend 0.21890532899851678 time
train_step spend 0.6349782790057361 time
policy_value spend 0.21972711899434216 time
train_step spend 0.6663778349975473 time
policy_value spend 0.22788726299768314 time
train_step spend 0.667720407996967 time
policy_value spend 0.22747744899970712 time
train_step spend 0.6669112520030467 time
policy_value spend 0.2278067520019249 time
kl:0.01003,lr_multiplier:11.391,loss:4.0262956619262695,entropy:5.001201152801514,explained_var_old:0.995833695,explained_var_new:0.996122539
output spend 0.00016109200078062713 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007885860999522265 time
recovery_state_mcts_prob spend 0.2764035260042874 time
state_batch spend 0.0019168470025761053 time
mcts_probs_batch spend 0.006368953996570781 time
winner_batch spend 0.0003075639979215339 time
policy_value spend 0.22837950700341025 time
train_step spend 0.6711490710004 time
policy_value spend 0.2279656070022611 time
train_step spend 0.6536001750064315 time
policy_value spend 0.21667428099317476 time
train_step spend 0.6358633269992424 time
policy_value spend 0.21762870300153736 time
train_step spend 0.6352864329965087 time
policy_value spend 0.2175242410012288 time
train_step spend 0.6358680999983335 time
policy_value spend 0.21060335800575558 time
kl:0.00783,lr_multiplier:11.391,loss:4.1113481521606445,entropy:5.053106784820557,explained_var_old:0.999495268,explained_var_new:0.999626219
output spend 0.00023104900174075738 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007109324003977235 time
recovery_state_mcts_prob spend 0.2636788689997047 time
state_batch spend 0.0018058380010188557 time
mcts_probs_batch spend 0.004646702996979002 time
winner_batch spend 0.00028719499823637307 time
policy_value spend 0.20943589100352256 time
train_step spend 0.6160777900004177 time
policy_value spend 0.209728346002521 time
train_step spend 0.6155944989950513 time
policy_value spend 0.20996740300324745 time
train_step spend 0.6167436440009624 time
policy_value spend 0.2103397240061895 time
train_step spend 0.6157132459993591 time
policy_value spend 0.21081283999956213 time
train_step spend 0.6155868909991113 time
policy_value spend 0.2109801780025009 time
kl:0.01364,lr_multiplier:11.391,loss:4.156880855560303,entropy:5.089377403259277,explained_var_old:0.995970488,explained_var_new:0.996266067
output spend 0.00015222799993352965 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0069422050000866875 time
recovery_state_mcts_prob spend 0.2640742989970022 time
state_batch spend 0.002050322997092735 time
mcts_probs_batch spend 0.006163799000205472 time
winner_batch spend 0.0004001220004283823 time
policy_value spend 0.21087184300267836 time
train_step spend 0.6153652020002482 time
policy_value spend 0.20985797900357284 time
train_step spend 0.6152275140048005 time
policy_value spend 0.208773309001117 time
train_step spend 0.6029494770045858 time
policy_value spend 0.20798055399791338 time
train_step spend 0.6041351789972396 time
policy_value spend 0.20568606899905717 time
train_step spend 0.6026529699956882 time
policy_value spend 0.20552864000637783 time
kl:0.00824,lr_multiplier:11.391,loss:4.127101421356201,entropy:5.062265872955322,explained_var_old:0.988263726,explained_var_new:0.991197228
output spend 0.0001512119997642003 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006692235001537483 time
recovery_state_mcts_prob spend 0.2522749100025976 time
state_batch spend 0.0017359830017085187 time
mcts_probs_batch spend 0.004382492996228393 time
winner_batch spend 0.00028178500360809267 time
policy_value spend 0.20596360999479657 time
train_step spend 0.6016973209989374 time
policy_value spend 0.20595774999674177 time
train_step spend 0.6025949559989385 time
policy_value spend 0.2061207469960209 time
train_step spend 0.6024068089973298 time
policy_value spend 0.206419937996543 time
train_step spend 0.6018292630033102 time
policy_value spend 0.20585235500038834 time
train_step spend 0.609485681001388 time
policy_value spend 0.21740613699512323 time
kl:0.00930,lr_multiplier:11.391,loss:4.091005802154541,entropy:5.020576000213623,explained_var_old:0.992048562,explained_var_new:0.992874444
output spend 0.00016007900558179244 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007372339001449291 time
recovery_state_mcts_prob spend 0.2735596459970111 time
state_batch spend 0.0019883760032826103 time
mcts_probs_batch spend 0.004426934996445198 time
winner_batch spend 0.00028645500424318016 time
policy_value spend 0.21706405499571702 time
train_step spend 0.6371364220030955 time
policy_value spend 0.2196050880011171 time
train_step spend 0.637070627999492 time
policy_value spend 0.21892033200128935 time
train_step spend 0.6435609699983615 time
policy_value spend 0.21865624299971387 time
train_step spend 0.6382067930026096 time
policy_value spend 0.21769099600351183 time
train_step spend 0.6374856519978493 time
policy_value spend 0.21821167100279126 time
kl:0.01682,lr_multiplier:11.391,loss:4.129327774047852,entropy:5.072605133056641,explained_var_old:0.998061121,explained_var_new:0.999479890
output spend 0.00014846099657006562 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007606530001794454 time
recovery_state_mcts_prob spend 0.282445219992951 time
state_batch spend 0.002104043000144884 time
mcts_probs_batch spend 0.004751612999825738 time
winner_batch spend 0.00029759000608464703 time
policy_value spend 0.21669423699495383 time
train_step spend 0.6370164229956572 time
policy_value spend 0.21785938199900556 time
train_step spend 0.637794356996892 time
policy_value spend 0.22018485500302631 time
train_step spend 0.6610844489987358 time
policy_value spend 0.22998405999533134 time
train_step spend 0.672090879001189 time
policy_value spend 0.22940085600566817 time
train_step spend 0.6901596850002534 time
policy_value spend 0.24427407800249057 time
kl:0.01662,lr_multiplier:11.391,loss:4.121729373931885,entropy:5.015097618103027,explained_var_old:0.978439450,explained_var_new:0.987912416
output spend 0.0001602850024937652 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007999406996532343 time
recovery_state_mcts_prob spend 0.2908471289993031 time
state_batch spend 0.0021451150023494847 time
mcts_probs_batch spend 0.004989929999283049 time
winner_batch spend 0.00031302600109484047 time
policy_value spend 0.229926677995536 time
train_step spend 0.642026869005349 time
policy_value spend 0.216721005999716 time
train_step spend 0.6355579709997983 time
policy_value spend 0.21651581799960695 time
train_step spend 0.6345997360040201 time
policy_value spend 0.21683446499810088 time
train_step spend 0.6353053380007623 time
policy_value spend 0.21627037999860477 time
train_step spend 0.635669258001144 time
policy_value spend 0.21716452100372408 time
kl:0.02214,lr_multiplier:11.391,loss:4.1419525146484375,entropy:5.060691833496094,explained_var_old:0.992159784,explained_var_new:0.998796165
output spend 0.00017522399866720662 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006822866998845711 time
recovery_state_mcts_prob spend 0.25389325300056953 time
state_batch spend 0.0017662480022409 time
mcts_probs_batch spend 0.0060186269984114915 time
winner_batch spend 0.00027738600329030305 time
policy_value spend 0.20670208799856482 time
train_step spend 0.602422251002281 time
policy_value spend 0.20746415299799992 time
train_step spend 0.6033824350015493 time
policy_value spend 0.20555988299747696 time
train_step spend 0.6031894080006168 time
policy_value spend 0.2058291079956689 time
train_step spend 0.6033812340028817 time
policy_value spend 0.20632141600071918 time
train_step spend 0.6032692809967557 time
policy_value spend 0.20798082200053614 time
kl:0.03726,lr_multiplier:11.391,loss:4.123859882354736,entropy:5.091189384460449,explained_var_old:0.996953368,explained_var_new:0.999616265
output spend 0.00015537400031462312 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006593046004127245 time
recovery_state_mcts_prob spend 0.269426986000326 time
state_batch spend 0.0018772979965433478 time
mcts_probs_batch spend 0.007282743004907388 time
winner_batch spend 0.0002830569937941618 time
policy_value spend 0.20742673700442538 time
train_step spend 0.6040897740022046 time
policy_value spend 0.20700333699642215 time
train_step spend 0.6166810780050582 time
policy_value spend 0.21794615399994655 time
train_step spend 0.6345000619985512 time
policy_value spend 0.21682700000383193 time
train_step spend 0.6337386470040656 time
policy_value spend 0.21664197799691465 time
train_step spend 0.6336123380024219 time
policy_value spend 0.21690120899438625 time
kl:0.04715,lr_multiplier:7.594,loss:4.15358304977417,entropy:5.071678161621094,explained_var_old:0.995825112,explained_var_new:0.995929480
output spend 0.0001800379977794364 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008110627000860404 time
recovery_state_mcts_prob spend 0.2682833139988361 time
state_batch spend 0.0018355220017838292 time
mcts_probs_batch spend 0.006097077995946165 time
winner_batch spend 0.00029018700297456235 time
policy_value spend 0.21694887399644358 time
train_step spend 0.6372587780060712 time
policy_value spend 0.2171744809966185 time
train_step spend 0.6358965770050418 time
policy_value spend 0.21629879099782556 time
train_step spend 0.6337770760001149 time
policy_value spend 0.2165548030025093 time
train_step spend 0.6338004539938993 time
policy_value spend 0.21668323400081135 time
train_step spend 0.6328478479990736 time
policy_value spend 0.21607826599938562 time
kl:0.03395,lr_multiplier:7.594,loss:4.102813720703125,entropy:5.003081321716309,explained_var_old:0.991055667,explained_var_new:0.992006838
output spend 0.00014615500549552962 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006927957998414058 time
recovery_state_mcts_prob spend 0.2857169460039586 time
state_batch spend 0.00187743800051976 time
mcts_probs_batch spend 0.006134757997642737 time
winner_batch spend 0.0002871730030165054 time
policy_value spend 0.21577972499653697 time
train_step spend 0.630440164997708 time
policy_value spend 0.21886657700088108 time
train_step spend 0.6314149419995374 time
policy_value spend 0.2157045760031906 time
train_step spend 0.631639377999818 time
policy_value spend 0.2155558550002752 time
train_step spend 0.6319612779989257 time
policy_value spend 0.21939993699925253 time
train_step spend 0.6388694530032808 time
policy_value spend 0.2160386629984714 time
kl:0.01727,lr_multiplier:7.594,loss:4.159744739532471,entropy:5.101406574249268,explained_var_old:0.995180190,explained_var_new:0.995844781
output spend 0.00014695400022901595 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00719625400233781 time
recovery_state_mcts_prob spend 0.2727548159964499 time
state_batch spend 0.0018970790042658336 time
mcts_probs_batch spend 0.006247662997338921 time
winner_batch spend 0.00028147500415798277 time
policy_value spend 0.21752235199528513 time
train_step spend 0.6356098760006716 time
policy_value spend 0.216616112003976 time
train_step spend 0.6311844520023442 time
policy_value spend 0.21589871500327718 time
train_step spend 0.633000693997019 time
policy_value spend 0.21659947500302223 time
train_step spend 0.6340305670019006 time
policy_value spend 0.21670598600030644 time
train_step spend 0.6340056140033994 time
policy_value spend 0.21656328199605923 time
kl:0.01420,lr_multiplier:7.594,loss:4.102630138397217,entropy:5.040610313415527,explained_var_old:0.992119491,explained_var_new:0.995361269
output spend 0.00015692499437136576 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007186543996795081 time
recovery_state_mcts_prob spend 0.2694465270033106 time
state_batch spend 0.0018352179977227934 time
mcts_probs_batch spend 0.01280308000423247 time
winner_batch spend 0.0002884299974539317 time
policy_value spend 0.21930261699890252 time
train_step spend 0.6346449510019738 time
policy_value spend 0.21703585700015537 time
train_step spend 0.632749149997835 time
policy_value spend 0.2168965590026346 time
train_step spend 0.633018214997719 time
policy_value spend 0.21653986800083658 time
train_step spend 0.6337356149961124 time
policy_value spend 0.21619693700631615 time
train_step spend 0.6344211920004454 time
policy_value spend 0.21615464099886594 time
kl:0.02049,lr_multiplier:7.594,loss:4.103186130523682,entropy:5.044571876525879,explained_var_old:0.982852936,explained_var_new:0.986106634
output spend 0.00014600199938286096 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00877647299785167 time
recovery_state_mcts_prob spend 0.276861224003369 time
state_batch spend 0.002170285995816812 time
mcts_probs_batch spend 0.006471106004028115 time
winner_batch spend 0.0002881149994209409 time
policy_value spend 0.21659339899633778 time
train_step spend 0.6335213589991326 time
policy_value spend 0.21561965799628524 time
train_step spend 0.6318245009970269 time
policy_value spend 0.2159975820031832 time
train_step spend 0.6316817400002037 time
policy_value spend 0.2171311929996591 time
train_step spend 0.6320210529956967 time
policy_value spend 0.21592644700285746 time
train_step spend 0.632353670996963 time
policy_value spend 0.21576393400027882 time
kl:0.01338,lr_multiplier:7.594,loss:4.097289085388184,entropy:5.034100532531738,explained_var_old:0.987818778,explained_var_new:0.989595830
output spend 0.00017259200103580952 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0073158779996447265 time
recovery_state_mcts_prob spend 0.2683798120051506 time
state_batch spend 0.0019308789997012354 time
mcts_probs_batch spend 0.012176538999483455 time
winner_batch spend 0.0002873209959943779 time
policy_value spend 0.22844602500117617 time
train_step spend 0.6514672039993457 time
policy_value spend 0.23236747900227783 time
train_step spend 0.6481093749971478 time
policy_value spend 0.21665305399801582 time
train_step spend 0.6315112750016851 time
policy_value spend 0.2149271329981275 time
train_step spend 0.630290988003253 time
policy_value spend 0.21582754499831935 time
train_step spend 0.6297706660043332 time
policy_value spend 0.21489950199611485 time
kl:0.00953,lr_multiplier:11.391,loss:4.121214866638184,entropy:5.0200347900390625,explained_var_old:0.977613449,explained_var_new:0.982912004
output spend 0.00015124199853744358 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006921113999851514 time
recovery_state_mcts_prob spend 0.2695520220004255 time
state_batch spend 0.0018111020035576075 time
mcts_probs_batch spend 0.00533466599881649 time
winner_batch spend 0.0002820730005623773 time
policy_value spend 0.2150224889992387 time
train_step spend 0.6302191540016793 time
policy_value spend 0.21648376399389235 time
train_step spend 0.6301494439976523 time
policy_value spend 0.21517140300420579 time
train_step spend 0.6303813929989701 time
policy_value spend 0.21541926899953978 time
train_step spend 0.6300215029987157 time
policy_value spend 0.2154916180006694 time
train_step spend 0.6302288129954832 time
policy_value spend 0.21617045900347875 time
kl:0.00765,lr_multiplier:11.391,loss:4.065299034118652,entropy:5.009734630584717,explained_var_old:0.985757411,explained_var_new:0.988585472
output spend 0.000298865998047404 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00751911400584504 time
recovery_state_mcts_prob spend 0.2808111799968174 time
state_batch spend 0.001909578000777401 time
mcts_probs_batch spend 0.006936602003406733 time
winner_batch spend 0.0003675199986901134 time
policy_value spend 0.21541115699801594 time
train_step spend 0.629749826999614 time
policy_value spend 0.21660979099397082 time
train_step spend 0.6300984160043299 time
policy_value spend 0.21525529999780701 time
train_step spend 0.6308477130005485 time
policy_value spend 0.2154860099981306 time
train_step spend 0.6315393230033806 time
policy_value spend 0.21554235499934293 time
train_step spend 0.6302510850000544 time
policy_value spend 0.21507237399782753 time
kl:0.01119,lr_multiplier:11.391,loss:4.110415458679199,entropy:5.037881851196289,explained_var_old:0.988649011,explained_var_new:0.991560698
output spend 0.00014580500283045694 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008415698001044802 time
recovery_state_mcts_prob spend 0.2648961929953657 time
state_batch spend 0.0019135370021103881 time
mcts_probs_batch spend 0.006396028999006376 time
winner_batch spend 0.0003122590060229413 time
policy_value spend 0.21493255499808583 time
train_step spend 0.6294715149997501 time
policy_value spend 0.21593095099524362 time
train_step spend 0.6312147689968697 time
policy_value spend 0.21510437600227306 time
train_step spend 0.6301389360014582 time
policy_value spend 0.2153674270011834 time
train_step spend 0.6304052100022091 time
policy_value spend 0.21564836899779039 time
train_step spend 0.6303715460016974 time
policy_value spend 0.21516847699967911 time
kl:0.01226,lr_multiplier:11.391,loss:4.106222152709961,entropy:5.011289596557617,explained_var_old:0.988628209,explained_var_new:0.992677093
output spend 0.00014220499724615365 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006942435997189023 time
recovery_state_mcts_prob spend 0.27346431300247787 time
state_batch spend 0.0018593429995235056 time
mcts_probs_batch spend 0.006565531999513041 time
winner_batch spend 0.0002955469972221181 time
policy_value spend 0.215344891003042 time
train_step spend 0.630389981000917 time
policy_value spend 0.21638902199629229 time
train_step spend 0.6311726610001642 time
policy_value spend 0.21534701399650658 time
train_step spend 0.6303787050055689 time
policy_value spend 0.21606620499369456 time
train_step spend 0.6305733720000717 time
policy_value spend 0.2153157370048575 time
train_step spend 0.6313602779991925 time
policy_value spend 0.2163853449965245 time
kl:0.00833,lr_multiplier:11.391,loss:4.131387710571289,entropy:4.9989542961120605,explained_var_old:0.994181216,explained_var_new:0.995466709
output spend 0.0001644869989831932 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007834185998945031 time
recovery_state_mcts_prob spend 0.2668566930005909 time
state_batch spend 0.0019803350005531684 time
mcts_probs_batch spend 0.006444626997108571 time
winner_batch spend 0.0002823920003720559 time
policy_value spend 0.21595056600199314 time
train_step spend 0.6310408459976315 time
policy_value spend 0.21639311400213046 time
train_step spend 0.6318956360046286 time
policy_value spend 0.21502011999837123 time
train_step spend 0.6308338859962532 time
policy_value spend 0.2148023350018775 time
train_step spend 0.6307922839987441 time
policy_value spend 0.2182618739971076 time
train_step spend 0.6373447259975364 time
policy_value spend 0.21641216299758526 time
kl:0.01038,lr_multiplier:11.391,loss:4.161054611206055,entropy:5.099761486053467,explained_var_old:0.994129062,explained_var_new:0.995887399
output spend 0.00016162900283234194 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007110275997547433 time
recovery_state_mcts_prob spend 0.27289602200471563 time
state_batch spend 0.0020131999990553595 time
mcts_probs_batch spend 0.0064226879985653795 time
winner_batch spend 0.00031340699933934957 time
policy_value spend 0.21638733400322963 time
train_step spend 0.630325936996087 time
policy_value spend 0.21718294500169577 time
train_step spend 0.6306244979932671 time
policy_value spend 0.21609697100211633 time
train_step spend 0.6294322440007818 time
policy_value spend 0.21509850199799985 time
train_step spend 0.6284876839999924 time
policy_value spend 0.21587710299354512 time
train_step spend 0.6296921440007281 time
policy_value spend 0.21493592699698638 time
kl:0.01033,lr_multiplier:11.391,loss:4.132198810577393,entropy:5.114757061004639,explained_var_old:0.988498151,explained_var_new:0.990456760
output spend 0.000145883001096081 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007808738999301568 time
recovery_state_mcts_prob spend 0.2726794550035265 time
state_batch spend 0.0022629029990639538 time
mcts_probs_batch spend 0.006255366999539547 time
winner_batch spend 0.0002839299995684996 time
policy_value spend 0.21567076599603752 time
train_step spend 0.629938914993545 time
policy_value spend 0.21509407499979716 time
train_step spend 0.6290474699999322 time
policy_value spend 0.21925855400331784 time
train_step spend 0.6302411900032894 time
policy_value spend 0.2148140709978179 time
train_step spend 0.6297008100009407 time
policy_value spend 0.21438272300292738 time
train_step spend 0.6295513110017055 time
policy_value spend 0.2159358400022029 time
kl:0.01080,lr_multiplier:11.391,loss:4.084437370300293,entropy:5.006775856018066,explained_var_old:0.993018389,explained_var_new:0.995796621
output spend 0.00014459199883276597 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007637071001227014 time
recovery_state_mcts_prob spend 0.2672723939977004 time
state_batch spend 0.0018580140022095293 time
mcts_probs_batch spend 0.0047415049994015135 time
winner_batch spend 0.00029625100432895124 time
policy_value spend 0.2141817509982502 time
train_step spend 0.6298053349964903 time
policy_value spend 0.2157463160037878 time
train_step spend 0.6302110250035184 time
policy_value spend 0.2160609470010968 time
train_step spend 0.6292767990016728 time
policy_value spend 0.2147999590015388 time
train_step spend 0.6303608779999195 time
policy_value spend 0.21579432200087467 time
train_step spend 0.6300180460020783 time
policy_value spend 0.2151708259989391 time
kl:0.01001,lr_multiplier:11.391,loss:4.086366653442383,entropy:5.0532941818237305,explained_var_old:0.999382317,explained_var_new:0.999525011
output spend 0.0002669829991646111 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007504023997171316 time
recovery_state_mcts_prob spend 0.2882629759988049 time
state_batch spend 0.0018497760029276833 time
mcts_probs_batch spend 0.006472360997577198 time
winner_batch spend 0.00028754100640071556 time
policy_value spend 0.22873466099554207 time
train_step spend 0.6483879070001421 time
policy_value spend 0.21658475099684438 time
train_step spend 0.6308217079931637 time
policy_value spend 0.21497177600394934 time
train_step spend 0.629642061998311 time
policy_value spend 0.2148658299993258 time
train_step spend 0.6312986569973873 time
policy_value spend 0.21548925100069027 time
train_step spend 0.6294597720043384 time
policy_value spend 0.2146455599940964 time
kl:0.01242,lr_multiplier:11.391,loss:4.101667404174805,entropy:5.047242164611816,explained_var_old:0.992183685,explained_var_new:0.995550275
output spend 0.00014767699758522213 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008603673006291501 time
recovery_state_mcts_prob spend 0.2645135950006079 time
state_batch spend 0.0019293199948151596 time
mcts_probs_batch spend 0.006015555001795292 time
winner_batch spend 0.00028216400096425787 time
policy_value spend 0.2162608500002534 time
train_step spend 0.6308354509965284 time
policy_value spend 0.21444966100534657 time
train_step spend 0.6304382730013458 time
policy_value spend 0.21513488000346115 time
train_step spend 0.6300016699970001 time
policy_value spend 0.2151163529997575 time
train_step spend 0.6306663599971216 time
policy_value spend 0.21497940300469054 time
train_step spend 0.6295795039986842 time
policy_value spend 0.21571857100207126 time
kl:0.01046,lr_multiplier:11.391,loss:4.092926979064941,entropy:5.051417350769043,explained_var_old:0.994263768,explained_var_new:0.998681605
output spend 0.0002221180038759485 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009338114999991376 time
recovery_state_mcts_prob spend 0.2733585800015135 time
state_batch spend 0.001923878000525292 time
mcts_probs_batch spend 0.0048036640000646 time
winner_batch spend 0.000297155995212961 time
policy_value spend 0.21518870300496928 time
train_step spend 0.6318676649971167 time
policy_value spend 0.2152208019979298 time
train_step spend 0.6310954049986321 time
policy_value spend 0.21565520700096386 time
train_step spend 0.6307704479986569 time
policy_value spend 0.215921116003301 time
train_step spend 0.6311652599979425 time
policy_value spend 0.2157335960000637 time
train_step spend 0.6312180810054997 time
policy_value spend 0.21588004899967927 time
kl:0.00735,lr_multiplier:11.391,loss:4.096484184265137,entropy:5.067581653594971,explained_var_old:0.987896085,explained_var_new:0.988465548
output spend 0.00014575900422642007 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007952908999868669 time
recovery_state_mcts_prob spend 0.2707122369974968 time
state_batch spend 0.0023128610046114773 time
mcts_probs_batch spend 0.006531230996188242 time
winner_batch spend 0.0002862580004148185 time
policy_value spend 0.2159185280033853 time
train_step spend 0.631510667000839 time
policy_value spend 0.2157670539963874 time
train_step spend 0.6314828140020836 time
policy_value spend 0.21526863500184845 time
train_step spend 0.6306444630026817 time
policy_value spend 0.21553767300065374 time
train_step spend 0.6303767959980178 time
policy_value spend 0.21465573200111976 time
train_step spend 0.6290830989964888 time
policy_value spend 0.21568506000039633 time
kl:0.02017,lr_multiplier:11.391,loss:4.128703594207764,entropy:5.038301467895508,explained_var_old:0.990813732,explained_var_new:0.992946148
output spend 0.0001451819989597425 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.012063738002325408 time
recovery_state_mcts_prob spend 0.28630412900383817 time
state_batch spend 0.002168830993468873 time
mcts_probs_batch spend 0.004829948004044127 time
winner_batch spend 0.0003138739994028583 time
policy_value spend 0.2136142210001708 time
train_step spend 0.629793027001142 time
policy_value spend 0.2145739740008139 time
train_step spend 0.6296756439987803 time
policy_value spend 0.21541327100567287 time
train_step spend 0.6293935290013906 time
policy_value spend 0.2146093870032928 time
train_step spend 0.6300779550001607 time
policy_value spend 0.21441729299840517 time
train_step spend 0.6303958800053806 time
policy_value spend 0.21508695999364136 time
kl:0.01345,lr_multiplier:11.391,loss:4.023862361907959,entropy:4.98985481262207,explained_var_old:0.986964047,explained_var_new:0.991442859
output spend 0.00020329699327703565 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011153316998388618 time
recovery_state_mcts_prob spend 0.2702284640035941 time
state_batch spend 0.0018563560006441548 time
mcts_probs_batch spend 0.006220235998625867 time
winner_batch spend 0.0002902269989135675 time
policy_value spend 0.21602945400081808 time
train_step spend 0.6290779650007607 time
policy_value spend 0.21635417200013762 time
train_step spend 0.6302817629984929 time
policy_value spend 0.21548861300107092 time
train_step spend 0.6294656430036412 time
policy_value spend 0.21604338199540507 time
train_step spend 0.6295906260056654 time
policy_value spend 0.2155610119953053 time
train_step spend 0.6290822669980116 time
policy_value spend 0.21507125200150767 time
kl:0.02632,lr_multiplier:11.391,loss:4.117250919342041,entropy:4.9716267585754395,explained_var_old:0.977923334,explained_var_new:0.984596610
output spend 0.0001476580000598915 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007118881003407296 time
recovery_state_mcts_prob spend 0.274787850001303 time
state_batch spend 0.0020930690006935038 time
mcts_probs_batch spend 0.006114746000093874 time
winner_batch spend 0.00028393099637469277 time
policy_value spend 0.21533527700375998 time
train_step spend 0.6298373879981227 time
policy_value spend 0.21615579100034665 time
train_step spend 0.6291952790052164 time
policy_value spend 0.21552993999648606 time
train_step spend 0.6297633279973525 time
policy_value spend 0.21543202100292547 time
train_step spend 0.630545316998905 time
policy_value spend 0.21537464300490683 time
train_step spend 0.6302368350006873 time
policy_value spend 0.21569900199392578 time
kl:0.01885,lr_multiplier:11.391,loss:4.112188339233398,entropy:5.041860580444336,explained_var_old:0.984167874,explained_var_new:0.992523491
output spend 0.00014577499678125605 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007777131999318954 time
recovery_state_mcts_prob spend 0.2707740960031515 time
state_batch spend 0.0018520329977036454 time
mcts_probs_batch spend 0.005412749000242911 time
winner_batch spend 0.0002826689960784279 time
policy_value spend 0.2180497950030258 time
train_step spend 0.632068459999573 time
policy_value spend 0.2149289500011946 time
train_step spend 0.6288142990015331 time
policy_value spend 0.21654910600045696 time
train_step spend 0.6308559820026858 time
policy_value spend 0.2164414700018824 time
train_step spend 0.6298614810002618 time
policy_value spend 0.21537509599875193 time
train_step spend 0.6299216999977943 time
policy_value spend 0.2152710250011296 time
kl:0.02120,lr_multiplier:11.391,loss:4.071953773498535,entropy:4.99690055847168,explained_var_old:0.989100039,explained_var_new:0.994637132
output spend 0.00015402299322886392 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007745627997792326 time
recovery_state_mcts_prob spend 0.266276474998449 time
state_batch spend 0.0021344039996620268 time
mcts_probs_batch spend 0.006407216002116911 time
winner_batch spend 0.00028497000312199816 time
policy_value spend 0.21612314300000435 time
train_step spend 0.6310733160062227 time
policy_value spend 0.21548985999834258 time
train_step spend 0.6315852569969138 time
policy_value spend 0.21574879800027702 time
train_step spend 0.6485578219944728 time
policy_value spend 0.2298430150040076 time
train_step spend 0.658121073996881 time
policy_value spend 0.2171153899980709 time
train_step spend 0.6330699769969215 time
policy_value spend 0.2157307250017766 time
kl:0.01211,lr_multiplier:11.391,loss:4.046104907989502,entropy:5.013261795043945,explained_var_old:0.991067886,explained_var_new:0.994877696
output spend 0.00014759800251340494 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009454576000280213 time
recovery_state_mcts_prob spend 0.292555573003483 time
state_batch spend 0.001911678999022115 time
mcts_probs_batch spend 0.006609308999031782 time
winner_batch spend 0.00030006899760337546 time
policy_value spend 0.21600853700510925 time
train_step spend 0.6314768910015118 time
policy_value spend 0.21655988800193882 time
train_step spend 0.6302214990064385 time
policy_value spend 0.21565922399895499 time
train_step spend 0.6314657850016374 time
policy_value spend 0.21518999999534572 time
train_step spend 0.6291161319968523 time
policy_value spend 0.21500458700029412 time
train_step spend 0.6295338869967964 time
policy_value spend 0.21505811299721245 time
kl:0.00952,lr_multiplier:11.391,loss:4.076381206512451,entropy:4.9912261962890625,explained_var_old:0.990748227,explained_var_new:0.992344797
output spend 0.00014552799984812737 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00695726500271121 time
recovery_state_mcts_prob spend 0.2653580710029928 time
state_batch spend 0.0018630119957379065 time
mcts_probs_batch spend 0.00575363400275819 time
winner_batch spend 0.00029637699481099844 time
policy_value spend 0.2139321690046927 time
train_step spend 0.6299771630001487 time
policy_value spend 0.2189885769985267 time
train_step spend 0.6297253649972845 time
policy_value spend 0.21486763899883954 time
train_step spend 0.6291799129976425 time
policy_value spend 0.21462373100075638 time
train_step spend 0.6294910889992025 time
policy_value spend 0.2150521940056933 time
train_step spend 0.6299968099992839 time
policy_value spend 0.2155797489976976 time
kl:0.01417,lr_multiplier:11.391,loss:4.142973899841309,entropy:5.046909332275391,explained_var_old:0.982783139,explained_var_new:0.987289786
output spend 0.00014330499834613875 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007410911006445531 time
recovery_state_mcts_prob spend 0.27172994799911976 time
state_batch spend 0.0018499029974918813 time
mcts_probs_batch spend 0.00670000600075582 time
winner_batch spend 0.0002953930015792139 time
policy_value spend 0.21573883699602447 time
train_step spend 0.6299617609984125 time
policy_value spend 0.2155705620025401 time
train_step spend 0.630762439002865 time
policy_value spend 0.2148198599970783 time
train_step spend 0.6304877889997442 time
policy_value spend 0.21503144500456983 time
train_step spend 0.6301892190022045 time
policy_value spend 0.21612073500000406 time
train_step spend 0.6305811159982113 time
policy_value spend 0.21554084699891973 time
kl:0.01007,lr_multiplier:11.391,loss:4.063361644744873,entropy:4.9637675285339355,explained_var_old:0.987935722,explained_var_new:0.992955267
output spend 0.00014826699771219864 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008743222999328282 time
recovery_state_mcts_prob spend 0.2703992919996381 time
state_batch spend 0.002117346004524734 time
mcts_probs_batch spend 0.0060685439966619015 time
winner_batch spend 0.0002862620021915063 time
policy_value spend 0.21526686399738537 time
train_step spend 0.6308817950048251 time
policy_value spend 0.21498431499639992 time
train_step spend 0.6300751410017256 time
policy_value spend 0.21495749599853298 time
train_step spend 0.629418087999511 time
policy_value spend 0.21497277599701192 time
train_step spend 0.6317765229978249 time
policy_value spend 0.21542893500009086 time
train_step spend 0.6307266080038971 time
policy_value spend 0.2163435339971329 time
kl:0.01252,lr_multiplier:11.391,loss:4.081253528594971,entropy:4.998303413391113,explained_var_old:0.990349174,explained_var_new:0.990592718
output spend 0.00014497100346488878 time
已保存最新模型
current self-play batch: 900
load data begin
已加载数据
step i 372: 
random.sample spend 0.007501172003685497 time
recovery_state_mcts_prob spend 0.27064770399738336 time
state_batch spend 0.0018823080026777461 time
mcts_probs_batch spend 0.006298658998275641 time
winner_batch spend 0.0002899980026995763 time
policy_value spend 0.21696131600037916 time
train_step spend 0.6662435920006828 time
policy_value spend 0.22081419399910374 time
train_step spend 0.6338628550001886 time
policy_value spend 0.2155016449978575 time
train_step spend 0.6291690030047903 time
policy_value spend 0.21529614199971547 time
train_step spend 0.6299756850057747 time
policy_value spend 0.21572972299327375 time
train_step spend 0.630503428998054 time
policy_value spend 0.21479001000261633 time
kl:0.01231,lr_multiplier:11.391,loss:4.135806560516357,entropy:5.01294469833374,explained_var_old:0.989296377,explained_var_new:0.993764102
output spend 0.00020668200158979744 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00722319699707441 time
recovery_state_mcts_prob spend 0.27011590100300964 time
state_batch spend 0.0017718540038913488 time
mcts_probs_batch spend 0.0045985279939486645 time
winner_batch spend 0.00029425200045807287 time
policy_value spend 0.21414788399852114 time
train_step spend 0.6316017099961755 time
policy_value spend 0.21486102500057314 time
train_step spend 0.6317193899958511 time
policy_value spend 0.21563884100032737 time
train_step spend 0.6305396759998985 time
policy_value spend 0.21525558999564964 time
train_step spend 0.6318232650010032 time
policy_value spend 0.21519396799703827 time
train_step spend 0.6315112599986605 time
policy_value spend 0.2152248279962805 time
kl:0.03058,lr_multiplier:11.391,loss:4.116952896118164,entropy:5.01307487487793,explained_var_old:0.985786438,explained_var_new:0.995241642
output spend 0.00014976999955251813 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007776273996569216 time
recovery_state_mcts_prob spend 0.27579266000248026 time
state_batch spend 0.0018935150001198053 time
mcts_probs_batch spend 0.006347126996843144 time
winner_batch spend 0.0002904560024035163 time
policy_value spend 0.21601300899783382 time
train_step spend 0.630621162999887 time
policy_value spend 0.21612293399812188 time
train_step spend 0.6326868219985045 time
policy_value spend 0.2155365470025572 time
train_step spend 0.6303628000023309 time
policy_value spend 0.2146549960016273 time
train_step spend 0.6304541310018976 time
policy_value spend 0.21714911999879405 time
train_step spend 0.6322717009970802 time
policy_value spend 0.21634640400588978 time
kl:0.02402,lr_multiplier:11.391,loss:4.106168746948242,entropy:5.020864486694336,explained_var_old:0.984843969,explained_var_new:0.989661515
output spend 0.00014502699923468754 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008047831994190346 time
recovery_state_mcts_prob spend 0.2757628500039573 time
state_batch spend 0.0025884679998853244 time
mcts_probs_batch spend 0.01252819100045599 time
winner_batch spend 0.0005251229958957992 time
policy_value spend 0.21963959999993676 time
train_step spend 0.6297337779978989 time
policy_value spend 0.219249302004755 time
train_step spend 0.6303227410026011 time
policy_value spend 0.21450334200198995 time
train_step spend 0.6297953120010789 time
policy_value spend 0.21416992200101959 time
train_step spend 0.6290360639977735 time
policy_value spend 0.2143632559964317 time
train_step spend 0.6295642559998669 time
policy_value spend 0.2141484199964907 time
kl:0.02157,lr_multiplier:11.391,loss:4.005377769470215,entropy:5.001323699951172,explained_var_old:0.998122036,explained_var_new:0.999191582
output spend 0.00015412500215461478 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008400997001444921 time
recovery_state_mcts_prob spend 0.3010908419964835 time
state_batch spend 0.002161238000553567 time
mcts_probs_batch spend 0.005895449001400266 time
winner_batch spend 0.00028947599639650434 time
policy_value spend 0.21809491200110642 time
train_step spend 0.6647263929990004 time
policy_value spend 0.22670832100266125 time
train_step spend 0.6333027510045213 time
policy_value spend 0.21600479599874234 time
train_step spend 0.629258574997948 time
policy_value spend 0.2146447220002301 time
train_step spend 0.628927432000637 time
policy_value spend 0.21587141299823998 time
train_step spend 0.6291034610039787 time
policy_value spend 0.2146593919969746 time
kl:0.00944,lr_multiplier:11.391,loss:4.070844650268555,entropy:4.9917707443237305,explained_var_old:0.988867640,explained_var_new:0.992518246
output spend 0.00014746600209036842 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007503752000047825 time
recovery_state_mcts_prob spend 0.2676567779999459 time
state_batch spend 0.0019257189997006208 time
mcts_probs_batch spend 0.004487024998525158 time
winner_batch spend 0.0002970810019178316 time
policy_value spend 0.21505774799879873 time
train_step spend 0.631534977001138 time
policy_value spend 0.2172814509976888 time
train_step spend 0.6299746389995562 time
policy_value spend 0.2152067380011431 time
train_step spend 0.6298302579962183 time
policy_value spend 0.21482334999745945 time
train_step spend 0.6304882269978407 time
policy_value spend 0.21494243200140772 time
train_step spend 0.6298037439992186 time
policy_value spend 0.2147279310011072 time
kl:0.00791,lr_multiplier:11.391,loss:4.088135719299316,entropy:4.995308876037598,explained_var_old:0.994677305,explained_var_new:0.995757818
output spend 0.00014852399908704683 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0076602570043178275 time
recovery_state_mcts_prob spend 0.2733897779980907 time
state_batch spend 0.0019177689973730594 time
mcts_probs_batch spend 0.006063231005100533 time
winner_batch spend 0.0002775289976852946 time
policy_value spend 0.21541820999846095 time
train_step spend 0.6307309210023959 time
policy_value spend 0.21494047900341684 time
train_step spend 0.630094612002722 time
policy_value spend 0.21522812000330305 time
train_step spend 0.6291615029986133 time
policy_value spend 0.21502742700249655 time
train_step spend 0.6332426529988879 time
policy_value spend 0.21557366300112335 time
train_step spend 0.6294918739949935 time
policy_value spend 0.21566419300506823 time
kl:0.02793,lr_multiplier:11.391,loss:4.068422317504883,entropy:5.002483367919922,explained_var_old:0.993730247,explained_var_new:0.995719254
output spend 0.00016151199815794826 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006829792000644375 time
recovery_state_mcts_prob spend 0.2723198690000572 time
state_batch spend 0.0019721639982890338 time
mcts_probs_batch spend 0.006032404002326075 time
winner_batch spend 0.000287957998807542 time
policy_value spend 0.21555013999750372 time
train_step spend 0.6321344370007864 time
policy_value spend 0.2154297500019311 time
train_step spend 0.6306681620044401 time
policy_value spend 0.2161138769952231 time
train_step spend 0.6314122039984795 time
policy_value spend 0.2152342219997081 time
train_step spend 0.6312411960025202 time
policy_value spend 0.21511976199690253 time
train_step spend 0.6310551690039574 time
policy_value spend 0.21535514999413863 time
kl:0.01083,lr_multiplier:11.391,loss:4.121322154998779,entropy:5.0430707931518555,explained_var_old:0.990435839,explained_var_new:0.991903424
output spend 0.00014333199942484498 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007442992995493114 time
recovery_state_mcts_prob spend 0.2797358789975988 time
state_batch spend 0.003383752002264373 time
mcts_probs_batch spend 0.005433243000879884 time
winner_batch spend 0.00036394400376593694 time
policy_value spend 0.21456306199979736 time
train_step spend 0.630955280001217 time
policy_value spend 0.21565960500447545 time
train_step spend 0.6308581910052453 time
policy_value spend 0.2156423470005393 time
train_step spend 0.6305033439930412 time
policy_value spend 0.21554136500344612 time
train_step spend 0.6288877789993421 time
policy_value spend 0.21543281599588227 time
train_step spend 0.6296152290015016 time
policy_value spend 0.21508586600248236 time
kl:0.01457,lr_multiplier:11.391,loss:4.088264465332031,entropy:4.996868133544922,explained_var_old:0.991384268,explained_var_new:0.991946697
output spend 0.00014801100041950122 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007779211999149993 time
recovery_state_mcts_prob spend 0.2691624379949644 time
state_batch spend 0.002230320002126973 time
mcts_probs_batch spend 0.005980738998914603 time
winner_batch spend 0.000366917003702838 time
policy_value spend 0.2151449209995917 time
train_step spend 0.6295430829995894 time
policy_value spend 0.2188104039960308 time
train_step spend 0.6295191110039013 time
policy_value spend 0.21450821100006578 time
train_step spend 0.6294780950047425 time
policy_value spend 0.21542851199774304 time
train_step spend 0.6284954690054292 time
policy_value spend 0.21480404699832434 time
train_step spend 0.6298340200009989 time
policy_value spend 0.2149707889984711 time
kl:0.01136,lr_multiplier:11.391,loss:4.022068500518799,entropy:4.997305870056152,explained_var_old:0.998276591,explained_var_new:0.999471009
output spend 0.00014431000454351306 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007949498001835309 time
recovery_state_mcts_prob spend 0.2721581840014551 time
state_batch spend 0.0019211199978599325 time
mcts_probs_batch spend 0.0055418859992641956 time
winner_batch spend 0.0003516430006129667 time
policy_value spend 0.2150590809978894 time
train_step spend 0.6304649209996569 time
policy_value spend 0.215791080998315 time
train_step spend 0.628914998997061 time
policy_value spend 0.2153726190008456 time
train_step spend 0.6293943290002062 time
policy_value spend 0.22314680799900088 time
train_step spend 0.6305631760042161 time
policy_value spend 0.21569700999680208 time
train_step spend 0.6313189759966917 time
policy_value spend 0.2147635130022536 time
kl:0.02974,lr_multiplier:11.391,loss:4.08951473236084,entropy:4.991155624389648,explained_var_old:0.987496555,explained_var_new:0.992204905
output spend 0.0001511250011390075 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00843516799795907 time
recovery_state_mcts_prob spend 0.28074428500258364 time
state_batch spend 0.0022549740024260245 time
mcts_probs_batch spend 0.006220523995580152 time
winner_batch spend 0.0002842419999069534 time
policy_value spend 0.21531676800077548 time
train_step spend 0.6301629189983942 time
policy_value spend 0.21658517500327434 time
train_step spend 0.62928699299664 time
policy_value spend 0.21472236300178338 time
train_step spend 0.6294232340005692 time
policy_value spend 0.21488346499972977 time
train_step spend 0.6297426210003323 time
policy_value spend 0.21526617999916198 time
train_step spend 0.6293769069961854 time
policy_value spend 0.21589729800325586 time
kl:0.01071,lr_multiplier:11.391,loss:4.065553665161133,entropy:4.96970272064209,explained_var_old:0.998258650,explained_var_new:0.999487162
output spend 0.00014860199735267088 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007185769994975999 time
recovery_state_mcts_prob spend 0.2715942030044971 time
state_batch spend 0.0018907049961853772 time
mcts_probs_batch spend 0.006281095003942028 time
winner_batch spend 0.0002951679998659529 time
policy_value spend 0.2157767819953733 time
train_step spend 0.6303577519938699 time
policy_value spend 0.215220849000616 time
train_step spend 0.6305912600000738 time
policy_value spend 0.2158644640003331 time
train_step spend 0.6307663859988679 time
policy_value spend 0.21513191499980167 time
train_step spend 0.630182553002669 time
policy_value spend 0.2150099859936745 time
train_step spend 0.64498379399447 time
policy_value spend 0.22794612500001676 time
kl:0.01387,lr_multiplier:11.391,loss:4.067594528198242,entropy:4.9555253982543945,explained_var_old:0.990104258,explained_var_new:0.992895365
output spend 0.000156095004058443 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01139711200085003 time
recovery_state_mcts_prob spend 0.2760521520031034 time
state_batch spend 0.001885487996332813 time
mcts_probs_batch spend 0.01237062400468858 time
winner_batch spend 0.0002902409978560172 time
policy_value spend 0.21994870899652597 time
train_step spend 0.6349722689992632 time
policy_value spend 0.21508723899751203 time
train_step spend 0.6315913409998757 time
policy_value spend 0.21702545800508233 time
train_step spend 0.6305405890016118 time
policy_value spend 0.2157321979975677 time
train_step spend 0.6313305269941338 time
policy_value spend 0.21595072800118942 time
train_step spend 0.6313364890011144 time
policy_value spend 0.21532162299990887 time
kl:0.00786,lr_multiplier:11.391,loss:4.042024612426758,entropy:5.003884315490723,explained_var_old:0.999121070,explained_var_new:0.999653161
output spend 0.00014994500088505447 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007394838998152409 time
recovery_state_mcts_prob spend 0.27309057700040285 time
state_batch spend 0.0018259799981024116 time
mcts_probs_batch spend 0.0067303890027687885 time
winner_batch spend 0.00030666800012113526 time
policy_value spend 0.21571951499936404 time
train_step spend 0.6316087020022678 time
policy_value spend 0.21549321799830068 time
train_step spend 0.6305112529953476 time
policy_value spend 0.2158722160020261 time
train_step spend 0.6310583419981413 time
policy_value spend 0.2150588240037905 time
train_step spend 0.6301292110001668 time
policy_value spend 0.21582591900369152 time
train_step spend 0.6294849250043626 time
policy_value spend 0.21506989000044996 time
kl:0.00730,lr_multiplier:11.391,loss:4.165577411651611,entropy:5.060901165008545,explained_var_old:0.997079134,explained_var_new:0.999394715
output spend 0.00015303100371966138 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.01028021900128806 time
recovery_state_mcts_prob spend 0.26397021199954906 time
state_batch spend 0.001997992003452964 time
mcts_probs_batch spend 0.011966080994170625 time
winner_batch spend 0.00029200000426499173 time
policy_value spend 0.21739870499732206 time
train_step spend 0.6308169760013698 time
policy_value spend 0.21455168700049398 time
train_step spend 0.629329895004048 time
policy_value spend 0.21514346699404996 time
train_step spend 0.6298415530036436 time
policy_value spend 0.2149956459979876 time
train_step spend 0.6308073870022781 time
policy_value spend 0.2172328539963928 time
train_step spend 0.631042934001016 time
policy_value spend 0.2151096819943632 time
kl:0.00917,lr_multiplier:11.391,loss:4.050071716308594,entropy:4.949591636657715,explained_var_old:0.987141669,explained_var_new:0.988847733
output spend 0.0001450059935450554 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007202070999483112 time
recovery_state_mcts_prob spend 0.2693684230034705 time
state_batch spend 0.0019105489991488867 time
mcts_probs_batch spend 0.006766744998458307 time
winner_batch spend 0.000279416999546811 time
policy_value spend 0.21620475700183306 time
train_step spend 0.6294628340037889 time
policy_value spend 0.2150257059984142 time
train_step spend 0.6298938170002657 time
policy_value spend 0.21525727300468134 time
train_step spend 0.6295867730004829 time
policy_value spend 0.21561171199573437 time
train_step spend 0.6301198789951741 time
policy_value spend 0.21534773999883328 time
train_step spend 0.6296541219999199 time
policy_value spend 0.21542351699463325 time
kl:0.01086,lr_multiplier:11.391,loss:4.073399543762207,entropy:4.980916500091553,explained_var_old:0.988040805,explained_var_new:0.992005348
output spend 0.0001504219981143251 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007047115002933424 time
recovery_state_mcts_prob spend 0.27273767599399434 time
state_batch spend 0.001996549006435089 time
mcts_probs_batch spend 0.0044075319965486415 time
winner_batch spend 0.00029582199931610376 time
policy_value spend 0.21423734600102762 time
train_step spend 0.6335044450024725 time
policy_value spend 0.21410011500120163 time
train_step spend 0.6309465739977895 time
policy_value spend 0.21509482800320257 time
train_step spend 0.6299713979969965 time
policy_value spend 0.21514328500052216 time
train_step spend 0.6313465279963566 time
policy_value spend 0.21489466699858895 time
train_step spend 0.6297656039969297 time
policy_value spend 0.21493172400369076 time
kl:0.00971,lr_multiplier:11.391,loss:4.0817060470581055,entropy:4.998418807983398,explained_var_old:0.992987454,explained_var_new:0.996200979
output spend 0.0001449859992135316 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006937226004083641 time
recovery_state_mcts_prob spend 0.27602864900109125 time
state_batch spend 0.002095323994581122 time
mcts_probs_batch spend 0.008411437003815081 time
winner_batch spend 0.00029079299565637484 time
policy_value spend 0.21494137400441105 time
train_step spend 0.63091893800447 time
policy_value spend 0.21499341599701438 time
train_step spend 0.629116915006307 time
policy_value spend 0.2152931729942793 time
train_step spend 0.630742220004322 time
policy_value spend 0.21461711499432568 time
train_step spend 0.6300579710004968 time
policy_value spend 0.2153029740002239 time
train_step spend 0.6306916469984571 time
policy_value spend 0.2152129239984788 time
kl:0.01854,lr_multiplier:11.391,loss:4.060989856719971,entropy:4.958573341369629,explained_var_old:0.995076954,explained_var_new:0.995749593
output spend 0.00018251599976792932 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006851511003333144 time
recovery_state_mcts_prob spend 0.28631085899542086 time
state_batch spend 0.0018379570028628223 time
mcts_probs_batch spend 0.004422477999469265 time
winner_batch spend 0.0003002480007125996 time
policy_value spend 0.2153526670008432 time
train_step spend 0.6300179030004074 time
policy_value spend 0.21550771399779478 time
train_step spend 0.6306131309975171 time
policy_value spend 0.21507793600176228 time
train_step spend 0.6306586380014778 time
policy_value spend 0.2152362419947167 time
train_step spend 0.629809556005057 time
policy_value spend 0.21589764999953331 time
train_step spend 0.6310887719955645 time
policy_value spend 0.21528472199861426 time
kl:0.01773,lr_multiplier:11.391,loss:4.09153413772583,entropy:5.006033897399902,explained_var_old:0.973123729,explained_var_new:0.976883590
output spend 0.0001479660058976151 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009399059999850579 time
recovery_state_mcts_prob spend 0.270219123995048 time
state_batch spend 0.0018509200017433614 time
mcts_probs_batch spend 0.004471314998227172 time
winner_batch spend 0.00028933400608366355 time
policy_value spend 0.2147101480004494 time
train_step spend 0.6309554210019996 time
policy_value spend 0.21570419600175228 time
train_step spend 0.6306552839960204 time
policy_value spend 0.2152048710049712 time
train_step spend 0.6316926270010299 time
policy_value spend 0.21495120599865913 time
train_step spend 0.629277160995116 time
policy_value spend 0.21505903800425585 time
train_step spend 0.6292858730012085 time
policy_value spend 0.21532917600416113 time
kl:0.00862,lr_multiplier:11.391,loss:4.075908184051514,entropy:4.975739002227783,explained_var_old:0.998697937,explained_var_new:0.999191225
output spend 0.00014451600145548582 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009226456000760663 time
recovery_state_mcts_prob spend 0.2721178050051094 time
state_batch spend 0.001860427000792697 time
mcts_probs_batch spend 0.004443403995537665 time
winner_batch spend 0.00029347799863899127 time
policy_value spend 0.22348479900392704 time
train_step spend 0.6494638500007568 time
policy_value spend 0.2280529419949744 time
train_step spend 0.6453185739956098 time
policy_value spend 0.2162291830027243 time
train_step spend 0.6290958440004033 time
policy_value spend 0.21558185699541355 time
train_step spend 0.6292765329999384 time
policy_value spend 0.21511700300470693 time
train_step spend 0.6290963329956867 time
policy_value spend 0.2150258500041673 time
kl:0.00797,lr_multiplier:11.391,loss:4.070172309875488,entropy:4.9673943519592285,explained_var_old:0.998384714,explained_var_new:0.999254405
output spend 0.00017330799892079085 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008739753000554629 time
recovery_state_mcts_prob spend 0.26950897100323346 time
state_batch spend 0.0018423689980409108 time
mcts_probs_batch spend 0.006376500001351815 time
winner_batch spend 0.00031135999597609043 time
policy_value spend 0.2152504850018886 time
train_step spend 0.629288636999263 time
policy_value spend 0.21579466199909803 time
train_step spend 0.6289818309960538 time
policy_value spend 0.21487498100032099 time
train_step spend 0.6293664019976859 time
policy_value spend 0.21512901400274131 time
train_step spend 0.63072081500286 time
policy_value spend 0.21516426499874797 time
train_step spend 0.6302285679994384 time
policy_value spend 0.21463757499441272 time
kl:0.00979,lr_multiplier:11.391,loss:4.0512375831604,entropy:4.964535713195801,explained_var_old:0.988690615,explained_var_new:0.992037594
output spend 0.00015313999756472185 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010652572003891692 time
recovery_state_mcts_prob spend 0.26899453700025333 time
state_batch spend 0.002109048997226637 time
mcts_probs_batch spend 0.006427729997085407 time
winner_batch spend 0.00028715400549117476 time
policy_value spend 0.2160992559947772 time
train_step spend 0.6299151069979416 time
policy_value spend 0.2161325439956272 time
train_step spend 0.629940484999679 time
policy_value spend 0.21551108999847202 time
train_step spend 0.6294556220018421 time
policy_value spend 0.2154462920007063 time
train_step spend 0.6305790740007069 time
policy_value spend 0.21490001599886455 time
train_step spend 0.6300571429965203 time
policy_value spend 0.21505649800383253 time
kl:0.00724,lr_multiplier:11.391,loss:4.104254722595215,entropy:5.018979549407959,explained_var_old:0.992417693,explained_var_new:0.993379533
output spend 0.00014659400039818138 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008189512998797 time
recovery_state_mcts_prob spend 0.27413272500416497 time
state_batch spend 0.0018846429957193322 time
mcts_probs_batch spend 0.006385134998708963 time
winner_batch spend 0.0003139970067422837 time
policy_value spend 0.21501113699923735 time
train_step spend 0.6303959290016792 time
policy_value spend 0.21530877299665008 time
train_step spend 0.6300931689984282 time
policy_value spend 0.21548182200058363 time
train_step spend 0.6294978349978919 time
policy_value spend 0.21560612000030233 time
train_step spend 0.6305151839987957 time
policy_value spend 0.21499802499602083 time
train_step spend 0.6310974909938523 time
policy_value spend 0.21490224900480825 time
kl:0.00758,lr_multiplier:11.391,loss:4.0338263511657715,entropy:4.9806108474731445,explained_var_old:0.995892644,explained_var_new:0.996907532
output spend 0.0001438330000382848 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007319598000322003 time
recovery_state_mcts_prob spend 0.270299272997363 time
state_batch spend 0.0018134180063498206 time
mcts_probs_batch spend 0.0046067239964031614 time
winner_batch spend 0.0004259609995642677 time
policy_value spend 0.2144963690006989 time
train_step spend 0.6300203409991809 time
policy_value spend 0.2152861800059327 time
train_step spend 0.6310019750017091 time
policy_value spend 0.21495969100215007 time
train_step spend 0.6310473559933598 time
policy_value spend 0.21526717600499978 time
train_step spend 0.6308132769991062 time
policy_value spend 0.21554042200295953 time
train_step spend 0.6305988530002651 time
policy_value spend 0.2157265929999994 time
kl:0.00809,lr_multiplier:11.391,loss:4.041947841644287,entropy:4.9548020362854,explained_var_old:0.994676471,explained_var_new:0.995715737
output spend 0.00020834400493185967 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008395487006055191 time
recovery_state_mcts_prob spend 0.27135914799873717 time
state_batch spend 0.0021966779968352057 time
mcts_probs_batch spend 0.006036702005076222 time
winner_batch spend 0.0002885899957618676 time
policy_value spend 0.21542384000349557 time
train_step spend 0.6343711310037179 time
policy_value spend 0.2159561419975944 time
train_step spend 0.632669156002521 time
policy_value spend 0.21586413199838717 time
train_step spend 0.6311390880000545 time
policy_value spend 0.2150988459979999 time
train_step spend 0.6298475259973202 time
policy_value spend 0.2147474930025055 time
train_step spend 0.6290668829969945 time
policy_value spend 0.21494091000204207 time
kl:0.01183,lr_multiplier:11.391,loss:4.058482646942139,entropy:4.952003479003906,explained_var_old:0.995762169,explained_var_new:0.995875299
output spend 0.00014693599950987846 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006997773998591583 time
recovery_state_mcts_prob spend 0.27119423400290543 time
state_batch spend 0.00183320799987996 time
mcts_probs_batch spend 0.004908114999125246 time
winner_batch spend 0.00034390200016787276 time
policy_value spend 0.2141748970025219 time
train_step spend 0.6301651460016728 time
policy_value spend 0.21471833500254434 time
train_step spend 0.6290161009965232 time
policy_value spend 0.21485200899769552 time
train_step spend 0.6292368020003778 time
policy_value spend 0.215221061000193 time
train_step spend 0.6295950130006531 time
policy_value spend 0.2150888149990351 time
train_step spend 0.6327642340038437 time
policy_value spend 0.2152648089977447 time
kl:0.01279,lr_multiplier:11.391,loss:4.106708526611328,entropy:4.968025207519531,explained_var_old:0.984492362,explained_var_new:0.987953722
output spend 0.00014442099927691743 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070893119991524145 time
recovery_state_mcts_prob spend 0.2670643210003618 time
state_batch spend 0.002178239999921061 time
mcts_probs_batch spend 0.006410004003555514 time
winner_batch spend 0.0002851879980880767 time
policy_value spend 0.21484971699828748 time
train_step spend 0.6296231169981183 time
policy_value spend 0.21493508900312008 time
train_step spend 0.6300249849955435 time
policy_value spend 0.21544826200261014 time
train_step spend 0.6297587570006726 time
policy_value spend 0.21512876199994935 time
train_step spend 0.630042152995884 time
policy_value spend 0.21604097799718147 time
train_step spend 0.6302486790009425 time
policy_value spend 0.21552813400194282 time
kl:0.01438,lr_multiplier:11.391,loss:4.084445476531982,entropy:5.024849891662598,explained_var_old:0.991631031,explained_var_new:0.992524266
output spend 0.00014564599405275658 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00930974700168008 time
recovery_state_mcts_prob spend 0.2723442150017945 time
state_batch spend 0.0022386759956134483 time
mcts_probs_batch spend 0.0043889440057682805 time
winner_batch spend 0.000284423993434757 time
policy_value spend 0.21407994200126268 time
train_step spend 0.6297646919992985 time
policy_value spend 0.21480416099802824 time
train_step spend 0.630153418998816 time
policy_value spend 0.21553729500010377 time
train_step spend 0.6298994180033333 time
policy_value spend 0.21534823600086384 time
train_step spend 0.6301799020002363 time
policy_value spend 0.21593872200173791 time
train_step spend 0.6301524279988371 time
policy_value spend 0.21526758300024085 time
kl:0.00917,lr_multiplier:11.391,loss:4.000376224517822,entropy:4.940532684326172,explained_var_old:0.997948468,explained_var_new:0.999022365
output spend 0.000301530999422539 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007131802994990721 time
recovery_state_mcts_prob spend 0.3088374670041958 time
state_batch spend 0.0018418530016788282 time
mcts_probs_batch spend 0.005418209999334067 time
winner_batch spend 0.00031724199652671814 time
policy_value spend 0.22754991100373445 time
train_step spend 0.6458725930060609 time
policy_value spend 0.21675813399633626 time
train_step spend 0.6319151599964243 time
policy_value spend 0.21544357600214425 time
train_step spend 0.6296570919948863 time
policy_value spend 0.2154716580043896 time
train_step spend 0.6302971510012867 time
policy_value spend 0.21761729499849025 time
train_step spend 0.631605088005017 time
policy_value spend 0.216334402000939 time
kl:0.01967,lr_multiplier:11.391,loss:4.103667259216309,entropy:5.020679473876953,explained_var_old:0.988837719,explained_var_new:0.991890132
output spend 0.00014731600094819441 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008198811003239825 time
recovery_state_mcts_prob spend 0.2754060439983732 time
state_batch spend 0.0018738670041784644 time
mcts_probs_batch spend 0.004477682996366639 time
winner_batch spend 0.0002966090032714419 time
policy_value spend 0.21752020999701926 time
train_step spend 0.6307088289977401 time
policy_value spend 0.21502848800446372 time
train_step spend 0.6307626589987194 time
policy_value spend 0.21474374399986118 time
train_step spend 0.6306798939986038 time
policy_value spend 0.21528264199878322 time
train_step spend 0.6307675650023157 time
policy_value spend 0.21481438799673924 time
train_step spend 0.6315986389963655 time
policy_value spend 0.2153864869978861 time
kl:0.01500,lr_multiplier:11.391,loss:4.06648588180542,entropy:4.9664306640625,explained_var_old:0.991834283,explained_var_new:0.994484007
output spend 0.00015062100283103064 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.010609033997752704 time
recovery_state_mcts_prob spend 0.27653299200028414 time
state_batch spend 0.0018649459962034598 time
mcts_probs_batch spend 0.006926288006070536 time
winner_batch spend 0.0003519389938446693 time
policy_value spend 0.21592176600097446 time
train_step spend 0.6301639469966176 time
policy_value spend 0.21677729600196471 time
train_step spend 0.6311083019973012 time
policy_value spend 0.21456381900497945 time
train_step spend 0.6301975259993924 time
policy_value spend 0.21527659300045343 time
train_step spend 0.6293632680026349 time
policy_value spend 0.21473938699637074 time
train_step spend 0.6293216370031587 time
policy_value spend 0.2150151929963613 time
kl:0.01579,lr_multiplier:11.391,loss:4.012126922607422,entropy:4.951874732971191,explained_var_old:0.996646106,explained_var_new:0.998717606
output spend 0.00014206700143404305 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0076203479984542355 time
recovery_state_mcts_prob spend 0.27521733699541073 time
state_batch spend 0.001969559001736343 time
mcts_probs_batch spend 0.006665788998361677 time
winner_batch spend 0.0002906030058511533 time
policy_value spend 0.2149635049936478 time
train_step spend 0.6290814239982865 time
policy_value spend 0.21592177900311071 time
train_step spend 0.6290433530011796 time
policy_value spend 0.2147693849983625 time
train_step spend 0.6288905260007596 time
policy_value spend 0.21487096099735936 time
train_step spend 0.6301356469994062 time
policy_value spend 0.21458272500603925 time
train_step spend 0.6287781909995829 time
policy_value spend 0.21507778000523103 time
kl:0.01194,lr_multiplier:11.391,loss:4.070851802825928,entropy:4.988909721374512,explained_var_old:0.997963607,explained_var_new:0.999319136
output spend 0.0001460880012018606 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007983682000485715 time
recovery_state_mcts_prob spend 0.26603669499309035 time
state_batch spend 0.001820465004129801 time
mcts_probs_batch spend 0.006053170996892732 time
winner_batch spend 0.0002885409994632937 time
policy_value spend 0.2155076380004175 time
train_step spend 0.6302976219958509 time
policy_value spend 0.2149719470035052 time
train_step spend 0.6299747059965739 time
policy_value spend 0.2159385859995382 time
train_step spend 0.6294415320007829 time
policy_value spend 0.21495190399582498 time
train_step spend 0.6309023020003224 time
policy_value spend 0.2155053759997827 time
train_step spend 0.6293824559979839 time
policy_value spend 0.2150984910040279 time
kl:0.01673,lr_multiplier:11.391,loss:4.021761417388916,entropy:4.953188896179199,explained_var_old:0.996175110,explained_var_new:0.999306023
output spend 0.00014878100046189502 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0072934589989017695 time
recovery_state_mcts_prob spend 0.27632545700180344 time
state_batch spend 0.0017917069999384694 time
mcts_probs_batch spend 0.006697778000670951 time
winner_batch spend 0.0003332429987494834 time
policy_value spend 0.2151347649996751 time
train_step spend 0.630261566999252 time
policy_value spend 0.21501879100105725 time
train_step spend 0.6290581620050943 time
policy_value spend 0.21507822399871657 time
train_step spend 0.6299629589993856 time
policy_value spend 0.21498402200086275 time
train_step spend 0.6287929890022497 time
policy_value spend 0.21532859199942322 time
train_step spend 0.6298291720013367 time
policy_value spend 0.2146460500007379 time
kl:0.02535,lr_multiplier:11.391,loss:4.011746883392334,entropy:4.956455230712891,explained_var_old:0.993372023,explained_var_new:0.995705128
output spend 0.00014444000407820567 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007067063001159113 time
recovery_state_mcts_prob spend 0.27442525499645853 time
state_batch spend 0.0018030999999609776 time
mcts_probs_batch spend 0.004390897003759164 time
winner_batch spend 0.0002876269936678 time
policy_value spend 0.21477397600392578 time
train_step spend 0.629005495000456 time
policy_value spend 0.21462556799815502 time
train_step spend 0.6294845110023743 time
policy_value spend 0.21487500199873466 time
train_step spend 0.6298566699988442 time
policy_value spend 0.21548157000506762 time
train_step spend 0.6294931140000699 time
policy_value spend 0.21477906799555058 time
train_step spend 0.6323434090008959 time
policy_value spend 0.21607405800023116 time
kl:0.03239,lr_multiplier:11.391,loss:4.082028865814209,entropy:4.976432800292969,explained_var_old:0.986924410,explained_var_new:0.988370478
output spend 0.00015715300105512142 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007003858998359647 time
recovery_state_mcts_prob spend 0.2746873520009103 time
state_batch spend 0.0017974549991777167 time
mcts_probs_batch spend 0.0055197930050781 time
winner_batch spend 0.000329365000652615 time
policy_value spend 0.2146050709998235 time
train_step spend 0.6322255019986187 time
policy_value spend 0.21590657000342617 time
train_step spend 0.6300606550066732 time
policy_value spend 0.21532221599773038 time
train_step spend 0.6306961100053741 time
policy_value spend 0.21543482199922437 time
train_step spend 0.6306174979981733 time
policy_value spend 0.21596513600525213 time
train_step spend 0.631133303999377 time
policy_value spend 0.22104276799655054 time
kl:0.01211,lr_multiplier:11.391,loss:4.0802435874938965,entropy:5.000972747802734,explained_var_old:0.995612621,explained_var_new:0.996121407
output spend 0.00014514299982693046 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007873058995755855 time
recovery_state_mcts_prob spend 0.27457939800660824 time
state_batch spend 0.0018505809930502437 time
mcts_probs_batch spend 0.006851804006146267 time
winner_batch spend 0.0002790629951050505 time
policy_value spend 0.2157124869991094 time
train_step spend 0.6300873709988082 time
policy_value spend 0.22195487600401975 time
train_step spend 0.6306587869985378 time
policy_value spend 0.21584707900183275 time
train_step spend 0.6506025119961123 time
policy_value spend 0.22876920200360473 time
train_step spend 0.6584775800001808 time
policy_value spend 0.2158724990003975 time
train_step spend 0.631511400002637 time
policy_value spend 0.21488549200148555 time
kl:0.00828,lr_multiplier:11.391,loss:4.0738935470581055,entropy:4.964111328125,explained_var_old:0.984258056,explained_var_new:0.990225732
output spend 0.00014955399819882587 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007242538005812094 time
recovery_state_mcts_prob spend 0.2687310109977261 time
state_batch spend 0.0022338529961416498 time
mcts_probs_batch spend 0.0065395540004828945 time
winner_batch spend 0.0003171440039295703 time
policy_value spend 0.2159438320013578 time
train_step spend 0.6305078360019252 time
policy_value spend 0.21472351500415243 time
train_step spend 0.629514783002378 time
policy_value spend 0.21605334999912884 time
train_step spend 0.6298354059981648 time
policy_value spend 0.2153896190066007 time
train_step spend 0.6302315169959911 time
policy_value spend 0.21522250099951634 time
train_step spend 0.6299823119989014 time
policy_value spend 0.21573096700012684 time
kl:0.02114,lr_multiplier:11.391,loss:3.996105909347534,entropy:4.9063873291015625,explained_var_old:0.982384384,explained_var_new:0.990882754
output spend 0.00014209499931894243 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0075829740017070435 time
recovery_state_mcts_prob spend 0.2736804009982734 time
state_batch spend 0.0019208330049877986 time
mcts_probs_batch spend 0.00639533899811795 time
winner_batch spend 0.00035584400029620156 time
policy_value spend 0.21578721999685513 time
train_step spend 0.630597495000984 time
policy_value spend 0.21567805000086082 time
train_step spend 0.6287494979987969 time
policy_value spend 0.21542380100436276 time
train_step spend 0.6307005750059034 time
policy_value spend 0.21494327199616237 time
train_step spend 0.6310564259983948 time
policy_value spend 0.21547466499760048 time
train_step spend 0.6307082769999397 time
policy_value spend 0.21582556000066688 time
kl:0.01063,lr_multiplier:11.391,loss:4.071408271789551,entropy:4.978821754455566,explained_var_old:0.985218108,explained_var_new:0.990710199
output spend 0.00014489000022877008 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070188440004130825 time
recovery_state_mcts_prob spend 0.2709026970042032 time
state_batch spend 0.0018666339965420775 time
mcts_probs_batch spend 0.004381079001177568 time
winner_batch spend 0.00028898999880766496 time
policy_value spend 0.2141389149983297 time
train_step spend 0.6302071989994147 time
policy_value spend 0.21502701900317334 time
train_step spend 0.6301232199984952 time
policy_value spend 0.2152098790029413 time
train_step spend 0.6291401269991184 time
policy_value spend 0.21527008200064301 time
train_step spend 0.6346574150011293 time
policy_value spend 0.21707845100172563 time
train_step spend 0.6339684480044525 time
policy_value spend 0.2162491599956411 time
kl:0.01314,lr_multiplier:11.391,loss:3.9870846271514893,entropy:4.954614162445068,explained_var_old:0.990152061,explained_var_new:0.997717202
output spend 0.00022299700503936037 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008088470000075176 time
recovery_state_mcts_prob spend 0.2767388810025295 time
state_batch spend 0.002188001002650708 time
mcts_probs_batch spend 0.012936211998749059 time
winner_batch spend 0.0002967249965877272 time
policy_value spend 0.22066269000060856 time
train_step spend 0.6355065000025206 time
policy_value spend 0.2171406269990257 time
train_step spend 0.6348675550034386 time
policy_value spend 0.21682357599638635 time
train_step spend 0.6346403260031366 time
policy_value spend 0.21703512300155126 time
train_step spend 0.6348378909970052 time
policy_value spend 0.21669815300265327 time
train_step spend 0.6341632589974324 time
policy_value spend 0.21671389500261284 time
kl:0.02133,lr_multiplier:11.391,loss:4.042577266693115,entropy:4.947671413421631,explained_var_old:0.990564764,explained_var_new:0.995588660
output spend 0.0001460979983676225 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008063016997766681 time
recovery_state_mcts_prob spend 0.2695944459992461 time
state_batch spend 0.001920136004628148 time
mcts_probs_batch spend 0.0063303049973910674 time
winner_batch spend 0.00028622600075323135 time
policy_value spend 0.21761976199923083 time
train_step spend 0.6332549970029504 time
policy_value spend 0.21755663699877914 time
train_step spend 0.6328690290029044 time
policy_value spend 0.21594955599721288 time
train_step spend 0.6325285880011506 time
policy_value spend 0.21674205199815333 time
train_step spend 0.6329717070038896 time
policy_value spend 0.21604013799515087 time
train_step spend 0.6331495940030436 time
policy_value spend 0.21594552999886218 time
kl:0.01395,lr_multiplier:11.391,loss:3.983107805252075,entropy:4.961215019226074,explained_var_old:0.992071867,explained_var_new:0.992404044
output spend 0.00014475300122285262 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008335871003509965 time
recovery_state_mcts_prob spend 0.27607411699864315 time
state_batch spend 0.001825120001740288 time
mcts_probs_batch spend 0.00615133999963291 time
winner_batch spend 0.0002840410015778616 time
policy_value spend 0.2171582109949668 time
train_step spend 0.6345355090015801 time
policy_value spend 0.21629361200029962 time
train_step spend 0.6329023709986359 time
policy_value spend 0.21599785500438884 time
train_step spend 0.632998162000149 time
policy_value spend 0.21652515899768332 time
train_step spend 0.6249184539992712 time
policy_value spend 0.2135411670024041 time
train_step spend 0.6247916299980716 time
policy_value spend 0.2130095460015582 time
kl:0.01587,lr_multiplier:11.391,loss:4.0606160163879395,entropy:4.9676923751831055,explained_var_old:0.998063445,explained_var_new:0.999363899
output spend 0.00014597699919249862 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007175222999649122 time
recovery_state_mcts_prob spend 0.27068071800022153 time
state_batch spend 0.002052217001619283 time
mcts_probs_batch spend 0.004914381999697071 time
winner_batch spend 0.00029148799512768164 time
policy_value spend 0.2125431890017353 time
train_step spend 0.624107676994754 time
policy_value spend 0.21324170200387016 time
train_step spend 0.624447757996677 time
policy_value spend 0.21351012800005265 time
train_step spend 0.624343300005421 time
policy_value spend 0.21322567299648654 time
train_step spend 0.624457434998476 time
policy_value spend 0.21332578800502233 time
train_step spend 0.6244822890002979 time
policy_value spend 0.21327692799968645 time
kl:0.00782,lr_multiplier:11.391,loss:4.065249443054199,entropy:4.966641902923584,explained_var_old:0.987528563,explained_var_new:0.988396287
output spend 0.00015398300456581637 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006839795998530462 time
recovery_state_mcts_prob spend 0.2752513310042559 time
state_batch spend 0.0018643450021045282 time
mcts_probs_batch spend 0.006606604998523835 time
winner_batch spend 0.0003202019943273626 time
policy_value spend 0.21425171100418083 time
train_step spend 0.629809309997654 time
policy_value spend 0.21526050200191094 time
train_step spend 0.6287755969970021 time
policy_value spend 0.21479871799965622 time
train_step spend 0.6276091010004166 time
policy_value spend 0.21487696300027892 time
train_step spend 0.6291455609971308 time
policy_value spend 0.21524765100184595 time
train_step spend 0.6281946820017765 time
policy_value spend 0.21443354599614395 time
kl:0.01024,lr_multiplier:11.391,loss:4.002170562744141,entropy:4.894928932189941,explained_var_old:0.991030157,explained_var_new:0.995775342
output spend 0.00016002299526007846 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0072886130001279525 time
recovery_state_mcts_prob spend 0.2983633190015098 time
state_batch spend 0.0020676529966294765 time
mcts_probs_batch spend 0.006554113999300171 time
winner_batch spend 0.0003801600032602437 time
policy_value spend 0.21696944799623452 time
train_step spend 0.6622549570020055 time
policy_value spend 0.23146131500107003 time
train_step spend 0.6317072839956381 time
policy_value spend 0.21795679999922868 time
train_step spend 0.6302975050057285 time
policy_value spend 0.21569164699758403 time
train_step spend 0.63555451999855 time
policy_value spend 0.21739902500121389 time
train_step spend 0.6364202390032005 time
policy_value spend 0.2173930200005998 time
kl:0.01823,lr_multiplier:11.391,loss:4.064962387084961,entropy:4.975109100341797,explained_var_old:0.999151766,explained_var_new:0.999435246
output spend 0.00016804899496491998 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007047457002045121 time
recovery_state_mcts_prob spend 0.26483484899654286 time
state_batch spend 0.002304061003087554 time
mcts_probs_batch spend 0.006592564001039136 time
winner_batch spend 0.00029579799593193457 time
policy_value spend 0.21838283600664 time
train_step spend 0.6355435099976603 time
policy_value spend 0.220648793001601 time
train_step spend 0.6356362210062798 time
policy_value spend 0.21771264599374263 time
train_step spend 0.636488409996673 time
policy_value spend 0.2178178760004812 time
train_step spend 0.6360054439937812 time
policy_value spend 0.21729677999974228 time
train_step spend 0.6354236469996977 time
policy_value spend 0.21742776400060393 time
kl:0.01394,lr_multiplier:11.391,loss:4.051243305206299,entropy:4.962047100067139,explained_var_old:0.991594672,explained_var_new:0.992327392
output spend 0.00014796100003877655 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007898938994912896 time
recovery_state_mcts_prob spend 0.28147910199913895 time
state_batch spend 0.002065726999717299 time
mcts_probs_batch spend 0.008369762006623205 time
winner_batch spend 0.0002907739981310442 time
policy_value spend 0.22046715799660888 time
train_step spend 0.6367974940003478 time
policy_value spend 0.2165223780029919 time
train_step spend 0.6341005409994978 time
policy_value spend 0.2172831159987254 time
train_step spend 0.6343389699977706 time
policy_value spend 0.21765208800206892 time
train_step spend 0.6346145310017164 time
policy_value spend 0.21677794399874983 time
train_step spend 0.6339476499997545 time
policy_value spend 0.21711612299986882 time
kl:0.01743,lr_multiplier:11.391,loss:4.059183597564697,entropy:4.975854873657227,explained_var_old:0.988274157,explained_var_new:0.990683794
output spend 0.00015458100097021088 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006936076999409124 time
recovery_state_mcts_prob spend 0.27088578999973834 time
state_batch spend 0.002175913999963086 time
mcts_probs_batch spend 0.006261178998101968 time
winner_batch spend 0.0002953450020868331 time
policy_value spend 0.2174634219991276 time
train_step spend 0.6345163830046658 time
policy_value spend 0.21657554699777393 time
train_step spend 0.6344412930047838 time
policy_value spend 0.21676529399701394 time
train_step spend 0.6345643780005048 time
policy_value spend 0.21663680900383042 time
train_step spend 0.6075504959953832 time
policy_value spend 0.20746682699973462 time
train_step spend 0.6079513760050759 time
policy_value spend 0.20751716299855616 time
kl:0.01222,lr_multiplier:11.391,loss:4.018294811248779,entropy:4.939676284790039,explained_var_old:0.998409748,explained_var_new:0.999269664
output spend 0.00014053300401428714 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007174919002864044 time
recovery_state_mcts_prob spend 0.2570848679970368 time
state_batch spend 0.0017362200014758855 time
mcts_probs_batch spend 0.00452799800405046 time
winner_batch spend 0.0002844279952114448 time
policy_value spend 0.2066122720061685 time
train_step spend 0.6075971789978212 time
policy_value spend 0.20698724999965634 time
train_step spend 0.6063796599992202 time
policy_value spend 0.20729643300001044 time
train_step spend 0.6064912209985778 time
policy_value spend 0.20787165900401305 time
train_step spend 0.6064974230030202 time
policy_value spend 0.20774717399763176 time
train_step spend 0.6073551369991037 time
policy_value spend 0.20764577399677364 time
kl:0.00896,lr_multiplier:11.391,loss:4.043293476104736,entropy:4.947263717651367,explained_var_old:0.995774746,explained_var_new:0.998814285
output spend 0.00014036900392966345 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007848683002521284 time
recovery_state_mcts_prob spend 0.26703073699900415 time
state_batch spend 0.0021317549981176853 time
mcts_probs_batch spend 0.004368579997390043 time
winner_batch spend 0.000615830002061557 time
policy_value spend 0.2069948429998476 time
train_step spend 0.6182936580007663 time
policy_value spend 0.2138862869978766 time
train_step spend 0.6263160070011509 time
policy_value spend 0.21399739899788983 time
train_step spend 0.6254633889984689 time
policy_value spend 0.21400410099886358 time
train_step spend 0.6267313479984296 time
policy_value spend 0.21429941499809502 time
train_step spend 0.6269619920058176 time
policy_value spend 0.2142010869938531 time
kl:0.00942,lr_multiplier:11.391,loss:3.999708890914917,entropy:4.9767632484436035,explained_var_old:0.991060615,explained_var_new:0.996219099
output spend 0.0001472810035920702 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007433373997628223 time
recovery_state_mcts_prob spend 0.2690428130008513 time
state_batch spend 0.0021389469984569587 time
mcts_probs_batch spend 0.004842823000217322 time
winner_batch spend 0.0002868900046451017 time
policy_value spend 0.21397076799621573 time
train_step spend 0.6326315460028127 time
policy_value spend 0.2172998509995523 time
train_step spend 0.6254172190019744 time
policy_value spend 0.2141771879978478 time
train_step spend 0.6262517060022219 time
policy_value spend 0.2146216019973508 time
train_step spend 0.6293135520027135 time
policy_value spend 0.21740934199624462 time
train_step spend 0.6352086059996509 time
policy_value spend 0.21680695500253933 time
kl:0.01095,lr_multiplier:11.391,loss:4.042464256286621,entropy:4.918938636779785,explained_var_old:0.987639725,explained_var_new:0.988444567
output spend 0.00020513799972832203 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007162663001508918 time
recovery_state_mcts_prob spend 0.27210932099842466 time
state_batch spend 0.0018803910061251372 time
mcts_probs_batch spend 0.006721895995724481 time
winner_batch spend 0.00033448199974372983 time
policy_value spend 0.21711542399862083 time
train_step spend 0.634115157998167 time
policy_value spend 0.21806605900201248 time
train_step spend 0.6346550040034344 time
policy_value spend 0.21649260699632578 time
train_step spend 0.6343865279995953 time
policy_value spend 0.21700576599687338 time
train_step spend 0.6349688019981841 time
policy_value spend 0.21737704900442623 time
train_step spend 0.6352258929982781 time
policy_value spend 0.21701130399742397 time
kl:0.00870,lr_multiplier:11.391,loss:3.9830093383789062,entropy:4.93219518661499,explained_var_old:0.989997387,explained_var_new:0.996206522
output spend 0.00020333299471531063 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008614032005425543 time
recovery_state_mcts_prob spend 0.2668735650004237 time
state_batch spend 0.0021323239998309873 time
mcts_probs_batch spend 0.0057368449997738935 time
winner_batch spend 0.00029680899751838297 time
policy_value spend 0.21672268599650124 time
train_step spend 0.6350397389978752 time
policy_value spend 0.2165225749995443 time
train_step spend 0.6357712880053441 time
policy_value spend 0.2177766699969652 time
train_step spend 0.6350296090022312 time
policy_value spend 0.21785892699699616 time
train_step spend 0.6406635099992855 time
policy_value spend 0.21727018499950645 time
train_step spend 0.6503058940070332 time
policy_value spend 0.23026934499648632 time
kl:0.00873,lr_multiplier:11.391,loss:4.0639824867248535,entropy:4.970929145812988,explained_var_old:0.989877760,explained_var_new:0.995943606
output spend 0.0001664160008658655 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009567783999955282 time
recovery_state_mcts_prob spend 0.27305013399745803 time
state_batch spend 0.001823746002628468 time
mcts_probs_batch spend 0.006095450000429992 time
winner_batch spend 0.0003131379999103956 time
policy_value spend 0.2188798719944316 time
train_step spend 0.6354534639976919 time
policy_value spend 0.21699518200330203 time
train_step spend 0.6342631640000036 time
policy_value spend 0.21686857900203904 time
train_step spend 0.6346408570025233 time
policy_value spend 0.21685215400066227 time
train_step spend 0.6355943669987028 time
policy_value spend 0.21759617900534067 time
train_step spend 0.6361059789996943 time
policy_value spend 0.21639134799625026 time
kl:0.01732,lr_multiplier:11.391,loss:4.005925178527832,entropy:4.908225059509277,explained_var_old:0.988614619,explained_var_new:0.992235839
output spend 0.00014504000137094408 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007034535999991931 time
recovery_state_mcts_prob spend 0.2708342559999437 time
state_batch spend 0.0018616929955896921 time
mcts_probs_batch spend 0.006520043003547471 time
winner_batch spend 0.0003250969966757111 time
policy_value spend 0.2170536020057625 time
train_step spend 0.6367686279991176 time
policy_value spend 0.21684553099476034 time
train_step spend 0.6368109370014281 time
policy_value spend 0.21760027200070908 time
train_step spend 0.6362915499994415 time
policy_value spend 0.2171228719962528 time
train_step spend 0.6364722530051949 time
policy_value spend 0.21740797399979783 time
train_step spend 0.6358349119982449 time
policy_value spend 0.21779820999654476 time
kl:0.00889,lr_multiplier:11.391,loss:4.078660488128662,entropy:4.99912691116333,explained_var_old:0.992160320,explained_var_new:0.993888676
output spend 0.00014737400488229468 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007836826000129804 time
recovery_state_mcts_prob spend 0.27147033200162696 time
state_batch spend 0.002784404998237733 time
mcts_probs_batch spend 0.008171977002348285 time
winner_batch spend 0.00037680199602618814 time
policy_value spend 0.2184675469979993 time
train_step spend 0.6375016040037735 time
policy_value spend 0.2182770889994572 time
train_step spend 0.636027398002625 time
policy_value spend 0.21767900599661516 time
train_step spend 0.6346172579942504 time
policy_value spend 0.21661846900678938 time
train_step spend 0.6361492129944963 time
policy_value spend 0.2174898299999768 time
train_step spend 0.6344145269977162 time
policy_value spend 0.2174733690044377 time
kl:0.00843,lr_multiplier:11.391,loss:4.021646022796631,entropy:4.954390525817871,explained_var_old:0.986384153,explained_var_new:0.988699079
output spend 0.00014609700156142935 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007396111999696586 time
recovery_state_mcts_prob spend 0.2692835640045814 time
state_batch spend 0.001825622995966114 time
mcts_probs_batch spend 0.00576710300083505 time
winner_batch spend 0.00033119600266218185 time
policy_value spend 0.21719728199968813 time
train_step spend 0.6364032439960283 time
policy_value spend 0.21830347100330982 time
train_step spend 0.6357689930009656 time
policy_value spend 0.21685371499916073 time
train_step spend 0.6353653370024404 time
policy_value spend 0.21758540799783077 time
train_step spend 0.6385251020037686 time
policy_value spend 0.21680982999532716 time
train_step spend 0.6354813060024753 time
policy_value spend 0.2176988799983519 time
kl:0.01194,lr_multiplier:11.391,loss:4.030858993530273,entropy:4.960073947906494,explained_var_old:0.994741619,explained_var_new:0.999138951
output spend 0.00014572399959433824 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007511343996156938 time
recovery_state_mcts_prob spend 0.27521852800418856 time
state_batch spend 0.0018087499993271194 time
mcts_probs_batch spend 0.006220374998520128 time
winner_batch spend 0.00043220200313953683 time
policy_value spend 0.21617331900051795 time
train_step spend 0.6361545699983253 time
policy_value spend 0.21682133200374665 time
train_step spend 0.6341421749966685 time
policy_value spend 0.21659907000139356 time
train_step spend 0.6348603510050452 time
policy_value spend 0.21685228099522647 time
train_step spend 0.635629461001372 time
policy_value spend 0.21739129300112836 time
train_step spend 0.635316760999558 time
policy_value spend 0.2178988089945051 time
kl:0.01123,lr_multiplier:11.391,loss:4.029575347900391,entropy:4.922768592834473,explained_var_old:0.980866373,explained_var_new:0.985338390
output spend 0.00016448600217700005 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007056311995256692 time
recovery_state_mcts_prob spend 0.2687658700015163 time
state_batch spend 0.0024191920019802637 time
mcts_probs_batch spend 0.006183990997669753 time
winner_batch spend 0.00028737100365106016 time
policy_value spend 0.21574762799718883 time
train_step spend 0.635359547995904 time
policy_value spend 0.21672145400225418 time
train_step spend 0.6379933220014209 time
policy_value spend 0.2178599969993229 time
train_step spend 0.6340612489948398 time
policy_value spend 0.21656948000600096 time
train_step spend 0.6350735430023633 time
policy_value spend 0.2170551540039014 time
train_step spend 0.6350841159946867 time
policy_value spend 0.21675687300012214 time
kl:0.01171,lr_multiplier:11.391,loss:4.033204555511475,entropy:4.971315860748291,explained_var_old:0.991027296,explained_var_new:0.994879127
output spend 0.00017489700258010998 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007091357998433523 time
recovery_state_mcts_prob spend 0.2716275709972251 time
state_batch spend 0.0019076280004810542 time
mcts_probs_batch spend 0.0062853429990354925 time
winner_batch spend 0.00028495000151451677 time
policy_value spend 0.2176886699962779 time
train_step spend 0.6338663260030444 time
policy_value spend 0.2168765579990577 time
train_step spend 0.6346456259998376 time
policy_value spend 0.21660934599640314 time
train_step spend 0.634512223994534 time
policy_value spend 0.21699236700078472 time
train_step spend 0.612688592998893 time
policy_value spend 0.20527399700222304 time
train_step spend 0.6032060780053143 time
policy_value spend 0.2058631379986764 time
kl:0.00940,lr_multiplier:11.391,loss:4.059289932250977,entropy:4.984234809875488,explained_var_old:0.995784819,explained_var_new:0.999145389
output spend 0.00015228499978547916 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007019203003437724 time
recovery_state_mcts_prob spend 0.2628750919975573 time
state_batch spend 0.0019052919960813597 time
mcts_probs_batch spend 0.004457603004993871 time
winner_batch spend 0.0003179970008204691 time
policy_value spend 0.20518642599927261 time
train_step spend 0.6027760840006522 time
policy_value spend 0.20595401900209254 time
train_step spend 0.602339019998908 time
policy_value spend 0.2060802909982158 time
train_step spend 0.6031339889959781 time
policy_value spend 0.2062943130003987 time
train_step spend 0.6032745630000136 time
policy_value spend 0.20687183999689296 time
train_step spend 0.6036987580009736 time
policy_value spend 0.2059482399999979 time
kl:0.00957,lr_multiplier:11.391,loss:3.9997730255126953,entropy:4.888678550720215,explained_var_old:0.984067619,explained_var_new:0.988253474
output spend 0.00013967999984743074 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007145060000766534 time
recovery_state_mcts_prob spend 0.2694550789965433 time
state_batch spend 0.0018541590034146793 time
mcts_probs_batch spend 0.006325499001832213 time
winner_batch spend 0.00028880500030936673 time
policy_value spend 0.22675533699657535 time
train_step spend 0.6612937669997336 time
policy_value spend 0.23187382300238824 time
train_step spend 0.6508038969986956 time
policy_value spend 0.2182178439979907 time
train_step spend 0.6344152969977586 time
policy_value spend 0.21646743600285845 time
train_step spend 0.634470490993408 time
policy_value spend 0.21658625599957304 time
train_step spend 0.6341642830011551 time
policy_value spend 0.21706269800051814 time
kl:0.01034,lr_multiplier:11.391,loss:3.9946837425231934,entropy:4.880799293518066,explained_var_old:0.990042508,explained_var_new:0.992369592
output spend 0.00015239899948937818 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00704139700246742 time
recovery_state_mcts_prob spend 0.277242470998317 time
state_batch spend 0.00201927000307478 time
mcts_probs_batch spend 0.006299029002548195 time
winner_batch spend 0.0003141449997201562 time
policy_value spend 0.21767366099811625 time
train_step spend 0.6345590300043114 time
policy_value spend 0.21772709200013196 time
train_step spend 0.6343175549991429 time
policy_value spend 0.21711149000475416 time
train_step spend 0.6338981570006581 time
policy_value spend 0.21689380699535832 time
train_step spend 0.6337498799985042 time
policy_value spend 0.217509757996595 time
train_step spend 0.6355279150011484 time
policy_value spend 0.21717581400298513 time
kl:0.00889,lr_multiplier:11.391,loss:4.0213236808776855,entropy:4.958702564239502,explained_var_old:0.993237972,explained_var_new:0.995975971
output spend 0.0001444409936084412 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007178166997618973 time
recovery_state_mcts_prob spend 0.27637864999996964 time
state_batch spend 0.0023464949990739115 time
mcts_probs_batch spend 0.005484776003868319 time
winner_batch spend 0.0002855970014934428 time
policy_value spend 0.2168827599962242 time
train_step spend 0.6356156570036546 time
policy_value spend 0.22468327800015686 time
train_step spend 0.6339100999975926 time
policy_value spend 0.2172646140024881 time
train_step spend 0.6332236050002393 time
policy_value spend 0.2168304189981427 time
train_step spend 0.6344740179993096 time
policy_value spend 0.21677989800082287 time
train_step spend 0.6339041139945039 time
policy_value spend 0.21657041300204583 time
kl:0.02274,lr_multiplier:11.391,loss:4.043866157531738,entropy:4.939812183380127,explained_var_old:0.999015808,explained_var_new:0.999428511
output spend 0.00015496299602091312 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007061424999847077 time
recovery_state_mcts_prob spend 0.27549422700394643 time
state_batch spend 0.0024018999974941835 time
mcts_probs_batch spend 0.006780429001082666 time
winner_batch spend 0.0003604930025176145 time
policy_value spend 0.21678197100118268 time
train_step spend 0.6322848299969337 time
policy_value spend 0.21666741000080947 time
train_step spend 0.6304206839995459 time
policy_value spend 0.215008322003996 time
train_step spend 0.6299872470044647 time
policy_value spend 0.2153694739972707 time
train_step spend 0.6305916839992278 time
policy_value spend 0.2156182449980406 time
train_step spend 0.6297631370034651 time
policy_value spend 0.2152247729973169 time
kl:0.01705,lr_multiplier:11.391,loss:3.9613406658172607,entropy:4.901032447814941,explained_var_old:0.993677557,explained_var_new:0.996661186
output spend 0.00014553200162481517 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008307158001116477 time
recovery_state_mcts_prob spend 0.26903908399981447 time
state_batch spend 0.0018734410041361116 time
mcts_probs_batch spend 0.006423907994758338 time
winner_batch spend 0.0002954010051325895 time
policy_value spend 0.2157435529952636 time
train_step spend 0.629999921999115 time
policy_value spend 0.2161339529993711 time
train_step spend 0.6302754770003958 time
policy_value spend 0.2151187880008365 time
train_step spend 0.6310911109976587 time
policy_value spend 0.21523137600161135 time
train_step spend 0.6302419359999476 time
policy_value spend 0.21515342599741416 time
train_step spend 0.6245083839967265 time
policy_value spend 0.21339171400177293 time
kl:0.01683,lr_multiplier:11.391,loss:4.026652812957764,entropy:4.93722677230835,explained_var_old:0.986727476,explained_var_new:0.991444767
output spend 0.00015506099589401856 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008461404999252409 time
recovery_state_mcts_prob spend 0.2694637390013668 time
state_batch spend 0.002024118002736941 time
mcts_probs_batch spend 0.006746212995494716 time
winner_batch spend 0.00029058200016152114 time
policy_value spend 0.21311214900197228 time
train_step spend 0.6241515200017602 time
policy_value spend 0.21454069000174059 time
train_step spend 0.623313263997261 time
policy_value spend 0.21281261200056178 time
train_step spend 0.6236391220008954 time
policy_value spend 0.21335264400113374 time
train_step spend 0.6243456459997105 time
policy_value spend 0.2128824480023468 time
train_step spend 0.6238751229975605 time
policy_value spend 0.21312229700561147 time
kl:0.00987,lr_multiplier:11.391,loss:3.9961111545562744,entropy:4.886610507965088,explained_var_old:0.995267451,explained_var_new:0.995770395
output spend 0.00015542499750154093 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007008860004134476 time
recovery_state_mcts_prob spend 0.2633138050005073 time
state_batch spend 0.002151973996660672 time
mcts_probs_batch spend 0.0060052379994886 time
winner_batch spend 0.0003244340041419491 time
policy_value spend 0.21364539000205696 time
train_step spend 0.6255234100026428 time
policy_value spend 0.21716224899864756 time
train_step spend 0.636288316003629 time
policy_value spend 0.21608864500012714 time
train_step spend 0.6323226029999205 time
policy_value spend 0.21606857900042087 time
train_step spend 0.6326054949968238 time
policy_value spend 0.21623081200232264 time
train_step spend 0.6324241170004825 time
policy_value spend 0.21655060299963225 time
kl:0.02876,lr_multiplier:11.391,loss:4.030259609222412,entropy:4.941622734069824,explained_var_old:0.985363483,explained_var_new:0.989325225
output spend 0.00015341799735324457 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.011288385998341255 time
recovery_state_mcts_prob spend 0.2763814290010487 time
state_batch spend 0.001867029997811187 time
mcts_probs_batch spend 0.006287237003562041 time
winner_batch spend 0.0003023530007340014 time
policy_value spend 0.2164511709997896 time
train_step spend 0.6316353649963276 time
policy_value spend 0.21713034700223943 time
train_step spend 0.6322503740011598 time
policy_value spend 0.2161610670009395 time
train_step spend 0.6324764539967873 time
policy_value spend 0.21599047099880408 time
train_step spend 0.6323287719933433 time
policy_value spend 0.21603683099965565 time
train_step spend 0.6324171960004605 time
policy_value spend 0.2160426499976893 time
kl:0.03099,lr_multiplier:11.391,loss:4.078365325927734,entropy:4.980978965759277,explained_var_old:0.997022569,explained_var_new:0.998827875
output spend 0.0001498300043749623 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007170247998146806 time
recovery_state_mcts_prob spend 0.26760690100491047 time
state_batch spend 0.0018271890003234148 time
mcts_probs_batch spend 0.006138983997516334 time
winner_batch spend 0.0002816039996105246 time
policy_value spend 0.21650100700207986 time
train_step spend 0.6316057620060747 time
policy_value spend 0.21818920099758543 time
train_step spend 0.6322237700005644 time
policy_value spend 0.21647500000108266 time
train_step spend 0.6326874810038134 time
policy_value spend 0.2164986899952055 time
train_step spend 0.6323751710006036 time
policy_value spend 0.2164596509974217 time
train_step spend 0.6324593919998733 time
policy_value spend 0.21661053300340427 time
kl:0.00730,lr_multiplier:11.391,loss:4.03165340423584,entropy:4.972770690917969,explained_var_old:0.996407509,explained_var_new:0.999334574
output spend 0.0002849160009645857 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007575611001811922 time
recovery_state_mcts_prob spend 0.2939440179980011 time
state_batch spend 0.0020249410008545965 time
mcts_probs_batch spend 0.007118957997590769 time
winner_batch spend 0.00034521500492701307 time
policy_value spend 0.22870557900023414 time
train_step spend 0.6516442069987534 time
policy_value spend 0.21634505200199783 time
train_step spend 0.6306128119977075 time
policy_value spend 0.2161267150004278 time
train_step spend 0.6303551829987555 time
policy_value spend 0.21564104100252734 time
train_step spend 0.630231842995272 time
policy_value spend 0.21551241100678453 time
train_step spend 0.6309485910023795 time
policy_value spend 0.21516872399661224 time
kl:0.00777,lr_multiplier:11.391,loss:4.0408735275268555,entropy:4.964484214782715,explained_var_old:0.993337870,explained_var_new:0.995874643
output spend 0.00015241900109685957 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.009679233997303527 time
recovery_state_mcts_prob spend 0.2802999030027422 time
state_batch spend 0.002021034000790678 time
mcts_probs_batch spend 0.006370723000145517 time
winner_batch spend 0.00028671399923041463 time
policy_value spend 0.21510307699645637 time
train_step spend 0.6290341679996345 time
policy_value spend 0.2163602410000749 time
train_step spend 0.6298575149994576 time
policy_value spend 0.21487963399704313 time
train_step spend 0.6385594099992886 time
policy_value spend 0.21491027400043095 time
train_step spend 0.6275319979977212 time
policy_value spend 0.21262759000092046 time
train_step spend 0.6236794779979391 time
policy_value spend 0.21300096900085919 time
kl:0.01852,lr_multiplier:11.391,loss:4.025924205780029,entropy:4.96051025390625,explained_var_old:0.993095934,explained_var_new:0.993698359
output spend 0.00016315699758706614 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007838136996724643 time
recovery_state_mcts_prob spend 0.26357957199797966 time
state_batch spend 0.001929138001287356 time
mcts_probs_batch spend 0.013227904004452284 time
winner_batch spend 0.00029223199817351997 time
policy_value spend 0.21647531900089234 time
train_step spend 0.6244565230008448 time
policy_value spend 0.21240009000030113 time
train_step spend 0.6227520549946348 time
policy_value spend 0.21492669000144815 time
train_step spend 0.6238309390028007 time
policy_value spend 0.2124288959967089 time
train_step spend 0.6217967650009086 time
policy_value spend 0.21240311300061876 time
train_step spend 0.6224311830010265 time
policy_value spend 0.21361441999761155 time
kl:0.01272,lr_multiplier:11.391,loss:4.047722339630127,entropy:4.931094169616699,explained_var_old:0.992442071,explained_var_new:0.995934844
output spend 0.00018522300524637103 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007113934996596072 time
recovery_state_mcts_prob spend 0.2622219960030634 time
state_batch spend 0.0017923600025824271 time
mcts_probs_batch spend 0.008511358995747287 time
winner_batch spend 0.0002899489991250448 time
policy_value spend 0.21549868000147399 time
train_step spend 0.6313037830041139 time
policy_value spend 0.21589698900061194 time
train_step spend 0.6314445000025444 time
policy_value spend 0.21564311599649955 time
train_step spend 0.6318460490001598 time
policy_value spend 0.2158310500017251 time
train_step spend 0.6310590579960262 time
policy_value spend 0.21613811299903318 time
train_step spend 0.6323152080003638 time
policy_value spend 0.21682115399744362 time
kl:0.01037,lr_multiplier:11.391,loss:4.058433532714844,entropy:4.934905052185059,explained_var_old:0.987072408,explained_var_new:0.992591023
output spend 0.00019770499784499407 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007655845001863781 time
recovery_state_mcts_prob spend 0.2791425969990087 time
state_batch spend 0.0019593719989643432 time
mcts_probs_batch spend 0.0071284680016105995 time
winner_batch spend 0.0002997880001203157 time
policy_value spend 0.21784586399735417 time
train_step spend 0.6340688049967866 time
policy_value spend 0.21777610100252787 time
train_step spend 0.633250411003246 time
policy_value spend 0.21662159499828704 time
train_step spend 0.631673691998003 time
policy_value spend 0.21579602800193243 time
train_step spend 0.6322188539998024 time
policy_value spend 0.21681327199621592 time
train_step spend 0.6335085979953874 time
policy_value spend 0.21788954499788815 time
kl:0.00839,lr_multiplier:11.391,loss:3.97957181930542,entropy:4.9077043533325195,explained_var_old:0.986855268,explained_var_new:0.992575109
output spend 0.0003368199977558106 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007369222003035247 time
recovery_state_mcts_prob spend 0.2701033080011257 time
state_batch spend 0.0018218650002381764 time
mcts_probs_batch spend 0.00888134200067725 time
winner_batch spend 0.0003405859970371239 time
policy_value spend 0.21877669599780347 time
train_step spend 0.635036253996077 time
policy_value spend 0.2168029820022639 time
train_step spend 0.6326387070002966 time
policy_value spend 0.21767322599771433 time
train_step spend 0.6325842419973924 time
policy_value spend 0.21700038899871288 time
train_step spend 0.6334723350009881 time
policy_value spend 0.2164110689991503 time
train_step spend 0.6336385460017482 time
policy_value spend 0.21647449099691585 time
kl:0.03457,lr_multiplier:11.391,loss:4.034022808074951,entropy:4.95144510269165,explained_var_old:0.988604009,explained_var_new:0.993827403
output spend 0.00014757800090592355 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008078038001258392 time
recovery_state_mcts_prob spend 0.2727350880013546 time
state_batch spend 0.0020295529975555837 time
mcts_probs_batch spend 0.006117242999607697 time
winner_batch spend 0.0002837960055330768 time
policy_value spend 0.21668746099749114 time
train_step spend 0.6344197360012913 time
policy_value spend 0.21475081700191367 time
train_step spend 0.6306837180018192 time
policy_value spend 0.2153940420030267 time
train_step spend 0.6292257239983883 time
policy_value spend 0.21458077800343744 time
train_step spend 0.6293320549957571 time
policy_value spend 0.21532338800170692 time
train_step spend 0.6294335779966787 time
policy_value spend 0.21467064799799118 time
kl:0.01457,lr_multiplier:11.391,loss:4.022006988525391,entropy:4.919674873352051,explained_var_old:0.974422991,explained_var_new:0.994320393
output spend 0.00015427300240844488 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007254172000102699 time
recovery_state_mcts_prob spend 0.2736437920029857 time
state_batch spend 0.002053099997283425 time
mcts_probs_batch spend 0.006099347003328148 time
winner_batch spend 0.00032583699794486165 time
policy_value spend 0.21554547599953366 time
train_step spend 0.6289366300043184 time
policy_value spend 0.21719352500076639 time
train_step spend 0.6291817509991233 time
policy_value spend 0.21527958499791566 time
train_step spend 0.6297606770021957 time
policy_value spend 0.21529969499533763 time
train_step spend 0.6280550980009139 time
policy_value spend 0.21285821399942506 time
train_step spend 0.6268796299991664 time
policy_value spend 0.21324296000238974 time
kl:0.01270,lr_multiplier:11.391,loss:4.031345367431641,entropy:4.960076332092285,explained_var_old:0.998936415,explained_var_new:0.999458015
output spend 0.0001881400021375157 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008255110995378345 time
recovery_state_mcts_prob spend 0.2690085659996839 time
state_batch spend 0.0018473900054232217 time
mcts_probs_batch spend 0.006290792000072543 time
winner_batch spend 0.00029953799821669236 time
policy_value spend 0.2131046439972124 time
train_step spend 0.6227643989986973 time
policy_value spend 0.21277764099795604 time
train_step spend 0.6228339980007149 time
policy_value spend 0.21239786200021626 time
train_step spend 0.6384039059994393 time
policy_value spend 0.2244150010010344 time
train_step spend 0.6513708710044739 time
policy_value spend 0.21420309499808354 time
train_step spend 0.6259857699988061 time
policy_value spend 0.21313863999966998 time
kl:0.01714,lr_multiplier:11.391,loss:3.9964051246643066,entropy:4.921258449554443,explained_var_old:0.991771758,explained_var_new:0.997039258
output spend 0.00014634600665885955 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070473689993377775 time
recovery_state_mcts_prob spend 0.2643798139979481 time
state_batch spend 0.002124814003764186 time
mcts_probs_batch spend 0.004347960995801259 time
winner_batch spend 0.0002853250043699518 time
policy_value spend 0.21273360600025626 time
train_step spend 0.6262825380035792 time
policy_value spend 0.2158042739974917 time
train_step spend 0.6310035409987904 time
policy_value spend 0.21550040500005707 time
train_step spend 0.6311936359998072 time
policy_value spend 0.21535967399540823 time
train_step spend 0.6321454969947808 time
policy_value spend 0.21677353200357175 time
train_step spend 0.6319844629979343 time
policy_value spend 0.2160796790049062 time
kl:0.01638,lr_multiplier:11.391,loss:4.007203578948975,entropy:4.971388816833496,explained_var_old:0.992830515,explained_var_new:0.995993137
output spend 0.0001555720009491779 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007069857994792983 time
recovery_state_mcts_prob spend 0.2715597720016376 time
state_batch spend 0.001768991001881659 time
mcts_probs_batch spend 0.004443147998244967 time
winner_batch spend 0.00028674500208580866 time
policy_value spend 0.21532760900299763 time
train_step spend 0.631890824995935 time
policy_value spend 0.2161347220026073 time
train_step spend 0.631781805997889 time
policy_value spend 0.21593896100239363 time
train_step spend 0.6315189020024263 time
policy_value spend 0.21528063499863492 time
train_step spend 0.6323731390002649 time
policy_value spend 0.21697934700205224 time
train_step spend 0.6340875240057358 time
policy_value spend 0.2166678259964101 time
kl:0.00973,lr_multiplier:11.391,loss:3.9717113971710205,entropy:4.883368015289307,explained_var_old:0.993904829,explained_var_new:0.995703340
output spend 0.0001943339957506396 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007523865999246482 time
recovery_state_mcts_prob spend 0.26747123500535963 time
state_batch spend 0.002085137995891273 time
mcts_probs_batch spend 0.0065194530034204945 time
winner_batch spend 0.00028496600134531036 time
policy_value spend 0.21703403299761703 time
train_step spend 0.6333718659952865 time
policy_value spend 0.21554684000147972 time
train_step spend 0.6323970519952127 time
policy_value spend 0.21613549000176135 time
train_step spend 0.633431775997451 time
policy_value spend 0.2164860300035798 time
train_step spend 0.6334782159974566 time
policy_value spend 0.21619612500217045 time
train_step spend 0.6332226540034753 time
policy_value spend 0.21610068999871146 time
kl:0.01649,lr_multiplier:11.391,loss:3.975193738937378,entropy:4.881279945373535,explained_var_old:0.984399617,explained_var_new:0.988403201
output spend 0.00014470999303739518 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007434511004248634 time
recovery_state_mcts_prob spend 0.2686888579992228 time
state_batch spend 0.001749392002238892 time
mcts_probs_batch spend 0.004631530995538924 time
winner_batch spend 0.000318307000270579 time
policy_value spend 0.2156010890030302 time
train_step spend 0.6332667020033114 time
policy_value spend 0.21419480699842097 time
train_step spend 0.6301653580012498 time
policy_value spend 0.21517639800003963 time
train_step spend 0.6296402880034293 time
policy_value spend 0.21535636499902466 time
train_step spend 0.6300054690000252 time
policy_value spend 0.21498141299525741 time
train_step spend 0.6313454929986619 time
policy_value spend 0.21581400600553025 time
kl:0.00986,lr_multiplier:11.391,loss:3.9634530544281006,entropy:4.884230136871338,explained_var_old:0.984083891,explained_var_new:0.988708556
output spend 0.00015542199980700389 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006613589001062792 time
recovery_state_mcts_prob spend 0.27475167899683584 time
state_batch spend 0.0019016049991478212 time
mcts_probs_batch spend 0.004880098000285216 time
winner_batch spend 0.00030085100297583267 time
policy_value spend 0.21481537199724698 time
train_step spend 0.6293872829992324 time
policy_value spend 0.21490131900645792 time
train_step spend 0.6294996279975749 time
policy_value spend 0.21456649500032654 time
train_step spend 0.6291618179966463 time
policy_value spend 0.21580080399871804 time
train_step spend 0.6299167709948961 time
policy_value spend 0.2133932700016885 time
train_step spend 0.62386345500272 time
policy_value spend 0.21262171400303487 time
kl:0.01461,lr_multiplier:11.391,loss:4.0535383224487305,entropy:4.949049949645996,explained_var_old:0.998045266,explained_var_new:0.999382079
output spend 0.00015019100101199 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070600260005448945 time
recovery_state_mcts_prob spend 0.2734445259993663 time
state_batch spend 0.001890630999696441 time
mcts_probs_batch spend 0.004774884000653401 time
winner_batch spend 0.0003128099997411482 time
policy_value spend 0.21312629399471916 time
train_step spend 0.624088288997882 time
policy_value spend 0.21302375700179255 time
train_step spend 0.6229295299999649 time
policy_value spend 0.21259290199668612 time
train_step spend 0.6236797569945338 time
policy_value spend 0.21294115300406702 time
train_step spend 0.6234562750032637 time
policy_value spend 0.2123628679983085 time
train_step spend 0.6233194130036281 time
policy_value spend 0.21303801899921382 time
kl:0.01179,lr_multiplier:11.391,loss:4.106123924255371,entropy:4.98883056640625,explained_var_old:0.987024307,explained_var_new:0.988483548
output spend 0.00022553800226887688 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008110527996905148 time
recovery_state_mcts_prob spend 0.26477504200011026 time
state_batch spend 0.001820892000978347 time
mcts_probs_batch spend 0.006885062000947073 time
winner_batch spend 0.0002995789982378483 time
policy_value spend 0.21337407800456276 time
train_step spend 0.6244370749991504 time
policy_value spend 0.2155220900021959 time
train_step spend 0.6304783529994893 time
policy_value spend 0.21574733500165166 time
train_step spend 0.6311236379988259 time
policy_value spend 0.2161577649967512 time
train_step spend 0.630202977998124 time
policy_value spend 0.2163474760018289 time
train_step spend 0.6310926010046387 time
policy_value spend 0.21585175400105072 time
kl:0.01100,lr_multiplier:11.391,loss:4.010470867156982,entropy:4.9119157791137695,explained_var_old:0.979225159,explained_var_new:0.984111309
output spend 0.0001461930005461909 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008519986004102975 time
recovery_state_mcts_prob spend 0.2690618139968137 time
state_batch spend 0.0018363490016781725 time
mcts_probs_batch spend 0.006855608000478242 time
winner_batch spend 0.00028856199787696823 time
policy_value spend 0.21548867800447624 time
train_step spend 0.6309866629962926 time
policy_value spend 0.21700677800254198 time
train_step spend 0.6307296509985463 time
policy_value spend 0.21568456599925412 time
train_step spend 0.6310611180015258 time
policy_value spend 0.21564840499922866 time
train_step spend 0.6323519149955246 time
policy_value spend 0.21550346000003628 time
train_step spend 0.6362613870005589 time
policy_value spend 0.21710254199570045 time
kl:0.00966,lr_multiplier:11.391,loss:4.041991710662842,entropy:4.924403667449951,explained_var_old:0.996415436,explained_var_new:0.999269009
output spend 0.00014510199980577454 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0070992369946907274 time
recovery_state_mcts_prob spend 0.3056637720001163 time
state_batch spend 0.0020254810006008483 time
mcts_probs_batch spend 0.006774562003556639 time
winner_batch spend 0.00031231899629347026 time
policy_value spend 0.21831969100458082 time
train_step spend 0.6683803680061828 time
policy_value spend 0.22805863599933218 time
train_step spend 0.6365216100020916 time
policy_value spend 0.21744225599832134 time
train_step spend 0.6330288949975511 time
policy_value spend 0.2159886080044089 time
train_step spend 0.6324105370003963 time
policy_value spend 0.21676071100228 time
train_step spend 0.6326489909988595 time
policy_value spend 0.21721782800159417 time
kl:0.01778,lr_multiplier:11.391,loss:4.039168834686279,entropy:4.886533737182617,explained_var_old:0.995745659,explained_var_new:0.998743296
output spend 0.0001512989983893931 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008187323997844942 time
recovery_state_mcts_prob spend 0.28299419300310547 time
state_batch spend 0.0017441550007788464 time
mcts_probs_batch spend 0.006383143998391461 time
winner_batch spend 0.00027890999626833946 time
policy_value spend 0.2166301410034066 time
train_step spend 0.6329416640001 time
policy_value spend 0.2151128580007935 time
train_step spend 0.629213621999952 time
policy_value spend 0.2161632319985074 time
train_step spend 0.6339205149997724 time
policy_value spend 0.2157867889982299 time
train_step spend 0.6306802569961292 time
policy_value spend 0.21559567499934928 time
train_step spend 0.630098278998048 time
policy_value spend 0.2156106490001548 time
kl:0.01080,lr_multiplier:11.391,loss:4.012946128845215,entropy:4.930440902709961,explained_var_old:0.996876895,explained_var_new:0.999524355
output spend 0.00014719900354975834 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.0072145379963330925 time
recovery_state_mcts_prob spend 0.2666786170011619 time
state_batch spend 0.0017513569982838817 time
mcts_probs_batch spend 0.006280181005422492 time
winner_batch spend 0.0003008399944519624 time
policy_value spend 0.21632621800381457 time
train_step spend 0.6295171350066084 time
policy_value spend 0.2159791129961377 time
train_step spend 0.6304146109978319 time
policy_value spend 0.21517249300086405 time
train_step spend 0.6308793720018002 time
policy_value spend 0.21574761500232853 time
train_step spend 0.6299732990009943 time
policy_value spend 0.213511206995463 time
train_step spend 0.6240021220000926 time
policy_value spend 0.21324074800213566 time
kl:0.01500,lr_multiplier:11.391,loss:3.964040756225586,entropy:4.920687198638916,explained_var_old:0.999355435,explained_var_new:0.999562144
output spend 0.00014126500173006207 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007088792997819837 time
recovery_state_mcts_prob spend 0.27247960900422186 time
state_batch spend 0.0019772129962802865 time
mcts_probs_batch spend 0.006139176002761815 time
winner_batch spend 0.0002879509993363172 time
policy_value spend 0.21333752800273942 time
train_step spend 0.6229562730004545 time
policy_value spend 0.2162247189990012 time
train_step spend 0.6234745970068616 time
policy_value spend 0.21309651699993992 time
train_step spend 0.6231575339988922 time
policy_value spend 0.21366740600205958 time
train_step spend 0.6246935540038976 time
policy_value spend 0.2130421789988759 time
train_step spend 0.6240904290025355 time
policy_value spend 0.2141265129976091 time
kl:0.01039,lr_multiplier:11.391,loss:4.059165954589844,entropy:4.929923057556152,explained_var_old:0.995755255,explained_var_new:0.995930672
output spend 0.00014376499893842265 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.008224384997447487 time
recovery_state_mcts_prob spend 0.26367061599739827 time
state_batch spend 0.001975720006157644 time
mcts_probs_batch spend 0.006116544995165896 time
winner_batch spend 0.0002772189982351847 time
policy_value spend 0.21344005900027696 time
train_step spend 0.6233264670008793 time
policy_value spend 0.21489231500163442 time
train_step spend 0.6318104849997326 time
policy_value spend 0.2155780590037466 time
train_step spend 0.6313309869947261 time
policy_value spend 0.2153533710006741 time
train_step spend 0.6307789600032265 time
policy_value spend 0.21582732499518897 time
train_step spend 0.631586043004063 time
policy_value spend 0.21535209399735322 time
kl:0.01046,lr_multiplier:11.391,loss:3.9852731227874756,entropy:4.896137237548828,explained_var_old:0.995892644,explained_var_new:0.996087551
output spend 0.00016861799667822197 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007192315999418497 time
recovery_state_mcts_prob spend 0.268740205996437 time
state_batch spend 0.0017551830023876391 time
mcts_probs_batch spend 0.004562666996207554 time
winner_batch spend 0.00044291700032772496 time
policy_value spend 0.21501987400552025 time
train_step spend 0.6318156960041961 time
policy_value spend 0.2151672849940951 time
train_step spend 0.6313654120021965 time
policy_value spend 0.21575877299619606 time
train_step spend 0.6304900629984331 time
policy_value spend 0.21647128500626422 time
train_step spend 0.6311780700052623 time
policy_value spend 0.2153840839964687 time
train_step spend 0.6338494819938205 time
policy_value spend 0.21610140100528952 time
kl:0.02462,lr_multiplier:11.391,loss:3.9086711406707764,entropy:4.846302032470703,explained_var_old:0.994869053,explained_var_new:0.995938122
output spend 0.00019943000370403752 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007549630994617473 time
recovery_state_mcts_prob spend 0.27046181700279703 time
state_batch spend 0.0018087930002366193 time
mcts_probs_batch spend 0.004081503000634257 time
winner_batch spend 0.0002883100023609586 time
policy_value spend 0.21530005199747393 time
train_step spend 0.6317177540040575 time
policy_value spend 0.2159652880000067 time
train_step spend 0.6326227440004004 time
policy_value spend 0.21672784100519493 time
train_step spend 0.6325802099963767 time
policy_value spend 0.21615370100334985 time
train_step spend 0.6322863489986048 time
policy_value spend 0.21617038200201932 time
train_step spend 0.6317711980009335 time
policy_value spend 0.21620001599512761 time
kl:0.00952,lr_multiplier:11.391,loss:4.011963844299316,entropy:4.923569679260254,explained_var_old:0.997205496,explained_var_new:0.999156952
output spend 0.00014663599722553045 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.007253345997014549 time
recovery_state_mcts_prob spend 0.28269501300383126 time
state_batch spend 0.0021255819956422783 time
mcts_probs_batch spend 0.00466150400461629 time
winner_batch spend 0.0002902790001826361 time
policy_value spend 0.2156397449944052 time
train_step spend 0.6328390230046352 time
policy_value spend 0.21540735199960181 time
train_step spend 0.6315059429980465 time
policy_value spend 0.21492433099774644 time
train_step spend 0.6301304080043337 time
policy_value spend 0.21525171399844112 time
train_step spend 0.6307130190034513 time
policy_value spend 0.21519758199428907 time
train_step spend 0.6293883300022571 time
policy_value spend 0.2154578859990579 time
kl:0.03731,lr_multiplier:11.391,loss:3.999126672744751,entropy:4.932767868041992,explained_var_old:0.982210994,explained_var_new:0.991412580
output spend 0.0001437559985788539 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.00794002300244756 time
recovery_state_mcts_prob spend 0.2670625949976966 time
state_batch spend 0.0017395280010532588 time
mcts_probs_batch spend 0.004554833001748193 time
winner_batch spend 0.0002910879993578419 time
policy_value spend 0.2144166910002241 time
train_step spend 0.6301367109990679 time
policy_value spend 0.21550232900335686 time
train_step spend 0.6303275270038284 time
policy_value spend 0.21471324999583885 time
train_step spend 0.6302513199989335 time
policy_value spend 0.21556102600152371 time
train_step spend 0.6292890010008705 time
policy_value spend 0.21517305399902398 time
train_step spend 0.6389800619945163 time
policy_value spend 0.2259389450046001 time
kl:0.01505,lr_multiplier:11.391,loss:3.9450743198394775,entropy:4.854516506195068,explained_var_old:0.982253909,explained_var_new:0.989041507
output spend 0.00015121699834708124 time
已保存最新模型
load data begin
已加载数据
step i 372: 
random.sample spend 0.006952946001547389 time
recovery_state_mcts_prob spend 0.264702127999044 time
state_batch spend 0.0018446510002831928 time
mcts_probs_batch spend 0.004395294999994803 time
winner_batch spend 0.00037506400258280337 time
policy_value spend 0.21314050399814732 time
train_step spend 0.622440690996882 time
policy_value spend 0.21297687300102552 time
train_step spend 0.6224298060042202 time
policy_value spend 0.21268995599530172 time
train_step spend 0.6231342760002008 time
policy_value spend 0.21321405599883292 time
train_step spend 0.6226029500030563 time
policy_value spend 0.21298382399982074 time
train_step spend 0.6218424549952033 time
policy_value spend 0.21286216899898136 time
kl:0.01072,lr_multiplier:11.391,loss:3.9729740619659424,entropy:4.913547039031982,explained_var_old:0.989323735,explained_var_new:0.991767406
output spend 0.00014449599984800443 time
已保存最新模型
current self-play batch: 1000
